Ë≠¶Âëä: Êú™Ê£ÄÊµãÂà∞ HF_TOKEN Êàñ HUGGING_FACE_HUB_TOKEN ÁéØÂ¢ÉÂèòÈáè
Â¶ÇÊûúÈÅáÂà∞ gated repo ÈîôËØØÔºåËØ∑ËÆæÁΩÆ: export HF_TOKEN=your_token
==========================================
üöÄ Starting SimLingo Full Training on Cluster
==========================================
Job ID: 21029531
Node: skl-a-25
GPUs: 1
Working Directory: /home/mh2803/projects/simlingo
Dataset Path: /shared/rc/llm-gen-agent/mhu/simlingo_dataset/database/simlingo_extracted
Bucket Path: /shared/rc/llm-gen-agent/mhu/simlingo_dataset/database/bucketsv2_simlingo
Training Args: experiment=cluster_training_full

Note: This is the full SimLingo model with language capabilities
Using simlingo_training (not simlingo_base_training)
==========================================
[2026-01-25 02:18:15,218] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2026-01-25 02:18:48,261][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - vision_select_layer: -1
[2026-01-25 02:18:48,261][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - ps_version: v2
[2026-01-25 02:18:48,261][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - min_dynamic_patch: 1
[2026-01-25 02:18:48,261][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - max_dynamic_patch: 12
[2026-01-25 02:18:49,892][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - vision_select_layer: -1
[2026-01-25 02:18:49,892][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - ps_version: v2
[2026-01-25 02:18:49,892][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - min_dynamic_patch: 1
[2026-01-25 02:18:49,892][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - max_dynamic_patch: 12
[2026-01-25 02:18:50,572][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - vision_select_layer: -1
[2026-01-25 02:18:50,573][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - ps_version: v2
[2026-01-25 02:18:50,573][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - min_dynamic_patch: 1
[2026-01-25 02:18:50,573][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - max_dynamic_patch: 12
FlashAttention2 is not installed.
[2026-01-25 02:19:02,024][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.modeling_internvl_chat][INFO] - num_image_token: 256
[2026-01-25 02:19:05,940][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.modeling_internvl_chat][INFO] - ps_version: v2
[91mUsing OpenGVLab/InternVL2-1B as the image encoder.[0m
[2026-01-25 02:19:09,274][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - vision_select_layer: -1
[2026-01-25 02:19:09,274][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - ps_version: v2
[2026-01-25 02:19:09,274][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - min_dynamic_patch: 1
[2026-01-25 02:19:09,274][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - max_dynamic_patch: 12
[2026-01-25 02:19:09,354][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.modeling_internvl_chat][INFO] - num_image_token: 256
[2026-01-25 02:19:09,354][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.modeling_internvl_chat][INFO] - ps_version: v2
Using PEFT model
trainable params: 17,596,416 || all params: 647,260,288 || trainable%: 2.7186
model:
  vision_model:
    variant: OpenGVLab/InternVL2-1B
    embed_dim: 512
    freeze: false
    _target_: simlingo_training.models.encoder.vlm.VLMEncoderModel
  language_model:
    variant: OpenGVLab/InternVL2-1B
    lora: true
    lora_alpha: 64
    lora_r: 32
    lora_dropout: 0.1
    _target_: simlingo_training.models.language_model.llm.LLM
  lr: 3.0e-05
  weight_decay: 0.1
  betas:
  - 0.9
  - 0.999
  pct_start: 0.05
  speed_wps_mode: 2d
  predict_route_as_wps: true
  _target_: simlingo_training.models.driving.DrivingModel
data_module:
  base_dataset:
    data_path: /shared/rc/llm-gen-agent/mhu/simlingo_dataset/database/simlingo_extracted
    bucket_path: /shared/rc/llm-gen-agent/mhu/simlingo_dataset/database/bucketsv2_simlingo
    cut_bottom_quarter: true
    use_1d_wps: false
    use_commentary: false
    use_qa: false
    qa_augmentation: false
    commentary_augmentation: true
    use_old_towns: true
    use_only_old_towns: false
    use_town13: true
    skip_first_n_frames: 10
    pred_len: 11
    hist_len: 1
    hist_len_commentary: 5
    img_augmentation: true
    img_augmentation_prob: 0.5
    img_shift_augmentation: true
    img_shift_augmentation_prob: 0.5
    use_safety_flag: true
    num_route_points: 20
    route_as: target_point_command
    use_lmdrive_commands: true
  driving_dataset:
    _target_: simlingo_training.dataloader.dataset_driving.Data_Driving
  dreamer_dataset: null
  qa_dataset:
    _target_: simlingo_training.dataloader.dataset_eval_qa_comm.Data_Eval
  insteval_dataset:
    _target_: simlingo_training.dataloader.dataset_eval_dreamer.Eval_Dreamer
  batch_size: 4
  num_workers: 8
  train_partitions: null
  train_partitions_dreamer: null
  use_global_img: false
  _target_: simlingo_training.dataloader.datamodule.DataModule
seed: 42
gpus: 1
resume: false
resume_path: null
debug: false
overfit: 0
fp16_loss_scale: 32.0
enable_wandb: true
wandb_project: simlingo
name: cluster_training_full
wandb_name: 2026_01_25_02_18_46_cluster_training_full
max_epochs: 15
precision: 16-mixed
strategy: deepspeed_stage_2
val_every_n_epochs: 2
checkpoint: null

Number of GPUS: 1
[Bucket: all] Scanning routes in /shared/rc/llm-gen-agent/mhu/simlingo_dataset/database/simlingo_extracted...
Found 9109 routes in /shared/rc/llm-gen-agent/mhu/simlingo_dataset/database/simlingo_extracted
Use 9017 routes.
  0%|          | 0/9017 [00:00<?, ?it/s]  0%|          | 5/9017 [00:00<03:10, 47.32it/s]  0%|          | 10/9017 [00:00<03:08, 47.79it/s]  0%|          | 15/9017 [00:00<03:16, 45.72it/s]  0%|          | 20/9017 [00:00<03:22, 44.40it/s]  0%|          | 26/9017 [00:00<03:10, 47.20it/s]  0%|          | 31/9017 [00:00<03:20, 44.91it/s]  0%|          | 36/9017 [00:00<03:24, 43.90it/s]  0%|          | 41/9017 [00:00<03:25, 43.65it/s]  1%|          | 46/9017 [00:01<03:18, 45.30it/s]  1%|          | 53/9017 [00:01<02:56, 50.92it/s]  1%|          | 59/9017 [00:01<03:08, 47.43it/s]  1%|          | 64/9017 [00:01<03:14, 46.05it/s]  1%|          | 70/9017 [00:01<03:02, 49.04it/s]  1%|          | 76/9017 [00:01<03:04, 48.36it/s]  1%|          | 82/9017 [00:01<02:54, 51.33it/s]  1%|          | 88/9017 [00:01<03:03, 48.67it/s]  1%|          | 93/9017 [00:01<03:03, 48.69it/s]  1%|          | 99/9017 [00:02<03:01, 49.04it/s]  1%|          | 104/9017 [00:02<03:02, 48.76it/s]  1%|          | 110/9017 [00:02<02:58, 50.00it/s]  1%|‚ñè         | 116/9017 [00:02<02:57, 50.01it/s]  1%|‚ñè         | 122/9017 [00:02<02:58, 49.93it/s]  1%|‚ñè         | 129/9017 [00:02<02:42, 54.81it/s]  1%|‚ñè         | 135/9017 [00:02<02:46, 53.39it/s]  2%|‚ñè         | 141/9017 [00:02<02:52, 51.40it/s]  2%|‚ñè         | 147/9017 [00:03<03:00, 49.12it/s]  2%|‚ñè         | 152/9017 [00:03<03:01, 48.92it/s]  2%|‚ñè         | 157/9017 [00:03<03:01, 48.83it/s]  2%|‚ñè         | 162/9017 [00:03<03:08, 47.06it/s]  2%|‚ñè         | 167/9017 [00:03<03:07, 47.08it/s]  2%|‚ñè         | 172/9017 [00:03<03:10, 46.37it/s]  2%|‚ñè         | 177/9017 [00:03<03:11, 46.12it/s]  2%|‚ñè         | 182/9017 [00:04<05:58, 24.62it/s]  2%|‚ñè         | 187/9017 [00:04<05:13, 28.16it/s]  2%|‚ñè         | 192/9017 [00:04<04:36, 31.87it/s]  2%|‚ñè         | 199/9017 [00:04<03:46, 39.01it/s]  2%|‚ñè         | 205/9017 [00:04<03:23, 43.40it/s]  2%|‚ñè         | 211/9017 [00:04<03:13, 45.42it/s]  2%|‚ñè         | 217/9017 [00:04<03:15, 44.94it/s]  2%|‚ñè         | 223/9017 [00:04<03:05, 47.35it/s]  3%|‚ñé         | 229/9017 [00:05<02:54, 50.29it/s]  3%|‚ñé         | 235/9017 [00:05<02:57, 49.61it/s]  3%|‚ñé         | 241/9017 [00:05<03:02, 48.02it/s]  3%|‚ñé         | 247/9017 [00:05<02:54, 50.22it/s]  3%|‚ñé         | 253/9017 [00:05<02:52, 50.76it/s]  3%|‚ñé         | 259/9017 [00:05<02:59, 48.83it/s]  3%|‚ñé         | 265/9017 [00:05<02:56, 49.70it/s]  3%|‚ñé         | 271/9017 [00:05<02:58, 49.09it/s]  3%|‚ñé         | 277/9017 [00:05<02:53, 50.31it/s]  3%|‚ñé         | 283/9017 [00:06<02:48, 51.85it/s]  3%|‚ñé         | 289/9017 [00:06<02:42, 53.81it/s]  3%|‚ñé         | 295/9017 [00:06<02:51, 50.80it/s]  3%|‚ñé         | 301/9017 [00:06<03:06, 46.75it/s]  3%|‚ñé         | 306/9017 [00:06<03:06, 46.70it/s]  3%|‚ñé         | 312/9017 [00:06<02:54, 49.77it/s]  4%|‚ñé         | 318/9017 [00:06<02:50, 51.07it/s]  4%|‚ñé         | 324/9017 [00:06<02:45, 52.55it/s]  4%|‚ñé         | 330/9017 [00:07<02:43, 53.25it/s]  4%|‚ñé         | 336/9017 [00:07<02:44, 52.88it/s]  4%|‚ñç         | 342/9017 [00:07<02:45, 52.29it/s]  4%|‚ñç         | 348/9017 [00:07<02:47, 51.71it/s]  4%|‚ñç         | 354/9017 [00:07<02:40, 53.91it/s]  4%|‚ñç         | 360/9017 [00:07<02:37, 54.82it/s]  4%|‚ñç         | 366/9017 [00:07<02:50, 50.68it/s]  4%|‚ñç         | 372/9017 [00:07<03:00, 48.00it/s]  4%|‚ñç         | 377/9017 [00:07<03:15, 44.13it/s]  4%|‚ñç         | 382/9017 [00:08<03:13, 44.72it/s]  4%|‚ñç         | 388/9017 [00:08<03:06, 46.29it/s]  4%|‚ñç         | 394/9017 [00:08<02:57, 48.51it/s]  4%|‚ñç         | 399/9017 [00:08<02:56, 48.80it/s]  5%|‚ñç         | 406/9017 [00:08<02:39, 54.05it/s]  5%|‚ñç         | 412/9017 [00:08<02:59, 48.01it/s]  5%|‚ñç         | 417/9017 [00:08<02:59, 47.93it/s]  5%|‚ñç         | 423/9017 [00:08<02:55, 48.88it/s]  5%|‚ñç         | 428/9017 [00:09<02:58, 48.07it/s]  5%|‚ñç         | 435/9017 [00:09<02:42, 52.69it/s]  5%|‚ñç         | 441/9017 [00:09<02:40, 53.35it/s]  5%|‚ñç         | 447/9017 [00:09<02:40, 53.30it/s]  5%|‚ñå         | 453/9017 [00:09<02:43, 52.44it/s]  5%|‚ñå         | 459/9017 [00:09<02:45, 51.62it/s]  5%|‚ñå         | 465/9017 [00:09<02:47, 50.96it/s]  5%|‚ñå         | 471/9017 [00:09<02:57, 48.09it/s]  5%|‚ñå         | 476/9017 [00:09<02:56, 48.35it/s]  5%|‚ñå         | 481/9017 [00:10<02:56, 48.23it/s]  5%|‚ñå         | 486/9017 [00:10<02:55, 48.65it/s]  5%|‚ñå         | 491/9017 [00:10<03:02, 46.66it/s]  6%|‚ñå         | 496/9017 [00:10<03:00, 47.18it/s]  6%|‚ñå         | 502/9017 [00:10<02:52, 49.35it/s]  6%|‚ñå         | 508/9017 [00:10<03:06, 45.63it/s]  6%|‚ñå         | 513/9017 [00:10<03:03, 46.37it/s]  6%|‚ñå         | 519/9017 [00:10<02:56, 48.24it/s]  6%|‚ñå         | 524/9017 [00:10<02:57, 47.92it/s]  6%|‚ñå         | 529/9017 [00:11<03:00, 47.05it/s]  6%|‚ñå         | 536/9017 [00:11<02:44, 51.56it/s]  6%|‚ñå         | 542/9017 [00:11<02:45, 51.08it/s]  6%|‚ñå         | 548/9017 [00:11<02:46, 50.92it/s]  6%|‚ñå         | 554/9017 [00:11<02:51, 49.31it/s]  6%|‚ñå         | 560/9017 [00:11<02:53, 48.66it/s]  6%|‚ñã         | 567/9017 [00:11<02:43, 51.80it/s]  6%|‚ñã         | 573/9017 [00:11<02:47, 50.43it/s]  6%|‚ñã         | 579/9017 [00:12<02:49, 49.75it/s]  6%|‚ñã         | 586/9017 [00:12<02:43, 51.67it/s]  7%|‚ñã         | 592/9017 [00:12<02:48, 50.05it/s]  7%|‚ñã         | 598/9017 [00:12<02:56, 47.58it/s]  7%|‚ñã         | 603/9017 [00:12<03:02, 46.09it/s]  7%|‚ñã         | 608/9017 [00:12<03:08, 44.49it/s]  7%|‚ñã         | 614/9017 [00:12<03:02, 45.99it/s]  7%|‚ñã         | 620/9017 [00:12<02:56, 47.62it/s]  7%|‚ñã         | 626/9017 [00:13<02:54, 48.11it/s]  7%|‚ñã         | 632/9017 [00:13<02:49, 49.52it/s]  7%|‚ñã         | 637/9017 [00:13<02:58, 46.87it/s]  7%|‚ñã         | 643/9017 [00:13<02:48, 49.72it/s]  7%|‚ñã         | 649/9017 [00:13<02:39, 52.49it/s]  7%|‚ñã         | 655/9017 [00:13<04:37, 30.09it/s]  7%|‚ñã         | 661/9017 [00:13<04:00, 34.81it/s]  7%|‚ñã         | 667/9017 [00:14<03:35, 38.83it/s]  7%|‚ñã         | 674/9017 [00:14<03:09, 43.96it/s]  8%|‚ñä         | 680/9017 [00:14<03:08, 44.26it/s]  8%|‚ñä         | 685/9017 [00:14<03:06, 44.60it/s]  8%|‚ñä         | 690/9017 [00:14<03:08, 44.23it/s]  8%|‚ñä         | 695/9017 [00:14<03:07, 44.37it/s]  8%|‚ñä         | 700/9017 [00:14<03:04, 45.17it/s]  8%|‚ñä         | 705/9017 [00:14<03:01, 45.78it/s]  8%|‚ñä         | 711/9017 [00:15<02:52, 48.06it/s]  8%|‚ñä         | 717/9017 [00:15<02:48, 49.39it/s]  8%|‚ñä         | 723/9017 [00:15<02:42, 51.06it/s]  8%|‚ñä         | 730/9017 [00:15<02:33, 54.06it/s]  8%|‚ñä         | 736/9017 [00:15<02:36, 53.00it/s]  8%|‚ñä         | 742/9017 [00:15<02:41, 51.39it/s]  8%|‚ñä         | 748/9017 [00:15<02:40, 51.43it/s]  8%|‚ñä         | 754/9017 [00:15<02:35, 53.01it/s]  8%|‚ñä         | 760/9017 [00:15<02:40, 51.39it/s]  8%|‚ñä         | 766/9017 [00:16<02:34, 53.34it/s]  9%|‚ñä         | 772/9017 [00:16<02:32, 54.19it/s]  9%|‚ñä         | 778/9017 [00:16<02:28, 55.55it/s]  9%|‚ñä         | 784/9017 [00:16<02:38, 52.02it/s]  9%|‚ñâ         | 790/9017 [00:16<02:33, 53.45it/s]  9%|‚ñâ         | 796/9017 [00:16<02:35, 52.73it/s]  9%|‚ñâ         | 802/9017 [00:16<02:39, 51.34it/s]  9%|‚ñâ         | 808/9017 [00:16<02:42, 50.54it/s]  9%|‚ñâ         | 814/9017 [00:16<02:40, 51.07it/s]  9%|‚ñâ         | 820/9017 [00:17<02:46, 49.09it/s]  9%|‚ñâ         | 827/9017 [00:17<02:36, 52.44it/s]  9%|‚ñâ         | 833/9017 [00:17<02:46, 49.21it/s]  9%|‚ñâ         | 839/9017 [00:17<02:43, 49.99it/s]  9%|‚ñâ         | 845/9017 [00:17<02:51, 47.77it/s]  9%|‚ñâ         | 850/9017 [00:17<02:54, 46.67it/s]  9%|‚ñâ         | 855/9017 [00:17<02:55, 46.46it/s] 10%|‚ñâ         | 860/9017 [00:17<02:56, 46.28it/s] 10%|‚ñâ         | 866/9017 [00:18<02:47, 48.54it/s] 10%|‚ñâ         | 871/9017 [00:18<02:49, 48.02it/s] 10%|‚ñâ         | 877/9017 [00:18<02:40, 50.59it/s] 10%|‚ñâ         | 883/9017 [00:18<02:37, 51.73it/s] 10%|‚ñâ         | 889/9017 [00:18<02:44, 49.51it/s] 10%|‚ñâ         | 895/9017 [00:18<02:42, 49.84it/s] 10%|‚ñâ         | 901/9017 [00:18<02:38, 51.07it/s] 10%|‚ñà         | 907/9017 [00:18<02:43, 49.75it/s] 10%|‚ñà         | 913/9017 [00:18<02:43, 49.44it/s] 10%|‚ñà         | 919/9017 [00:19<02:40, 50.45it/s] 10%|‚ñà         | 925/9017 [00:19<02:45, 48.81it/s] 10%|‚ñà         | 932/9017 [00:19<02:35, 52.07it/s] 10%|‚ñà         | 938/9017 [00:19<02:36, 51.75it/s] 10%|‚ñà         | 945/9017 [00:19<02:30, 53.61it/s] 11%|‚ñà         | 951/9017 [00:19<02:38, 51.00it/s] 11%|‚ñà         | 957/9017 [00:19<02:37, 51.08it/s] 11%|‚ñà         | 963/9017 [00:19<02:41, 49.97it/s] 11%|‚ñà         | 969/9017 [00:20<02:35, 51.90it/s] 11%|‚ñà         | 975/9017 [00:20<02:37, 51.16it/s] 11%|‚ñà         | 981/9017 [00:20<02:39, 50.29it/s] 11%|‚ñà         | 987/9017 [00:20<02:46, 48.36it/s] 11%|‚ñà         | 992/9017 [00:20<02:44, 48.67it/s] 11%|‚ñà         | 997/9017 [00:20<02:50, 46.96it/s] 11%|‚ñà         | 1004/9017 [00:20<02:34, 51.85it/s] 11%|‚ñà         | 1010/9017 [00:20<02:31, 52.77it/s] 11%|‚ñà‚ñè        | 1016/9017 [00:21<02:33, 52.06it/s] 11%|‚ñà‚ñè        | 1022/9017 [00:21<02:38, 50.50it/s] 11%|‚ñà‚ñè        | 1029/9017 [00:21<02:31, 52.64it/s] 11%|‚ñà‚ñè        | 1036/9017 [00:21<02:20, 56.80it/s] 12%|‚ñà‚ñè        | 1043/9017 [00:21<02:16, 58.62it/s] 12%|‚ñà‚ñè        | 1049/9017 [00:21<02:17, 57.78it/s] 12%|‚ñà‚ñè        | 1055/9017 [00:21<02:30, 52.95it/s] 12%|‚ñà‚ñè        | 1062/9017 [00:21<02:19, 56.87it/s] 12%|‚ñà‚ñè        | 1068/9017 [00:21<02:21, 56.37it/s] 12%|‚ñà‚ñè        | 1074/9017 [00:22<02:30, 52.84it/s] 12%|‚ñà‚ñè        | 1080/9017 [00:22<02:28, 53.28it/s] 12%|‚ñà‚ñè        | 1086/9017 [00:22<02:32, 51.88it/s] 12%|‚ñà‚ñè        | 1092/9017 [00:22<02:39, 49.80it/s] 12%|‚ñà‚ñè        | 1098/9017 [00:22<02:47, 47.18it/s] 12%|‚ñà‚ñè        | 1104/9017 [00:22<02:39, 49.62it/s] 12%|‚ñà‚ñè        | 1110/9017 [00:22<02:55, 45.12it/s] 12%|‚ñà‚ñè        | 1115/9017 [00:22<02:54, 45.28it/s] 12%|‚ñà‚ñè        | 1121/9017 [00:23<02:49, 46.54it/s] 12%|‚ñà‚ñè        | 1127/9017 [00:23<02:44, 47.94it/s] 13%|‚ñà‚ñé        | 1133/9017 [00:23<02:42, 48.37it/s] 13%|‚ñà‚ñé        | 1138/9017 [00:23<02:44, 47.86it/s] 13%|‚ñà‚ñé        | 1144/9017 [00:23<02:36, 50.19it/s] 13%|‚ñà‚ñé        | 1150/9017 [00:23<02:39, 49.17it/s] 13%|‚ñà‚ñé        | 1156/9017 [00:23<02:39, 49.26it/s] 13%|‚ñà‚ñé        | 1162/9017 [00:23<02:30, 52.04it/s] 13%|‚ñà‚ñé        | 1168/9017 [00:23<02:33, 51.25it/s] 13%|‚ñà‚ñé        | 1174/9017 [00:24<02:40, 48.86it/s] 13%|‚ñà‚ñé        | 1181/9017 [00:24<02:28, 52.81it/s] 13%|‚ñà‚ñé        | 1187/9017 [00:24<02:26, 53.48it/s] 13%|‚ñà‚ñé        | 1193/9017 [00:24<02:25, 53.63it/s] 13%|‚ñà‚ñé        | 1199/9017 [00:24<02:24, 54.07it/s] 13%|‚ñà‚ñé        | 1205/9017 [00:24<02:24, 53.97it/s] 13%|‚ñà‚ñé        | 1211/9017 [00:24<02:23, 54.29it/s] 13%|‚ñà‚ñé        | 1217/9017 [00:24<02:30, 51.90it/s] 14%|‚ñà‚ñé        | 1223/9017 [00:25<05:18, 24.49it/s] 14%|‚ñà‚ñé        | 1228/9017 [00:25<04:38, 27.94it/s] 14%|‚ñà‚ñé        | 1233/9017 [00:25<04:12, 30.77it/s] 14%|‚ñà‚ñé        | 1239/9017 [00:25<03:36, 35.89it/s] 14%|‚ñà‚ñç        | 1245/9017 [00:25<03:16, 39.65it/s] 14%|‚ñà‚ñç        | 1251/9017 [00:26<03:02, 42.55it/s] 14%|‚ñà‚ñç        | 1258/9017 [00:26<02:43, 47.38it/s] 14%|‚ñà‚ñç        | 1264/9017 [00:26<02:35, 49.72it/s] 14%|‚ñà‚ñç        | 1270/9017 [00:26<02:36, 49.45it/s] 14%|‚ñà‚ñç        | 1276/9017 [00:26<02:28, 52.14it/s] 14%|‚ñà‚ñç        | 1282/9017 [00:26<02:24, 53.48it/s] 14%|‚ñà‚ñç        | 1288/9017 [00:26<02:25, 53.00it/s] 14%|‚ñà‚ñç        | 1295/9017 [00:26<02:21, 54.65it/s] 14%|‚ñà‚ñç        | 1301/9017 [00:26<02:24, 53.39it/s] 14%|‚ñà‚ñç        | 1307/9017 [00:27<02:21, 54.40it/s] 15%|‚ñà‚ñç        | 1313/9017 [00:27<02:28, 51.86it/s] 15%|‚ñà‚ñç        | 1320/9017 [00:27<02:19, 55.06it/s] 15%|‚ñà‚ñç        | 1326/9017 [00:27<02:23, 53.74it/s] 15%|‚ñà‚ñç        | 1332/9017 [00:27<02:20, 54.74it/s] 15%|‚ñà‚ñç        | 1340/9017 [00:27<02:07, 60.01it/s] 15%|‚ñà‚ñç        | 1347/9017 [00:27<02:14, 56.91it/s] 15%|‚ñà‚ñå        | 1353/9017 [00:27<02:13, 57.28it/s] 15%|‚ñà‚ñå        | 1359/9017 [00:27<02:12, 57.91it/s] 15%|‚ñà‚ñå        | 1366/9017 [00:28<02:10, 58.49it/s] 15%|‚ñà‚ñå        | 1372/9017 [00:28<02:23, 53.20it/s] 15%|‚ñà‚ñå        | 1378/9017 [00:28<02:22, 53.44it/s] 15%|‚ñà‚ñå        | 1384/9017 [00:28<02:26, 51.94it/s] 15%|‚ñà‚ñå        | 1392/9017 [00:28<02:10, 58.29it/s] 16%|‚ñà‚ñå        | 1398/9017 [00:28<02:10, 58.37it/s] 16%|‚ñà‚ñå        | 1404/9017 [00:28<02:10, 58.21it/s] 16%|‚ñà‚ñå        | 1411/9017 [00:28<02:05, 60.43it/s] 16%|‚ñà‚ñå        | 1418/9017 [00:29<02:14, 56.69it/s] 16%|‚ñà‚ñå        | 1425/9017 [00:29<02:10, 58.11it/s] 16%|‚ñà‚ñå        | 1431/9017 [00:29<02:13, 56.95it/s] 16%|‚ñà‚ñå        | 1437/9017 [00:29<02:12, 57.14it/s] 16%|‚ñà‚ñå        | 1444/9017 [00:29<02:06, 60.03it/s] 16%|‚ñà‚ñå        | 1451/9017 [00:29<02:09, 58.33it/s] 16%|‚ñà‚ñå        | 1457/9017 [00:29<02:16, 55.27it/s] 16%|‚ñà‚ñå        | 1464/9017 [00:29<02:10, 58.01it/s] 16%|‚ñà‚ñã        | 1470/9017 [00:29<02:16, 55.25it/s] 16%|‚ñà‚ñã        | 1476/9017 [00:30<02:23, 52.50it/s] 16%|‚ñà‚ñã        | 1482/9017 [00:30<02:18, 54.36it/s] 17%|‚ñà‚ñã        | 1489/9017 [00:30<02:11, 57.25it/s] 17%|‚ñà‚ñã        | 1496/9017 [00:30<02:08, 58.59it/s] 17%|‚ñà‚ñã        | 1502/9017 [00:30<02:09, 58.13it/s] 17%|‚ñà‚ñã        | 1508/9017 [00:30<02:15, 55.61it/s] 17%|‚ñà‚ñã        | 1514/9017 [00:30<02:23, 52.29it/s] 17%|‚ñà‚ñã        | 1520/9017 [00:30<02:26, 51.06it/s] 17%|‚ñà‚ñã        | 1526/9017 [00:30<02:20, 53.29it/s] 17%|‚ñà‚ñã        | 1533/9017 [00:31<02:11, 56.83it/s] 17%|‚ñà‚ñã        | 1539/9017 [00:31<02:23, 52.10it/s] 17%|‚ñà‚ñã        | 1545/9017 [00:31<02:25, 51.22it/s] 17%|‚ñà‚ñã        | 1551/9017 [00:31<02:29, 50.10it/s] 17%|‚ñà‚ñã        | 1557/9017 [00:31<02:26, 50.97it/s] 17%|‚ñà‚ñã        | 1563/9017 [00:31<02:21, 52.50it/s] 17%|‚ñà‚ñã        | 1569/9017 [00:31<02:33, 48.44it/s] 17%|‚ñà‚ñã        | 1575/9017 [00:31<02:29, 49.77it/s] 18%|‚ñà‚ñä        | 1581/9017 [00:32<02:35, 47.96it/s] 18%|‚ñà‚ñä        | 1588/9017 [00:32<02:25, 51.18it/s] 18%|‚ñà‚ñä        | 1594/9017 [00:32<02:22, 52.15it/s] 18%|‚ñà‚ñä        | 1600/9017 [00:32<02:28, 49.80it/s] 18%|‚ñà‚ñä        | 1606/9017 [00:32<02:25, 51.02it/s] 18%|‚ñà‚ñä        | 1613/9017 [00:32<02:14, 54.88it/s] 18%|‚ñà‚ñä        | 1620/9017 [00:32<02:08, 57.56it/s] 18%|‚ñà‚ñä        | 1626/9017 [00:32<02:09, 56.87it/s] 18%|‚ñà‚ñä        | 1632/9017 [00:32<02:07, 57.72it/s] 18%|‚ñà‚ñä        | 1639/9017 [00:33<02:04, 59.40it/s] 18%|‚ñà‚ñä        | 1645/9017 [00:33<02:06, 58.32it/s] 18%|‚ñà‚ñä        | 1651/9017 [00:33<02:10, 56.58it/s] 18%|‚ñà‚ñä        | 1657/9017 [00:33<02:12, 55.43it/s] 18%|‚ñà‚ñä        | 1663/9017 [00:33<02:15, 54.20it/s] 19%|‚ñà‚ñä        | 1669/9017 [00:33<02:20, 52.43it/s] 19%|‚ñà‚ñä        | 1675/9017 [00:33<02:24, 50.86it/s] 19%|‚ñà‚ñä        | 1681/9017 [00:33<02:27, 49.74it/s] 19%|‚ñà‚ñä        | 1686/9017 [00:34<02:30, 48.87it/s] 19%|‚ñà‚ñâ        | 1692/9017 [00:34<02:38, 46.08it/s] 19%|‚ñà‚ñâ        | 1699/9017 [00:34<02:28, 49.32it/s] 19%|‚ñà‚ñâ        | 1705/9017 [00:34<02:22, 51.29it/s] 19%|‚ñà‚ñâ        | 1711/9017 [00:34<02:22, 51.24it/s] 19%|‚ñà‚ñâ        | 1718/9017 [00:34<02:15, 53.73it/s] 19%|‚ñà‚ñâ        | 1724/9017 [00:34<02:16, 53.41it/s] 19%|‚ñà‚ñâ        | 1730/9017 [00:34<02:12, 54.82it/s] 19%|‚ñà‚ñâ        | 1737/9017 [00:34<02:05, 57.99it/s] 19%|‚ñà‚ñâ        | 1743/9017 [00:35<02:20, 51.85it/s] 19%|‚ñà‚ñâ        | 1749/9017 [00:35<02:27, 49.27it/s] 19%|‚ñà‚ñâ        | 1755/9017 [00:35<02:22, 51.05it/s] 20%|‚ñà‚ñâ        | 1761/9017 [00:35<02:21, 51.12it/s] 20%|‚ñà‚ñâ        | 1767/9017 [00:35<02:24, 50.02it/s] 20%|‚ñà‚ñâ        | 1773/9017 [00:35<02:51, 42.28it/s] 20%|‚ñà‚ñâ        | 1779/9017 [00:35<02:38, 45.63it/s] 20%|‚ñà‚ñâ        | 1786/9017 [00:35<02:23, 50.54it/s] 20%|‚ñà‚ñâ        | 1792/9017 [00:36<02:27, 48.84it/s] 20%|‚ñà‚ñâ        | 1798/9017 [00:36<02:34, 46.85it/s] 20%|‚ñà‚ñà        | 1804/9017 [00:36<02:26, 49.08it/s] 20%|‚ñà‚ñà        | 1810/9017 [00:36<02:24, 50.02it/s] 20%|‚ñà‚ñà        | 1816/9017 [00:36<02:18, 52.00it/s] 20%|‚ñà‚ñà        | 1822/9017 [00:36<02:17, 52.35it/s] 20%|‚ñà‚ñà        | 1829/9017 [00:36<02:08, 55.82it/s] 20%|‚ñà‚ñà        | 1836/9017 [00:36<02:05, 57.20it/s] 20%|‚ñà‚ñà        | 1842/9017 [00:37<02:10, 54.81it/s] 20%|‚ñà‚ñà        | 1848/9017 [00:37<02:11, 54.69it/s] 21%|‚ñà‚ñà        | 1854/9017 [00:37<02:07, 56.11it/s] 21%|‚ñà‚ñà        | 1860/9017 [00:37<02:08, 55.60it/s] 21%|‚ñà‚ñà        | 1866/9017 [00:37<02:11, 54.18it/s] 21%|‚ñà‚ñà        | 1872/9017 [00:37<02:12, 53.78it/s] 21%|‚ñà‚ñà        | 1878/9017 [00:37<02:18, 51.68it/s] 21%|‚ñà‚ñà        | 1884/9017 [00:37<02:20, 50.73it/s] 21%|‚ñà‚ñà        | 1890/9017 [00:37<02:24, 49.43it/s] 21%|‚ñà‚ñà        | 1895/9017 [00:38<02:31, 46.87it/s] 21%|‚ñà‚ñà        | 1900/9017 [00:38<02:31, 47.10it/s] 21%|‚ñà‚ñà        | 1906/9017 [00:38<02:22, 49.89it/s] 21%|‚ñà‚ñà        | 1912/9017 [00:38<02:21, 50.29it/s] 21%|‚ñà‚ñà‚ñè       | 1918/9017 [00:38<02:37, 45.16it/s] 21%|‚ñà‚ñà‚ñè       | 1924/9017 [00:38<02:28, 47.86it/s] 21%|‚ñà‚ñà‚ñè       | 1929/9017 [00:38<02:27, 48.00it/s] 21%|‚ñà‚ñà‚ñè       | 1934/9017 [00:38<02:26, 48.46it/s] 22%|‚ñà‚ñà‚ñè       | 1939/9017 [00:39<02:45, 42.86it/s] 22%|‚ñà‚ñà‚ñè       | 1944/9017 [00:39<02:50, 41.41it/s] 22%|‚ñà‚ñà‚ñè       | 1951/9017 [00:39<02:27, 48.00it/s] 22%|‚ñà‚ñà‚ñè       | 1957/9017 [00:39<02:22, 49.65it/s] 22%|‚ñà‚ñà‚ñè       | 1963/9017 [00:39<02:27, 47.68it/s] 22%|‚ñà‚ñà‚ñè       | 1968/9017 [00:39<02:38, 44.37it/s] 22%|‚ñà‚ñà‚ñè       | 1973/9017 [00:39<02:39, 44.08it/s] 22%|‚ñà‚ñà‚ñè       | 1978/9017 [00:39<02:53, 40.64it/s] 22%|‚ñà‚ñà‚ñè       | 1984/9017 [00:40<02:37, 44.76it/s] 22%|‚ñà‚ñà‚ñè       | 1989/9017 [00:40<02:39, 44.08it/s] 22%|‚ñà‚ñà‚ñè       | 1994/9017 [00:40<05:56, 19.70it/s] 22%|‚ñà‚ñà‚ñè       | 2000/9017 [00:40<04:40, 24.99it/s] 22%|‚ñà‚ñà‚ñè       | 2006/9017 [00:40<03:57, 29.56it/s] 22%|‚ñà‚ñà‚ñè       | 2011/9017 [00:41<03:34, 32.60it/s] 22%|‚ñà‚ñà‚ñè       | 2016/9017 [00:41<03:13, 36.15it/s] 22%|‚ñà‚ñà‚ñè       | 2021/9017 [00:41<02:58, 39.09it/s] 22%|‚ñà‚ñà‚ñè       | 2027/9017 [00:41<02:44, 42.53it/s] 23%|‚ñà‚ñà‚ñé       | 2032/9017 [00:41<02:41, 43.23it/s] 23%|‚ñà‚ñà‚ñé       | 2038/9017 [00:41<02:29, 46.71it/s] 23%|‚ñà‚ñà‚ñé       | 2044/9017 [00:41<02:21, 49.18it/s] 23%|‚ñà‚ñà‚ñé       | 2050/9017 [00:41<02:26, 47.63it/s] 23%|‚ñà‚ñà‚ñé       | 2056/9017 [00:41<02:17, 50.72it/s] 23%|‚ñà‚ñà‚ñé       | 2062/9017 [00:42<02:17, 50.58it/s] 23%|‚ñà‚ñà‚ñé       | 2068/9017 [00:42<02:22, 48.92it/s] 23%|‚ñà‚ñà‚ñé       | 2074/9017 [00:42<02:23, 48.40it/s] 23%|‚ñà‚ñà‚ñé       | 2079/9017 [00:42<02:27, 47.10it/s] 23%|‚ñà‚ñà‚ñé       | 2085/9017 [00:42<02:18, 49.91it/s] 23%|‚ñà‚ñà‚ñé       | 2091/9017 [00:42<02:17, 50.49it/s] 23%|‚ñà‚ñà‚ñé       | 2097/9017 [00:42<02:13, 51.82it/s] 23%|‚ñà‚ñà‚ñé       | 2103/9017 [00:42<02:14, 51.36it/s] 23%|‚ñà‚ñà‚ñé       | 2109/9017 [00:43<02:13, 51.91it/s] 23%|‚ñà‚ñà‚ñé       | 2115/9017 [00:43<02:14, 51.42it/s] 24%|‚ñà‚ñà‚ñé       | 2121/9017 [00:43<02:13, 51.55it/s] 24%|‚ñà‚ñà‚ñé       | 2127/9017 [00:43<02:10, 52.79it/s] 24%|‚ñà‚ñà‚ñé       | 2134/9017 [00:43<02:06, 54.29it/s] 24%|‚ñà‚ñà‚ñé       | 2140/9017 [00:43<02:10, 52.51it/s] 24%|‚ñà‚ñà‚ñç       | 2146/9017 [00:43<02:10, 52.72it/s] 24%|‚ñà‚ñà‚ñç       | 2152/9017 [00:43<02:07, 53.95it/s] 24%|‚ñà‚ñà‚ñç       | 2158/9017 [00:43<02:10, 52.63it/s] 24%|‚ñà‚ñà‚ñç       | 2164/9017 [00:44<02:08, 53.29it/s] 24%|‚ñà‚ñà‚ñç       | 2170/9017 [00:44<02:18, 49.37it/s] 24%|‚ñà‚ñà‚ñç       | 2176/9017 [00:44<02:19, 49.19it/s] 24%|‚ñà‚ñà‚ñç       | 2182/9017 [00:44<02:18, 49.44it/s] 24%|‚ñà‚ñà‚ñç       | 2187/9017 [00:44<02:18, 49.27it/s] 24%|‚ñà‚ñà‚ñç       | 2192/9017 [00:44<02:27, 46.12it/s] 24%|‚ñà‚ñà‚ñç       | 2198/9017 [00:44<02:18, 49.08it/s] 24%|‚ñà‚ñà‚ñç       | 2204/9017 [00:44<02:15, 50.21it/s] 25%|‚ñà‚ñà‚ñç       | 2210/9017 [00:45<02:16, 50.02it/s] 25%|‚ñà‚ñà‚ñç       | 2216/9017 [00:45<02:14, 50.74it/s] 25%|‚ñà‚ñà‚ñç       | 2222/9017 [00:45<02:15, 50.29it/s] 25%|‚ñà‚ñà‚ñç       | 2228/9017 [00:45<02:10, 52.05it/s] 25%|‚ñà‚ñà‚ñç       | 2234/9017 [00:45<02:07, 53.09it/s] 25%|‚ñà‚ñà‚ñç       | 2240/9017 [00:45<02:07, 52.99it/s] 25%|‚ñà‚ñà‚ñç       | 2246/9017 [00:45<02:24, 46.99it/s] 25%|‚ñà‚ñà‚ñç       | 2252/9017 [00:45<02:19, 48.42it/s] 25%|‚ñà‚ñà‚ñå       | 2258/9017 [00:45<02:17, 49.20it/s] 25%|‚ñà‚ñà‚ñå       | 2263/9017 [00:46<02:19, 48.33it/s] 25%|‚ñà‚ñà‚ñå       | 2269/9017 [00:46<02:15, 49.70it/s] 25%|‚ñà‚ñà‚ñå       | 2275/9017 [00:46<02:15, 49.78it/s] 25%|‚ñà‚ñà‚ñå       | 2281/9017 [00:46<02:19, 48.17it/s] 25%|‚ñà‚ñà‚ñå       | 2287/9017 [00:46<02:17, 49.04it/s] 25%|‚ñà‚ñà‚ñå       | 2293/9017 [00:46<02:21, 47.53it/s] 25%|‚ñà‚ñà‚ñå       | 2299/9017 [00:46<02:20, 47.85it/s] 26%|‚ñà‚ñà‚ñå       | 2304/9017 [00:46<02:20, 47.68it/s] 26%|‚ñà‚ñà‚ñå       | 2310/9017 [00:47<02:16, 49.20it/s] 26%|‚ñà‚ñà‚ñå       | 2316/9017 [00:47<02:10, 51.22it/s] 26%|‚ñà‚ñà‚ñå       | 2322/9017 [00:47<02:07, 52.62it/s] 26%|‚ñà‚ñà‚ñå       | 2329/9017 [00:47<01:59, 56.08it/s] 26%|‚ñà‚ñà‚ñå       | 2335/9017 [00:47<02:01, 54.95it/s] 26%|‚ñà‚ñà‚ñå       | 2341/9017 [00:47<02:05, 53.13it/s] 26%|‚ñà‚ñà‚ñå       | 2347/9017 [00:47<02:12, 50.34it/s] 26%|‚ñà‚ñà‚ñå       | 2353/9017 [00:47<02:16, 48.92it/s] 26%|‚ñà‚ñà‚ñå       | 2359/9017 [00:47<02:12, 50.29it/s] 26%|‚ñà‚ñà‚ñå       | 2365/9017 [00:48<02:10, 51.08it/s] 26%|‚ñà‚ñà‚ñã       | 2371/9017 [00:48<02:12, 50.17it/s] 26%|‚ñà‚ñà‚ñã       | 2377/9017 [00:48<02:11, 50.50it/s] 26%|‚ñà‚ñà‚ñã       | 2383/9017 [00:48<02:10, 50.78it/s] 26%|‚ñà‚ñà‚ñã       | 2389/9017 [00:48<02:18, 47.80it/s] 27%|‚ñà‚ñà‚ñã       | 2395/9017 [00:48<02:11, 50.43it/s] 27%|‚ñà‚ñà‚ñã       | 2401/9017 [00:48<02:18, 47.89it/s] 27%|‚ñà‚ñà‚ñã       | 2406/9017 [00:48<02:32, 43.25it/s] 27%|‚ñà‚ñà‚ñã       | 2412/9017 [00:49<02:22, 46.28it/s] 27%|‚ñà‚ñà‚ñã       | 2417/9017 [00:49<02:26, 45.03it/s] 27%|‚ñà‚ñà‚ñã       | 2423/9017 [00:49<02:21, 46.45it/s] 27%|‚ñà‚ñà‚ñã       | 2429/9017 [00:49<02:16, 48.14it/s] 27%|‚ñà‚ñà‚ñã       | 2434/9017 [00:49<02:18, 47.47it/s] 27%|‚ñà‚ñà‚ñã       | 2439/9017 [00:49<02:18, 47.54it/s] 27%|‚ñà‚ñà‚ñã       | 2445/9017 [00:49<02:14, 48.84it/s] 27%|‚ñà‚ñà‚ñã       | 2451/9017 [00:49<02:11, 49.93it/s] 27%|‚ñà‚ñà‚ñã       | 2457/9017 [00:50<02:08, 50.98it/s] 27%|‚ñà‚ñà‚ñã       | 2463/9017 [00:50<02:08, 50.99it/s] 27%|‚ñà‚ñà‚ñã       | 2469/9017 [00:50<02:07, 51.25it/s] 27%|‚ñà‚ñà‚ñã       | 2476/9017 [00:50<01:57, 55.43it/s] 28%|‚ñà‚ñà‚ñä       | 2482/9017 [00:50<02:04, 52.60it/s] 28%|‚ñà‚ñà‚ñä       | 2488/9017 [00:50<02:17, 47.53it/s] 28%|‚ñà‚ñà‚ñä       | 2493/9017 [00:50<02:27, 44.35it/s] 28%|‚ñà‚ñà‚ñä       | 2499/9017 [00:50<02:20, 46.53it/s] 28%|‚ñà‚ñà‚ñä       | 2504/9017 [00:50<02:19, 46.84it/s] 28%|‚ñà‚ñà‚ñä       | 2512/9017 [00:51<02:00, 53.86it/s] 28%|‚ñà‚ñà‚ñä       | 2518/9017 [00:51<02:04, 52.19it/s] 28%|‚ñà‚ñà‚ñä       | 2524/9017 [00:51<02:00, 53.95it/s] 28%|‚ñà‚ñà‚ñä       | 2530/9017 [00:51<01:59, 54.22it/s] 28%|‚ñà‚ñà‚ñä       | 2536/9017 [00:51<02:06, 51.38it/s] 28%|‚ñà‚ñà‚ñä       | 2542/9017 [00:51<02:02, 52.96it/s] 28%|‚ñà‚ñà‚ñä       | 2548/9017 [00:51<02:05, 51.40it/s] 28%|‚ñà‚ñà‚ñä       | 2554/9017 [00:51<02:01, 53.38it/s] 28%|‚ñà‚ñà‚ñä       | 2560/9017 [00:52<02:06, 51.07it/s] 28%|‚ñà‚ñà‚ñä       | 2566/9017 [00:52<02:03, 52.09it/s] 29%|‚ñà‚ñà‚ñä       | 2572/9017 [00:52<01:59, 53.84it/s] 29%|‚ñà‚ñà‚ñä       | 2578/9017 [00:52<01:57, 54.68it/s] 29%|‚ñà‚ñà‚ñä       | 2585/9017 [00:52<01:55, 55.82it/s] 29%|‚ñà‚ñà‚ñä       | 2591/9017 [00:52<01:58, 54.19it/s] 29%|‚ñà‚ñà‚ñâ       | 2597/9017 [00:52<02:04, 51.62it/s] 29%|‚ñà‚ñà‚ñâ       | 2603/9017 [00:52<02:03, 51.92it/s] 29%|‚ñà‚ñà‚ñâ       | 2609/9017 [00:53<02:19, 45.89it/s] 29%|‚ñà‚ñà‚ñâ       | 2614/9017 [00:53<02:20, 45.63it/s] 29%|‚ñà‚ñà‚ñâ       | 2619/9017 [00:53<02:22, 44.79it/s] 29%|‚ñà‚ñà‚ñâ       | 2624/9017 [00:53<02:20, 45.41it/s] 29%|‚ñà‚ñà‚ñâ       | 2630/9017 [00:53<02:12, 48.22it/s] 29%|‚ñà‚ñà‚ñâ       | 2635/9017 [00:53<02:12, 48.00it/s] 29%|‚ñà‚ñà‚ñâ       | 2641/9017 [00:53<02:06, 50.52it/s] 29%|‚ñà‚ñà‚ñâ       | 2647/9017 [00:53<02:10, 48.65it/s] 29%|‚ñà‚ñà‚ñâ       | 2652/9017 [00:53<02:11, 48.41it/s] 29%|‚ñà‚ñà‚ñâ       | 2657/9017 [00:53<02:10, 48.58it/s] 30%|‚ñà‚ñà‚ñâ       | 2663/9017 [00:54<02:10, 48.70it/s] 30%|‚ñà‚ñà‚ñâ       | 2669/9017 [00:54<02:08, 49.40it/s] 30%|‚ñà‚ñà‚ñâ       | 2675/9017 [00:54<02:06, 50.10it/s] 30%|‚ñà‚ñà‚ñâ       | 2681/9017 [00:54<02:15, 46.69it/s] 30%|‚ñà‚ñà‚ñâ       | 2686/9017 [00:54<02:16, 46.47it/s] 30%|‚ñà‚ñà‚ñâ       | 2691/9017 [00:54<02:14, 47.20it/s] 30%|‚ñà‚ñà‚ñâ       | 2697/9017 [00:54<02:08, 49.37it/s] 30%|‚ñà‚ñà‚ñâ       | 2702/9017 [00:54<02:35, 40.62it/s] 30%|‚ñà‚ñà‚ñà       | 2707/9017 [00:55<02:27, 42.66it/s] 30%|‚ñà‚ñà‚ñà       | 2712/9017 [00:55<02:22, 44.17it/s] 30%|‚ñà‚ñà‚ñà       | 2718/9017 [00:55<02:13, 47.06it/s] 30%|‚ñà‚ñà‚ñà       | 2724/9017 [00:55<02:12, 47.61it/s] 30%|‚ñà‚ñà‚ñà       | 2730/9017 [00:55<02:09, 48.55it/s] 30%|‚ñà‚ñà‚ñà       | 2735/9017 [00:55<02:17, 45.83it/s] 30%|‚ñà‚ñà‚ñà       | 2741/9017 [00:55<02:13, 46.85it/s] 30%|‚ñà‚ñà‚ñà       | 2748/9017 [00:55<01:59, 52.37it/s] 31%|‚ñà‚ñà‚ñà       | 2754/9017 [00:56<01:58, 53.00it/s] 31%|‚ñà‚ñà‚ñà       | 2760/9017 [00:56<01:57, 53.46it/s] 31%|‚ñà‚ñà‚ñà       | 2766/9017 [00:56<01:59, 52.37it/s] 31%|‚ñà‚ñà‚ñà       | 2772/9017 [00:56<02:04, 50.21it/s] 31%|‚ñà‚ñà‚ñà       | 2778/9017 [00:56<02:09, 48.18it/s] 31%|‚ñà‚ñà‚ñà       | 2783/9017 [00:56<02:18, 44.92it/s] 31%|‚ñà‚ñà‚ñà       | 2789/9017 [00:56<02:12, 47.18it/s] 31%|‚ñà‚ñà‚ñà       | 2794/9017 [00:56<02:10, 47.76it/s] 31%|‚ñà‚ñà‚ñà       | 2799/9017 [00:56<02:14, 46.21it/s] 31%|‚ñà‚ñà‚ñà       | 2805/9017 [00:57<02:05, 49.39it/s] 31%|‚ñà‚ñà‚ñà       | 2810/9017 [00:57<02:18, 44.83it/s] 31%|‚ñà‚ñà‚ñà       | 2815/9017 [00:57<02:16, 45.42it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 2820/9017 [00:57<02:17, 45.23it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 2826/9017 [00:57<02:07, 48.58it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 2832/9017 [00:57<02:03, 50.06it/s] 31%|‚ñà‚ñà‚ñà‚ñè      | 2838/9017 [00:57<01:59, 51.79it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 2844/9017 [00:57<01:54, 53.82it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 2850/9017 [00:58<02:03, 49.84it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 2856/9017 [00:58<02:03, 49.88it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 2862/9017 [00:58<02:05, 48.90it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 2868/9017 [00:58<02:01, 50.64it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 2874/9017 [00:58<01:57, 52.22it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 2880/9017 [00:59<05:18, 19.26it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 2887/9017 [00:59<04:04, 25.08it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 2893/9017 [00:59<03:25, 29.79it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 2899/9017 [00:59<02:56, 34.68it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 2905/9017 [00:59<02:38, 38.58it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 2911/9017 [00:59<02:30, 40.57it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 2917/9017 [00:59<02:22, 42.70it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 2922/9017 [01:00<02:19, 43.76it/s] 32%|‚ñà‚ñà‚ñà‚ñè      | 2928/9017 [01:00<02:12, 45.86it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 2934/9017 [01:00<02:07, 47.67it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 2940/9017 [01:00<02:05, 48.56it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 2946/9017 [01:00<01:59, 50.78it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 2952/9017 [01:00<01:58, 51.04it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 2958/9017 [01:00<02:05, 48.33it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 2964/9017 [01:00<02:01, 49.95it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 2970/9017 [01:00<02:01, 49.77it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 2976/9017 [01:01<02:03, 48.89it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 2982/9017 [01:01<02:01, 49.49it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 2987/9017 [01:01<02:02, 49.14it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 2993/9017 [01:01<01:58, 51.05it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 2999/9017 [01:01<02:03, 48.58it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 3005/9017 [01:01<01:58, 50.68it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 3011/9017 [01:01<02:04, 48.38it/s] 33%|‚ñà‚ñà‚ñà‚ñé      | 3017/9017 [01:01<02:00, 49.84it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 3023/9017 [01:02<01:55, 51.81it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 3029/9017 [01:02<01:55, 51.66it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 3035/9017 [01:02<01:54, 52.21it/s] 34%|‚ñà‚ñà‚ñà‚ñé      | 3041/9017 [01:02<01:54, 52.12it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 3048/9017 [01:02<01:51, 53.35it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 3054/9017 [01:02<01:51, 53.46it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 3060/9017 [01:02<01:55, 51.40it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 3066/9017 [01:02<01:58, 50.32it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 3072/9017 [01:02<01:57, 50.45it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 3078/9017 [01:03<01:57, 50.70it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 3084/9017 [01:03<01:57, 50.70it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 3090/9017 [01:03<01:51, 52.94it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 3096/9017 [01:03<01:50, 53.44it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 3102/9017 [01:03<01:58, 50.11it/s] 34%|‚ñà‚ñà‚ñà‚ñç      | 3108/9017 [01:03<01:53, 52.09it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 3114/9017 [01:03<01:58, 49.61it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 3120/9017 [01:03<01:59, 49.39it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 3126/9017 [01:04<01:56, 50.54it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 3132/9017 [01:04<01:57, 50.18it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 3138/9017 [01:04<01:57, 49.89it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 3144/9017 [01:04<02:55, 33.46it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 3150/9017 [01:04<02:38, 37.11it/s] 35%|‚ñà‚ñà‚ñà‚ñç      | 3155/9017 [01:04<02:29, 39.18it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 3160/9017 [01:04<02:23, 40.76it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 3167/9017 [01:05<02:07, 46.03it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 3172/9017 [01:05<02:06, 46.27it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 3179/9017 [01:05<01:58, 49.21it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 3185/9017 [01:05<01:56, 49.91it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 3191/9017 [01:05<01:55, 50.47it/s] 35%|‚ñà‚ñà‚ñà‚ñå      | 3197/9017 [01:05<01:59, 48.83it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 3202/9017 [01:05<02:01, 48.03it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 3208/9017 [01:05<01:56, 49.85it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 3214/9017 [01:06<02:01, 47.85it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 3220/9017 [01:06<01:59, 48.41it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 3225/9017 [01:06<02:02, 47.45it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 3231/9017 [01:06<01:59, 48.24it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 3236/9017 [01:06<02:03, 46.91it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 3242/9017 [01:06<01:58, 48.87it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 3247/9017 [01:06<02:04, 46.38it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 3254/9017 [01:06<01:52, 51.14it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 3260/9017 [01:06<01:52, 51.09it/s] 36%|‚ñà‚ñà‚ñà‚ñå      | 3266/9017 [01:07<01:56, 49.25it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 3271/9017 [01:07<01:59, 48.11it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 3277/9017 [01:07<01:56, 49.13it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 3283/9017 [01:07<01:51, 51.47it/s] 36%|‚ñà‚ñà‚ñà‚ñã      | 3289/9017 [01:07<01:52, 50.76it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 3295/9017 [01:07<01:57, 48.64it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 3301/9017 [01:07<01:56, 49.24it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 3308/9017 [01:07<01:48, 52.48it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 3314/9017 [01:08<01:47, 52.94it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 3320/9017 [01:08<01:46, 53.26it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 3326/9017 [01:08<01:49, 51.76it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 3332/9017 [01:08<01:48, 52.31it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 3339/9017 [01:08<01:40, 56.53it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 3345/9017 [01:08<01:40, 56.45it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 3351/9017 [01:08<01:43, 54.60it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 3357/9017 [01:08<01:49, 51.78it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 3363/9017 [01:08<01:47, 52.44it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 3369/9017 [01:09<01:51, 50.52it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 3375/9017 [01:09<02:08, 43.83it/s] 37%|‚ñà‚ñà‚ñà‚ñã      | 3380/9017 [01:09<02:05, 44.75it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 3386/9017 [01:09<02:01, 46.29it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 3392/9017 [01:09<02:07, 44.11it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 3398/9017 [01:09<02:01, 46.24it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 3403/9017 [01:09<02:02, 45.98it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 3409/9017 [01:09<01:56, 48.31it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 3414/9017 [01:10<01:55, 48.68it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 3419/9017 [01:10<02:04, 45.14it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 3425/9017 [01:10<01:56, 47.80it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 3430/9017 [01:10<02:04, 44.85it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 3436/9017 [01:10<01:56, 47.78it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 3442/9017 [01:10<01:54, 48.54it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 3447/9017 [01:10<01:53, 48.91it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 3453/9017 [01:10<01:49, 50.80it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 3459/9017 [01:10<01:51, 49.84it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 3465/9017 [01:11<01:50, 50.32it/s] 38%|‚ñà‚ñà‚ñà‚ñä      | 3471/9017 [01:11<01:50, 50.05it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 3477/9017 [01:11<01:50, 50.11it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 3483/9017 [01:11<01:51, 49.46it/s] 39%|‚ñà‚ñà‚ñà‚ñä      | 3489/9017 [01:11<01:49, 50.37it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 3495/9017 [01:11<01:53, 48.54it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 3501/9017 [01:11<01:52, 49.09it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 3507/9017 [01:11<01:51, 49.61it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 3513/9017 [01:12<01:46, 51.67it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 3519/9017 [01:12<01:48, 50.76it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 3525/9017 [01:12<01:46, 51.38it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 3531/9017 [01:12<01:56, 47.27it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 3536/9017 [01:12<01:57, 46.70it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 3542/9017 [01:12<01:49, 49.77it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 3548/9017 [01:12<01:44, 52.20it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 3554/9017 [01:12<01:44, 52.44it/s] 39%|‚ñà‚ñà‚ñà‚ñâ      | 3561/9017 [01:12<01:39, 54.76it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 3567/9017 [01:13<01:42, 53.07it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 3573/9017 [01:13<01:41, 53.85it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 3579/9017 [01:13<01:41, 53.61it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 3585/9017 [01:13<01:45, 51.45it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 3591/9017 [01:13<01:53, 47.74it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 3597/9017 [01:13<01:51, 48.70it/s] 40%|‚ñà‚ñà‚ñà‚ñâ      | 3602/9017 [01:13<01:51, 48.44it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 3608/9017 [01:13<01:46, 50.80it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 3614/9017 [01:14<01:49, 49.34it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 3619/9017 [01:14<01:49, 49.10it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 3624/9017 [01:14<01:51, 48.52it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 3631/9017 [01:14<01:41, 52.89it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 3638/9017 [01:14<01:39, 54.08it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 3644/9017 [01:14<01:37, 55.20it/s] 40%|‚ñà‚ñà‚ñà‚ñà      | 3650/9017 [01:14<01:37, 55.07it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 3656/9017 [01:14<01:38, 54.62it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 3662/9017 [01:14<01:39, 53.77it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 3668/9017 [01:15<01:38, 54.27it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 3674/9017 [01:15<01:43, 51.42it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 3680/9017 [01:15<01:45, 50.61it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 3686/9017 [01:15<01:49, 48.67it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 3692/9017 [01:15<01:44, 50.86it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 3698/9017 [01:15<01:49, 48.60it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 3703/9017 [01:15<01:50, 48.15it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 3709/9017 [01:15<01:46, 49.80it/s] 41%|‚ñà‚ñà‚ñà‚ñà      | 3715/9017 [01:16<01:45, 50.39it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3721/9017 [01:16<01:45, 50.10it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3727/9017 [01:16<01:43, 51.19it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3733/9017 [01:16<01:50, 47.92it/s] 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3739/9017 [01:16<01:45, 50.11it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3745/9017 [01:16<01:46, 49.61it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3751/9017 [01:16<01:50, 47.60it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3756/9017 [01:16<01:54, 46.05it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3762/9017 [01:16<01:51, 46.99it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3768/9017 [01:17<01:44, 50.11it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3774/9017 [01:17<01:42, 51.24it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3780/9017 [01:17<02:00, 43.28it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3786/9017 [01:17<01:54, 45.49it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3791/9017 [01:17<01:52, 46.52it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3796/9017 [01:17<01:55, 45.23it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3802/9017 [01:17<01:50, 47.00it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3808/9017 [01:17<01:45, 49.32it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3814/9017 [01:18<01:42, 50.94it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3820/9017 [01:18<01:41, 51.33it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3826/9017 [01:18<01:46, 48.94it/s] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3832/9017 [01:18<01:44, 49.64it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3838/9017 [01:18<01:38, 52.32it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3844/9017 [01:18<01:38, 52.62it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3850/9017 [01:18<01:41, 50.92it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3856/9017 [01:18<01:37, 52.88it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3862/9017 [01:18<01:38, 52.31it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3868/9017 [01:19<01:39, 51.61it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3874/9017 [01:19<01:35, 53.59it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3880/9017 [01:19<01:38, 52.06it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3886/9017 [01:19<01:41, 50.39it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3893/9017 [01:19<01:36, 53.17it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3899/9017 [01:19<01:36, 53.15it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3905/9017 [01:19<01:40, 50.71it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3911/9017 [01:19<01:50, 46.36it/s] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3917/9017 [01:20<01:46, 47.97it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3923/9017 [01:20<01:42, 49.66it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3929/9017 [01:20<01:45, 48.20it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3934/9017 [01:20<01:50, 46.04it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3939/9017 [01:20<01:54, 44.41it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3944/9017 [01:20<02:04, 40.59it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 3951/9017 [01:20<01:55, 43.88it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 3957/9017 [01:20<01:51, 45.47it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 3962/9017 [01:21<01:55, 43.88it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 3967/9017 [01:21<01:51, 45.37it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 3973/9017 [01:21<01:44, 48.42it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 3978/9017 [01:21<01:51, 45.22it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 3984/9017 [01:21<02:13, 37.57it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 3990/9017 [01:21<02:01, 41.39it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 3995/9017 [01:21<01:56, 43.03it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4000/9017 [01:22<01:56, 43.12it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4006/9017 [01:22<01:50, 45.43it/s] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4011/9017 [01:22<01:50, 45.35it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4017/9017 [01:22<01:42, 48.76it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4022/9017 [01:22<01:42, 48.90it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4029/9017 [01:22<01:36, 51.79it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4035/9017 [01:22<01:36, 51.68it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4041/9017 [01:22<01:46, 46.77it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4047/9017 [01:22<01:43, 47.95it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4052/9017 [01:23<03:29, 23.72it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4058/9017 [01:23<02:53, 28.52it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4063/9017 [01:23<02:35, 31.94it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4068/9017 [01:23<02:21, 34.90it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4073/9017 [01:23<02:10, 37.88it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4078/9017 [01:24<02:08, 38.38it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4084/9017 [01:24<01:55, 42.71it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4089/9017 [01:24<01:57, 41.99it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4094/9017 [01:24<01:56, 42.21it/s] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4099/9017 [01:24<01:53, 43.19it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4104/9017 [01:24<01:50, 44.55it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4109/9017 [01:24<01:50, 44.23it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4114/9017 [01:24<01:50, 44.52it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4119/9017 [01:24<01:46, 45.84it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4124/9017 [01:25<01:47, 45.51it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4130/9017 [01:25<01:42, 47.50it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4136/9017 [01:25<01:37, 49.90it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4142/9017 [01:25<01:34, 51.53it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4148/9017 [01:25<01:35, 51.11it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4154/9017 [01:25<01:30, 53.46it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4160/9017 [01:25<01:41, 47.81it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4165/9017 [01:25<01:46, 45.47it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4170/9017 [01:25<01:45, 46.09it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4176/9017 [01:26<01:43, 46.80it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4181/9017 [01:26<01:46, 45.62it/s] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4188/9017 [01:26<01:34, 50.91it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4194/9017 [01:26<01:39, 48.48it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4201/9017 [01:26<01:33, 51.40it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4207/9017 [01:26<01:33, 51.50it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4213/9017 [01:26<01:30, 53.16it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4219/9017 [01:26<01:34, 50.83it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4225/9017 [01:27<01:34, 50.81it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4231/9017 [01:27<01:32, 51.94it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4237/9017 [01:27<01:35, 50.04it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4243/9017 [01:27<01:35, 49.83it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4249/9017 [01:27<01:33, 50.98it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4255/9017 [01:27<01:36, 49.43it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4260/9017 [01:27<01:41, 47.06it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4265/9017 [01:27<01:43, 46.12it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4271/9017 [01:27<01:38, 48.38it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4276/9017 [01:28<01:37, 48.64it/s] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4282/9017 [01:28<01:34, 49.85it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4288/9017 [01:28<01:34, 50.12it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4294/9017 [01:28<02:00, 39.23it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4299/9017 [01:28<01:58, 39.84it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4305/9017 [01:28<01:46, 44.30it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4311/9017 [01:28<01:52, 41.91it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4316/9017 [01:29<01:47, 43.80it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4321/9017 [01:29<01:47, 43.74it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4327/9017 [01:29<01:39, 47.18it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4333/9017 [01:29<01:34, 49.41it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4339/9017 [01:29<01:31, 51.22it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4345/9017 [01:29<01:30, 51.88it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4351/9017 [01:29<01:30, 51.70it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4357/9017 [01:29<01:36, 48.31it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4363/9017 [01:29<01:30, 51.21it/s] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4369/9017 [01:30<01:35, 48.75it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4374/9017 [01:30<01:37, 47.53it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4380/9017 [01:30<01:32, 50.39it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4387/9017 [01:30<01:24, 54.55it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4393/9017 [01:30<01:25, 54.29it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4399/9017 [01:30<01:31, 50.74it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4405/9017 [01:30<01:35, 48.32it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4410/9017 [01:30<01:35, 48.39it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4415/9017 [01:30<01:37, 47.28it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4420/9017 [01:31<01:38, 46.76it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4425/9017 [01:31<01:36, 47.49it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4430/9017 [01:31<01:38, 46.56it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4435/9017 [01:31<01:39, 45.95it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4440/9017 [01:31<01:48, 42.16it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4445/9017 [01:31<01:43, 43.96it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4450/9017 [01:31<01:40, 45.23it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4455/9017 [01:31<01:38, 46.27it/s] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4460/9017 [01:32<01:43, 44.04it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4466/9017 [01:32<01:37, 46.71it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4471/9017 [01:32<01:45, 43.16it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4476/9017 [01:32<01:42, 44.40it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4482/9017 [01:32<01:39, 45.67it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4488/9017 [01:32<01:32, 49.14it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4495/9017 [01:32<01:28, 51.17it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4501/9017 [01:32<01:32, 48.80it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4506/9017 [01:32<01:35, 47.32it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4512/9017 [01:33<01:31, 49.23it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4517/9017 [01:33<01:33, 48.03it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4522/9017 [01:33<01:33, 48.25it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4527/9017 [01:33<01:33, 48.04it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4532/9017 [01:33<01:47, 41.82it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4537/9017 [01:33<01:44, 42.91it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4543/9017 [01:33<01:40, 44.48it/s] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4550/9017 [01:33<01:30, 49.39it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4556/9017 [01:34<01:29, 49.61it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4562/9017 [01:34<01:40, 44.51it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4568/9017 [01:34<01:36, 46.22it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4574/9017 [01:34<01:33, 47.76it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4579/9017 [01:34<01:31, 48.30it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4585/9017 [01:34<01:32, 47.95it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4590/9017 [01:34<01:36, 46.06it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4596/9017 [01:34<01:32, 47.72it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4601/9017 [01:34<01:32, 47.71it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4606/9017 [01:35<01:33, 47.31it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4611/9017 [01:35<01:43, 42.54it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4617/9017 [01:35<01:36, 45.78it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4623/9017 [01:35<01:34, 46.48it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4628/9017 [01:35<01:39, 43.90it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4633/9017 [01:35<01:56, 37.64it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4637/9017 [01:35<02:06, 34.50it/s] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4642/9017 [01:36<01:56, 37.67it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4648/9017 [01:36<01:45, 41.58it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4653/9017 [01:36<01:41, 43.17it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4659/9017 [01:36<01:32, 47.22it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4664/9017 [01:36<01:31, 47.49it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4670/9017 [01:36<01:29, 48.76it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4675/9017 [01:36<01:34, 45.84it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4681/9017 [01:36<01:35, 45.40it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4690/9017 [01:36<01:20, 54.06it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4696/9017 [01:37<01:23, 51.86it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4702/9017 [01:37<01:30, 47.61it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4708/9017 [01:37<01:25, 50.55it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4714/9017 [01:37<01:26, 49.49it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4720/9017 [01:37<01:28, 48.36it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4725/9017 [01:37<01:35, 44.95it/s] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4731/9017 [01:37<01:31, 46.80it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4736/9017 [01:37<01:34, 45.28it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4742/9017 [01:38<01:32, 46.26it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4747/9017 [01:38<01:35, 44.92it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4752/9017 [01:38<01:32, 45.94it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4758/9017 [01:38<01:28, 48.25it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4764/9017 [01:38<01:25, 49.79it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4770/9017 [01:38<01:25, 49.82it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4776/9017 [01:38<01:23, 50.74it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4782/9017 [01:38<01:20, 52.35it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4788/9017 [01:39<01:55, 36.58it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4793/9017 [01:39<01:47, 39.31it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4798/9017 [01:39<01:44, 40.20it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4803/9017 [01:39<01:43, 40.84it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4808/9017 [01:39<01:41, 41.57it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4813/9017 [01:39<01:37, 43.24it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4818/9017 [01:39<01:36, 43.47it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4824/9017 [01:39<01:30, 46.14it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4830/9017 [01:40<01:24, 49.43it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4837/9017 [01:40<01:16, 55.00it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4845/9017 [01:40<01:10, 58.81it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4851/9017 [01:40<01:11, 58.55it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4858/9017 [01:40<01:11, 58.38it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4864/9017 [01:40<01:14, 55.63it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4870/9017 [01:40<01:20, 51.59it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4876/9017 [01:40<01:28, 47.00it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4883/9017 [01:41<01:18, 52.44it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4889/9017 [01:41<01:21, 50.83it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4895/9017 [01:41<01:26, 47.39it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4902/9017 [01:41<01:20, 51.11it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4908/9017 [01:41<01:17, 52.88it/s] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4914/9017 [01:41<01:15, 54.47it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4920/9017 [01:41<01:13, 55.38it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4926/9017 [01:41<01:20, 50.58it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4932/9017 [01:41<01:22, 49.41it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4938/9017 [01:42<01:19, 51.57it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4944/9017 [01:42<01:18, 51.86it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4950/9017 [01:42<01:15, 53.79it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4956/9017 [01:42<01:16, 53.16it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 4962/9017 [01:42<01:17, 52.47it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 4968/9017 [01:42<01:20, 50.10it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 4974/9017 [01:42<01:20, 50.49it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 4982/9017 [01:42<01:11, 56.21it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 4988/9017 [01:43<01:16, 52.83it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 4994/9017 [01:43<01:17, 51.67it/s] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5000/9017 [01:43<01:19, 50.62it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5006/9017 [01:43<01:19, 50.19it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5012/9017 [01:43<01:17, 52.00it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5018/9017 [01:43<01:20, 49.54it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5024/9017 [01:43<01:20, 49.50it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5030/9017 [01:43<01:19, 50.22it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5037/9017 [01:43<01:12, 54.74it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5043/9017 [01:44<01:15, 52.94it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5049/9017 [01:44<01:14, 53.33it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5055/9017 [01:44<01:14, 53.53it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5061/9017 [01:44<01:14, 53.25it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5067/9017 [01:44<01:16, 51.96it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5073/9017 [01:44<01:19, 49.50it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5078/9017 [01:44<01:24, 46.86it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5084/9017 [01:44<01:22, 47.45it/s] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5089/9017 [01:45<01:24, 46.49it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5095/9017 [01:45<01:18, 50.00it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5101/9017 [01:45<01:20, 48.83it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5107/9017 [01:45<01:17, 50.39it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5113/9017 [01:45<01:19, 49.38it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5119/9017 [01:45<01:16, 51.09it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5125/9017 [01:45<01:19, 48.97it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5132/9017 [01:45<01:14, 52.38it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5139/9017 [01:45<01:10, 54.80it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5145/9017 [01:46<01:12, 53.56it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5151/9017 [01:46<01:13, 52.43it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5157/9017 [01:46<01:12, 52.91it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5163/9017 [01:46<01:15, 50.82it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5169/9017 [01:46<01:14, 51.33it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5175/9017 [01:46<01:17, 49.48it/s] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5181/9017 [01:46<01:13, 52.10it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5187/9017 [01:46<01:12, 52.67it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5193/9017 [01:47<01:11, 53.61it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5200/9017 [01:47<01:08, 55.86it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5206/9017 [01:47<01:07, 56.78it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5212/9017 [01:47<01:07, 56.00it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5218/9017 [01:47<01:11, 52.88it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5224/9017 [01:47<01:13, 51.74it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5230/9017 [01:47<01:15, 50.25it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5236/9017 [01:47<01:18, 48.45it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5241/9017 [01:47<01:17, 48.46it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5246/9017 [01:48<01:18, 48.19it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5252/9017 [01:48<01:15, 49.59it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5258/9017 [01:48<01:14, 50.62it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5264/9017 [01:48<01:12, 52.06it/s] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5270/9017 [01:48<01:14, 50.32it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5276/9017 [01:48<01:21, 45.64it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5282/9017 [01:48<01:19, 46.76it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5288/9017 [01:48<01:15, 49.57it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5294/9017 [01:49<01:12, 51.51it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5300/9017 [01:49<01:11, 51.63it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5306/9017 [01:49<01:14, 49.79it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5312/9017 [01:49<01:14, 49.87it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5318/9017 [01:49<01:14, 49.60it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5325/9017 [01:49<01:08, 54.11it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5331/9017 [01:49<01:12, 51.10it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5338/9017 [01:49<01:08, 54.08it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5344/9017 [01:49<01:08, 53.26it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5350/9017 [01:50<01:08, 53.54it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5356/9017 [01:50<01:10, 52.17it/s] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5362/9017 [01:50<01:08, 53.10it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5369/9017 [01:50<01:03, 57.59it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5375/9017 [01:50<01:10, 51.96it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5381/9017 [01:50<01:15, 48.16it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5387/9017 [01:50<01:11, 51.11it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5393/9017 [01:50<01:10, 51.23it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5399/9017 [01:51<01:17, 46.41it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5405/9017 [01:51<01:13, 49.05it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5411/9017 [01:51<01:17, 46.45it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5417/9017 [01:51<01:14, 48.59it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5422/9017 [01:51<01:15, 47.91it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5427/9017 [01:52<03:08, 19.01it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5432/9017 [01:52<02:37, 22.75it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5438/9017 [01:52<02:07, 28.04it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5443/9017 [01:52<01:55, 31.03it/s] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5450/9017 [01:52<01:35, 37.52it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5457/9017 [01:52<01:21, 43.90it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5463/9017 [01:52<01:20, 44.19it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5469/9017 [01:53<01:16, 46.18it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5475/9017 [01:53<01:16, 46.53it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5481/9017 [01:53<01:15, 46.71it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5487/9017 [01:53<01:11, 49.45it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5493/9017 [01:53<01:13, 47.90it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5499/9017 [01:53<01:11, 49.37it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5505/9017 [01:53<01:12, 48.65it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5510/9017 [01:53<01:11, 48.93it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5516/9017 [01:54<01:08, 51.01it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5522/9017 [01:54<01:11, 48.79it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5528/9017 [01:54<01:08, 51.26it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5534/9017 [01:54<01:06, 52.46it/s] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5540/9017 [01:54<01:12, 48.21it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5546/9017 [01:54<01:11, 48.85it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5552/9017 [01:54<01:07, 50.98it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5559/9017 [01:54<01:02, 55.10it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5565/9017 [01:54<01:04, 53.38it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5571/9017 [01:55<01:03, 54.09it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5577/9017 [01:55<01:04, 53.51it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5583/9017 [01:55<01:05, 52.45it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5589/9017 [01:55<01:06, 51.36it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5595/9017 [01:55<01:06, 51.40it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5601/9017 [01:55<01:09, 49.10it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5607/9017 [01:55<01:06, 51.45it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5613/9017 [01:55<01:17, 43.84it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5618/9017 [01:56<01:16, 44.46it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5624/9017 [01:56<01:11, 47.62it/s] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5630/9017 [01:56<01:07, 50.07it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5636/9017 [01:56<01:04, 52.57it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5642/9017 [01:56<01:06, 50.86it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5648/9017 [01:56<01:06, 50.70it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5654/9017 [01:56<01:14, 45.01it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5659/9017 [01:56<01:16, 44.06it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5664/9017 [01:57<01:13, 45.50it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5669/9017 [01:57<01:15, 44.21it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5675/9017 [01:57<01:11, 46.80it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5680/9017 [01:57<01:10, 47.17it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5685/9017 [01:57<01:10, 47.44it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5690/9017 [01:57<01:10, 47.35it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5696/9017 [01:57<01:07, 49.34it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5702/9017 [01:57<01:06, 49.87it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5708/9017 [01:57<01:03, 52.35it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5714/9017 [01:57<01:00, 54.24it/s] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5721/9017 [01:58<01:00, 54.51it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5727/9017 [01:58<01:02, 52.44it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5733/9017 [01:58<01:03, 51.91it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5739/9017 [01:58<01:05, 49.88it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5745/9017 [01:58<01:05, 50.05it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5751/9017 [01:58<01:04, 50.47it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5757/9017 [01:58<01:07, 48.35it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5762/9017 [01:58<01:09, 47.11it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5767/9017 [01:59<01:09, 46.94it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5772/9017 [01:59<01:11, 45.38it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5777/9017 [01:59<01:11, 45.63it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5784/9017 [01:59<01:03, 51.29it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5790/9017 [01:59<01:05, 49.46it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5795/9017 [01:59<01:05, 49.07it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5800/9017 [01:59<01:05, 48.92it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5806/9017 [01:59<01:02, 51.42it/s] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5812/9017 [02:00<01:04, 49.38it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5817/9017 [02:00<01:05, 48.85it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5822/9017 [02:00<01:10, 45.42it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5827/9017 [02:00<01:10, 45.36it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5832/9017 [02:00<01:09, 45.70it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5837/9017 [02:00<01:08, 46.23it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5842/9017 [02:00<01:14, 42.41it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5847/9017 [02:00<01:12, 43.82it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5852/9017 [02:00<01:10, 44.95it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5857/9017 [02:01<01:09, 45.29it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5862/9017 [02:01<01:08, 46.07it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5868/9017 [02:01<01:05, 48.24it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5874/9017 [02:01<01:04, 48.48it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5880/9017 [02:01<01:02, 50.37it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5886/9017 [02:01<00:59, 52.63it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5892/9017 [02:01<01:03, 49.19it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5897/9017 [02:01<01:06, 47.16it/s] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5902/9017 [02:01<01:06, 47.07it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5907/9017 [02:02<01:07, 45.74it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5913/9017 [02:02<01:05, 47.51it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5918/9017 [02:02<01:05, 47.38it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5923/9017 [02:02<01:10, 43.61it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5928/9017 [02:02<01:11, 43.36it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5933/9017 [02:02<01:12, 42.33it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5938/9017 [02:02<01:11, 43.03it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5944/9017 [02:02<01:08, 44.65it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5949/9017 [02:02<01:08, 44.91it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5954/9017 [02:03<01:07, 45.41it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5961/9017 [02:03<01:02, 48.55it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5966/9017 [02:03<01:02, 48.77it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5972/9017 [02:03<01:00, 50.10it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 5978/9017 [02:03<00:59, 50.94it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 5984/9017 [02:03<00:57, 52.92it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 5990/9017 [02:03<00:57, 52.70it/s] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 5996/9017 [02:03<00:59, 51.00it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6002/9017 [02:04<00:59, 50.91it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6008/9017 [02:04<01:00, 50.06it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6014/9017 [02:04<01:03, 47.64it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6019/9017 [02:04<01:03, 47.20it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6024/9017 [02:04<01:02, 47.92it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6030/9017 [02:04<01:01, 48.76it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6036/9017 [02:04<00:59, 49.95it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6042/9017 [02:04<01:02, 47.62it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6048/9017 [02:04<01:00, 49.03it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6053/9017 [02:05<01:02, 47.16it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6059/9017 [02:05<01:01, 48.22it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6065/9017 [02:05<01:00, 49.07it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6070/9017 [02:05<01:02, 47.51it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6075/9017 [02:05<01:05, 44.59it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6080/9017 [02:05<01:04, 45.42it/s] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6085/9017 [02:05<01:03, 46.23it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6091/9017 [02:05<01:01, 47.37it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6097/9017 [02:06<00:59, 49.44it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6104/9017 [02:06<00:54, 53.62it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6110/9017 [02:06<00:56, 51.27it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6116/9017 [02:06<00:56, 51.00it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6122/9017 [02:06<00:58, 49.26it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6128/9017 [02:06<00:57, 49.81it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6135/9017 [02:06<00:54, 53.27it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6141/9017 [02:06<00:54, 52.57it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6147/9017 [02:06<00:57, 49.71it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6153/9017 [02:07<00:56, 50.58it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6159/9017 [02:07<00:56, 50.66it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6165/9017 [02:07<01:00, 46.83it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6170/9017 [02:07<01:04, 43.97it/s] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6176/9017 [02:07<01:02, 45.37it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6181/9017 [02:07<01:02, 45.30it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6186/9017 [02:07<01:01, 46.10it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6191/9017 [02:07<01:00, 46.93it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6197/9017 [02:08<00:59, 47.73it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6204/9017 [02:08<00:54, 51.67it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6210/9017 [02:08<00:55, 50.41it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6217/9017 [02:08<00:50, 55.05it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6223/9017 [02:08<00:53, 52.70it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6229/9017 [02:08<00:53, 51.79it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6235/9017 [02:08<00:53, 52.26it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6241/9017 [02:08<00:54, 50.73it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6247/9017 [02:09<00:53, 52.22it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6253/9017 [02:09<00:52, 52.52it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6259/9017 [02:09<00:56, 49.02it/s] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6265/9017 [02:09<00:55, 49.72it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6271/9017 [02:09<00:55, 49.10it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6277/9017 [02:09<00:55, 48.98it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6283/9017 [02:09<00:53, 50.64it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6289/9017 [02:09<00:53, 51.25it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6295/9017 [02:09<00:52, 52.30it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6301/9017 [02:10<00:53, 50.52it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6307/9017 [02:10<00:59, 45.30it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6314/9017 [02:10<00:54, 49.98it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6320/9017 [02:10<00:53, 50.18it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6327/9017 [02:10<00:50, 53.71it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6333/9017 [02:10<00:53, 50.46it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6339/9017 [02:10<00:52, 50.69it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6345/9017 [02:10<00:53, 50.01it/s] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6351/9017 [02:11<00:53, 49.86it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6357/9017 [02:11<00:53, 49.36it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6363/9017 [02:11<00:53, 49.46it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6369/9017 [02:11<00:52, 50.67it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6375/9017 [02:11<00:53, 49.84it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6382/9017 [02:11<00:48, 54.70it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6388/9017 [02:11<00:48, 54.44it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6394/9017 [02:11<00:51, 50.69it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6400/9017 [02:12<00:52, 49.92it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6406/9017 [02:12<00:53, 48.98it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6411/9017 [02:12<00:53, 48.39it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6416/9017 [02:12<00:53, 48.32it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6421/9017 [02:12<00:56, 45.70it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6426/9017 [02:12<00:59, 43.48it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6432/9017 [02:12<00:56, 45.50it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6437/9017 [02:12<00:56, 45.47it/s] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6444/9017 [02:12<00:52, 49.13it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6449/9017 [02:13<00:52, 48.74it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6454/9017 [02:13<00:52, 48.80it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6460/9017 [02:13<00:50, 50.86it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6466/9017 [02:13<00:53, 47.68it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6471/9017 [02:13<00:52, 48.24it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6477/9017 [02:13<00:51, 49.65it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6483/9017 [02:13<00:50, 50.01it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6489/9017 [02:13<00:50, 50.14it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6495/9017 [02:14<00:51, 48.83it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6501/9017 [02:14<00:50, 50.12it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6507/9017 [02:14<00:50, 49.92it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6513/9017 [02:14<00:49, 50.50it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6519/9017 [02:14<00:50, 49.84it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6525/9017 [02:14<00:48, 51.20it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6531/9017 [02:14<00:49, 49.79it/s] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6536/9017 [02:14<00:52, 47.40it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6543/9017 [02:14<00:48, 50.70it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6549/9017 [02:15<00:53, 45.92it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6555/9017 [02:15<00:49, 49.32it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6561/9017 [02:15<00:49, 49.99it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6567/9017 [02:15<00:48, 50.18it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6573/9017 [02:15<00:46, 52.48it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6579/9017 [02:15<00:52, 46.21it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6585/9017 [02:15<00:51, 47.19it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6590/9017 [02:15<00:52, 45.98it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6596/9017 [02:16<00:50, 47.73it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6601/9017 [02:16<00:51, 47.16it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6606/9017 [02:16<00:51, 47.22it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6611/9017 [02:16<00:52, 46.09it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6617/9017 [02:16<00:49, 48.94it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6622/9017 [02:16<00:50, 47.18it/s] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6627/9017 [02:16<00:51, 46.15it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6632/9017 [02:16<00:51, 46.18it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6637/9017 [02:16<00:52, 45.21it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6643/9017 [02:17<00:51, 46.20it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6649/9017 [02:17<00:48, 48.55it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6655/9017 [02:17<00:46, 50.27it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6661/9017 [02:17<00:53, 44.06it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6666/9017 [02:17<00:51, 45.48it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6671/9017 [02:17<00:51, 45.13it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6676/9017 [02:17<00:51, 45.34it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6681/9017 [02:17<00:55, 42.38it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6687/9017 [02:18<00:51, 45.44it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6692/9017 [02:18<00:54, 42.94it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6698/9017 [02:18<00:51, 44.80it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6703/9017 [02:18<00:53, 43.17it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6708/9017 [02:18<00:52, 43.75it/s] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6714/9017 [02:18<00:50, 45.56it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6719/9017 [02:18<00:53, 42.81it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6724/9017 [02:18<00:52, 43.41it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6730/9017 [02:19<00:49, 46.22it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6736/9017 [02:19<00:47, 48.17it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6742/9017 [02:19<00:47, 47.65it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6748/9017 [02:19<00:44, 50.43it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6754/9017 [02:19<00:44, 50.92it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6760/9017 [02:19<00:44, 50.73it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6766/9017 [02:19<00:43, 52.05it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6772/9017 [02:19<00:42, 53.25it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6779/9017 [02:19<00:40, 55.37it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6785/9017 [02:20<00:41, 53.43it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6791/9017 [02:20<00:45, 49.10it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6796/9017 [02:20<00:45, 49.10it/s] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6802/9017 [02:20<00:42, 51.83it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6808/9017 [02:20<00:41, 52.85it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6814/9017 [02:20<00:42, 51.47it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6820/9017 [02:20<00:42, 51.91it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6826/9017 [02:20<00:41, 53.34it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6832/9017 [02:21<00:44, 48.93it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6837/9017 [02:21<00:44, 48.86it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6843/9017 [02:21<00:43, 50.40it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6850/9017 [02:21<00:39, 54.44it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6856/9017 [02:21<00:40, 52.85it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6862/9017 [02:21<00:39, 54.66it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6868/9017 [02:21<00:39, 53.77it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6874/9017 [02:21<00:39, 53.98it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6880/9017 [02:21<00:38, 55.10it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6886/9017 [02:22<00:41, 51.31it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6892/9017 [02:22<00:42, 49.94it/s] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6898/9017 [02:22<00:42, 50.36it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6904/9017 [02:22<00:41, 51.53it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6910/9017 [02:22<00:42, 50.17it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6916/9017 [02:22<00:41, 51.11it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6922/9017 [02:22<00:40, 51.29it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6928/9017 [02:22<00:42, 49.13it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6933/9017 [02:22<00:42, 49.18it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6938/9017 [02:23<00:42, 48.52it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6944/9017 [02:23<00:41, 50.40it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6950/9017 [02:23<00:41, 49.82it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6956/9017 [02:23<00:39, 51.87it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6962/9017 [02:23<00:39, 52.58it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6968/9017 [02:23<00:38, 53.55it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6974/9017 [02:23<00:39, 52.32it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6980/9017 [02:23<00:40, 50.34it/s] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6986/9017 [02:24<00:41, 49.33it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 6992/9017 [02:24<00:44, 45.35it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 6997/9017 [02:24<00:48, 41.80it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7002/9017 [02:26<04:52,  6.89it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7006/9017 [02:29<08:26,  3.97it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7011/9017 [02:29<06:07,  5.46it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7015/9017 [02:29<04:48,  6.95it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7021/9017 [02:29<03:20,  9.95it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7027/9017 [02:29<02:24, 13.74it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7034/9017 [02:29<01:43, 19.10it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7039/9017 [02:29<01:28, 22.25it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7045/9017 [02:29<01:11, 27.67it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7050/9017 [02:29<01:03, 31.05it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7055/9017 [02:30<00:56, 34.48it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7062/9017 [02:30<00:48, 40.38it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7068/9017 [02:30<00:44, 43.33it/s] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7074/9017 [02:30<00:42, 45.22it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7080/9017 [02:30<00:43, 44.93it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7086/9017 [02:30<00:42, 45.61it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7091/9017 [02:30<00:41, 46.11it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7096/9017 [02:30<00:42, 45.10it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7102/9017 [02:30<00:40, 47.12it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7108/9017 [02:31<00:39, 48.94it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7114/9017 [02:31<00:37, 50.98it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7120/9017 [02:31<00:36, 52.17it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7126/9017 [02:31<00:36, 51.66it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7132/9017 [02:31<00:36, 51.27it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7138/9017 [02:31<00:37, 49.61it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7143/9017 [02:31<00:37, 49.39it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7149/9017 [02:31<00:36, 51.59it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7155/9017 [02:32<00:36, 50.40it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7161/9017 [02:32<00:35, 52.59it/s] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7167/9017 [02:32<00:39, 47.10it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7173/9017 [02:32<00:37, 49.84it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7181/9017 [02:32<00:32, 56.50it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7187/9017 [02:32<00:32, 55.86it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7193/9017 [02:32<00:34, 52.76it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7200/9017 [02:32<00:32, 56.12it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7206/9017 [02:32<00:31, 56.99it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7212/9017 [02:33<00:32, 55.28it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7218/9017 [02:33<01:32, 19.52it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7223/9017 [02:33<01:19, 22.69it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7228/9017 [02:34<01:08, 26.13it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7233/9017 [02:34<01:01, 29.08it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7238/9017 [02:34<00:54, 32.57it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7244/9017 [02:34<00:47, 37.54it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7249/9017 [02:34<00:45, 38.68it/s] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7254/9017 [02:34<00:45, 39.01it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7260/9017 [02:34<00:40, 43.90it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7265/9017 [02:34<00:40, 43.57it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7271/9017 [02:34<00:37, 46.72it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7277/9017 [02:35<00:35, 48.87it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7283/9017 [02:35<00:36, 48.10it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7288/9017 [02:35<00:36, 47.64it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7294/9017 [02:35<00:33, 50.80it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7300/9017 [02:35<00:51, 33.44it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7306/9017 [02:35<00:45, 37.90it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7313/9017 [02:35<00:39, 43.25it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7318/9017 [02:36<00:39, 43.27it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7323/9017 [02:36<00:38, 43.71it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7328/9017 [02:36<00:38, 44.09it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7333/9017 [02:36<00:37, 44.63it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7339/9017 [02:36<00:35, 46.78it/s] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7344/9017 [02:36<00:35, 46.69it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7350/9017 [02:36<00:33, 49.84it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7356/9017 [02:36<00:32, 51.14it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7362/9017 [02:36<00:32, 51.26it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7368/9017 [02:37<00:34, 47.72it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7374/9017 [02:37<00:34, 48.17it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7379/9017 [02:37<00:33, 48.60it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7385/9017 [02:37<00:32, 49.52it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7390/9017 [02:37<00:33, 48.83it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7395/9017 [02:37<00:34, 47.65it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7400/9017 [02:37<00:38, 42.01it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7406/9017 [02:37<00:35, 45.02it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7412/9017 [02:38<00:38, 41.62it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7418/9017 [02:38<00:35, 44.49it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7424/9017 [02:38<00:33, 47.27it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7430/9017 [02:38<00:33, 47.98it/s] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7436/9017 [02:38<00:31, 49.42it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7442/9017 [02:38<00:31, 49.36it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7448/9017 [02:38<00:31, 49.70it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7454/9017 [02:38<00:32, 48.55it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7462/9017 [02:39<00:28, 55.32it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7468/9017 [02:39<00:30, 51.62it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7474/9017 [02:39<00:30, 50.98it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7480/9017 [02:39<00:31, 48.87it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7485/9017 [02:39<00:47, 32.17it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7490/9017 [02:39<00:43, 35.18it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7495/9017 [02:39<00:40, 37.48it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7500/9017 [02:40<00:38, 39.46it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7505/9017 [02:40<00:37, 39.96it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7511/9017 [02:40<00:33, 44.74it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7517/9017 [02:40<00:32, 46.72it/s] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7524/9017 [02:40<00:30, 49.67it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7530/9017 [02:40<00:29, 49.82it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7536/9017 [02:40<00:31, 47.59it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7541/9017 [02:40<00:30, 47.66it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7547/9017 [02:41<00:30, 48.46it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7553/9017 [02:41<00:28, 51.43it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7559/9017 [02:41<00:28, 50.83it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7565/9017 [02:41<00:28, 50.18it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7571/9017 [02:41<00:30, 47.26it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7576/9017 [02:41<00:46, 30.73it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7581/9017 [02:41<00:42, 33.60it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7587/9017 [02:42<00:38, 37.54it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7594/9017 [02:42<00:32, 43.34it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7600/9017 [02:42<00:29, 47.26it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7606/9017 [02:42<00:28, 50.39it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7612/9017 [02:42<00:27, 51.99it/s] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7618/9017 [02:42<00:25, 53.89it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7624/9017 [02:42<00:28, 49.43it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7630/9017 [02:42<00:27, 50.27it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7636/9017 [02:42<00:28, 49.22it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7642/9017 [02:43<00:27, 50.15it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7648/9017 [02:43<00:29, 46.86it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7653/9017 [02:43<00:28, 47.56it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7659/9017 [02:43<00:28, 47.85it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7664/9017 [02:43<00:29, 46.52it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7669/9017 [02:43<00:28, 47.00it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7674/9017 [02:43<00:28, 47.45it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7680/9017 [02:43<00:26, 50.25it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7686/9017 [02:44<00:25, 51.66it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7692/9017 [02:44<00:27, 48.61it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7697/9017 [02:44<00:28, 46.88it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7702/9017 [02:44<00:27, 47.09it/s] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7709/9017 [02:44<00:25, 51.62it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7715/9017 [02:44<00:36, 35.49it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7721/9017 [02:44<00:32, 40.46it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7726/9017 [02:44<00:30, 41.87it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7732/9017 [02:45<00:28, 45.08it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7738/9017 [02:45<00:26, 47.99it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7744/9017 [02:45<00:26, 48.80it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7750/9017 [02:45<00:25, 49.02it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7756/9017 [02:45<00:26, 48.01it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7761/9017 [02:45<00:26, 47.74it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7767/9017 [02:45<00:25, 49.08it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7772/9017 [02:45<00:29, 42.08it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7779/9017 [02:46<00:26, 46.05it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7784/9017 [02:46<00:27, 45.47it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7791/9017 [02:46<00:24, 50.91it/s] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7797/9017 [02:46<00:25, 48.77it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7802/9017 [02:46<00:25, 47.20it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7807/9017 [02:46<00:26, 45.97it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7813/9017 [02:46<00:25, 48.06it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7819/9017 [02:46<00:23, 51.07it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7825/9017 [02:47<00:24, 49.07it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7830/9017 [02:47<00:24, 48.77it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7836/9017 [02:47<00:23, 49.45it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7841/9017 [02:47<00:24, 48.70it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7846/9017 [02:47<00:25, 45.38it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7851/9017 [02:47<00:25, 45.93it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7856/9017 [02:47<00:25, 45.73it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7861/9017 [02:47<00:26, 44.42it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7866/9017 [02:47<00:28, 39.95it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7871/9017 [02:48<00:27, 42.00it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7876/9017 [02:48<00:26, 43.54it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7882/9017 [02:48<00:23, 47.87it/s] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7888/9017 [02:48<00:22, 50.25it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7894/9017 [02:48<00:22, 49.21it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7899/9017 [02:48<00:25, 44.14it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7905/9017 [02:48<00:23, 46.41it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7910/9017 [02:48<00:23, 46.61it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7915/9017 [02:48<00:24, 45.63it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7921/9017 [02:49<00:23, 47.48it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7926/9017 [02:49<00:24, 44.99it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7931/9017 [02:49<00:23, 46.05it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7937/9017 [02:49<00:21, 49.44it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7942/9017 [02:49<00:33, 32.14it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7947/9017 [02:49<00:31, 34.33it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7953/9017 [02:49<00:27, 39.36it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7958/9017 [02:50<00:25, 41.48it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7964/9017 [02:50<00:24, 42.85it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7970/9017 [02:50<00:22, 46.56it/s] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7975/9017 [02:50<00:22, 45.93it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7982/9017 [02:50<00:20, 51.66it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7988/9017 [02:50<00:21, 48.81it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7994/9017 [02:50<00:21, 47.06it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 8001/9017 [02:50<00:20, 50.24it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8007/9017 [02:51<00:20, 48.53it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8013/9017 [02:51<00:20, 50.05it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8019/9017 [02:51<00:20, 49.19it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8025/9017 [02:51<00:19, 51.92it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8032/9017 [02:51<00:17, 56.05it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8038/9017 [02:51<00:20, 47.86it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8044/9017 [02:51<00:20, 47.30it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8049/9017 [02:51<00:20, 47.16it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8054/9017 [02:52<00:20, 47.30it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8059/9017 [02:52<00:20, 47.20it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8064/9017 [02:52<00:19, 47.69it/s] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8070/9017 [02:52<00:19, 49.55it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8075/9017 [02:52<00:20, 45.48it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8080/9017 [02:52<00:20, 45.92it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8085/9017 [02:52<00:20, 44.90it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8091/9017 [02:52<00:19, 46.54it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8096/9017 [02:52<00:19, 47.30it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8102/9017 [02:53<00:18, 48.22it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8108/9017 [02:53<00:17, 50.81it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8115/9017 [02:53<00:16, 54.19it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8122/9017 [02:53<00:15, 57.04it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8128/9017 [02:53<00:16, 54.36it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8134/9017 [02:53<00:24, 35.60it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8140/9017 [02:53<00:22, 38.63it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8145/9017 [02:54<00:21, 40.22it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8150/9017 [02:54<00:21, 39.72it/s] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8156/9017 [02:54<00:19, 43.54it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8161/9017 [02:54<00:19, 44.82it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8166/9017 [02:54<00:19, 44.53it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8172/9017 [02:54<00:18, 45.95it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8177/9017 [02:54<00:18, 45.55it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8183/9017 [02:54<00:16, 49.23it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8189/9017 [02:54<00:16, 50.93it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8195/9017 [02:55<00:15, 51.68it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8201/9017 [02:55<00:15, 52.02it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8208/9017 [02:55<00:14, 56.30it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8214/9017 [02:55<00:15, 52.58it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8220/9017 [02:55<00:15, 51.03it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8226/9017 [02:55<00:15, 52.64it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8232/9017 [02:55<00:15, 51.95it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8238/9017 [02:55<00:14, 53.90it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8244/9017 [02:55<00:14, 52.20it/s] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8250/9017 [02:56<00:14, 51.65it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8257/9017 [02:56<00:14, 53.68it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8263/9017 [02:56<00:14, 52.23it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8269/9017 [02:56<00:15, 47.72it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8275/9017 [02:56<00:14, 49.95it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8281/9017 [02:56<00:14, 52.45it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8287/9017 [02:56<00:14, 50.21it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8293/9017 [02:56<00:14, 51.56it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8299/9017 [02:57<00:13, 51.88it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8305/9017 [02:57<00:13, 53.53it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8311/9017 [02:57<00:12, 55.03it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8317/9017 [02:57<00:13, 52.18it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8323/9017 [02:57<00:13, 52.11it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8329/9017 [02:57<00:13, 52.63it/s] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8335/9017 [02:57<00:14, 48.52it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8341/9017 [02:57<00:13, 49.13it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8346/9017 [02:57<00:13, 49.27it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8353/9017 [02:58<00:12, 53.32it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8359/9017 [02:58<00:12, 52.90it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8365/9017 [02:58<00:13, 49.24it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8370/9017 [02:58<00:13, 47.80it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8375/9017 [02:58<00:19, 32.26it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8380/9017 [02:58<00:17, 35.51it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8385/9017 [02:58<00:17, 36.91it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8391/9017 [02:59<00:15, 41.69it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8396/9017 [02:59<00:15, 41.27it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8402/9017 [02:59<00:13, 45.05it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8407/9017 [02:59<00:13, 44.64it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8412/9017 [02:59<00:13, 44.59it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8418/9017 [02:59<00:12, 48.56it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8423/9017 [02:59<00:12, 46.66it/s] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8428/9017 [02:59<00:12, 46.89it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8434/9017 [02:59<00:11, 48.93it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8439/9017 [03:00<00:11, 48.64it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8445/9017 [03:00<00:11, 49.67it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8451/9017 [03:00<00:11, 50.55it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8457/9017 [03:00<00:11, 49.06it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8462/9017 [03:00<00:13, 42.65it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8467/9017 [03:00<00:12, 42.32it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8472/9017 [03:00<00:14, 38.50it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8477/9017 [03:00<00:13, 41.11it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8482/9017 [03:01<00:12, 41.30it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8487/9017 [03:01<00:12, 43.48it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8493/9017 [03:01<00:11, 45.26it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8498/9017 [03:01<00:11, 44.89it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8504/9017 [03:01<00:10, 47.35it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8510/9017 [03:01<00:10, 49.71it/s] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8516/9017 [03:01<00:09, 51.32it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8522/9017 [03:01<00:09, 50.90it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8528/9017 [03:01<00:09, 52.96it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8534/9017 [03:02<00:11, 42.51it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8539/9017 [03:02<00:10, 43.81it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8544/9017 [03:02<00:10, 45.09it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8549/9017 [03:02<00:10, 45.89it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8554/9017 [03:02<00:14, 32.86it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8560/9017 [03:02<00:12, 37.14it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8565/9017 [03:02<00:11, 39.63it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8570/9017 [03:03<00:10, 41.72it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8577/9017 [03:03<00:09, 44.48it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8583/9017 [03:03<00:09, 46.81it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8588/9017 [03:03<00:09, 46.01it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8594/9017 [03:03<00:08, 49.63it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8600/9017 [03:03<00:08, 51.27it/s] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8606/9017 [03:03<00:08, 51.02it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8612/9017 [03:03<00:08, 50.42it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8618/9017 [03:04<00:08, 48.63it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8623/9017 [03:04<00:08, 48.02it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8628/9017 [03:04<00:08, 48.51it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8633/9017 [03:04<00:08, 46.62it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8638/9017 [03:04<00:08, 46.91it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8644/9017 [03:04<00:07, 50.32it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8651/9017 [03:04<00:06, 54.62it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8658/9017 [03:04<00:06, 56.19it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8664/9017 [03:04<00:06, 53.59it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8670/9017 [03:05<00:06, 54.23it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8677/9017 [03:05<00:06, 55.45it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8683/9017 [03:05<00:06, 54.48it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8689/9017 [03:05<00:06, 53.13it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8695/9017 [03:05<00:06, 52.58it/s] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8701/9017 [03:05<00:06, 51.73it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8707/9017 [03:05<00:06, 50.28it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8713/9017 [03:05<00:06, 48.98it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8718/9017 [03:05<00:06, 47.13it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8723/9017 [03:06<00:06, 46.54it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8728/9017 [03:06<00:06, 46.98it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8733/9017 [03:06<00:06, 43.99it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8738/9017 [03:06<00:06, 44.71it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8743/9017 [03:06<00:06, 44.79it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8748/9017 [03:06<00:05, 46.09it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8753/9017 [03:06<00:05, 44.15it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8759/9017 [03:06<00:05, 46.86it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8765/9017 [03:07<00:05, 47.16it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8770/9017 [03:07<00:05, 47.44it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8775/9017 [03:07<00:05, 42.94it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8781/9017 [03:07<00:05, 45.32it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8786/9017 [03:07<00:04, 46.51it/s] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8791/9017 [03:07<00:04, 46.28it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8797/9017 [03:07<00:04, 48.73it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8803/9017 [03:07<00:04, 49.71it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8808/9017 [03:07<00:04, 47.66it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8813/9017 [03:08<00:04, 47.35it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8818/9017 [03:08<00:04, 47.30it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8823/9017 [03:08<00:04, 45.27it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8829/9017 [03:08<00:03, 48.24it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8834/9017 [03:08<00:03, 47.57it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8839/9017 [03:08<00:05, 32.95it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8844/9017 [03:08<00:04, 35.10it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8850/9017 [03:08<00:04, 40.45it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8855/9017 [03:09<00:03, 42.05it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8860/9017 [03:09<00:03, 42.99it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8867/9017 [03:09<00:03, 49.07it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8873/9017 [03:09<00:02, 51.58it/s] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8879/9017 [03:09<00:02, 50.88it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8885/9017 [03:09<00:02, 47.41it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8890/9017 [03:09<00:02, 46.74it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8895/9017 [03:09<00:02, 46.92it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8900/9017 [03:10<00:02, 44.02it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8906/9017 [03:10<00:02, 46.66it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8912/9017 [03:10<00:02, 49.94it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8918/9017 [03:10<00:01, 50.23it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8924/9017 [03:10<00:01, 48.98it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8929/9017 [03:10<00:01, 47.95it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8934/9017 [03:10<00:01, 46.73it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8939/9017 [03:10<00:01, 46.79it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8945/9017 [03:10<00:01, 48.34it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8951/9017 [03:11<00:01, 48.91it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8956/9017 [03:11<00:01, 47.42it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8962/9017 [03:11<00:01, 48.82it/s] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8968/9017 [03:11<00:00, 50.83it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8974/9017 [03:11<00:00, 49.21it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8979/9017 [03:11<00:00, 44.42it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8984/9017 [03:11<00:00, 45.34it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8989/9017 [03:11<00:00, 46.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8995/9017 [03:11<00:00, 49.58it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 9001/9017 [03:12<00:00, 48.81it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 9007/9017 [03:12<00:00, 49.09it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 9012/9017 [03:12<00:00, 48.28it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9017/9017 [03:12<00:00, 46.23it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9017/9017 [03:12<00:00, 46.86it/s]
[train samples]: Loading 1071915 images from /shared/rc/llm-gen-agent/mhu/simlingo_dataset/database/simlingo_extracted for bucket all
Total amount of routes: 18034
Crashed routes: 704
Perfect routes: 8313
Fail reasons: {'route_crashed': 694, 'no_results.json': 10}
[Bucket: all] Scanning routes in /shared/rc/llm-gen-agent/mhu/simlingo_dataset/database/simlingo_extracted...
Found 9109 routes in /shared/rc/llm-gen-agent/mhu/simlingo_dataset/database/simlingo_extracted
Use 92 routes.
  0%|          | 0/92 [00:00<?, ?it/s] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 49/92 [00:00<00:00, 436.46it/s]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 92/92 [00:00<00:00, 338.04it/s]
[val samples]: Loading 10407 images from /shared/rc/llm-gen-agent/mhu/simlingo_dataset/database/simlingo_extracted for bucket all
Total amount of routes: 184
Crashed routes: 10
Perfect routes: 82
Fail reasons: {'route_crashed': 9, 'no_results.json': 1}
Num samples: 2143830
Num samples all: 1071915
Sanity Checking: |          | 0/? [00:00<?, ?it/s]Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
============================================================
[Input Before LLM] - Global Step 0
============================================================
  Adaptor embeddings shape: torch.Size([4, 585, 896])
  Input embeddings shape: torch.Size([4, 585, 896])
  Attention mask shape: torch.Size([4, 585])
  Input dtype: torch.float16
  Adaptor embeddings range: [-43.7812, 35.7812]
  Input embeddings range: [-43.7812, 35.7812]
  Input embeddings mean: 0.0102, std: 0.9121
  Language inputs shape: torch.Size([4, 555, 896])

============================================================
Global Step 0
============================================================

[Losses]
  language_loss: 0.099121 (shape: torch.Size([4, 554]), count: 28)
  route_loss: 16.343750 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 8.898438 (shape: torch.Size([4, 10]), count: 40)
Validation visualization!
visualise_training_examples cannot open resource
Sanity Checking DataLoader 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:22<00:22,  0.04it/s]
============================================================
[Input Before LLM] - Global Step 0
============================================================
  Adaptor embeddings shape: torch.Size([4, 585, 896])
  Input embeddings shape: torch.Size([4, 585, 896])
  Attention mask shape: torch.Size([4, 585])
  Input dtype: torch.float16
  Adaptor embeddings range: [-7.8203, 8.1641]
  Input embeddings range: [-7.8203, 8.1641]
  Input embeddings mean: 0.0093, std: 0.7461
  Language inputs shape: torch.Size([4, 555, 896])

============================================================
Global Step 0
============================================================

[Losses]
  language_loss: 0.094788 (shape: torch.Size([4, 554]), count: 28)
  route_loss: 15.812500 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 5.085938 (shape: torch.Size([4, 10]), count: 40)
Validation visualization!
visualise_training_examples cannot open resource
Sanity Checking DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:40<00:00,  0.05it/s]                                                                           Training: |          | 0/? [00:00<?, ?it/s]Training:   0%|          | 0/535957 [00:00<?, ?it/s]Epoch 0:   0%|          | 0/535957 [00:00<?, ?it/s] 
============================================================
[Input Before LLM] - Global Step 0
============================================================
  Adaptor embeddings shape: torch.Size([4, 586, 896])
  Input embeddings shape: torch.Size([4, 586, 896])
  Attention mask shape: torch.Size([4, 586])
  Input dtype: torch.float16
  Adaptor embeddings range: [-7.3281, 8.6172]
  Input embeddings range: [-7.3281, 8.6172]
  Input embeddings mean: 0.0096, std: 0.7954
  Language inputs shape: torch.Size([4, 556, 896])

============================================================
Global Step 0
============================================================

[Losses]
  language_loss: 0.100708 (shape: torch.Size([4, 555]), count: 28)
  route_loss: 15.851562 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 22.562500 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 1/535957 [00:02<301:35:12,  0.49it/s]Epoch 0:   0%|          | 1/535957 [00:02<301:40:18,  0.49it/s, v_num=full, train/loss_step=46.40]Epoch 0:   0%|          | 2/535957 [00:02<196:22:12,  0.76it/s, v_num=full, train/loss_step=46.40]Epoch 0:   0%|          | 2/535957 [00:02<197:58:12,  0.75it/s, v_num=full, train/loss_step=35.50]Epoch 0:   0%|          | 3/535957 [00:03<161:26:10,  0.92it/s, v_num=full, train/loss_step=35.50]Epoch 0:   0%|          | 3/535957 [00:03<161:27:59,  0.92it/s, v_num=full, train/loss_step=29.30]Epoch 0:   0%|          | 4/535957 [00:03<142:57:17,  1.04it/s, v_num=full, train/loss_step=29.30]Epoch 0:   0%|          | 4/535957 [00:03<142:58:33,  1.04it/s, v_num=full, train/loss_step=26.00]Epoch 0:   0%|          | 5/535957 [00:04<131:59:26,  1.13it/s, v_num=full, train/loss_step=26.00]Epoch 0:   0%|          | 5/535957 [00:04<132:00:46,  1.13it/s, v_num=full, train/loss_step=30.00]Epoch 0:   0%|          | 6/535957 [00:05<124:47:56,  1.19it/s, v_num=full, train/loss_step=30.00]Epoch 0:   0%|          | 6/535957 [00:05<124:49:01,  1.19it/s, v_num=full, train/loss_step=30.80]Epoch 0:   0%|          | 7/535957 [00:05<119:39:42,  1.24it/s, v_num=full, train/loss_step=30.80]Epoch 0:   0%|          | 7/535957 [00:05<119:41:12,  1.24it/s, v_num=full, train/loss_step=33.90]Epoch 0:   0%|          | 8/535957 [00:06<115:46:36,  1.29it/s, v_num=full, train/loss_step=33.90]Epoch 0:   0%|          | 8/535957 [00:06<115:47:24,  1.29it/s, v_num=full, train/loss_step=26.10]Epoch 0:   0%|          | 9/535957 [00:06<112:42:30,  1.32it/s, v_num=full, train/loss_step=26.10]Epoch 0:   0%|          | 9/535957 [00:06<112:43:14,  1.32it/s, v_num=full, train/loss_step=28.10]Epoch 0:   0%|          | 10/535957 [00:07<110:16:41,  1.35it/s, v_num=full, train/loss_step=28.10]Epoch 0:   0%|          | 10/535957 [00:07<110:17:19,  1.35it/s, v_num=full, train/loss_step=23.50]
============================================================
Global Step 10
============================================================

[Losses]
  language_loss: 0.094116 (shape: torch.Size([4, 547]), count: 28)
  route_loss: 11.351562 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 9.664062 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 11/535957 [00:07<108:15:23,  1.38it/s, v_num=full, train/loss_step=23.50]Epoch 0:   0%|          | 11/535957 [00:07<108:15:50,  1.38it/s, v_num=full, train/loss_step=28.40]Epoch 0:   0%|          | 12/535957 [00:08<106:33:45,  1.40it/s, v_num=full, train/loss_step=28.40]Epoch 0:   0%|          | 12/535957 [00:08<106:34:16,  1.40it/s, v_num=full, train/loss_step=28.40]Epoch 0:   0%|          | 13/535957 [00:09<105:06:27,  1.42it/s, v_num=full, train/loss_step=28.40]Epoch 0:   0%|          | 13/535957 [00:09<105:06:57,  1.42it/s, v_num=full, train/loss_step=29.50]Epoch 0:   0%|          | 14/535957 [00:09<103:31:27,  1.44it/s, v_num=full, train/loss_step=29.50]Epoch 0:   0%|          | 14/535957 [00:09<103:31:55,  1.44it/s, v_num=full, train/loss_step=26.90]Epoch 0:   0%|          | 15/535957 [00:10<102:13:47,  1.46it/s, v_num=full, train/loss_step=26.90]Epoch 0:   0%|          | 15/535957 [00:10<102:14:09,  1.46it/s, v_num=full, train/loss_step=24.90]Epoch 0:   0%|          | 16/535957 [00:10<101:06:26,  1.47it/s, v_num=full, train/loss_step=24.90]Epoch 0:   0%|          | 16/535957 [00:10<101:06:47,  1.47it/s, v_num=full, train/loss_step=23.50]Epoch 0:   0%|          | 17/535957 [00:11<100:03:17,  1.49it/s, v_num=full, train/loss_step=23.50]Epoch 0:   0%|          | 17/535957 [00:11<100:03:41,  1.49it/s, v_num=full, train/loss_step=22.50]Epoch 0:   0%|          | 18/535957 [00:11<99:10:28,  1.50it/s, v_num=full, train/loss_step=22.50] Epoch 0:   0%|          | 18/535957 [00:11<99:10:45,  1.50it/s, v_num=full, train/loss_step=29.20]Epoch 0:   0%|          | 19/535957 [00:12<98:26:06,  1.51it/s, v_num=full, train/loss_step=29.20]Epoch 0:   0%|          | 19/535957 [00:12<98:26:32,  1.51it/s, v_num=full, train/loss_step=27.70]Epoch 0:   0%|          | 20/535957 [00:13<97:47:18,  1.52it/s, v_num=full, train/loss_step=27.70]Epoch 0:   0%|          | 20/535957 [00:13<97:47:41,  1.52it/s, v_num=full, train/loss_step=20.80]
============================================================
Global Step 20
============================================================

[Losses]
  language_loss: 0.082825 (shape: torch.Size([4, 562]), count: 28)
  route_loss: 8.750000 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 6.757812 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 21/535957 [00:13<97:12:43,  1.53it/s, v_num=full, train/loss_step=20.80]Epoch 0:   0%|          | 21/535957 [00:13<97:13:03,  1.53it/s, v_num=full, train/loss_step=22.20]Epoch 0:   0%|          | 22/535957 [00:14<96:37:15,  1.54it/s, v_num=full, train/loss_step=22.20]Epoch 0:   0%|          | 22/535957 [00:14<96:37:29,  1.54it/s, v_num=full, train/loss_step=19.20]Epoch 0:   0%|          | 23/535957 [00:14<96:02:00,  1.55it/s, v_num=full, train/loss_step=19.20]Epoch 0:   0%|          | 23/535957 [00:14<96:02:19,  1.55it/s, v_num=full, train/loss_step=20.60]Epoch 0:   0%|          | 24/535957 [00:15<95:32:59,  1.56it/s, v_num=full, train/loss_step=20.60]Epoch 0:   0%|          | 24/535957 [00:15<95:33:15,  1.56it/s, v_num=full, train/loss_step=20.40]Epoch 0:   0%|          | 25/535957 [00:16<95:25:20,  1.56it/s, v_num=full, train/loss_step=20.40]Epoch 0:   0%|          | 25/535957 [00:16<95:25:34,  1.56it/s, v_num=full, train/loss_step=19.80]Epoch 0:   0%|          | 26/535957 [00:16<95:04:24,  1.57it/s, v_num=full, train/loss_step=19.80]Epoch 0:   0%|          | 26/535957 [00:16<95:04:38,  1.57it/s, v_num=full, train/loss_step=19.20]Epoch 0:   0%|          | 27/535957 [00:17<94:39:49,  1.57it/s, v_num=full, train/loss_step=19.20]Epoch 0:   0%|          | 27/535957 [00:17<94:40:01,  1.57it/s, v_num=full, train/loss_step=24.90]Epoch 0:   0%|          | 28/535957 [00:17<94:15:37,  1.58it/s, v_num=full, train/loss_step=24.90]Epoch 0:   0%|          | 28/535957 [00:17<94:15:48,  1.58it/s, v_num=full, train/loss_step=21.30]Epoch 0:   0%|          | 29/535957 [00:18<93:55:15,  1.59it/s, v_num=full, train/loss_step=21.30]Epoch 0:   0%|          | 29/535957 [00:18<93:55:25,  1.58it/s, v_num=full, train/loss_step=20.00]Epoch 0:   0%|          | 30/535957 [00:18<93:34:23,  1.59it/s, v_num=full, train/loss_step=20.00]Epoch 0:   0%|          | 30/535957 [00:18<93:34:33,  1.59it/s, v_num=full, train/loss_step=19.80]
============================================================
Global Step 30
============================================================

[Losses]
  language_loss: 0.073608 (shape: torch.Size([4, 561]), count: 28)
  route_loss: 5.875000 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 10.382812 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 31/535957 [00:19<93:16:58,  1.60it/s, v_num=full, train/loss_step=19.80]Epoch 0:   0%|          | 31/535957 [00:19<93:17:07,  1.60it/s, v_num=full, train/loss_step=22.20]Epoch 0:   0%|          | 32/535957 [00:19<92:59:59,  1.60it/s, v_num=full, train/loss_step=22.20]Epoch 0:   0%|          | 32/535957 [00:19<93:00:12,  1.60it/s, v_num=full, train/loss_step=26.00]Epoch 0:   0%|          | 33/535957 [00:20<92:41:43,  1.61it/s, v_num=full, train/loss_step=26.00]Epoch 0:   0%|          | 33/535957 [00:20<92:41:54,  1.61it/s, v_num=full, train/loss_step=15.20]Epoch 0:   0%|          | 34/535957 [00:21<92:26:04,  1.61it/s, v_num=full, train/loss_step=15.20]Epoch 0:   0%|          | 34/535957 [00:21<92:26:15,  1.61it/s, v_num=full, train/loss_step=18.50]Epoch 0:   0%|          | 35/535957 [00:21<92:08:49,  1.62it/s, v_num=full, train/loss_step=18.50]Epoch 0:   0%|          | 35/535957 [00:21<92:08:59,  1.62it/s, v_num=full, train/loss_step=22.10]Epoch 0:   0%|          | 36/535957 [00:22<91:53:08,  1.62it/s, v_num=full, train/loss_step=22.10]Epoch 0:   0%|          | 36/535957 [00:22<91:53:20,  1.62it/s, v_num=full, train/loss_step=16.20]Epoch 0:   0%|          | 37/535957 [00:22<91:39:00,  1.62it/s, v_num=full, train/loss_step=16.20]Epoch 0:   0%|          | 37/535957 [00:22<91:39:11,  1.62it/s, v_num=full, train/loss_step=13.70]Epoch 0:   0%|          | 38/535957 [00:23<91:24:31,  1.63it/s, v_num=full, train/loss_step=13.70]Epoch 0:   0%|          | 38/535957 [00:23<91:24:42,  1.63it/s, v_num=full, train/loss_step=15.50]Epoch 0:   0%|          | 39/535957 [00:23<91:10:36,  1.63it/s, v_num=full, train/loss_step=15.50]Epoch 0:   0%|          | 39/535957 [00:23<91:10:47,  1.63it/s, v_num=full, train/loss_step=16.10]Epoch 0:   0%|          | 40/535957 [00:24<90:58:41,  1.64it/s, v_num=full, train/loss_step=16.10]Epoch 0:   0%|          | 40/535957 [00:24<90:58:51,  1.64it/s, v_num=full, train/loss_step=21.10]
============================================================
Global Step 40
============================================================

[Losses]
  language_loss: 0.058777 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 2.677734 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 12.226562 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 41/535957 [00:25<90:46:57,  1.64it/s, v_num=full, train/loss_step=21.10]Epoch 0:   0%|          | 41/535957 [00:25<90:47:06,  1.64it/s, v_num=full, train/loss_step=19.60]Epoch 0:   0%|          | 42/535957 [00:25<90:36:31,  1.64it/s, v_num=full, train/loss_step=19.60]Epoch 0:   0%|          | 42/535957 [00:25<90:36:40,  1.64it/s, v_num=full, train/loss_step=16.80]Epoch 0:   0%|          | 43/535957 [00:26<90:25:50,  1.65it/s, v_num=full, train/loss_step=16.80]Epoch 0:   0%|          | 43/535957 [00:26<90:25:58,  1.65it/s, v_num=full, train/loss_step=12.30]Epoch 0:   0%|          | 44/535957 [00:26<90:16:17,  1.65it/s, v_num=full, train/loss_step=12.30]Epoch 0:   0%|          | 44/535957 [00:26<90:16:26,  1.65it/s, v_num=full, train/loss_step=14.20]Epoch 0:   0%|          | 45/535957 [00:27<90:07:08,  1.65it/s, v_num=full, train/loss_step=14.20]Epoch 0:   0%|          | 45/535957 [00:27<90:07:18,  1.65it/s, v_num=full, train/loss_step=13.10]Epoch 0:   0%|          | 46/535957 [00:27<89:58:13,  1.65it/s, v_num=full, train/loss_step=13.10]Epoch 0:   0%|          | 46/535957 [00:27<89:58:22,  1.65it/s, v_num=full, train/loss_step=12.40]Epoch 0:   0%|          | 47/535957 [00:28<89:50:37,  1.66it/s, v_num=full, train/loss_step=12.40]Epoch 0:   0%|          | 47/535957 [00:28<89:50:45,  1.66it/s, v_num=full, train/loss_step=11.20]Epoch 0:   0%|          | 48/535957 [00:28<89:42:41,  1.66it/s, v_num=full, train/loss_step=11.20]Epoch 0:   0%|          | 48/535957 [00:28<89:42:49,  1.66it/s, v_num=full, train/loss_step=20.80]Epoch 0:   0%|          | 49/535957 [00:29<89:35:36,  1.66it/s, v_num=full, train/loss_step=20.80]Epoch 0:   0%|          | 49/535957 [00:29<89:35:44,  1.66it/s, v_num=full, train/loss_step=12.40]Epoch 0:   0%|          | 50/535957 [00:30<89:28:45,  1.66it/s, v_num=full, train/loss_step=12.40]Epoch 0:   0%|          | 50/535957 [00:30<89:28:53,  1.66it/s, v_num=full, train/loss_step=14.30]
============================================================
Global Step 50
============================================================

[Losses]
  language_loss: 0.052979 (shape: torch.Size([4, 553]), count: 28)
  route_loss: 2.259766 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 9.859375 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 51/535957 [00:30<89:23:27,  1.67it/s, v_num=full, train/loss_step=14.30]Epoch 0:   0%|          | 51/535957 [00:30<89:23:33,  1.67it/s, v_num=full, train/loss_step=16.30]Epoch 0:   0%|          | 52/535957 [00:31<89:15:59,  1.67it/s, v_num=full, train/loss_step=16.30]Epoch 0:   0%|          | 52/535957 [00:31<89:16:07,  1.67it/s, v_num=full, train/loss_step=12.20]Epoch 0:   0%|          | 53/535957 [00:31<89:09:23,  1.67it/s, v_num=full, train/loss_step=12.20]Epoch 0:   0%|          | 53/535957 [00:31<89:09:30,  1.67it/s, v_num=full, train/loss_step=13.90]Epoch 0:   0%|          | 54/535957 [00:32<89:02:09,  1.67it/s, v_num=full, train/loss_step=13.90]Epoch 0:   0%|          | 54/535957 [00:32<89:02:16,  1.67it/s, v_num=full, train/loss_step=10.20]Epoch 0:   0%|          | 55/535957 [00:32<88:56:47,  1.67it/s, v_num=full, train/loss_step=10.20]Epoch 0:   0%|          | 55/535957 [00:32<88:56:54,  1.67it/s, v_num=full, train/loss_step=10.10]Epoch 0:   0%|          | 56/535957 [00:33<88:50:43,  1.68it/s, v_num=full, train/loss_step=10.10]Epoch 0:   0%|          | 56/535957 [00:33<88:50:50,  1.68it/s, v_num=full, train/loss_step=11.20]Epoch 0:   0%|          | 57/535957 [00:33<88:45:31,  1.68it/s, v_num=full, train/loss_step=11.20]Epoch 0:   0%|          | 57/535957 [00:33<88:45:38,  1.68it/s, v_num=full, train/loss_step=12.90]Epoch 0:   0%|          | 58/535957 [00:34<88:39:55,  1.68it/s, v_num=full, train/loss_step=12.90]Epoch 0:   0%|          | 58/535957 [00:34<88:40:01,  1.68it/s, v_num=full, train/loss_step=11.00]Epoch 0:   0%|          | 59/535957 [00:35<88:33:56,  1.68it/s, v_num=full, train/loss_step=11.00]Epoch 0:   0%|          | 59/535957 [00:35<88:34:03,  1.68it/s, v_num=full, train/loss_step=16.00]Epoch 0:   0%|          | 60/535957 [00:35<88:29:13,  1.68it/s, v_num=full, train/loss_step=16.00]Epoch 0:   0%|          | 60/535957 [00:35<88:29:20,  1.68it/s, v_num=full, train/loss_step=8.730]
============================================================
Global Step 60
============================================================

[Losses]
  language_loss: 0.045349 (shape: torch.Size([4, 546]), count: 28)
  route_loss: 0.976562 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 5.792969 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 61/535957 [00:36<88:23:55,  1.68it/s, v_num=full, train/loss_step=8.730]Epoch 0:   0%|          | 61/535957 [00:36<88:23:59,  1.68it/s, v_num=full, train/loss_step=10.30]Epoch 0:   0%|          | 62/535957 [00:36<88:18:41,  1.69it/s, v_num=full, train/loss_step=10.30]Epoch 0:   0%|          | 62/535957 [00:36<88:18:46,  1.69it/s, v_num=full, train/loss_step=8.710]Epoch 0:   0%|          | 63/535957 [00:37<88:13:25,  1.69it/s, v_num=full, train/loss_step=8.710]Epoch 0:   0%|          | 63/535957 [00:37<88:13:30,  1.69it/s, v_num=full, train/loss_step=12.40]Epoch 0:   0%|          | 64/535957 [00:37<88:08:22,  1.69it/s, v_num=full, train/loss_step=12.40]Epoch 0:   0%|          | 64/535957 [00:37<88:08:28,  1.69it/s, v_num=full, train/loss_step=11.60]Epoch 0:   0%|          | 65/535957 [00:38<88:03:23,  1.69it/s, v_num=full, train/loss_step=11.60]Epoch 0:   0%|          | 65/535957 [00:38<88:03:29,  1.69it/s, v_num=full, train/loss_step=9.410]Epoch 0:   0%|          | 66/535957 [00:39<87:59:40,  1.69it/s, v_num=full, train/loss_step=9.410]Epoch 0:   0%|          | 66/535957 [00:39<87:59:46,  1.69it/s, v_num=full, train/loss_step=13.90]Epoch 0:   0%|          | 67/535957 [00:39<87:56:05,  1.69it/s, v_num=full, train/loss_step=13.90]Epoch 0:   0%|          | 67/535957 [00:39<87:56:11,  1.69it/s, v_num=full, train/loss_step=10.10]Epoch 0:   0%|          | 68/535957 [00:40<87:51:55,  1.69it/s, v_num=full, train/loss_step=10.10]Epoch 0:   0%|          | 68/535957 [00:40<87:52:00,  1.69it/s, v_num=full, train/loss_step=12.00]Epoch 0:   0%|          | 69/535957 [00:40<87:47:53,  1.70it/s, v_num=full, train/loss_step=12.00]Epoch 0:   0%|          | 69/535957 [00:40<87:47:59,  1.70it/s, v_num=full, train/loss_step=14.40]Epoch 0:   0%|          | 70/535957 [00:41<87:44:17,  1.70it/s, v_num=full, train/loss_step=14.40]Epoch 0:   0%|          | 70/535957 [00:41<87:44:22,  1.70it/s, v_num=full, train/loss_step=14.40]
============================================================
Global Step 70
============================================================

[Losses]
  language_loss: 0.036591 (shape: torch.Size([4, 559]), count: 28)
  route_loss: 1.794922 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 6.359375 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 71/535957 [00:41<87:40:41,  1.70it/s, v_num=full, train/loss_step=14.40]Epoch 0:   0%|          | 71/535957 [00:41<87:40:47,  1.70it/s, v_num=full, train/loss_step=11.10]Epoch 0:   0%|          | 72/535957 [00:42<87:37:08,  1.70it/s, v_num=full, train/loss_step=11.10]Epoch 0:   0%|          | 72/535957 [00:42<87:37:13,  1.70it/s, v_num=full, train/loss_step=13.60]Epoch 0:   0%|          | 73/535957 [00:42<87:33:25,  1.70it/s, v_num=full, train/loss_step=13.60]Epoch 0:   0%|          | 73/535957 [00:42<87:33:30,  1.70it/s, v_num=full, train/loss_step=11.50]Epoch 0:   0%|          | 74/535957 [00:43<87:29:59,  1.70it/s, v_num=full, train/loss_step=11.50]Epoch 0:   0%|          | 74/535957 [00:43<87:30:05,  1.70it/s, v_num=full, train/loss_step=7.020]Epoch 0:   0%|          | 75/535957 [00:44<87:26:33,  1.70it/s, v_num=full, train/loss_step=7.020]Epoch 0:   0%|          | 75/535957 [00:44<87:26:39,  1.70it/s, v_num=full, train/loss_step=13.40]Epoch 0:   0%|          | 76/535957 [00:44<87:23:21,  1.70it/s, v_num=full, train/loss_step=13.40]Epoch 0:   0%|          | 76/535957 [00:44<87:23:26,  1.70it/s, v_num=full, train/loss_step=11.90]Epoch 0:   0%|          | 77/535957 [00:45<87:20:14,  1.70it/s, v_num=full, train/loss_step=11.90]Epoch 0:   0%|          | 77/535957 [00:45<87:20:19,  1.70it/s, v_num=full, train/loss_step=10.50]Epoch 0:   0%|          | 78/535957 [00:45<87:17:02,  1.71it/s, v_num=full, train/loss_step=10.50]Epoch 0:   0%|          | 78/535957 [00:45<87:17:06,  1.71it/s, v_num=full, train/loss_step=8.000]Epoch 0:   0%|          | 79/535957 [00:46<87:13:42,  1.71it/s, v_num=full, train/loss_step=8.000]Epoch 0:   0%|          | 79/535957 [00:46<87:13:47,  1.71it/s, v_num=full, train/loss_step=15.50]Epoch 0:   0%|          | 80/535957 [00:46<87:10:56,  1.71it/s, v_num=full, train/loss_step=15.50]Epoch 0:   0%|          | 80/535957 [00:46<87:11:00,  1.71it/s, v_num=full, train/loss_step=8.940]
============================================================
Global Step 80
============================================================

[Losses]
  language_loss: 0.032776 (shape: torch.Size([4, 546]), count: 28)
  route_loss: 2.541016 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 6.398438 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 81/535957 [00:47<87:08:24,  1.71it/s, v_num=full, train/loss_step=8.940]Epoch 0:   0%|          | 81/535957 [00:47<87:08:29,  1.71it/s, v_num=full, train/loss_step=11.50]Epoch 0:   0%|          | 82/535957 [00:47<87:05:22,  1.71it/s, v_num=full, train/loss_step=11.50]Epoch 0:   0%|          | 82/535957 [00:47<87:05:26,  1.71it/s, v_num=full, train/loss_step=10.90]Epoch 0:   0%|          | 83/535957 [00:48<87:03:27,  1.71it/s, v_num=full, train/loss_step=10.90]Epoch 0:   0%|          | 83/535957 [00:48<87:03:31,  1.71it/s, v_num=full, train/loss_step=9.450]Epoch 0:   0%|          | 84/535957 [00:49<87:00:46,  1.71it/s, v_num=full, train/loss_step=9.450]Epoch 0:   0%|          | 84/535957 [00:49<87:00:51,  1.71it/s, v_num=full, train/loss_step=10.10]Epoch 0:   0%|          | 85/535957 [00:49<86:58:39,  1.71it/s, v_num=full, train/loss_step=10.10]Epoch 0:   0%|          | 85/535957 [00:49<86:58:44,  1.71it/s, v_num=full, train/loss_step=10.60]Epoch 0:   0%|          | 86/535957 [00:50<86:56:51,  1.71it/s, v_num=full, train/loss_step=10.60]Epoch 0:   0%|          | 86/535957 [00:50<86:56:54,  1.71it/s, v_num=full, train/loss_step=10.10]Epoch 0:   0%|          | 87/535957 [00:50<86:54:29,  1.71it/s, v_num=full, train/loss_step=10.10]Epoch 0:   0%|          | 87/535957 [00:50<86:54:33,  1.71it/s, v_num=full, train/loss_step=10.90]Epoch 0:   0%|          | 88/535957 [00:51<86:52:21,  1.71it/s, v_num=full, train/loss_step=10.90]Epoch 0:   0%|          | 88/535957 [00:51<86:52:24,  1.71it/s, v_num=full, train/loss_step=10.70]Epoch 0:   0%|          | 89/535957 [00:51<86:50:31,  1.71it/s, v_num=full, train/loss_step=10.70]Epoch 0:   0%|          | 89/535957 [00:51<86:50:36,  1.71it/s, v_num=full, train/loss_step=9.890]Epoch 0:   0%|          | 90/535957 [00:52<86:48:36,  1.71it/s, v_num=full, train/loss_step=9.890]Epoch 0:   0%|          | 90/535957 [00:52<86:48:40,  1.71it/s, v_num=full, train/loss_step=16.30]
============================================================
Global Step 90
============================================================

[Losses]
  language_loss: 0.027206 (shape: torch.Size([4, 554]), count: 28)
  route_loss: 1.083008 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 6.601562 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 91/535957 [00:53<86:46:20,  1.72it/s, v_num=full, train/loss_step=16.30]Epoch 0:   0%|          | 91/535957 [00:53<86:46:23,  1.72it/s, v_num=full, train/loss_step=9.840]Epoch 0:   0%|          | 92/535957 [00:53<86:44:00,  1.72it/s, v_num=full, train/loss_step=9.840]Epoch 0:   0%|          | 92/535957 [00:53<86:44:04,  1.72it/s, v_num=full, train/loss_step=10.50]Epoch 0:   0%|          | 93/535957 [00:54<86:41:43,  1.72it/s, v_num=full, train/loss_step=10.50]Epoch 0:   0%|          | 93/535957 [00:54<86:41:47,  1.72it/s, v_num=full, train/loss_step=9.770]Epoch 0:   0%|          | 94/535957 [00:54<86:40:06,  1.72it/s, v_num=full, train/loss_step=9.770]Epoch 0:   0%|          | 94/535957 [00:54<86:40:09,  1.72it/s, v_num=full, train/loss_step=6.940]Epoch 0:   0%|          | 95/535957 [00:55<86:37:53,  1.72it/s, v_num=full, train/loss_step=6.940]Epoch 0:   0%|          | 95/535957 [00:55<86:37:56,  1.72it/s, v_num=full, train/loss_step=8.320]Epoch 0:   0%|          | 96/535957 [00:55<86:35:55,  1.72it/s, v_num=full, train/loss_step=8.320]Epoch 0:   0%|          | 96/535957 [00:55<86:35:58,  1.72it/s, v_num=full, train/loss_step=7.050]Epoch 0:   0%|          | 97/535957 [00:56<86:33:48,  1.72it/s, v_num=full, train/loss_step=7.050]Epoch 0:   0%|          | 97/535957 [00:56<86:33:53,  1.72it/s, v_num=full, train/loss_step=7.180]Epoch 0:   0%|          | 98/535957 [00:56<86:31:50,  1.72it/s, v_num=full, train/loss_step=7.180]Epoch 0:   0%|          | 98/535957 [00:56<86:31:54,  1.72it/s, v_num=full, train/loss_step=14.00]Epoch 0:   0%|          | 99/535957 [00:57<86:29:54,  1.72it/s, v_num=full, train/loss_step=14.00]Epoch 0:   0%|          | 99/535957 [00:57<86:29:58,  1.72it/s, v_num=full, train/loss_step=3.910]Epoch 0:   0%|          | 100/535957 [01:09<103:44:57,  1.43it/s, v_num=full, train/loss_step=3.910]Epoch 0:   0%|          | 100/535957 [01:09<103:45:03,  1.43it/s, v_num=full, train/loss_step=5.980]
============================================================
[Input Before LLM] - Global Step 100
============================================================
  Adaptor embeddings shape: torch.Size([4, 589, 896])
  Input embeddings shape: torch.Size([4, 589, 896])
  Attention mask shape: torch.Size([4, 589])
  Input dtype: torch.float16
  Adaptor embeddings range: [-7.6992, 8.7500]
  Input embeddings range: [-7.6992, 8.7500]
  Input embeddings mean: 0.0048, std: 0.7598
  Language inputs shape: torch.Size([4, 559, 896])

============================================================
Global Step 100
============================================================

[Losses]
  language_loss: 0.018768 (shape: torch.Size([4, 558]), count: 28)
  route_loss: 1.346680 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 9.046875 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 101/535957 [01:10<103:38:22,  1.44it/s, v_num=full, train/loss_step=5.980]Epoch 0:   0%|          | 101/535957 [01:10<103:38:25,  1.44it/s, v_num=full, train/loss_step=11.90]Epoch 0:   0%|          | 102/535957 [01:10<103:26:23,  1.44it/s, v_num=full, train/loss_step=11.90]Epoch 0:   0%|          | 102/535957 [01:10<103:26:26,  1.44it/s, v_num=full, train/loss_step=11.20]Epoch 0:   0%|          | 103/535957 [01:11<103:13:30,  1.44it/s, v_num=full, train/loss_step=11.20]Epoch 0:   0%|          | 103/535957 [01:11<103:13:33,  1.44it/s, v_num=full, train/loss_step=7.270]Epoch 0:   0%|          | 104/535957 [01:11<103:01:23,  1.44it/s, v_num=full, train/loss_step=7.270]Epoch 0:   0%|          | 104/535957 [01:11<103:01:27,  1.44it/s, v_num=full, train/loss_step=10.20]Epoch 0:   0%|          | 105/535957 [01:12<102:50:01,  1.45it/s, v_num=full, train/loss_step=10.20]Epoch 0:   0%|          | 105/535957 [01:12<102:50:05,  1.45it/s, v_num=full, train/loss_step=11.90]Epoch 0:   0%|          | 106/535957 [01:13<102:39:00,  1.45it/s, v_num=full, train/loss_step=11.90]Epoch 0:   0%|          | 106/535957 [01:13<102:39:03,  1.45it/s, v_num=full, train/loss_step=6.960]Epoch 0:   0%|          | 107/535957 [01:13<102:28:15,  1.45it/s, v_num=full, train/loss_step=6.960]Epoch 0:   0%|          | 107/535957 [01:13<102:28:19,  1.45it/s, v_num=full, train/loss_step=18.50]Epoch 0:   0%|          | 108/535957 [01:14<102:17:28,  1.46it/s, v_num=full, train/loss_step=18.50]Epoch 0:   0%|          | 108/535957 [01:14<102:17:32,  1.46it/s, v_num=full, train/loss_step=10.70]Epoch 0:   0%|          | 109/535957 [01:14<102:07:11,  1.46it/s, v_num=full, train/loss_step=10.70]Epoch 0:   0%|          | 109/535957 [01:14<102:07:14,  1.46it/s, v_num=full, train/loss_step=17.40]Epoch 0:   0%|          | 110/535957 [01:15<101:57:07,  1.46it/s, v_num=full, train/loss_step=17.40]Epoch 0:   0%|          | 110/535957 [01:15<101:57:09,  1.46it/s, v_num=full, train/loss_step=11.60]
============================================================
Global Step 110
============================================================

[Losses]
  language_loss: 0.021118 (shape: torch.Size([4, 552]), count: 28)
  route_loss: 3.085938 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 11.625000 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 111/535957 [01:15<101:46:46,  1.46it/s, v_num=full, train/loss_step=11.60]Epoch 0:   0%|          | 111/535957 [01:15<101:46:49,  1.46it/s, v_num=full, train/loss_step=16.40]Epoch 0:   0%|          | 112/535957 [01:16<101:37:08,  1.46it/s, v_num=full, train/loss_step=16.40]Epoch 0:   0%|          | 112/535957 [01:16<101:37:11,  1.46it/s, v_num=full, train/loss_step=17.00]Epoch 0:   0%|          | 113/535957 [01:17<101:27:38,  1.47it/s, v_num=full, train/loss_step=17.00]Epoch 0:   0%|          | 113/535957 [01:17<101:27:41,  1.47it/s, v_num=full, train/loss_step=7.780]Epoch 0:   0%|          | 114/535957 [01:17<101:17:30,  1.47it/s, v_num=full, train/loss_step=7.780]Epoch 0:   0%|          | 114/535957 [01:19<104:07:05,  1.43it/s, v_num=full, train/loss_step=7.140]Epoch 0:   0%|          | 115/535957 [01:22<107:06:33,  1.39it/s, v_num=full, train/loss_step=7.140]Epoch 0:   0%|          | 115/535957 [01:22<107:06:35,  1.39it/s, v_num=full, train/loss_step=14.30]Epoch 0:   0%|          | 116/535957 [01:23<106:54:01,  1.39it/s, v_num=full, train/loss_step=14.30]Epoch 0:   0%|          | 116/535957 [01:23<106:54:04,  1.39it/s, v_num=full, train/loss_step=7.190]Epoch 0:   0%|          | 117/535957 [01:23<106:42:21,  1.39it/s, v_num=full, train/loss_step=7.190]Epoch 0:   0%|          | 117/535957 [01:23<106:42:25,  1.39it/s, v_num=full, train/loss_step=10.70]Epoch 0:   0%|          | 118/535957 [01:24<106:33:28,  1.40it/s, v_num=full, train/loss_step=10.70]Epoch 0:   0%|          | 118/535957 [01:24<106:33:32,  1.40it/s, v_num=full, train/loss_step=7.030]Epoch 0:   0%|          | 119/535957 [01:25<106:24:36,  1.40it/s, v_num=full, train/loss_step=7.030]Epoch 0:   0%|          | 119/535957 [01:25<106:24:39,  1.40it/s, v_num=full, train/loss_step=11.10]Epoch 0:   0%|          | 120/535957 [01:25<106:15:30,  1.40it/s, v_num=full, train/loss_step=11.10]Epoch 0:   0%|          | 120/535957 [01:25<106:15:33,  1.40it/s, v_num=full, train/loss_step=7.550]
============================================================
Global Step 120
============================================================

[Losses]
  language_loss: 0.014648 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 2.501953 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 9.109375 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 121/535957 [01:26<106:07:05,  1.40it/s, v_num=full, train/loss_step=7.550]Epoch 0:   0%|          | 121/535957 [01:26<106:07:08,  1.40it/s, v_num=full, train/loss_step=12.80]Epoch 0:   0%|          | 122/535957 [01:26<105:58:40,  1.40it/s, v_num=full, train/loss_step=12.80]Epoch 0:   0%|          | 122/535957 [01:26<105:58:43,  1.40it/s, v_num=full, train/loss_step=6.770]Epoch 0:   0%|          | 123/535957 [01:27<105:50:15,  1.41it/s, v_num=full, train/loss_step=6.770]Epoch 0:   0%|          | 123/535957 [01:27<105:50:18,  1.41it/s, v_num=full, train/loss_step=5.960]Epoch 0:   0%|          | 124/535957 [01:28<105:43:09,  1.41it/s, v_num=full, train/loss_step=5.960]Epoch 0:   0%|          | 124/535957 [01:28<105:43:12,  1.41it/s, v_num=full, train/loss_step=5.190]Epoch 0:   0%|          | 125/535957 [01:28<105:34:44,  1.41it/s, v_num=full, train/loss_step=5.190]Epoch 0:   0%|          | 125/535957 [01:28<105:34:47,  1.41it/s, v_num=full, train/loss_step=8.930]Epoch 0:   0%|          | 126/535957 [01:29<105:25:53,  1.41it/s, v_num=full, train/loss_step=8.930]Epoch 0:   0%|          | 126/535957 [01:29<105:25:57,  1.41it/s, v_num=full, train/loss_step=11.70]Epoch 0:   0%|          | 127/535957 [01:29<105:17:40,  1.41it/s, v_num=full, train/loss_step=11.70]Epoch 0:   0%|          | 127/535957 [01:29<105:17:43,  1.41it/s, v_num=full, train/loss_step=8.880]Epoch 0:   0%|          | 128/535957 [01:30<105:08:48,  1.42it/s, v_num=full, train/loss_step=8.880]Epoch 0:   0%|          | 128/535957 [01:30<105:08:51,  1.42it/s, v_num=full, train/loss_step=7.340]Epoch 0:   0%|          | 129/535957 [01:31<105:00:21,  1.42it/s, v_num=full, train/loss_step=7.340]Epoch 0:   0%|          | 129/535957 [01:31<105:00:24,  1.42it/s, v_num=full, train/loss_step=10.00]Epoch 0:   0%|          | 130/535957 [01:31<104:52:11,  1.42it/s, v_num=full, train/loss_step=10.00]Epoch 0:   0%|          | 130/535957 [01:31<104:52:14,  1.42it/s, v_num=full, train/loss_step=14.80]
============================================================
Global Step 130
============================================================

[Losses]
  language_loss: 0.009521 (shape: torch.Size([4, 549]), count: 28)
  route_loss: 0.957520 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 2.935547 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 131/535957 [01:32<104:44:05,  1.42it/s, v_num=full, train/loss_step=14.80]Epoch 0:   0%|          | 131/535957 [01:32<104:44:08,  1.42it/s, v_num=full, train/loss_step=4.640]Epoch 0:   0%|          | 132/535957 [01:32<104:35:52,  1.42it/s, v_num=full, train/loss_step=4.640]Epoch 0:   0%|          | 132/535957 [01:32<104:35:54,  1.42it/s, v_num=full, train/loss_step=6.340]Epoch 0:   0%|          | 133/535957 [01:33<104:28:13,  1.42it/s, v_num=full, train/loss_step=6.340]Epoch 0:   0%|          | 133/535957 [01:33<104:28:16,  1.42it/s, v_num=full, train/loss_step=11.70]Epoch 0:   0%|          | 134/535957 [01:33<104:20:35,  1.43it/s, v_num=full, train/loss_step=11.70]Epoch 0:   0%|          | 134/535957 [01:33<104:20:37,  1.43it/s, v_num=full, train/loss_step=9.940]Epoch 0:   0%|          | 135/535957 [01:34<104:13:17,  1.43it/s, v_num=full, train/loss_step=9.940]Epoch 0:   0%|          | 135/535957 [01:34<104:13:19,  1.43it/s, v_num=full, train/loss_step=6.320]Epoch 0:   0%|          | 136/535957 [01:35<104:05:52,  1.43it/s, v_num=full, train/loss_step=6.320]Epoch 0:   0%|          | 136/535957 [01:35<104:05:54,  1.43it/s, v_num=full, train/loss_step=5.250]Epoch 0:   0%|          | 137/535957 [01:35<103:58:55,  1.43it/s, v_num=full, train/loss_step=5.250]Epoch 0:   0%|          | 137/535957 [01:35<103:58:57,  1.43it/s, v_num=full, train/loss_step=9.910]Epoch 0:   0%|          | 138/535957 [01:36<103:51:20,  1.43it/s, v_num=full, train/loss_step=9.910]Epoch 0:   0%|          | 138/535957 [01:36<103:51:22,  1.43it/s, v_num=full, train/loss_step=8.530]Epoch 0:   0%|          | 139/535957 [01:36<103:44:01,  1.43it/s, v_num=full, train/loss_step=8.530]Epoch 0:   0%|          | 139/535957 [01:36<103:44:04,  1.43it/s, v_num=full, train/loss_step=8.050]Epoch 0:   0%|          | 140/535957 [01:37<103:36:26,  1.44it/s, v_num=full, train/loss_step=8.050]Epoch 0:   0%|          | 140/535957 [01:37<103:36:29,  1.44it/s, v_num=full, train/loss_step=12.50]
============================================================
Global Step 140
============================================================

[Losses]
  language_loss: 0.008438 (shape: torch.Size([4, 556]), count: 28)
  route_loss: 2.189453 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 5.320312 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 141/535957 [01:38<103:29:11,  1.44it/s, v_num=full, train/loss_step=12.50]Epoch 0:   0%|          | 141/535957 [01:38<103:29:13,  1.44it/s, v_num=full, train/loss_step=8.180]Epoch 0:   0%|          | 142/535957 [01:38<103:22:51,  1.44it/s, v_num=full, train/loss_step=8.180]Epoch 0:   0%|          | 142/535957 [01:38<103:22:53,  1.44it/s, v_num=full, train/loss_step=10.40]Epoch 0:   0%|          | 143/535957 [01:39<103:16:22,  1.44it/s, v_num=full, train/loss_step=10.40]Epoch 0:   0%|          | 143/535957 [01:39<103:16:25,  1.44it/s, v_num=full, train/loss_step=7.330]Epoch 0:   0%|          | 144/535957 [01:39<103:09:51,  1.44it/s, v_num=full, train/loss_step=7.330]Epoch 0:   0%|          | 144/535957 [01:39<103:09:54,  1.44it/s, v_num=full, train/loss_step=6.720]Epoch 0:   0%|          | 145/535957 [01:40<103:03:48,  1.44it/s, v_num=full, train/loss_step=6.720]Epoch 0:   0%|          | 145/535957 [01:40<103:03:50,  1.44it/s, v_num=full, train/loss_step=5.380]Epoch 0:   0%|          | 146/535957 [01:40<102:57:32,  1.45it/s, v_num=full, train/loss_step=5.380]Epoch 0:   0%|          | 146/535957 [01:40<102:57:34,  1.45it/s, v_num=full, train/loss_step=7.610]Epoch 0:   0%|          | 147/535957 [01:41<102:51:13,  1.45it/s, v_num=full, train/loss_step=7.610]Epoch 0:   0%|          | 147/535957 [01:41<102:51:15,  1.45it/s, v_num=full, train/loss_step=8.460]Epoch 0:   0%|          | 148/535957 [01:42<102:44:58,  1.45it/s, v_num=full, train/loss_step=8.460]Epoch 0:   0%|          | 148/535957 [01:42<102:45:01,  1.45it/s, v_num=full, train/loss_step=8.000]Epoch 0:   0%|          | 149/535957 [01:42<102:39:32,  1.45it/s, v_num=full, train/loss_step=8.000]Epoch 0:   0%|          | 149/535957 [01:42<102:39:34,  1.45it/s, v_num=full, train/loss_step=6.450]Epoch 0:   0%|          | 150/535957 [01:43<102:34:21,  1.45it/s, v_num=full, train/loss_step=6.450]Epoch 0:   0%|          | 150/535957 [01:43<102:34:23,  1.45it/s, v_num=full, train/loss_step=8.240]
============================================================
Global Step 150
============================================================

[Losses]
  language_loss: 0.006721 (shape: torch.Size([4, 556]), count: 28)
  route_loss: 1.401367 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 5.273438 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 151/535957 [01:43<102:28:48,  1.45it/s, v_num=full, train/loss_step=8.240]Epoch 0:   0%|          | 151/535957 [01:43<102:28:51,  1.45it/s, v_num=full, train/loss_step=7.210]Epoch 0:   0%|          | 152/535957 [01:44<102:21:30,  1.45it/s, v_num=full, train/loss_step=7.210]Epoch 0:   0%|          | 152/535957 [01:44<102:21:33,  1.45it/s, v_num=full, train/loss_step=6.290]Epoch 0:   0%|          | 153/535957 [01:45<102:14:02,  1.46it/s, v_num=full, train/loss_step=6.290]Epoch 0:   0%|          | 153/535957 [01:45<102:14:04,  1.46it/s, v_num=full, train/loss_step=9.770]Epoch 0:   0%|          | 154/535957 [01:45<102:06:46,  1.46it/s, v_num=full, train/loss_step=9.770]Epoch 0:   0%|          | 154/535957 [01:45<102:06:48,  1.46it/s, v_num=full, train/loss_step=8.180]Epoch 0:   0%|          | 155/535957 [01:46<101:59:32,  1.46it/s, v_num=full, train/loss_step=8.180]Epoch 0:   0%|          | 155/535957 [01:46<101:59:35,  1.46it/s, v_num=full, train/loss_step=7.500]Epoch 0:   0%|          | 156/535957 [01:46<101:52:33,  1.46it/s, v_num=full, train/loss_step=7.500]Epoch 0:   0%|          | 156/535957 [01:46<101:52:35,  1.46it/s, v_num=full, train/loss_step=13.50]Epoch 0:   0%|          | 157/535957 [01:47<101:46:04,  1.46it/s, v_num=full, train/loss_step=13.50]Epoch 0:   0%|          | 157/535957 [01:47<101:46:06,  1.46it/s, v_num=full, train/loss_step=11.20]Epoch 0:   0%|          | 158/535957 [01:47<101:39:35,  1.46it/s, v_num=full, train/loss_step=11.20]Epoch 0:   0%|          | 158/535957 [01:47<101:39:38,  1.46it/s, v_num=full, train/loss_step=9.840]Epoch 0:   0%|          | 159/535957 [01:48<101:32:54,  1.47it/s, v_num=full, train/loss_step=9.840]Epoch 0:   0%|          | 159/535957 [01:48<101:32:56,  1.47it/s, v_num=full, train/loss_step=10.80]Epoch 0:   0%|          | 160/535957 [01:49<101:26:20,  1.47it/s, v_num=full, train/loss_step=10.80]Epoch 0:   0%|          | 160/535957 [01:49<101:26:22,  1.47it/s, v_num=full, train/loss_step=3.960]
============================================================
Global Step 160
============================================================

[Losses]
  language_loss: 0.004261 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 0.939453 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 1.994141 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 161/535957 [01:49<101:20:09,  1.47it/s, v_num=full, train/loss_step=3.960]Epoch 0:   0%|          | 161/535957 [01:49<101:20:12,  1.47it/s, v_num=full, train/loss_step=3.270]Epoch 0:   0%|          | 162/535957 [01:50<101:13:59,  1.47it/s, v_num=full, train/loss_step=3.270]Epoch 0:   0%|          | 162/535957 [01:50<101:14:02,  1.47it/s, v_num=full, train/loss_step=9.540]Epoch 0:   0%|          | 163/535957 [01:50<101:07:30,  1.47it/s, v_num=full, train/loss_step=9.540]Epoch 0:   0%|          | 163/535957 [01:50<101:07:32,  1.47it/s, v_num=full, train/loss_step=6.820]Epoch 0:   0%|          | 164/535957 [01:51<101:01:11,  1.47it/s, v_num=full, train/loss_step=6.820]Epoch 0:   0%|          | 164/535957 [01:51<101:01:13,  1.47it/s, v_num=full, train/loss_step=10.50]Epoch 0:   0%|          | 165/535957 [01:51<100:54:25,  1.47it/s, v_num=full, train/loss_step=10.50]Epoch 0:   0%|          | 165/535957 [01:51<100:54:27,  1.47it/s, v_num=full, train/loss_step=8.590]Epoch 0:   0%|          | 166/535957 [01:52<100:48:10,  1.48it/s, v_num=full, train/loss_step=8.590]Epoch 0:   0%|          | 166/535957 [01:52<100:48:12,  1.48it/s, v_num=full, train/loss_step=6.780]Epoch 0:   0%|          | 167/535957 [01:52<100:41:49,  1.48it/s, v_num=full, train/loss_step=6.780]Epoch 0:   0%|          | 167/535957 [01:52<100:41:51,  1.48it/s, v_num=full, train/loss_step=3.530]Epoch 0:   0%|          | 168/535957 [01:53<100:36:02,  1.48it/s, v_num=full, train/loss_step=3.530]Epoch 0:   0%|          | 168/535957 [01:53<100:36:03,  1.48it/s, v_num=full, train/loss_step=11.20]Epoch 0:   0%|          | 169/535957 [01:54<100:29:41,  1.48it/s, v_num=full, train/loss_step=11.20]Epoch 0:   0%|          | 169/535957 [01:54<100:29:43,  1.48it/s, v_num=full, train/loss_step=5.770]Epoch 0:   0%|          | 170/535957 [01:54<100:23:50,  1.48it/s, v_num=full, train/loss_step=5.770]Epoch 0:   0%|          | 170/535957 [01:54<100:23:53,  1.48it/s, v_num=full, train/loss_step=5.840]
============================================================
Global Step 170
============================================================

[Losses]
  language_loss: 0.002270 (shape: torch.Size([4, 552]), count: 28)
  route_loss: 0.329590 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 8.156250 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 171/535957 [01:55<100:18:08,  1.48it/s, v_num=full, train/loss_step=5.840]Epoch 0:   0%|          | 171/535957 [01:55<100:18:10,  1.48it/s, v_num=full, train/loss_step=8.660]Epoch 0:   0%|          | 172/535957 [01:55<100:12:18,  1.49it/s, v_num=full, train/loss_step=8.660]Epoch 0:   0%|          | 172/535957 [01:55<100:12:21,  1.49it/s, v_num=full, train/loss_step=3.580]Epoch 0:   0%|          | 173/535957 [01:56<100:06:43,  1.49it/s, v_num=full, train/loss_step=3.580]Epoch 0:   0%|          | 173/535957 [01:56<100:06:45,  1.49it/s, v_num=full, train/loss_step=14.80]Epoch 0:   0%|          | 174/535957 [01:56<100:01:03,  1.49it/s, v_num=full, train/loss_step=14.80]Epoch 0:   0%|          | 174/535957 [01:56<100:01:05,  1.49it/s, v_num=full, train/loss_step=4.780]Epoch 0:   0%|          | 175/535957 [01:57<99:55:29,  1.49it/s, v_num=full, train/loss_step=4.780] Epoch 0:   0%|          | 175/535957 [01:57<99:55:31,  1.49it/s, v_num=full, train/loss_step=3.540]Epoch 0:   0%|          | 176/535957 [01:58<99:49:36,  1.49it/s, v_num=full, train/loss_step=3.540]Epoch 0:   0%|          | 176/535957 [01:58<99:49:38,  1.49it/s, v_num=full, train/loss_step=5.930]Epoch 0:   0%|          | 177/535957 [01:58<99:44:25,  1.49it/s, v_num=full, train/loss_step=5.930]Epoch 0:   0%|          | 177/535957 [01:58<99:44:26,  1.49it/s, v_num=full, train/loss_step=8.280]Epoch 0:   0%|          | 178/535957 [01:59<99:38:58,  1.49it/s, v_num=full, train/loss_step=8.280]Epoch 0:   0%|          | 178/535957 [01:59<99:39:00,  1.49it/s, v_num=full, train/loss_step=4.360]Epoch 0:   0%|          | 179/535957 [01:59<99:33:23,  1.49it/s, v_num=full, train/loss_step=4.360]Epoch 0:   0%|          | 179/535957 [01:59<99:33:25,  1.49it/s, v_num=full, train/loss_step=6.570]Epoch 0:   0%|          | 180/535957 [02:00<99:45:13,  1.49it/s, v_num=full, train/loss_step=6.570]Epoch 0:   0%|          | 180/535957 [02:00<99:45:15,  1.49it/s, v_num=full, train/loss_step=6.420]
============================================================
Global Step 180
============================================================

[Losses]
  language_loss: 0.002352 (shape: torch.Size([4, 561]), count: 28)
  route_loss: 1.499023 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 5.292969 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 181/535957 [02:01<99:39:58,  1.49it/s, v_num=full, train/loss_step=6.420]Epoch 0:   0%|          | 181/535957 [02:01<99:40:01,  1.49it/s, v_num=full, train/loss_step=6.980]Epoch 0:   0%|          | 182/535957 [02:01<99:34:28,  1.49it/s, v_num=full, train/loss_step=6.980]Epoch 0:   0%|          | 182/535957 [02:01<99:34:31,  1.49it/s, v_num=full, train/loss_step=10.70]Epoch 0:   0%|          | 183/535957 [02:02<99:29:00,  1.50it/s, v_num=full, train/loss_step=10.70]Epoch 0:   0%|          | 183/535957 [02:02<99:29:02,  1.50it/s, v_num=full, train/loss_step=7.200]Epoch 0:   0%|          | 184/535957 [02:02<99:23:30,  1.50it/s, v_num=full, train/loss_step=7.200]Epoch 0:   0%|          | 184/535957 [02:02<99:23:32,  1.50it/s, v_num=full, train/loss_step=4.720]Epoch 0:   0%|          | 185/535957 [02:03<99:18:11,  1.50it/s, v_num=full, train/loss_step=4.720]Epoch 0:   0%|          | 185/535957 [02:03<99:18:13,  1.50it/s, v_num=full, train/loss_step=11.10]Epoch 0:   0%|          | 186/535957 [02:04<99:13:02,  1.50it/s, v_num=full, train/loss_step=11.10]Epoch 0:   0%|          | 186/535957 [02:04<99:13:04,  1.50it/s, v_num=full, train/loss_step=10.70]Epoch 0:   0%|          | 187/535957 [02:04<99:07:49,  1.50it/s, v_num=full, train/loss_step=10.70]Epoch 0:   0%|          | 187/535957 [02:04<99:07:50,  1.50it/s, v_num=full, train/loss_step=5.550]Epoch 0:   0%|          | 188/535957 [02:05<99:02:53,  1.50it/s, v_num=full, train/loss_step=5.550]Epoch 0:   0%|          | 188/535957 [02:05<99:02:54,  1.50it/s, v_num=full, train/loss_step=5.730]Epoch 0:   0%|          | 189/535957 [02:05<98:58:16,  1.50it/s, v_num=full, train/loss_step=5.730]Epoch 0:   0%|          | 189/535957 [02:05<98:58:23,  1.50it/s, v_num=full, train/loss_step=7.550]Epoch 0:   0%|          | 190/535957 [02:06<98:53:32,  1.50it/s, v_num=full, train/loss_step=7.550]Epoch 0:   0%|          | 190/535957 [02:06<98:53:34,  1.50it/s, v_num=full, train/loss_step=4.330]
============================================================
Global Step 190
============================================================

[Losses]
  language_loss: 0.001747 (shape: torch.Size([4, 547]), count: 28)
  route_loss: 2.367188 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.449219 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 191/535957 [02:06<98:48:58,  1.51it/s, v_num=full, train/loss_step=4.330]Epoch 0:   0%|          | 191/535957 [02:06<98:49:00,  1.51it/s, v_num=full, train/loss_step=6.950]Epoch 0:   0%|          | 192/535957 [02:07<98:44:03,  1.51it/s, v_num=full, train/loss_step=6.950]Epoch 0:   0%|          | 192/535957 [02:07<98:44:05,  1.51it/s, v_num=full, train/loss_step=6.940]Epoch 0:   0%|          | 193/535957 [02:07<98:39:23,  1.51it/s, v_num=full, train/loss_step=6.940]Epoch 0:   0%|          | 193/535957 [02:07<98:39:25,  1.51it/s, v_num=full, train/loss_step=9.120]Epoch 0:   0%|          | 194/535957 [02:08<98:34:58,  1.51it/s, v_num=full, train/loss_step=9.120]Epoch 0:   0%|          | 194/535957 [02:08<98:35:00,  1.51it/s, v_num=full, train/loss_step=10.40]Epoch 0:   0%|          | 195/535957 [02:09<98:30:16,  1.51it/s, v_num=full, train/loss_step=10.40]Epoch 0:   0%|          | 195/535957 [02:09<98:30:18,  1.51it/s, v_num=full, train/loss_step=8.400]Epoch 0:   0%|          | 196/535957 [02:09<98:25:33,  1.51it/s, v_num=full, train/loss_step=8.400]Epoch 0:   0%|          | 196/535957 [02:09<98:25:35,  1.51it/s, v_num=full, train/loss_step=6.020]Epoch 0:   0%|          | 197/535957 [02:10<98:20:57,  1.51it/s, v_num=full, train/loss_step=6.020]Epoch 0:   0%|          | 197/535957 [02:10<98:20:59,  1.51it/s, v_num=full, train/loss_step=7.290]Epoch 0:   0%|          | 198/535957 [02:10<98:16:09,  1.51it/s, v_num=full, train/loss_step=7.290]Epoch 0:   0%|          | 198/535957 [02:10<98:16:11,  1.51it/s, v_num=full, train/loss_step=6.320]Epoch 0:   0%|          | 199/535957 [02:11<98:11:54,  1.52it/s, v_num=full, train/loss_step=6.320]Epoch 0:   0%|          | 199/535957 [02:11<98:11:56,  1.52it/s, v_num=full, train/loss_step=3.970]Epoch 0:   0%|          | 200/535957 [02:16<101:55:11,  1.46it/s, v_num=full, train/loss_step=3.970]Epoch 0:   0%|          | 200/535957 [02:16<101:55:12,  1.46it/s, v_num=full, train/loss_step=11.40]
============================================================
[Input Before LLM] - Global Step 200
============================================================
  Adaptor embeddings shape: torch.Size([4, 592, 896])
  Input embeddings shape: torch.Size([4, 592, 896])
  Attention mask shape: torch.Size([4, 592])
  Input dtype: torch.float16
  Adaptor embeddings range: [-60.6875, 51.9062]
  Input embeddings range: [-60.6875, 51.9062]
  Input embeddings mean: 0.0010, std: 0.8433
  Language inputs shape: torch.Size([4, 562, 896])

============================================================
Global Step 200
============================================================

[Losses]
  language_loss: 0.001577 (shape: torch.Size([4, 561]), count: 28)
  route_loss: 2.337891 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 7.109375 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 201/535957 [02:17<101:51:20,  1.46it/s, v_num=full, train/loss_step=11.40]Epoch 0:   0%|          | 201/535957 [02:17<101:51:22,  1.46it/s, v_num=full, train/loss_step=9.570]Epoch 0:   0%|          | 202/535957 [02:18<101:45:56,  1.46it/s, v_num=full, train/loss_step=9.570]Epoch 0:   0%|          | 202/535957 [02:18<101:45:59,  1.46it/s, v_num=full, train/loss_step=10.50]Epoch 0:   0%|          | 203/535957 [02:18<101:40:43,  1.46it/s, v_num=full, train/loss_step=10.50]Epoch 0:   0%|          | 203/535957 [02:18<101:40:45,  1.46it/s, v_num=full, train/loss_step=8.670]Epoch 0:   0%|          | 204/535957 [02:19<101:35:09,  1.46it/s, v_num=full, train/loss_step=8.670]Epoch 0:   0%|          | 204/535957 [02:19<101:35:11,  1.46it/s, v_num=full, train/loss_step=4.490]Epoch 0:   0%|          | 205/535957 [02:19<101:30:03,  1.47it/s, v_num=full, train/loss_step=4.490]Epoch 0:   0%|          | 205/535957 [02:19<101:30:05,  1.47it/s, v_num=full, train/loss_step=8.810]Epoch 0:   0%|          | 206/535957 [02:20<101:24:47,  1.47it/s, v_num=full, train/loss_step=8.810]Epoch 0:   0%|          | 206/535957 [02:20<101:24:49,  1.47it/s, v_num=full, train/loss_step=10.20]Epoch 0:   0%|          | 207/535957 [02:20<101:19:38,  1.47it/s, v_num=full, train/loss_step=10.20]Epoch 0:   0%|          | 207/535957 [02:20<101:19:40,  1.47it/s, v_num=full, train/loss_step=8.700]Epoch 0:   0%|          | 208/535957 [02:21<101:14:28,  1.47it/s, v_num=full, train/loss_step=8.700]Epoch 0:   0%|          | 208/535957 [02:21<101:14:30,  1.47it/s, v_num=full, train/loss_step=7.750]Epoch 0:   0%|          | 209/535957 [02:22<101:09:15,  1.47it/s, v_num=full, train/loss_step=7.750]Epoch 0:   0%|          | 209/535957 [02:22<101:09:17,  1.47it/s, v_num=full, train/loss_step=10.00]Epoch 0:   0%|          | 210/535957 [02:22<101:04:07,  1.47it/s, v_num=full, train/loss_step=10.00]Epoch 0:   0%|          | 210/535957 [02:22<101:04:09,  1.47it/s, v_num=full, train/loss_step=9.720]
============================================================
Global Step 210
============================================================

[Losses]
  language_loss: 0.001430 (shape: torch.Size([4, 554]), count: 28)
  route_loss: 1.821289 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 6.742188 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 211/535957 [02:23<100:59:11,  1.47it/s, v_num=full, train/loss_step=9.720]Epoch 0:   0%|          | 211/535957 [02:23<100:59:13,  1.47it/s, v_num=full, train/loss_step=8.670]Epoch 0:   0%|          | 212/535957 [02:23<100:54:15,  1.47it/s, v_num=full, train/loss_step=8.670]Epoch 0:   0%|          | 212/535957 [02:23<100:54:17,  1.47it/s, v_num=full, train/loss_step=13.00]Epoch 0:   0%|          | 213/535957 [02:24<100:49:22,  1.48it/s, v_num=full, train/loss_step=13.00]Epoch 0:   0%|          | 213/535957 [02:24<100:49:24,  1.48it/s, v_num=full, train/loss_step=4.140]Epoch 0:   0%|          | 214/535957 [02:24<100:44:34,  1.48it/s, v_num=full, train/loss_step=4.140]Epoch 0:   0%|          | 214/535957 [02:24<100:44:36,  1.48it/s, v_num=full, train/loss_step=9.940]Epoch 0:   0%|          | 215/535957 [02:25<100:39:45,  1.48it/s, v_num=full, train/loss_step=9.940]Epoch 0:   0%|          | 215/535957 [02:25<100:39:46,  1.48it/s, v_num=full, train/loss_step=4.470]Epoch 0:   0%|          | 216/535957 [02:25<100:34:56,  1.48it/s, v_num=full, train/loss_step=4.470]Epoch 0:   0%|          | 216/535957 [02:25<100:34:58,  1.48it/s, v_num=full, train/loss_step=4.950]Epoch 0:   0%|          | 217/535957 [02:26<100:30:11,  1.48it/s, v_num=full, train/loss_step=4.950]Epoch 0:   0%|          | 217/535957 [02:26<100:30:13,  1.48it/s, v_num=full, train/loss_step=5.640]Epoch 0:   0%|          | 218/535957 [02:27<100:25:30,  1.48it/s, v_num=full, train/loss_step=5.640]Epoch 0:   0%|          | 218/535957 [02:27<100:25:32,  1.48it/s, v_num=full, train/loss_step=10.90]Epoch 0:   0%|          | 219/535957 [02:27<100:20:44,  1.48it/s, v_num=full, train/loss_step=10.90]Epoch 0:   0%|          | 219/535957 [02:27<100:20:46,  1.48it/s, v_num=full, train/loss_step=4.200]Epoch 0:   0%|          | 220/535957 [02:28<100:16:02,  1.48it/s, v_num=full, train/loss_step=4.200]Epoch 0:   0%|          | 220/535957 [02:28<100:16:04,  1.48it/s, v_num=full, train/loss_step=3.880]
============================================================
Global Step 220
============================================================

[Losses]
  language_loss: 0.001236 (shape: torch.Size([4, 553]), count: 28)
  route_loss: 0.758301 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 2.876953 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 221/535957 [02:28<100:11:48,  1.49it/s, v_num=full, train/loss_step=3.880]Epoch 0:   0%|          | 221/535957 [02:28<100:11:50,  1.49it/s, v_num=full, train/loss_step=3.730]Epoch 0:   0%|          | 222/535957 [02:29<100:07:27,  1.49it/s, v_num=full, train/loss_step=3.730]Epoch 0:   0%|          | 222/535957 [02:29<100:07:29,  1.49it/s, v_num=full, train/loss_step=3.740]Epoch 0:   0%|          | 223/535957 [02:29<100:03:07,  1.49it/s, v_num=full, train/loss_step=3.740]Epoch 0:   0%|          | 223/535957 [02:29<100:03:09,  1.49it/s, v_num=full, train/loss_step=6.930]Epoch 0:   0%|          | 224/535957 [02:30<99:58:55,  1.49it/s, v_num=full, train/loss_step=6.930] Epoch 0:   0%|          | 224/535957 [02:30<99:58:57,  1.49it/s, v_num=full, train/loss_step=5.260]Epoch 0:   0%|          | 225/535957 [02:31<99:54:29,  1.49it/s, v_num=full, train/loss_step=5.260]Epoch 0:   0%|          | 225/535957 [02:31<99:54:31,  1.49it/s, v_num=full, train/loss_step=6.500]Epoch 0:   0%|          | 226/535957 [02:31<99:50:14,  1.49it/s, v_num=full, train/loss_step=6.500]Epoch 0:   0%|          | 226/535957 [02:31<99:50:16,  1.49it/s, v_num=full, train/loss_step=10.60]Epoch 0:   0%|          | 227/535957 [02:32<99:45:51,  1.49it/s, v_num=full, train/loss_step=10.60]Epoch 0:   0%|          | 227/535957 [02:32<99:45:53,  1.49it/s, v_num=full, train/loss_step=5.030]Epoch 0:   0%|          | 228/535957 [02:32<99:41:43,  1.49it/s, v_num=full, train/loss_step=5.030]Epoch 0:   0%|          | 228/535957 [02:32<99:41:44,  1.49it/s, v_num=full, train/loss_step=6.230]Epoch 0:   0%|          | 229/535957 [02:33<99:37:39,  1.49it/s, v_num=full, train/loss_step=6.230]Epoch 0:   0%|          | 229/535957 [02:33<99:37:41,  1.49it/s, v_num=full, train/loss_step=3.440]Epoch 0:   0%|          | 230/535957 [02:33<99:33:27,  1.49it/s, v_num=full, train/loss_step=3.440]Epoch 0:   0%|          | 230/535957 [02:33<99:33:29,  1.49it/s, v_num=full, train/loss_step=11.00]
============================================================
Global Step 230
============================================================

[Losses]
  language_loss: 0.001405 (shape: torch.Size([4, 560]), count: 28)
  route_loss: 2.208984 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.191406 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 231/535957 [02:34<99:29:17,  1.50it/s, v_num=full, train/loss_step=11.00]Epoch 0:   0%|          | 231/535957 [02:34<99:29:18,  1.50it/s, v_num=full, train/loss_step=6.510]Epoch 0:   0%|          | 232/535957 [02:34<99:25:09,  1.50it/s, v_num=full, train/loss_step=6.510]Epoch 0:   0%|          | 232/535957 [02:34<99:25:11,  1.50it/s, v_num=full, train/loss_step=11.50]Epoch 0:   0%|          | 233/535957 [02:35<99:21:09,  1.50it/s, v_num=full, train/loss_step=11.50]Epoch 0:   0%|          | 233/535957 [02:35<99:21:10,  1.50it/s, v_num=full, train/loss_step=8.480]Epoch 0:   0%|          | 234/535957 [02:36<99:17:13,  1.50it/s, v_num=full, train/loss_step=8.480]Epoch 0:   0%|          | 234/535957 [02:36<99:17:15,  1.50it/s, v_num=full, train/loss_step=10.30]Epoch 0:   0%|          | 235/535957 [02:36<99:13:18,  1.50it/s, v_num=full, train/loss_step=10.30]Epoch 0:   0%|          | 235/535957 [02:36<99:13:20,  1.50it/s, v_num=full, train/loss_step=3.430]Epoch 0:   0%|          | 236/535957 [02:37<99:09:14,  1.50it/s, v_num=full, train/loss_step=3.430]Epoch 0:   0%|          | 236/535957 [02:37<99:09:16,  1.50it/s, v_num=full, train/loss_step=4.070]Epoch 0:   0%|          | 237/535957 [02:37<99:05:09,  1.50it/s, v_num=full, train/loss_step=4.070]Epoch 0:   0%|          | 237/535957 [02:37<99:05:11,  1.50it/s, v_num=full, train/loss_step=3.730]Epoch 0:   0%|          | 238/535957 [02:38<99:01:20,  1.50it/s, v_num=full, train/loss_step=3.730]Epoch 0:   0%|          | 238/535957 [02:38<99:01:22,  1.50it/s, v_num=full, train/loss_step=9.790]Epoch 0:   0%|          | 239/535957 [02:38<98:57:26,  1.50it/s, v_num=full, train/loss_step=9.790]Epoch 0:   0%|          | 239/535957 [02:38<98:57:27,  1.50it/s, v_num=full, train/loss_step=6.970]Epoch 0:   0%|          | 240/535957 [02:39<98:53:21,  1.50it/s, v_num=full, train/loss_step=6.970]Epoch 0:   0%|          | 240/535957 [02:39<98:53:22,  1.50it/s, v_num=full, train/loss_step=5.170]
============================================================
Global Step 240
============================================================

[Losses]
  language_loss: 0.001787 (shape: torch.Size([4, 546]), count: 28)
  route_loss: 2.103516 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.421875 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 241/535957 [02:40<98:49:33,  1.51it/s, v_num=full, train/loss_step=5.170]Epoch 0:   0%|          | 241/535957 [02:40<98:49:34,  1.51it/s, v_num=full, train/loss_step=6.670]Epoch 0:   0%|          | 242/535957 [02:40<98:45:50,  1.51it/s, v_num=full, train/loss_step=6.670]Epoch 0:   0%|          | 242/535957 [02:40<98:45:52,  1.51it/s, v_num=full, train/loss_step=7.170]Epoch 0:   0%|          | 243/535957 [02:41<98:42:10,  1.51it/s, v_num=full, train/loss_step=7.170]Epoch 0:   0%|          | 243/535957 [02:41<98:42:11,  1.51it/s, v_num=full, train/loss_step=7.250]Epoch 0:   0%|          | 244/535957 [02:41<98:38:11,  1.51it/s, v_num=full, train/loss_step=7.250]Epoch 0:   0%|          | 244/535957 [02:41<98:38:12,  1.51it/s, v_num=full, train/loss_step=6.340]Epoch 0:   0%|          | 245/535957 [02:42<98:34:25,  1.51it/s, v_num=full, train/loss_step=6.340]Epoch 0:   0%|          | 245/535957 [02:42<98:34:26,  1.51it/s, v_num=full, train/loss_step=4.890]Epoch 0:   0%|          | 246/535957 [02:42<98:30:52,  1.51it/s, v_num=full, train/loss_step=4.890]Epoch 0:   0%|          | 246/535957 [02:42<98:30:54,  1.51it/s, v_num=full, train/loss_step=7.230]Epoch 0:   0%|          | 247/535957 [02:43<98:27:13,  1.51it/s, v_num=full, train/loss_step=7.230]Epoch 0:   0%|          | 247/535957 [02:43<98:27:15,  1.51it/s, v_num=full, train/loss_step=7.700]Epoch 0:   0%|          | 248/535957 [02:43<98:23:41,  1.51it/s, v_num=full, train/loss_step=7.700]Epoch 0:   0%|          | 248/535957 [02:43<98:23:43,  1.51it/s, v_num=full, train/loss_step=6.290]Epoch 0:   0%|          | 249/535957 [02:44<98:20:00,  1.51it/s, v_num=full, train/loss_step=6.290]Epoch 0:   0%|          | 249/535957 [02:44<98:20:01,  1.51it/s, v_num=full, train/loss_step=7.270]Epoch 0:   0%|          | 250/535957 [02:45<98:16:20,  1.51it/s, v_num=full, train/loss_step=7.270]Epoch 0:   0%|          | 250/535957 [02:45<98:16:22,  1.51it/s, v_num=full, train/loss_step=7.300]
============================================================
Global Step 250
============================================================

[Losses]
  language_loss: 0.001397 (shape: torch.Size([4, 561]), count: 28)
  route_loss: 1.670898 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 8.070312 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 251/535957 [02:45<98:12:59,  1.52it/s, v_num=full, train/loss_step=7.300]Epoch 0:   0%|          | 251/535957 [02:45<98:13:00,  1.52it/s, v_num=full, train/loss_step=9.860]Epoch 0:   0%|          | 252/535957 [02:46<98:10:12,  1.52it/s, v_num=full, train/loss_step=9.860]Epoch 0:   0%|          | 252/535957 [02:46<98:10:14,  1.52it/s, v_num=full, train/loss_step=6.840]Epoch 0:   0%|          | 253/535957 [02:46<98:06:36,  1.52it/s, v_num=full, train/loss_step=6.840]Epoch 0:   0%|          | 253/535957 [02:46<98:06:38,  1.52it/s, v_num=full, train/loss_step=8.170]Epoch 0:   0%|          | 254/535957 [02:47<98:03:05,  1.52it/s, v_num=full, train/loss_step=8.170]Epoch 0:   0%|          | 254/535957 [02:47<98:03:07,  1.52it/s, v_num=full, train/loss_step=4.280]Epoch 0:   0%|          | 255/535957 [02:47<97:59:41,  1.52it/s, v_num=full, train/loss_step=4.280]Epoch 0:   0%|          | 255/535957 [02:47<97:59:42,  1.52it/s, v_num=full, train/loss_step=7.610]Epoch 0:   0%|          | 256/535957 [02:48<97:56:12,  1.52it/s, v_num=full, train/loss_step=7.610]Epoch 0:   0%|          | 256/535957 [02:48<97:56:14,  1.52it/s, v_num=full, train/loss_step=7.940]Epoch 0:   0%|          | 257/535957 [02:49<97:52:38,  1.52it/s, v_num=full, train/loss_step=7.940]Epoch 0:   0%|          | 257/535957 [02:49<97:52:39,  1.52it/s, v_num=full, train/loss_step=3.890]Epoch 0:   0%|          | 258/535957 [02:49<97:49:15,  1.52it/s, v_num=full, train/loss_step=3.890]Epoch 0:   0%|          | 258/535957 [02:49<97:49:16,  1.52it/s, v_num=full, train/loss_step=5.010]Epoch 0:   0%|          | 259/535957 [02:50<97:45:51,  1.52it/s, v_num=full, train/loss_step=5.010]Epoch 0:   0%|          | 259/535957 [02:50<97:45:53,  1.52it/s, v_num=full, train/loss_step=6.150]Epoch 0:   0%|          | 260/535957 [02:50<97:42:31,  1.52it/s, v_num=full, train/loss_step=6.150]Epoch 0:   0%|          | 260/535957 [02:50<97:42:32,  1.52it/s, v_num=full, train/loss_step=5.050]
============================================================
Global Step 260
============================================================

[Losses]
  language_loss: 0.001143 (shape: torch.Size([4, 552]), count: 28)
  route_loss: 0.887207 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.492188 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 261/535957 [02:51<97:39:20,  1.52it/s, v_num=full, train/loss_step=5.050]Epoch 0:   0%|          | 261/535957 [02:51<97:39:21,  1.52it/s, v_num=full, train/loss_step=4.470]Epoch 0:   0%|          | 262/535957 [02:51<97:35:59,  1.52it/s, v_num=full, train/loss_step=4.470]Epoch 0:   0%|          | 262/535957 [02:51<97:36:00,  1.52it/s, v_num=full, train/loss_step=4.850]Epoch 0:   0%|          | 263/535957 [02:52<97:32:42,  1.53it/s, v_num=full, train/loss_step=4.850]Epoch 0:   0%|          | 263/535957 [02:52<97:32:43,  1.53it/s, v_num=full, train/loss_step=7.530]Epoch 0:   0%|          | 264/535957 [02:52<97:29:32,  1.53it/s, v_num=full, train/loss_step=7.530]Epoch 0:   0%|          | 264/535957 [02:52<97:29:34,  1.53it/s, v_num=full, train/loss_step=7.340]Epoch 0:   0%|          | 265/535957 [02:53<97:26:21,  1.53it/s, v_num=full, train/loss_step=7.340]Epoch 0:   0%|          | 265/535957 [02:53<97:26:23,  1.53it/s, v_num=full, train/loss_step=10.50]Epoch 0:   0%|          | 266/535957 [02:54<97:23:05,  1.53it/s, v_num=full, train/loss_step=10.50]Epoch 0:   0%|          | 266/535957 [02:54<97:23:06,  1.53it/s, v_num=full, train/loss_step=4.860]Epoch 0:   0%|          | 267/535957 [02:54<97:19:57,  1.53it/s, v_num=full, train/loss_step=4.860]Epoch 0:   0%|          | 267/535957 [02:54<97:19:58,  1.53it/s, v_num=full, train/loss_step=3.790]Epoch 0:   0%|          | 268/535957 [02:55<97:16:58,  1.53it/s, v_num=full, train/loss_step=3.790]Epoch 0:   0%|          | 268/535957 [02:55<97:17:00,  1.53it/s, v_num=full, train/loss_step=3.370]Epoch 0:   0%|          | 269/535957 [02:55<97:14:02,  1.53it/s, v_num=full, train/loss_step=3.370]Epoch 0:   0%|          | 269/535957 [02:55<97:14:03,  1.53it/s, v_num=full, train/loss_step=6.400]Epoch 0:   0%|          | 270/535957 [02:56<97:10:58,  1.53it/s, v_num=full, train/loss_step=6.400]Epoch 0:   0%|          | 270/535957 [02:56<97:10:59,  1.53it/s, v_num=full, train/loss_step=11.00]
============================================================
Global Step 270
============================================================

[Losses]
  language_loss: 0.001159 (shape: torch.Size([4, 560]), count: 28)
  route_loss: 2.271484 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 5.980469 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 271/535957 [02:56<97:07:59,  1.53it/s, v_num=full, train/loss_step=11.00]Epoch 0:   0%|          | 271/535957 [02:56<97:08:00,  1.53it/s, v_num=full, train/loss_step=8.340]Epoch 0:   0%|          | 272/535957 [02:57<97:04:57,  1.53it/s, v_num=full, train/loss_step=8.340]Epoch 0:   0%|          | 272/535957 [02:57<97:04:58,  1.53it/s, v_num=full, train/loss_step=6.180]Epoch 0:   0%|          | 273/535957 [02:58<97:01:56,  1.53it/s, v_num=full, train/loss_step=6.180]Epoch 0:   0%|          | 273/535957 [02:58<97:01:58,  1.53it/s, v_num=full, train/loss_step=5.240]Epoch 0:   0%|          | 274/535957 [02:58<96:58:59,  1.53it/s, v_num=full, train/loss_step=5.240]Epoch 0:   0%|          | 274/535957 [02:58<96:59:00,  1.53it/s, v_num=full, train/loss_step=9.990]Epoch 0:   0%|          | 275/535957 [02:59<96:55:59,  1.54it/s, v_num=full, train/loss_step=9.990]Epoch 0:   0%|          | 275/535957 [02:59<96:56:00,  1.54it/s, v_num=full, train/loss_step=6.600]Epoch 0:   0%|          | 276/535957 [02:59<96:52:59,  1.54it/s, v_num=full, train/loss_step=6.600]Epoch 0:   0%|          | 276/535957 [02:59<96:53:00,  1.54it/s, v_num=full, train/loss_step=6.290]Epoch 0:   0%|          | 277/535957 [03:00<96:50:09,  1.54it/s, v_num=full, train/loss_step=6.290]Epoch 0:   0%|          | 277/535957 [03:00<96:50:11,  1.54it/s, v_num=full, train/loss_step=4.020]Epoch 0:   0%|          | 278/535957 [03:00<96:47:20,  1.54it/s, v_num=full, train/loss_step=4.020]Epoch 0:   0%|          | 278/535957 [03:00<96:47:21,  1.54it/s, v_num=full, train/loss_step=9.480]Epoch 0:   0%|          | 279/535957 [03:01<96:44:28,  1.54it/s, v_num=full, train/loss_step=9.480]Epoch 0:   0%|          | 279/535957 [03:01<96:44:30,  1.54it/s, v_num=full, train/loss_step=8.850]Epoch 0:   0%|          | 280/535957 [03:01<96:41:46,  1.54it/s, v_num=full, train/loss_step=8.850]Epoch 0:   0%|          | 280/535957 [03:01<96:41:47,  1.54it/s, v_num=full, train/loss_step=7.980]
============================================================
Global Step 280
============================================================

[Losses]
  language_loss: 0.000717 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 2.101562 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.941406 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 281/535957 [03:02<96:38:58,  1.54it/s, v_num=full, train/loss_step=7.980]Epoch 0:   0%|          | 281/535957 [03:02<96:38:59,  1.54it/s, v_num=full, train/loss_step=6.100]Epoch 0:   0%|          | 282/535957 [03:03<96:36:09,  1.54it/s, v_num=full, train/loss_step=6.100]Epoch 0:   0%|          | 282/535957 [03:03<96:36:10,  1.54it/s, v_num=full, train/loss_step=8.320]Epoch 0:   0%|          | 283/535957 [03:03<96:33:24,  1.54it/s, v_num=full, train/loss_step=8.320]Epoch 0:   0%|          | 283/535957 [03:03<96:33:25,  1.54it/s, v_num=full, train/loss_step=4.320]Epoch 0:   0%|          | 284/535957 [03:04<96:30:37,  1.54it/s, v_num=full, train/loss_step=4.320]Epoch 0:   0%|          | 284/535957 [03:04<96:30:38,  1.54it/s, v_num=full, train/loss_step=12.80]Epoch 0:   0%|          | 285/535957 [03:04<96:27:50,  1.54it/s, v_num=full, train/loss_step=12.80]Epoch 0:   0%|          | 285/535957 [03:04<96:27:51,  1.54it/s, v_num=full, train/loss_step=6.040]Epoch 0:   0%|          | 286/535957 [03:05<96:25:13,  1.54it/s, v_num=full, train/loss_step=6.040]Epoch 0:   0%|          | 286/535957 [03:05<96:25:14,  1.54it/s, v_num=full, train/loss_step=6.470]Epoch 0:   0%|          | 287/535957 [03:05<96:22:36,  1.54it/s, v_num=full, train/loss_step=6.470]Epoch 0:   0%|          | 287/535957 [03:05<96:22:38,  1.54it/s, v_num=full, train/loss_step=5.870]Epoch 0:   0%|          | 288/535957 [03:06<96:19:48,  1.54it/s, v_num=full, train/loss_step=5.870]Epoch 0:   0%|          | 288/535957 [03:06<96:19:49,  1.54it/s, v_num=full, train/loss_step=2.830]Epoch 0:   0%|          | 289/535957 [03:07<96:17:15,  1.55it/s, v_num=full, train/loss_step=2.830]Epoch 0:   0%|          | 289/535957 [03:07<96:17:17,  1.55it/s, v_num=full, train/loss_step=6.000]Epoch 0:   0%|          | 290/535957 [03:07<96:14:43,  1.55it/s, v_num=full, train/loss_step=6.000]Epoch 0:   0%|          | 290/535957 [03:07<96:14:45,  1.55it/s, v_num=full, train/loss_step=7.920]
============================================================
Global Step 290
============================================================

[Losses]
  language_loss: 0.000957 (shape: torch.Size([4, 558]), count: 28)
  route_loss: 3.109375 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 6.179688 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 291/535957 [03:08<96:12:10,  1.55it/s, v_num=full, train/loss_step=7.920]Epoch 0:   0%|          | 291/535957 [03:08<96:12:11,  1.55it/s, v_num=full, train/loss_step=9.370]Epoch 0:   0%|          | 292/535957 [03:08<96:09:26,  1.55it/s, v_num=full, train/loss_step=9.370]Epoch 0:   0%|          | 292/535957 [03:08<96:09:28,  1.55it/s, v_num=full, train/loss_step=7.980]Epoch 0:   0%|          | 293/535957 [03:09<96:06:56,  1.55it/s, v_num=full, train/loss_step=7.980]Epoch 0:   0%|          | 293/535957 [03:09<96:06:57,  1.55it/s, v_num=full, train/loss_step=6.760]Epoch 0:   0%|          | 294/535957 [03:09<96:04:25,  1.55it/s, v_num=full, train/loss_step=6.760]Epoch 0:   0%|          | 294/535957 [03:09<96:04:26,  1.55it/s, v_num=full, train/loss_step=14.20]Epoch 0:   0%|          | 295/535957 [03:10<96:01:41,  1.55it/s, v_num=full, train/loss_step=14.20]Epoch 0:   0%|          | 295/535957 [03:10<96:01:42,  1.55it/s, v_num=full, train/loss_step=3.420]Epoch 0:   0%|          | 296/535957 [03:10<95:59:05,  1.55it/s, v_num=full, train/loss_step=3.420]Epoch 0:   0%|          | 296/535957 [03:10<95:59:06,  1.55it/s, v_num=full, train/loss_step=5.590]Epoch 0:   0%|          | 297/535957 [03:11<95:56:28,  1.55it/s, v_num=full, train/loss_step=5.590]Epoch 0:   0%|          | 297/535957 [03:11<95:56:29,  1.55it/s, v_num=full, train/loss_step=4.930]Epoch 0:   0%|          | 298/535957 [03:12<95:53:59,  1.55it/s, v_num=full, train/loss_step=4.930]Epoch 0:   0%|          | 298/535957 [03:12<95:54:00,  1.55it/s, v_num=full, train/loss_step=9.050]Epoch 0:   0%|          | 299/535957 [03:12<95:51:51,  1.55it/s, v_num=full, train/loss_step=9.050]Epoch 0:   0%|          | 299/535957 [03:12<95:51:53,  1.55it/s, v_num=full, train/loss_step=6.020]Epoch 0:   0%|          | 300/535957 [03:18<98:18:19,  1.51it/s, v_num=full, train/loss_step=6.020]Epoch 0:   0%|          | 300/535957 [03:18<98:18:20,  1.51it/s, v_num=full, train/loss_step=7.690]
============================================================
[Input Before LLM] - Global Step 300
============================================================
  Adaptor embeddings shape: torch.Size([4, 578, 896])
  Input embeddings shape: torch.Size([4, 578, 896])
  Attention mask shape: torch.Size([4, 578])
  Input dtype: torch.float16
  Adaptor embeddings range: [-60.7188, 54.5312]
  Input embeddings range: [-60.7188, 54.5312]
  Input embeddings mean: 0.0018, std: 0.9307
  Language inputs shape: torch.Size([4, 548, 896])

============================================================
Global Step 300
============================================================

[Losses]
  language_loss: 0.001704 (shape: torch.Size([4, 547]), count: 28)
  route_loss: 3.291016 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.191406 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 301/535957 [03:18<98:16:00,  1.51it/s, v_num=full, train/loss_step=7.690]Epoch 0:   0%|          | 301/535957 [03:18<98:16:01,  1.51it/s, v_num=full, train/loss_step=7.620]Epoch 0:   0%|          | 302/535957 [03:19<98:12:56,  1.51it/s, v_num=full, train/loss_step=7.620]Epoch 0:   0%|          | 302/535957 [03:19<98:12:57,  1.51it/s, v_num=full, train/loss_step=4.100]Epoch 0:   0%|          | 303/535957 [03:19<98:09:59,  1.52it/s, v_num=full, train/loss_step=4.100]Epoch 0:   0%|          | 303/535957 [03:19<98:10:00,  1.52it/s, v_num=full, train/loss_step=4.840]Epoch 0:   0%|          | 304/535957 [03:20<98:07:16,  1.52it/s, v_num=full, train/loss_step=4.840]Epoch 0:   0%|          | 304/535957 [03:20<98:07:17,  1.52it/s, v_num=full, train/loss_step=6.740]Epoch 0:   0%|          | 305/535957 [03:21<98:04:19,  1.52it/s, v_num=full, train/loss_step=6.740]Epoch 0:   0%|          | 305/535957 [03:21<98:04:21,  1.52it/s, v_num=full, train/loss_step=7.680]Epoch 0:   0%|          | 306/535957 [03:21<98:01:25,  1.52it/s, v_num=full, train/loss_step=7.680]Epoch 0:   0%|          | 306/535957 [03:21<98:01:27,  1.52it/s, v_num=full, train/loss_step=10.10]Epoch 0:   0%|          | 307/535957 [03:22<97:58:38,  1.52it/s, v_num=full, train/loss_step=10.10]Epoch 0:   0%|          | 307/535957 [03:22<97:58:39,  1.52it/s, v_num=full, train/loss_step=9.340]Epoch 0:   0%|          | 308/535957 [03:22<97:55:44,  1.52it/s, v_num=full, train/loss_step=9.340]Epoch 0:   0%|          | 308/535957 [03:22<97:55:46,  1.52it/s, v_num=full, train/loss_step=9.120]Epoch 0:   0%|          | 309/535957 [03:23<97:52:56,  1.52it/s, v_num=full, train/loss_step=9.120]Epoch 0:   0%|          | 309/535957 [03:23<97:52:58,  1.52it/s, v_num=full, train/loss_step=9.920]Epoch 0:   0%|          | 310/535957 [03:23<97:50:06,  1.52it/s, v_num=full, train/loss_step=9.920]Epoch 0:   0%|          | 310/535957 [03:23<97:50:07,  1.52it/s, v_num=full, train/loss_step=7.550]
============================================================
Global Step 310
============================================================

[Losses]
  language_loss: 0.000619 (shape: torch.Size([4, 560]), count: 28)
  route_loss: 1.876953 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.500000 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 311/535957 [03:24<97:47:16,  1.52it/s, v_num=full, train/loss_step=7.550]Epoch 0:   0%|          | 311/535957 [03:24<97:47:17,  1.52it/s, v_num=full, train/loss_step=6.430]Epoch 0:   0%|          | 312/535957 [03:24<97:44:24,  1.52it/s, v_num=full, train/loss_step=6.430]Epoch 0:   0%|          | 312/535957 [03:24<97:44:25,  1.52it/s, v_num=full, train/loss_step=6.500]Epoch 0:   0%|          | 313/535957 [03:25<97:41:39,  1.52it/s, v_num=full, train/loss_step=6.500]Epoch 0:   0%|          | 313/535957 [03:25<97:41:40,  1.52it/s, v_num=full, train/loss_step=5.390]Epoch 0:   0%|          | 314/535957 [03:26<97:38:50,  1.52it/s, v_num=full, train/loss_step=5.390]Epoch 0:   0%|          | 314/535957 [03:26<97:38:52,  1.52it/s, v_num=full, train/loss_step=10.00]Epoch 0:   0%|          | 315/535957 [03:26<97:36:05,  1.52it/s, v_num=full, train/loss_step=10.00]Epoch 0:   0%|          | 315/535957 [03:26<97:36:07,  1.52it/s, v_num=full, train/loss_step=2.770]Epoch 0:   0%|          | 316/535957 [03:27<97:33:23,  1.53it/s, v_num=full, train/loss_step=2.770]Epoch 0:   0%|          | 316/535957 [03:27<97:33:24,  1.53it/s, v_num=full, train/loss_step=5.400]Epoch 0:   0%|          | 317/535957 [03:27<97:30:41,  1.53it/s, v_num=full, train/loss_step=5.400]Epoch 0:   0%|          | 317/535957 [03:27<97:30:42,  1.53it/s, v_num=full, train/loss_step=3.780]Epoch 0:   0%|          | 318/535957 [03:28<97:28:00,  1.53it/s, v_num=full, train/loss_step=3.780]Epoch 0:   0%|          | 318/535957 [03:28<97:28:01,  1.53it/s, v_num=full, train/loss_step=7.020]Epoch 0:   0%|          | 319/535957 [03:28<97:25:18,  1.53it/s, v_num=full, train/loss_step=7.020]Epoch 0:   0%|          | 319/535957 [03:28<97:25:19,  1.53it/s, v_num=full, train/loss_step=5.890]Epoch 0:   0%|          | 320/535957 [03:29<97:22:43,  1.53it/s, v_num=full, train/loss_step=5.890]Epoch 0:   0%|          | 320/535957 [03:29<97:22:44,  1.53it/s, v_num=full, train/loss_step=5.400]
============================================================
Global Step 320
============================================================

[Losses]
  language_loss: 0.000568 (shape: torch.Size([4, 559]), count: 28)
  route_loss: 0.892090 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 2.265625 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 321/535957 [03:29<97:20:06,  1.53it/s, v_num=full, train/loss_step=5.400]Epoch 0:   0%|          | 321/535957 [03:29<97:20:07,  1.53it/s, v_num=full, train/loss_step=3.200]Epoch 0:   0%|          | 322/535957 [03:30<97:17:18,  1.53it/s, v_num=full, train/loss_step=3.200]Epoch 0:   0%|          | 322/535957 [03:30<97:17:19,  1.53it/s, v_num=full, train/loss_step=7.620]Epoch 0:   0%|          | 323/535957 [03:31<97:14:38,  1.53it/s, v_num=full, train/loss_step=7.620]Epoch 0:   0%|          | 323/535957 [03:31<97:14:39,  1.53it/s, v_num=full, train/loss_step=8.710]Epoch 0:   0%|          | 324/535957 [03:31<97:12:01,  1.53it/s, v_num=full, train/loss_step=8.710]Epoch 0:   0%|          | 324/535957 [03:31<97:12:02,  1.53it/s, v_num=full, train/loss_step=8.210]Epoch 0:   0%|          | 325/535957 [03:32<97:09:23,  1.53it/s, v_num=full, train/loss_step=8.210]Epoch 0:   0%|          | 325/535957 [03:32<97:09:23,  1.53it/s, v_num=full, train/loss_step=7.510]Epoch 0:   0%|          | 326/535957 [03:32<97:06:55,  1.53it/s, v_num=full, train/loss_step=7.510]Epoch 0:   0%|          | 326/535957 [03:32<97:06:56,  1.53it/s, v_num=full, train/loss_step=2.790]Epoch 0:   0%|          | 327/535957 [03:33<97:04:23,  1.53it/s, v_num=full, train/loss_step=2.790]Epoch 0:   0%|          | 327/535957 [03:33<97:04:24,  1.53it/s, v_num=full, train/loss_step=9.800]Epoch 0:   0%|          | 328/535957 [03:33<97:02:03,  1.53it/s, v_num=full, train/loss_step=9.800]Epoch 0:   0%|          | 328/535957 [03:33<97:02:04,  1.53it/s, v_num=full, train/loss_step=2.970]Epoch 0:   0%|          | 329/535957 [03:34<96:59:39,  1.53it/s, v_num=full, train/loss_step=2.970]Epoch 0:   0%|          | 329/535957 [03:34<96:59:41,  1.53it/s, v_num=full, train/loss_step=3.860]Epoch 0:   0%|          | 330/535957 [03:35<96:57:19,  1.53it/s, v_num=full, train/loss_step=3.860]Epoch 0:   0%|          | 330/535957 [03:35<96:57:20,  1.53it/s, v_num=full, train/loss_step=1.700]
============================================================
Global Step 330
============================================================

[Losses]
  language_loss: 0.000697 (shape: torch.Size([4, 561]), count: 28)
  route_loss: 2.427734 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.750000 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 331/535957 [03:35<96:55:01,  1.54it/s, v_num=full, train/loss_step=1.700]Epoch 0:   0%|          | 331/535957 [03:35<96:55:02,  1.54it/s, v_num=full, train/loss_step=7.230]Epoch 0:   0%|          | 332/535957 [03:36<96:52:38,  1.54it/s, v_num=full, train/loss_step=7.230]Epoch 0:   0%|          | 332/535957 [03:36<96:52:40,  1.54it/s, v_num=full, train/loss_step=3.650]Epoch 0:   0%|          | 333/535957 [03:36<96:50:20,  1.54it/s, v_num=full, train/loss_step=3.650]Epoch 0:   0%|          | 333/535957 [03:36<96:50:21,  1.54it/s, v_num=full, train/loss_step=8.520]Epoch 0:   0%|          | 334/535957 [03:37<96:48:01,  1.54it/s, v_num=full, train/loss_step=8.520]Epoch 0:   0%|          | 334/535957 [03:37<96:48:03,  1.54it/s, v_num=full, train/loss_step=4.220]Epoch 0:   0%|          | 335/535957 [03:37<96:45:38,  1.54it/s, v_num=full, train/loss_step=4.220]Epoch 0:   0%|          | 335/535957 [03:37<96:45:39,  1.54it/s, v_num=full, train/loss_step=8.270]Epoch 0:   0%|          | 336/535957 [03:38<96:43:13,  1.54it/s, v_num=full, train/loss_step=8.270]Epoch 0:   0%|          | 336/535957 [03:38<96:43:14,  1.54it/s, v_num=full, train/loss_step=9.370]Epoch 0:   0%|          | 337/535957 [03:38<96:40:49,  1.54it/s, v_num=full, train/loss_step=9.370]Epoch 0:   0%|          | 337/535957 [03:38<96:40:50,  1.54it/s, v_num=full, train/loss_step=1.540]Epoch 0:   0%|          | 338/535957 [03:39<96:38:32,  1.54it/s, v_num=full, train/loss_step=1.540]Epoch 0:   0%|          | 338/535957 [03:39<96:38:33,  1.54it/s, v_num=full, train/loss_step=7.840]Epoch 0:   0%|          | 339/535957 [03:40<96:35:59,  1.54it/s, v_num=full, train/loss_step=7.840]Epoch 0:   0%|          | 339/535957 [03:40<96:36:01,  1.54it/s, v_num=full, train/loss_step=4.880]Epoch 0:   0%|          | 340/535957 [03:40<96:33:32,  1.54it/s, v_num=full, train/loss_step=4.880]Epoch 0:   0%|          | 340/535957 [03:40<96:33:33,  1.54it/s, v_num=full, train/loss_step=6.950]
============================================================
Global Step 340
============================================================

[Losses]
  language_loss: 0.000740 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 0.811523 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 2.548828 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 341/535957 [03:41<96:31:09,  1.54it/s, v_num=full, train/loss_step=6.950]Epoch 0:   0%|          | 341/535957 [03:41<96:31:10,  1.54it/s, v_num=full, train/loss_step=3.420]Epoch 0:   0%|          | 342/535957 [03:41<96:28:39,  1.54it/s, v_num=full, train/loss_step=3.420]Epoch 0:   0%|          | 342/535957 [03:41<96:28:39,  1.54it/s, v_num=full, train/loss_step=7.470]Epoch 0:   0%|          | 343/535957 [03:42<96:26:07,  1.54it/s, v_num=full, train/loss_step=7.470]Epoch 0:   0%|          | 343/535957 [03:42<96:26:08,  1.54it/s, v_num=full, train/loss_step=5.560]Epoch 0:   0%|          | 344/535957 [03:42<96:23:39,  1.54it/s, v_num=full, train/loss_step=5.560]Epoch 0:   0%|          | 344/535957 [03:42<96:23:40,  1.54it/s, v_num=full, train/loss_step=6.090]Epoch 0:   0%|          | 345/535957 [03:43<96:21:21,  1.54it/s, v_num=full, train/loss_step=6.090]Epoch 0:   0%|          | 345/535957 [03:43<96:21:22,  1.54it/s, v_num=full, train/loss_step=13.20]Epoch 0:   0%|          | 346/535957 [03:43<96:19:06,  1.54it/s, v_num=full, train/loss_step=13.20]Epoch 0:   0%|          | 346/535957 [03:43<96:19:07,  1.54it/s, v_num=full, train/loss_step=5.520]Epoch 0:   0%|          | 347/535957 [03:44<96:16:51,  1.55it/s, v_num=full, train/loss_step=5.520]Epoch 0:   0%|          | 347/535957 [03:44<96:16:52,  1.55it/s, v_num=full, train/loss_step=10.10]Epoch 0:   0%|          | 348/535957 [03:45<96:14:41,  1.55it/s, v_num=full, train/loss_step=10.10]Epoch 0:   0%|          | 348/535957 [03:45<96:14:42,  1.55it/s, v_num=full, train/loss_step=4.000]Epoch 0:   0%|          | 349/535957 [03:45<96:12:31,  1.55it/s, v_num=full, train/loss_step=4.000]Epoch 0:   0%|          | 349/535957 [03:45<96:12:33,  1.55it/s, v_num=full, train/loss_step=9.730]Epoch 0:   0%|          | 350/535957 [03:46<96:10:10,  1.55it/s, v_num=full, train/loss_step=9.730]Epoch 0:   0%|          | 350/535957 [03:46<96:10:11,  1.55it/s, v_num=full, train/loss_step=11.50]
============================================================
Global Step 350
============================================================

[Losses]
  language_loss: 0.000343 (shape: torch.Size([4, 547]), count: 28)
  route_loss: 1.525391 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.351562 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 351/535957 [03:46<96:08:03,  1.55it/s, v_num=full, train/loss_step=11.50]Epoch 0:   0%|          | 351/535957 [03:46<96:08:04,  1.55it/s, v_num=full, train/loss_step=5.900]Epoch 0:   0%|          | 352/535957 [03:47<96:05:47,  1.55it/s, v_num=full, train/loss_step=5.900]Epoch 0:   0%|          | 352/535957 [03:47<96:05:48,  1.55it/s, v_num=full, train/loss_step=9.270]Epoch 0:   0%|          | 353/535957 [03:47<96:03:46,  1.55it/s, v_num=full, train/loss_step=9.270]Epoch 0:   0%|          | 353/535957 [03:47<96:03:47,  1.55it/s, v_num=full, train/loss_step=6.410]Epoch 0:   0%|          | 354/535957 [03:48<96:01:42,  1.55it/s, v_num=full, train/loss_step=6.410]Epoch 0:   0%|          | 354/535957 [03:48<96:01:43,  1.55it/s, v_num=full, train/loss_step=4.290]Epoch 0:   0%|          | 355/535957 [03:49<95:59:33,  1.55it/s, v_num=full, train/loss_step=4.290]Epoch 0:   0%|          | 355/535957 [03:49<95:59:34,  1.55it/s, v_num=full, train/loss_step=7.730]Epoch 0:   0%|          | 356/535957 [03:49<95:57:19,  1.55it/s, v_num=full, train/loss_step=7.730]Epoch 0:   0%|          | 356/535957 [03:49<95:57:20,  1.55it/s, v_num=full, train/loss_step=6.250]Epoch 0:   0%|          | 357/535957 [03:50<95:55:17,  1.55it/s, v_num=full, train/loss_step=6.250]Epoch 0:   0%|          | 357/535957 [03:50<95:55:18,  1.55it/s, v_num=full, train/loss_step=12.90]Epoch 0:   0%|          | 358/535957 [03:50<95:53:08,  1.55it/s, v_num=full, train/loss_step=12.90]Epoch 0:   0%|          | 358/535957 [03:50<95:53:09,  1.55it/s, v_num=full, train/loss_step=6.070]Epoch 0:   0%|          | 359/535957 [03:51<95:51:00,  1.55it/s, v_num=full, train/loss_step=6.070]Epoch 0:   0%|          | 359/535957 [03:51<95:51:01,  1.55it/s, v_num=full, train/loss_step=7.120]Epoch 0:   0%|          | 360/535957 [03:51<95:48:58,  1.55it/s, v_num=full, train/loss_step=7.120]Epoch 0:   0%|          | 360/535957 [03:51<95:48:59,  1.55it/s, v_num=full, train/loss_step=2.470]
============================================================
Global Step 360
============================================================

[Losses]
  language_loss: 0.000471 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 1.757812 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 6.117188 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 361/535957 [03:52<95:46:58,  1.55it/s, v_num=full, train/loss_step=2.470]Epoch 0:   0%|          | 361/535957 [03:52<95:46:59,  1.55it/s, v_num=full, train/loss_step=7.910]Epoch 0:   0%|          | 362/535957 [03:52<95:44:58,  1.55it/s, v_num=full, train/loss_step=7.910]Epoch 0:   0%|          | 362/535957 [03:52<95:44:59,  1.55it/s, v_num=full, train/loss_step=9.430]Epoch 0:   0%|          | 363/535957 [03:53<95:42:56,  1.55it/s, v_num=full, train/loss_step=9.430]Epoch 0:   0%|          | 363/535957 [03:53<95:42:57,  1.55it/s, v_num=full, train/loss_step=8.230]Epoch 0:   0%|          | 364/535957 [03:54<95:40:54,  1.55it/s, v_num=full, train/loss_step=8.230]Epoch 0:   0%|          | 364/535957 [03:54<95:40:55,  1.55it/s, v_num=full, train/loss_step=3.500]Epoch 0:   0%|          | 365/535957 [03:54<95:38:47,  1.56it/s, v_num=full, train/loss_step=3.500]Epoch 0:   0%|          | 365/535957 [03:54<95:38:48,  1.56it/s, v_num=full, train/loss_step=4.340]Epoch 0:   0%|          | 366/535957 [03:55<95:36:50,  1.56it/s, v_num=full, train/loss_step=4.340]Epoch 0:   0%|          | 366/535957 [03:55<95:36:51,  1.56it/s, v_num=full, train/loss_step=4.280]Epoch 0:   0%|          | 367/535957 [03:55<95:34:51,  1.56it/s, v_num=full, train/loss_step=4.280]Epoch 0:   0%|          | 367/535957 [03:55<95:34:52,  1.56it/s, v_num=full, train/loss_step=6.660]Epoch 0:   0%|          | 368/535957 [03:56<95:32:55,  1.56it/s, v_num=full, train/loss_step=6.660]Epoch 0:   0%|          | 368/535957 [03:56<95:32:56,  1.56it/s, v_num=full, train/loss_step=6.630]Epoch 0:   0%|          | 369/535957 [03:56<95:30:55,  1.56it/s, v_num=full, train/loss_step=6.630]Epoch 0:   0%|          | 369/535957 [03:56<95:30:57,  1.56it/s, v_num=full, train/loss_step=5.110]Epoch 0:   0%|          | 370/535957 [03:57<95:29:04,  1.56it/s, v_num=full, train/loss_step=5.110]Epoch 0:   0%|          | 370/535957 [03:57<95:29:05,  1.56it/s, v_num=full, train/loss_step=5.770]
============================================================
Global Step 370
============================================================

[Losses]
  language_loss: 0.001037 (shape: torch.Size([4, 551]), count: 28)
  route_loss: 1.653320 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 7.160156 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 371/535957 [03:58<95:27:17,  1.56it/s, v_num=full, train/loss_step=5.770]Epoch 0:   0%|          | 371/535957 [03:58<95:27:18,  1.56it/s, v_num=full, train/loss_step=8.900]Epoch 0:   0%|          | 372/535957 [03:58<95:25:24,  1.56it/s, v_num=full, train/loss_step=8.900]Epoch 0:   0%|          | 372/535957 [03:58<95:25:25,  1.56it/s, v_num=full, train/loss_step=8.830]Epoch 0:   0%|          | 373/535957 [03:59<95:23:31,  1.56it/s, v_num=full, train/loss_step=8.830]Epoch 0:   0%|          | 373/535957 [03:59<95:23:32,  1.56it/s, v_num=full, train/loss_step=6.830]Epoch 0:   0%|          | 374/535957 [03:59<95:21:42,  1.56it/s, v_num=full, train/loss_step=6.830]Epoch 0:   0%|          | 374/535957 [03:59<95:21:43,  1.56it/s, v_num=full, train/loss_step=9.900]Epoch 0:   0%|          | 375/535957 [04:00<95:19:46,  1.56it/s, v_num=full, train/loss_step=9.900]Epoch 0:   0%|          | 375/535957 [04:00<95:19:47,  1.56it/s, v_num=full, train/loss_step=8.690]Epoch 0:   0%|          | 376/535957 [04:00<95:18:24,  1.56it/s, v_num=full, train/loss_step=8.690]Epoch 0:   0%|          | 376/535957 [04:00<95:18:25,  1.56it/s, v_num=full, train/loss_step=11.20]Epoch 0:   0%|          | 377/535957 [04:01<95:16:31,  1.56it/s, v_num=full, train/loss_step=11.20]Epoch 0:   0%|          | 377/535957 [04:01<95:16:32,  1.56it/s, v_num=full, train/loss_step=11.10]Epoch 0:   0%|          | 378/535957 [04:01<95:14:36,  1.56it/s, v_num=full, train/loss_step=11.10]Epoch 0:   0%|          | 378/535957 [04:01<95:14:37,  1.56it/s, v_num=full, train/loss_step=5.280]Epoch 0:   0%|          | 379/535957 [04:02<95:12:41,  1.56it/s, v_num=full, train/loss_step=5.280]Epoch 0:   0%|          | 379/535957 [04:02<95:12:42,  1.56it/s, v_num=full, train/loss_step=3.800]Epoch 0:   0%|          | 380/535957 [04:03<95:10:54,  1.56it/s, v_num=full, train/loss_step=3.800]Epoch 0:   0%|          | 380/535957 [04:03<95:10:55,  1.56it/s, v_num=full, train/loss_step=3.440]
============================================================
Global Step 380
============================================================

[Losses]
  language_loss: 0.000851 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 2.666016 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 8.460938 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 381/535957 [04:03<95:09:07,  1.56it/s, v_num=full, train/loss_step=3.440]Epoch 0:   0%|          | 381/535957 [04:03<95:09:08,  1.56it/s, v_num=full, train/loss_step=11.20]Epoch 0:   0%|          | 382/535957 [04:04<95:07:16,  1.56it/s, v_num=full, train/loss_step=11.20]Epoch 0:   0%|          | 382/535957 [04:04<95:07:17,  1.56it/s, v_num=full, train/loss_step=6.920]Epoch 0:   0%|          | 383/535957 [04:04<95:05:25,  1.56it/s, v_num=full, train/loss_step=6.920]Epoch 0:   0%|          | 383/535957 [04:04<95:05:26,  1.56it/s, v_num=full, train/loss_step=8.100]Epoch 0:   0%|          | 384/535957 [04:05<95:03:39,  1.56it/s, v_num=full, train/loss_step=8.100]Epoch 0:   0%|          | 384/535957 [04:05<95:03:40,  1.56it/s, v_num=full, train/loss_step=6.470]Epoch 0:   0%|          | 385/535957 [04:05<95:01:48,  1.57it/s, v_num=full, train/loss_step=6.470]Epoch 0:   0%|          | 385/535957 [04:05<95:01:49,  1.57it/s, v_num=full, train/loss_step=6.520]Epoch 0:   0%|          | 386/535957 [04:06<95:00:01,  1.57it/s, v_num=full, train/loss_step=6.520]Epoch 0:   0%|          | 386/535957 [04:06<95:00:02,  1.57it/s, v_num=full, train/loss_step=1.940]Epoch 0:   0%|          | 387/535957 [04:07<94:58:17,  1.57it/s, v_num=full, train/loss_step=1.940]Epoch 0:   0%|          | 387/535957 [04:07<94:58:17,  1.57it/s, v_num=full, train/loss_step=6.950]Epoch 0:   0%|          | 388/535957 [04:07<94:56:30,  1.57it/s, v_num=full, train/loss_step=6.950]Epoch 0:   0%|          | 388/535957 [04:07<94:56:31,  1.57it/s, v_num=full, train/loss_step=10.60]Epoch 0:   0%|          | 389/535957 [04:08<94:54:45,  1.57it/s, v_num=full, train/loss_step=10.60]Epoch 0:   0%|          | 389/535957 [04:08<94:54:46,  1.57it/s, v_num=full, train/loss_step=5.570]Epoch 0:   0%|          | 390/535957 [04:08<94:53:10,  1.57it/s, v_num=full, train/loss_step=5.570]Epoch 0:   0%|          | 390/535957 [04:08<94:53:11,  1.57it/s, v_num=full, train/loss_step=5.260]
============================================================
Global Step 390
============================================================

[Losses]
  language_loss: 0.000536 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 1.124023 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 6.863281 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 391/535957 [04:09<94:51:34,  1.57it/s, v_num=full, train/loss_step=5.260]Epoch 0:   0%|          | 391/535957 [04:09<94:51:35,  1.57it/s, v_num=full, train/loss_step=8.030]Epoch 0:   0%|          | 392/535957 [04:09<94:49:55,  1.57it/s, v_num=full, train/loss_step=8.030]Epoch 0:   0%|          | 392/535957 [04:09<94:49:56,  1.57it/s, v_num=full, train/loss_step=3.990]Epoch 0:   0%|          | 393/535957 [04:10<94:48:17,  1.57it/s, v_num=full, train/loss_step=3.990]Epoch 0:   0%|          | 393/535957 [04:10<94:48:17,  1.57it/s, v_num=full, train/loss_step=4.660]Epoch 0:   0%|          | 394/535957 [04:11<94:46:31,  1.57it/s, v_num=full, train/loss_step=4.660]Epoch 0:   0%|          | 394/535957 [04:11<94:46:32,  1.57it/s, v_num=full, train/loss_step=4.470]Epoch 0:   0%|          | 395/535957 [04:11<94:44:46,  1.57it/s, v_num=full, train/loss_step=4.470]Epoch 0:   0%|          | 395/535957 [04:11<94:44:47,  1.57it/s, v_num=full, train/loss_step=2.520]Epoch 0:   0%|          | 396/535957 [04:12<94:43:04,  1.57it/s, v_num=full, train/loss_step=2.520]Epoch 0:   0%|          | 396/535957 [04:12<94:43:05,  1.57it/s, v_num=full, train/loss_step=6.730]Epoch 0:   0%|          | 397/535957 [04:12<94:41:19,  1.57it/s, v_num=full, train/loss_step=6.730]Epoch 0:   0%|          | 397/535957 [04:12<94:41:20,  1.57it/s, v_num=full, train/loss_step=5.470]Epoch 0:   0%|          | 398/535957 [04:13<94:39:44,  1.57it/s, v_num=full, train/loss_step=5.470]Epoch 0:   0%|          | 398/535957 [04:13<94:39:45,  1.57it/s, v_num=full, train/loss_step=8.150]Epoch 0:   0%|          | 399/535957 [04:13<94:38:03,  1.57it/s, v_num=full, train/loss_step=8.150]Epoch 0:   0%|          | 399/535957 [04:13<94:38:03,  1.57it/s, v_num=full, train/loss_step=3.350]Epoch 0:   0%|          | 400/535957 [04:19<96:30:05,  1.54it/s, v_num=full, train/loss_step=3.350]Epoch 0:   0%|          | 400/535957 [04:19<96:30:06,  1.54it/s, v_num=full, train/loss_step=3.180]
============================================================
[Input Before LLM] - Global Step 400
============================================================
  Adaptor embeddings shape: torch.Size([4, 592, 896])
  Input embeddings shape: torch.Size([4, 592, 896])
  Attention mask shape: torch.Size([4, 592])
  Input dtype: torch.float16
  Adaptor embeddings range: [-14.9219, 13.6875]
  Input embeddings range: [-14.9219, 13.6875]
  Input embeddings mean: 0.0011, std: 0.7402
  Language inputs shape: torch.Size([4, 562, 896])

============================================================
Global Step 400
============================================================

[Losses]
  language_loss: 0.000679 (shape: torch.Size([4, 561]), count: 28)
  route_loss: 1.468750 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 7.449219 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 401/535957 [04:20<96:28:57,  1.54it/s, v_num=full, train/loss_step=3.180]Epoch 0:   0%|          | 401/535957 [04:20<96:28:58,  1.54it/s, v_num=full, train/loss_step=8.970]Epoch 0:   0%|          | 402/535957 [04:20<96:26:54,  1.54it/s, v_num=full, train/loss_step=8.970]Epoch 0:   0%|          | 402/535957 [04:20<96:26:55,  1.54it/s, v_num=full, train/loss_step=5.480]Epoch 0:   0%|          | 403/535957 [04:21<96:24:59,  1.54it/s, v_num=full, train/loss_step=5.480]Epoch 0:   0%|          | 403/535957 [04:21<96:25:00,  1.54it/s, v_num=full, train/loss_step=7.250]Epoch 0:   0%|          | 404/535957 [04:21<96:23:08,  1.54it/s, v_num=full, train/loss_step=7.250]Epoch 0:   0%|          | 404/535957 [04:21<96:23:09,  1.54it/s, v_num=full, train/loss_step=9.120]Epoch 0:   0%|          | 405/535957 [04:22<96:21:20,  1.54it/s, v_num=full, train/loss_step=9.120]Epoch 0:   0%|          | 405/535957 [04:22<96:21:20,  1.54it/s, v_num=full, train/loss_step=3.200]Epoch 0:   0%|          | 406/535957 [04:22<96:19:22,  1.54it/s, v_num=full, train/loss_step=3.200]Epoch 0:   0%|          | 406/535957 [04:22<96:19:23,  1.54it/s, v_num=full, train/loss_step=3.330]Epoch 0:   0%|          | 407/535957 [04:23<96:17:27,  1.54it/s, v_num=full, train/loss_step=3.330]Epoch 0:   0%|          | 407/535957 [04:23<96:17:28,  1.54it/s, v_num=full, train/loss_step=4.850]Epoch 0:   0%|          | 408/535957 [04:24<96:15:38,  1.55it/s, v_num=full, train/loss_step=4.850]Epoch 0:   0%|          | 408/535957 [04:24<96:15:39,  1.55it/s, v_num=full, train/loss_step=4.710]Epoch 0:   0%|          | 409/535957 [04:24<96:13:50,  1.55it/s, v_num=full, train/loss_step=4.710]Epoch 0:   0%|          | 409/535957 [04:24<96:13:51,  1.55it/s, v_num=full, train/loss_step=4.430]Epoch 0:   0%|          | 410/535957 [04:25<96:11:57,  1.55it/s, v_num=full, train/loss_step=4.430]Epoch 0:   0%|          | 410/535957 [04:25<96:11:58,  1.55it/s, v_num=full, train/loss_step=3.520]
============================================================
Global Step 410
============================================================

[Losses]
  language_loss: 0.000609 (shape: torch.Size([4, 559]), count: 28)
  route_loss: 1.333984 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 2.189453 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 411/535957 [04:25<96:10:00,  1.55it/s, v_num=full, train/loss_step=3.520]Epoch 0:   0%|          | 411/535957 [04:25<96:10:01,  1.55it/s, v_num=full, train/loss_step=3.570]Epoch 0:   0%|          | 412/535957 [04:26<96:08:04,  1.55it/s, v_num=full, train/loss_step=3.570]Epoch 0:   0%|          | 412/535957 [04:26<96:08:05,  1.55it/s, v_num=full, train/loss_step=4.820]Epoch 0:   0%|          | 413/535957 [04:26<96:06:18,  1.55it/s, v_num=full, train/loss_step=4.820]Epoch 0:   0%|          | 413/535957 [04:26<96:06:19,  1.55it/s, v_num=full, train/loss_step=4.210]Epoch 0:   0%|          | 414/535957 [04:27<96:04:25,  1.55it/s, v_num=full, train/loss_step=4.210]Epoch 0:   0%|          | 414/535957 [04:27<96:04:26,  1.55it/s, v_num=full, train/loss_step=6.020]Epoch 0:   0%|          | 415/535957 [04:27<96:02:25,  1.55it/s, v_num=full, train/loss_step=6.020]Epoch 0:   0%|          | 415/535957 [04:27<96:02:26,  1.55it/s, v_num=full, train/loss_step=9.790]Epoch 0:   0%|          | 416/535957 [04:28<96:00:34,  1.55it/s, v_num=full, train/loss_step=9.790]Epoch 0:   0%|          | 416/535957 [04:28<96:00:35,  1.55it/s, v_num=full, train/loss_step=9.830]Epoch 0:   0%|          | 417/535957 [04:29<95:58:42,  1.55it/s, v_num=full, train/loss_step=9.830]Epoch 0:   0%|          | 417/535957 [04:29<95:58:43,  1.55it/s, v_num=full, train/loss_step=3.950]Epoch 0:   0%|          | 418/535957 [04:29<95:56:55,  1.55it/s, v_num=full, train/loss_step=3.950]Epoch 0:   0%|          | 418/535957 [04:29<95:56:56,  1.55it/s, v_num=full, train/loss_step=4.370]Epoch 0:   0%|          | 419/535957 [04:30<95:55:26,  1.55it/s, v_num=full, train/loss_step=4.370]Epoch 0:   0%|          | 419/535957 [04:30<95:55:27,  1.55it/s, v_num=full, train/loss_step=2.820]Epoch 0:   0%|          | 420/535957 [04:30<95:53:39,  1.55it/s, v_num=full, train/loss_step=2.820]Epoch 0:   0%|          | 420/535957 [04:30<95:53:40,  1.55it/s, v_num=full, train/loss_step=2.910]
============================================================
Global Step 420
============================================================

[Losses]
  language_loss: 0.000634 (shape: torch.Size([4, 559]), count: 28)
  route_loss: 1.705078 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.132812 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 421/535957 [04:31<95:51:52,  1.55it/s, v_num=full, train/loss_step=2.910]Epoch 0:   0%|          | 421/535957 [04:31<95:51:53,  1.55it/s, v_num=full, train/loss_step=5.890]Epoch 0:   0%|          | 422/535957 [04:31<95:50:12,  1.55it/s, v_num=full, train/loss_step=5.890]Epoch 0:   0%|          | 422/535957 [04:31<95:50:13,  1.55it/s, v_num=full, train/loss_step=8.750]Epoch 0:   0%|          | 423/535957 [04:32<95:48:25,  1.55it/s, v_num=full, train/loss_step=8.750]Epoch 0:   0%|          | 423/535957 [04:32<95:48:26,  1.55it/s, v_num=full, train/loss_step=7.060]Epoch 0:   0%|          | 424/535957 [04:32<95:46:43,  1.55it/s, v_num=full, train/loss_step=7.060]Epoch 0:   0%|          | 424/535957 [04:32<95:46:44,  1.55it/s, v_num=full, train/loss_step=4.250]Epoch 0:   0%|          | 425/535957 [04:33<95:44:59,  1.55it/s, v_num=full, train/loss_step=4.250]Epoch 0:   0%|          | 425/535957 [04:33<95:45:00,  1.55it/s, v_num=full, train/loss_step=4.950]Epoch 0:   0%|          | 426/535957 [04:34<95:43:14,  1.55it/s, v_num=full, train/loss_step=4.950]Epoch 0:   0%|          | 426/535957 [04:34<95:43:15,  1.55it/s, v_num=full, train/loss_step=3.930]Epoch 0:   0%|          | 427/535957 [04:34<95:41:31,  1.55it/s, v_num=full, train/loss_step=3.930]Epoch 0:   0%|          | 427/535957 [04:34<95:41:32,  1.55it/s, v_num=full, train/loss_step=10.40]Epoch 0:   0%|          | 428/535957 [04:35<95:39:44,  1.56it/s, v_num=full, train/loss_step=10.40]Epoch 0:   0%|          | 428/535957 [04:35<95:39:45,  1.56it/s, v_num=full, train/loss_step=5.220]Epoch 0:   0%|          | 429/535957 [04:35<95:38:01,  1.56it/s, v_num=full, train/loss_step=5.220]Epoch 0:   0%|          | 429/535957 [04:35<95:38:02,  1.56it/s, v_num=full, train/loss_step=7.350]Epoch 0:   0%|          | 430/535957 [04:36<95:36:18,  1.56it/s, v_num=full, train/loss_step=7.350]Epoch 0:   0%|          | 430/535957 [04:36<95:36:19,  1.56it/s, v_num=full, train/loss_step=6.510]
============================================================
Global Step 430
============================================================

[Losses]
  language_loss: 0.000364 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 0.781738 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.890625 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 431/535957 [04:36<95:34:39,  1.56it/s, v_num=full, train/loss_step=6.510]Epoch 0:   0%|          | 431/535957 [04:36<95:34:40,  1.56it/s, v_num=full, train/loss_step=4.700]Epoch 0:   0%|          | 432/535957 [04:37<95:33:03,  1.56it/s, v_num=full, train/loss_step=4.700]Epoch 0:   0%|          | 432/535957 [04:37<95:33:04,  1.56it/s, v_num=full, train/loss_step=6.710]Epoch 0:   0%|          | 433/535957 [04:38<95:31:19,  1.56it/s, v_num=full, train/loss_step=6.710]Epoch 0:   0%|          | 433/535957 [04:38<95:31:20,  1.56it/s, v_num=full, train/loss_step=7.940]Epoch 0:   0%|          | 434/535957 [04:38<95:29:42,  1.56it/s, v_num=full, train/loss_step=7.940]Epoch 0:   0%|          | 434/535957 [04:38<95:29:43,  1.56it/s, v_num=full, train/loss_step=4.190]Epoch 0:   0%|          | 435/535957 [04:39<95:28:02,  1.56it/s, v_num=full, train/loss_step=4.190]Epoch 0:   0%|          | 435/535957 [04:39<95:28:03,  1.56it/s, v_num=full, train/loss_step=4.890]Epoch 0:   0%|          | 436/535957 [04:39<95:26:29,  1.56it/s, v_num=full, train/loss_step=4.890]Epoch 0:   0%|          | 436/535957 [04:39<95:26:29,  1.56it/s, v_num=full, train/loss_step=6.180]Epoch 0:   0%|          | 437/535957 [04:40<95:24:49,  1.56it/s, v_num=full, train/loss_step=6.180]Epoch 0:   0%|          | 437/535957 [04:40<95:24:49,  1.56it/s, v_num=full, train/loss_step=5.700]Epoch 0:   0%|          | 438/535957 [04:40<95:23:07,  1.56it/s, v_num=full, train/loss_step=5.700]Epoch 0:   0%|          | 438/535957 [04:40<95:23:08,  1.56it/s, v_num=full, train/loss_step=7.030]Epoch 0:   0%|          | 439/535957 [04:41<95:21:26,  1.56it/s, v_num=full, train/loss_step=7.030]Epoch 0:   0%|          | 439/535957 [04:41<95:21:27,  1.56it/s, v_num=full, train/loss_step=7.500]Epoch 0:   0%|          | 440/535957 [04:41<95:19:53,  1.56it/s, v_num=full, train/loss_step=7.500]Epoch 0:   0%|          | 440/535957 [04:41<95:19:54,  1.56it/s, v_num=full, train/loss_step=5.470]
============================================================
Global Step 440
============================================================

[Losses]
  language_loss: 0.000606 (shape: torch.Size([4, 546]), count: 28)
  route_loss: 0.980957 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 6.148438 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 441/535957 [04:42<95:18:17,  1.56it/s, v_num=full, train/loss_step=5.470]Epoch 0:   0%|          | 441/535957 [04:42<95:18:18,  1.56it/s, v_num=full, train/loss_step=7.180]Epoch 0:   0%|          | 442/535957 [04:43<95:16:37,  1.56it/s, v_num=full, train/loss_step=7.180]Epoch 0:   0%|          | 442/535957 [04:43<95:16:38,  1.56it/s, v_num=full, train/loss_step=5.730]Epoch 0:   0%|          | 443/535957 [04:43<95:14:58,  1.56it/s, v_num=full, train/loss_step=5.730]Epoch 0:   0%|          | 443/535957 [04:43<95:14:59,  1.56it/s, v_num=full, train/loss_step=11.30]Epoch 0:   0%|          | 444/535957 [04:44<95:13:28,  1.56it/s, v_num=full, train/loss_step=11.30]Epoch 0:   0%|          | 444/535957 [04:44<95:13:29,  1.56it/s, v_num=full, train/loss_step=4.590]Epoch 0:   0%|          | 445/535957 [04:44<95:11:58,  1.56it/s, v_num=full, train/loss_step=4.590]Epoch 0:   0%|          | 445/535957 [04:44<95:11:58,  1.56it/s, v_num=full, train/loss_step=7.320]Epoch 0:   0%|          | 446/535957 [04:45<95:10:26,  1.56it/s, v_num=full, train/loss_step=7.320]Epoch 0:   0%|          | 446/535957 [04:45<95:10:27,  1.56it/s, v_num=full, train/loss_step=7.090]Epoch 0:   0%|          | 447/535957 [04:45<95:08:52,  1.56it/s, v_num=full, train/loss_step=7.090]Epoch 0:   0%|          | 447/535957 [04:45<95:08:53,  1.56it/s, v_num=full, train/loss_step=16.00]Epoch 0:   0%|          | 448/535957 [04:46<95:07:19,  1.56it/s, v_num=full, train/loss_step=16.00]Epoch 0:   0%|          | 448/535957 [04:46<95:07:20,  1.56it/s, v_num=full, train/loss_step=4.460]Epoch 0:   0%|          | 449/535957 [04:47<95:05:49,  1.56it/s, v_num=full, train/loss_step=4.460]Epoch 0:   0%|          | 449/535957 [04:47<95:05:50,  1.56it/s, v_num=full, train/loss_step=5.190]Epoch 0:   0%|          | 450/535957 [04:47<95:04:20,  1.56it/s, v_num=full, train/loss_step=5.190]Epoch 0:   0%|          | 450/535957 [04:47<95:04:20,  1.56it/s, v_num=full, train/loss_step=7.440]
============================================================
Global Step 450
============================================================

[Losses]
  language_loss: 0.000479 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 1.273438 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 1.610352 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 451/535957 [04:48<95:02:46,  1.57it/s, v_num=full, train/loss_step=7.440]Epoch 0:   0%|          | 451/535957 [04:48<95:02:46,  1.57it/s, v_num=full, train/loss_step=2.920]Epoch 0:   0%|          | 452/535957 [04:48<95:01:11,  1.57it/s, v_num=full, train/loss_step=2.920]Epoch 0:   0%|          | 452/535957 [04:48<95:01:11,  1.57it/s, v_num=full, train/loss_step=4.890]Epoch 0:   0%|          | 453/535957 [04:49<94:59:38,  1.57it/s, v_num=full, train/loss_step=4.890]Epoch 0:   0%|          | 453/535957 [04:49<94:59:39,  1.57it/s, v_num=full, train/loss_step=7.920]Epoch 0:   0%|          | 454/535957 [04:49<94:58:00,  1.57it/s, v_num=full, train/loss_step=7.920]Epoch 0:   0%|          | 454/535957 [04:49<94:58:01,  1.57it/s, v_num=full, train/loss_step=5.650]Epoch 0:   0%|          | 455/535957 [04:50<94:56:31,  1.57it/s, v_num=full, train/loss_step=5.650]Epoch 0:   0%|          | 455/535957 [04:50<94:56:31,  1.57it/s, v_num=full, train/loss_step=6.950]Epoch 0:   0%|          | 456/535957 [04:50<94:54:57,  1.57it/s, v_num=full, train/loss_step=6.950]Epoch 0:   0%|          | 456/535957 [04:50<94:54:57,  1.57it/s, v_num=full, train/loss_step=5.840]Epoch 0:   0%|          | 457/535957 [04:51<94:53:26,  1.57it/s, v_num=full, train/loss_step=5.840]Epoch 0:   0%|          | 457/535957 [04:51<94:53:26,  1.57it/s, v_num=full, train/loss_step=2.680]Epoch 0:   0%|          | 458/535957 [04:52<94:51:57,  1.57it/s, v_num=full, train/loss_step=2.680]Epoch 0:   0%|          | 458/535957 [04:52<94:51:57,  1.57it/s, v_num=full, train/loss_step=7.770]Epoch 0:   0%|          | 459/535957 [04:52<94:50:25,  1.57it/s, v_num=full, train/loss_step=7.770]Epoch 0:   0%|          | 459/535957 [04:52<94:50:25,  1.57it/s, v_num=full, train/loss_step=6.420]Epoch 0:   0%|          | 460/535957 [04:53<94:48:52,  1.57it/s, v_num=full, train/loss_step=6.420]Epoch 0:   0%|          | 460/535957 [04:53<94:48:53,  1.57it/s, v_num=full, train/loss_step=6.730]
============================================================
Global Step 460
============================================================

[Losses]
  language_loss: 0.000602 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 2.011719 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.890625 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 461/535957 [04:53<94:47:28,  1.57it/s, v_num=full, train/loss_step=6.730]Epoch 0:   0%|          | 461/535957 [04:53<94:47:29,  1.57it/s, v_num=full, train/loss_step=6.950]Epoch 0:   0%|          | 462/535957 [04:54<94:45:58,  1.57it/s, v_num=full, train/loss_step=6.950]Epoch 0:   0%|          | 462/535957 [04:54<94:45:59,  1.57it/s, v_num=full, train/loss_step=6.940]Epoch 0:   0%|          | 463/535957 [04:54<94:44:33,  1.57it/s, v_num=full, train/loss_step=6.940]Epoch 0:   0%|          | 463/535957 [04:54<94:44:34,  1.57it/s, v_num=full, train/loss_step=5.920]Epoch 0:   0%|          | 464/535957 [04:55<94:43:04,  1.57it/s, v_num=full, train/loss_step=5.920]Epoch 0:   0%|          | 464/535957 [04:55<94:43:05,  1.57it/s, v_num=full, train/loss_step=4.840]Epoch 0:   0%|          | 465/535957 [04:56<94:41:32,  1.57it/s, v_num=full, train/loss_step=4.840]Epoch 0:   0%|          | 465/535957 [04:56<94:41:33,  1.57it/s, v_num=full, train/loss_step=4.440]Epoch 0:   0%|          | 466/535957 [04:56<94:40:06,  1.57it/s, v_num=full, train/loss_step=4.440]Epoch 0:   0%|          | 466/535957 [04:56<94:40:07,  1.57it/s, v_num=full, train/loss_step=9.500]Epoch 0:   0%|          | 467/535957 [04:57<94:38:42,  1.57it/s, v_num=full, train/loss_step=9.500]Epoch 0:   0%|          | 467/535957 [04:57<94:38:42,  1.57it/s, v_num=full, train/loss_step=8.350]Epoch 0:   0%|          | 468/535957 [04:57<94:37:19,  1.57it/s, v_num=full, train/loss_step=8.350]Epoch 0:   0%|          | 468/535957 [04:57<94:37:20,  1.57it/s, v_num=full, train/loss_step=5.620]Epoch 0:   0%|          | 469/535957 [04:58<94:35:51,  1.57it/s, v_num=full, train/loss_step=5.620]Epoch 0:   0%|          | 469/535957 [04:58<94:35:51,  1.57it/s, v_num=full, train/loss_step=4.610]Epoch 0:   0%|          | 470/535957 [04:58<94:34:22,  1.57it/s, v_num=full, train/loss_step=4.610]Epoch 0:   0%|          | 470/535957 [04:58<94:34:23,  1.57it/s, v_num=full, train/loss_step=9.620]
============================================================
Global Step 470
============================================================

[Losses]
  language_loss: 0.000403 (shape: torch.Size([4, 550]), count: 28)
  route_loss: 0.527832 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.644531 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 471/535957 [04:59<94:32:56,  1.57it/s, v_num=full, train/loss_step=9.620]Epoch 0:   0%|          | 471/535957 [04:59<94:32:57,  1.57it/s, v_num=full, train/loss_step=5.210]Epoch 0:   0%|          | 472/535957 [04:59<94:31:35,  1.57it/s, v_num=full, train/loss_step=5.210]Epoch 0:   0%|          | 472/535957 [04:59<94:31:36,  1.57it/s, v_num=full, train/loss_step=12.80]Epoch 0:   0%|          | 473/535957 [05:00<94:30:06,  1.57it/s, v_num=full, train/loss_step=12.80]Epoch 0:   0%|          | 473/535957 [05:00<94:30:07,  1.57it/s, v_num=full, train/loss_step=2.580]Epoch 0:   0%|          | 474/535957 [05:01<94:28:42,  1.57it/s, v_num=full, train/loss_step=2.580]Epoch 0:   0%|          | 474/535957 [05:01<94:28:43,  1.57it/s, v_num=full, train/loss_step=3.870]Epoch 0:   0%|          | 475/535957 [05:01<94:27:14,  1.57it/s, v_num=full, train/loss_step=3.870]Epoch 0:   0%|          | 475/535957 [05:01<94:27:15,  1.57it/s, v_num=full, train/loss_step=4.640]Epoch 0:   0%|          | 476/535957 [05:02<94:25:52,  1.58it/s, v_num=full, train/loss_step=4.640]Epoch 0:   0%|          | 476/535957 [05:02<94:25:53,  1.58it/s, v_num=full, train/loss_step=11.20]Epoch 0:   0%|          | 477/535957 [05:02<94:24:32,  1.58it/s, v_num=full, train/loss_step=11.20]Epoch 0:   0%|          | 477/535957 [05:02<94:24:33,  1.58it/s, v_num=full, train/loss_step=11.60]Epoch 0:   0%|          | 478/535957 [05:03<94:23:05,  1.58it/s, v_num=full, train/loss_step=11.60]Epoch 0:   0%|          | 478/535957 [05:03<94:23:06,  1.58it/s, v_num=full, train/loss_step=7.610]Epoch 0:   0%|          | 479/535957 [05:03<94:21:45,  1.58it/s, v_num=full, train/loss_step=7.610]Epoch 0:   0%|          | 479/535957 [05:03<94:21:45,  1.58it/s, v_num=full, train/loss_step=7.090]Epoch 0:   0%|          | 480/535957 [05:04<94:20:23,  1.58it/s, v_num=full, train/loss_step=7.090]Epoch 0:   0%|          | 480/535957 [05:04<94:20:24,  1.58it/s, v_num=full, train/loss_step=6.790]
============================================================
Global Step 480
============================================================

[Losses]
  language_loss: 0.000341 (shape: torch.Size([4, 564]), count: 28)
  route_loss: 0.795410 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.427734 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 481/535957 [05:04<94:18:59,  1.58it/s, v_num=full, train/loss_step=6.790]Epoch 0:   0%|          | 481/535957 [05:04<94:18:59,  1.58it/s, v_num=full, train/loss_step=4.250]Epoch 0:   0%|          | 482/535957 [05:05<94:17:38,  1.58it/s, v_num=full, train/loss_step=4.250]Epoch 0:   0%|          | 482/535957 [05:05<94:17:38,  1.58it/s, v_num=full, train/loss_step=6.620]Epoch 0:   0%|          | 483/535957 [05:06<94:16:16,  1.58it/s, v_num=full, train/loss_step=6.620]Epoch 0:   0%|          | 483/535957 [05:06<94:16:17,  1.58it/s, v_num=full, train/loss_step=2.800]Epoch 0:   0%|          | 484/535957 [05:06<94:14:51,  1.58it/s, v_num=full, train/loss_step=2.800]Epoch 0:   0%|          | 484/535957 [05:06<94:14:52,  1.58it/s, v_num=full, train/loss_step=9.460]Epoch 0:   0%|          | 485/535957 [05:07<94:13:26,  1.58it/s, v_num=full, train/loss_step=9.460]Epoch 0:   0%|          | 485/535957 [05:07<94:13:26,  1.58it/s, v_num=full, train/loss_step=2.930]Epoch 0:   0%|          | 486/535957 [05:07<94:12:00,  1.58it/s, v_num=full, train/loss_step=2.930]Epoch 0:   0%|          | 486/535957 [05:07<94:12:01,  1.58it/s, v_num=full, train/loss_step=3.360]Epoch 0:   0%|          | 487/535957 [05:08<94:10:42,  1.58it/s, v_num=full, train/loss_step=3.360]Epoch 0:   0%|          | 487/535957 [05:08<94:10:43,  1.58it/s, v_num=full, train/loss_step=4.710]Epoch 0:   0%|          | 488/535957 [05:08<94:09:15,  1.58it/s, v_num=full, train/loss_step=4.710]Epoch 0:   0%|          | 488/535957 [05:08<94:09:16,  1.58it/s, v_num=full, train/loss_step=5.800]Epoch 0:   0%|          | 489/535957 [05:09<94:07:54,  1.58it/s, v_num=full, train/loss_step=5.800]Epoch 0:   0%|          | 489/535957 [05:09<94:07:55,  1.58it/s, v_num=full, train/loss_step=2.980]Epoch 0:   0%|          | 490/535957 [05:10<94:06:39,  1.58it/s, v_num=full, train/loss_step=2.980]Epoch 0:   0%|          | 490/535957 [05:10<94:06:40,  1.58it/s, v_num=full, train/loss_step=7.290]
============================================================
Global Step 490
============================================================

[Losses]
  language_loss: 0.000250 (shape: torch.Size([4, 555]), count: 28)
  route_loss: 1.363281 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 6.164062 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 491/535957 [05:10<94:05:28,  1.58it/s, v_num=full, train/loss_step=7.290]Epoch 0:   0%|          | 491/535957 [05:10<94:05:28,  1.58it/s, v_num=full, train/loss_step=7.550]Epoch 0:   0%|          | 492/535957 [05:11<94:04:09,  1.58it/s, v_num=full, train/loss_step=7.550]Epoch 0:   0%|          | 492/535957 [05:11<94:04:10,  1.58it/s, v_num=full, train/loss_step=5.410]Epoch 0:   0%|          | 493/535957 [05:11<94:02:49,  1.58it/s, v_num=full, train/loss_step=5.410]Epoch 0:   0%|          | 493/535957 [05:11<94:02:50,  1.58it/s, v_num=full, train/loss_step=6.590]Epoch 0:   0%|          | 494/535957 [05:12<94:01:28,  1.58it/s, v_num=full, train/loss_step=6.590]Epoch 0:   0%|          | 494/535957 [05:12<94:01:29,  1.58it/s, v_num=full, train/loss_step=7.630]Epoch 0:   0%|          | 495/535957 [05:12<94:00:14,  1.58it/s, v_num=full, train/loss_step=7.630]Epoch 0:   0%|          | 495/535957 [05:12<94:00:15,  1.58it/s, v_num=full, train/loss_step=2.950]Epoch 0:   0%|          | 496/535957 [05:13<93:58:54,  1.58it/s, v_num=full, train/loss_step=2.950]Epoch 0:   0%|          | 496/535957 [05:13<93:58:54,  1.58it/s, v_num=full, train/loss_step=1.450]Epoch 0:   0%|          | 497/535957 [05:13<93:57:33,  1.58it/s, v_num=full, train/loss_step=1.450]Epoch 0:   0%|          | 497/535957 [05:13<93:57:34,  1.58it/s, v_num=full, train/loss_step=3.060]Epoch 0:   0%|          | 498/535957 [05:14<93:56:11,  1.58it/s, v_num=full, train/loss_step=3.060]Epoch 0:   0%|          | 498/535957 [05:14<93:56:11,  1.58it/s, v_num=full, train/loss_step=7.270]Epoch 0:   0%|          | 499/535957 [05:15<93:54:49,  1.58it/s, v_num=full, train/loss_step=7.270]Epoch 0:   0%|          | 499/535957 [05:15<93:54:50,  1.58it/s, v_num=full, train/loss_step=5.140]Epoch 0:   0%|          | 500/535957 [05:20<95:22:59,  1.56it/s, v_num=full, train/loss_step=5.140]Epoch 0:   0%|          | 500/535957 [05:20<95:25:07,  1.56it/s, v_num=full, train/loss_step=4.050]
============================================================
[Input Before LLM] - Global Step 500
============================================================
  Adaptor embeddings shape: torch.Size([4, 583, 896])
  Input embeddings shape: torch.Size([4, 583, 896])
  Attention mask shape: torch.Size([4, 583])
  Input dtype: torch.float16
  Adaptor embeddings range: [-24.1562, 21.3125]
  Input embeddings range: [-24.1562, 21.3125]
  Input embeddings mean: 0.0009, std: 0.7886
  Language inputs shape: torch.Size([4, 553, 896])

============================================================
Global Step 500
============================================================

[Losses]
  language_loss: 0.000379 (shape: torch.Size([4, 552]), count: 28)
  route_loss: 0.408203 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.193359 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 501/535957 [05:23<96:07:38,  1.55it/s, v_num=full, train/loss_step=4.050]Epoch 0:   0%|          | 501/535957 [05:23<96:07:39,  1.55it/s, v_num=full, train/loss_step=3.630]Epoch 0:   0%|          | 502/535957 [05:24<96:06:42,  1.55it/s, v_num=full, train/loss_step=3.630]Epoch 0:   0%|          | 502/535957 [05:24<96:06:43,  1.55it/s, v_num=full, train/loss_step=8.050]Epoch 0:   0%|          | 503/535957 [05:24<96:05:47,  1.55it/s, v_num=full, train/loss_step=8.050]Epoch 0:   0%|          | 503/535957 [05:24<96:05:48,  1.55it/s, v_num=full, train/loss_step=7.360]Epoch 0:   0%|          | 504/535957 [05:25<96:04:16,  1.55it/s, v_num=full, train/loss_step=7.360]Epoch 0:   0%|          | 504/535957 [05:25<96:04:17,  1.55it/s, v_num=full, train/loss_step=4.880]Epoch 0:   0%|          | 505/535957 [05:26<96:03:08,  1.55it/s, v_num=full, train/loss_step=4.880]Epoch 0:   0%|          | 505/535957 [05:26<96:03:10,  1.55it/s, v_num=full, train/loss_step=6.950]Epoch 0:   0%|          | 506/535957 [05:26<96:01:49,  1.55it/s, v_num=full, train/loss_step=6.950]Epoch 0:   0%|          | 506/535957 [05:26<96:01:50,  1.55it/s, v_num=full, train/loss_step=5.950]Epoch 0:   0%|          | 507/535957 [05:27<96:00:22,  1.55it/s, v_num=full, train/loss_step=5.950]Epoch 0:   0%|          | 507/535957 [05:27<96:00:23,  1.55it/s, v_num=full, train/loss_step=7.040]Epoch 0:   0%|          | 508/535957 [05:27<95:58:57,  1.55it/s, v_num=full, train/loss_step=7.040]Epoch 0:   0%|          | 508/535957 [05:27<95:58:58,  1.55it/s, v_num=full, train/loss_step=7.860]Epoch 0:   0%|          | 509/535957 [05:28<95:57:38,  1.55it/s, v_num=full, train/loss_step=7.860]Epoch 0:   0%|          | 509/535957 [05:28<95:57:38,  1.55it/s, v_num=full, train/loss_step=6.290]Epoch 0:   0%|          | 510/535957 [05:28<95:56:12,  1.55it/s, v_num=full, train/loss_step=6.290]Epoch 0:   0%|          | 510/535957 [05:28<95:56:13,  1.55it/s, v_num=full, train/loss_step=4.300]
============================================================
Global Step 510
============================================================

[Losses]
  language_loss: 0.000285 (shape: torch.Size([4, 561]), count: 28)
  route_loss: 2.251953 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.269531 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 511/535957 [05:29<95:54:48,  1.55it/s, v_num=full, train/loss_step=4.300]Epoch 0:   0%|          | 511/535957 [05:29<95:54:48,  1.55it/s, v_num=full, train/loss_step=6.540]Epoch 0:   0%|          | 512/535957 [05:30<95:53:09,  1.55it/s, v_num=full, train/loss_step=6.540]Epoch 0:   0%|          | 512/535957 [05:30<95:53:10,  1.55it/s, v_num=full, train/loss_step=5.470]Epoch 0:   0%|          | 513/535957 [05:30<95:51:42,  1.55it/s, v_num=full, train/loss_step=5.470]Epoch 0:   0%|          | 513/535957 [05:30<95:51:43,  1.55it/s, v_num=full, train/loss_step=1.950]Epoch 0:   0%|          | 514/535957 [05:31<95:50:16,  1.55it/s, v_num=full, train/loss_step=1.950]Epoch 0:   0%|          | 514/535957 [05:31<95:50:17,  1.55it/s, v_num=full, train/loss_step=6.410]Epoch 0:   0%|          | 515/535957 [05:31<95:48:46,  1.55it/s, v_num=full, train/loss_step=6.410]Epoch 0:   0%|          | 515/535957 [05:31<95:48:47,  1.55it/s, v_num=full, train/loss_step=5.500]Epoch 0:   0%|          | 516/535957 [05:32<95:47:18,  1.55it/s, v_num=full, train/loss_step=5.500]Epoch 0:   0%|          | 516/535957 [05:32<95:47:19,  1.55it/s, v_num=full, train/loss_step=7.310]Epoch 0:   0%|          | 517/535957 [05:32<95:45:51,  1.55it/s, v_num=full, train/loss_step=7.310]Epoch 0:   0%|          | 517/535957 [05:32<95:45:52,  1.55it/s, v_num=full, train/loss_step=3.350]Epoch 0:   0%|          | 518/535957 [05:33<95:44:29,  1.55it/s, v_num=full, train/loss_step=3.350]Epoch 0:   0%|          | 518/535957 [05:33<95:44:30,  1.55it/s, v_num=full, train/loss_step=6.300]Epoch 0:   0%|          | 519/535957 [05:34<95:43:12,  1.55it/s, v_num=full, train/loss_step=6.300]Epoch 0:   0%|          | 519/535957 [05:34<95:43:13,  1.55it/s, v_num=full, train/loss_step=5.390]Epoch 0:   0%|          | 520/535957 [05:34<95:41:42,  1.55it/s, v_num=full, train/loss_step=5.390]Epoch 0:   0%|          | 520/535957 [05:34<95:41:42,  1.55it/s, v_num=full, train/loss_step=6.440]
============================================================
Global Step 520
============================================================

[Losses]
  language_loss: 0.000316 (shape: torch.Size([4, 546]), count: 28)
  route_loss: 2.578125 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.132812 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 521/535957 [05:35<95:40:15,  1.55it/s, v_num=full, train/loss_step=6.440]Epoch 0:   0%|          | 521/535957 [05:35<95:40:16,  1.55it/s, v_num=full, train/loss_step=5.730]Epoch 0:   0%|          | 522/535957 [05:35<95:38:48,  1.56it/s, v_num=full, train/loss_step=5.730]Epoch 0:   0%|          | 522/535957 [05:35<95:38:49,  1.56it/s, v_num=full, train/loss_step=6.670]Epoch 0:   0%|          | 523/535957 [05:36<95:37:17,  1.56it/s, v_num=full, train/loss_step=6.670]Epoch 0:   0%|          | 523/535957 [05:36<95:37:18,  1.56it/s, v_num=full, train/loss_step=6.120]Epoch 0:   0%|          | 524/535957 [05:36<95:35:55,  1.56it/s, v_num=full, train/loss_step=6.120]Epoch 0:   0%|          | 524/535957 [05:36<95:35:56,  1.56it/s, v_num=full, train/loss_step=6.340]Epoch 0:   0%|          | 525/535957 [05:37<95:34:28,  1.56it/s, v_num=full, train/loss_step=6.340]Epoch 0:   0%|          | 525/535957 [05:37<95:34:28,  1.56it/s, v_num=full, train/loss_step=3.730]Epoch 0:   0%|          | 526/535957 [05:37<95:33:15,  1.56it/s, v_num=full, train/loss_step=3.730]Epoch 0:   0%|          | 526/535957 [05:37<95:33:15,  1.56it/s, v_num=full, train/loss_step=7.520]Epoch 0:   0%|          | 527/535957 [05:38<95:31:50,  1.56it/s, v_num=full, train/loss_step=7.520]Epoch 0:   0%|          | 527/535957 [05:38<95:31:51,  1.56it/s, v_num=full, train/loss_step=7.340]Epoch 0:   0%|          | 528/535957 [05:39<95:30:25,  1.56it/s, v_num=full, train/loss_step=7.340]Epoch 0:   0%|          | 528/535957 [05:39<95:30:26,  1.56it/s, v_num=full, train/loss_step=3.580]Epoch 0:   0%|          | 529/535957 [05:39<95:29:03,  1.56it/s, v_num=full, train/loss_step=3.580]Epoch 0:   0%|          | 529/535957 [05:39<95:29:04,  1.56it/s, v_num=full, train/loss_step=4.070]Epoch 0:   0%|          | 530/535957 [05:40<95:27:37,  1.56it/s, v_num=full, train/loss_step=4.070]Epoch 0:   0%|          | 530/535957 [05:40<95:27:38,  1.56it/s, v_num=full, train/loss_step=1.770]
============================================================
Global Step 530
============================================================

[Losses]
  language_loss: 0.000245 (shape: torch.Size([4, 552]), count: 28)
  route_loss: 1.307617 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 5.730469 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 531/535957 [05:40<95:26:20,  1.56it/s, v_num=full, train/loss_step=1.770]Epoch 0:   0%|          | 531/535957 [05:40<95:26:20,  1.56it/s, v_num=full, train/loss_step=7.060]Epoch 0:   0%|          | 532/535957 [05:41<95:24:54,  1.56it/s, v_num=full, train/loss_step=7.060]Epoch 0:   0%|          | 532/535957 [05:41<95:24:55,  1.56it/s, v_num=full, train/loss_step=5.870]Epoch 0:   0%|          | 533/535957 [05:41<95:23:34,  1.56it/s, v_num=full, train/loss_step=5.870]Epoch 0:   0%|          | 533/535957 [05:41<95:23:35,  1.56it/s, v_num=full, train/loss_step=7.930]Epoch 0:   0%|          | 534/535957 [05:42<95:22:22,  1.56it/s, v_num=full, train/loss_step=7.930]Epoch 0:   0%|          | 534/535957 [05:42<95:22:23,  1.56it/s, v_num=full, train/loss_step=6.400]Epoch 0:   0%|          | 535/535957 [05:42<95:21:06,  1.56it/s, v_num=full, train/loss_step=6.400]Epoch 0:   0%|          | 535/535957 [05:42<95:21:07,  1.56it/s, v_num=full, train/loss_step=8.160]Epoch 0:   0%|          | 536/535957 [05:43<95:19:59,  1.56it/s, v_num=full, train/loss_step=8.160]Epoch 0:   0%|          | 536/535957 [05:43<95:20:00,  1.56it/s, v_num=full, train/loss_step=3.330]Epoch 0:   0%|          | 537/535957 [05:44<95:18:35,  1.56it/s, v_num=full, train/loss_step=3.330]Epoch 0:   0%|          | 537/535957 [05:44<95:18:36,  1.56it/s, v_num=full, train/loss_step=5.740]Epoch 0:   0%|          | 538/535957 [05:44<95:17:19,  1.56it/s, v_num=full, train/loss_step=5.740]Epoch 0:   0%|          | 538/535957 [05:44<95:17:19,  1.56it/s, v_num=full, train/loss_step=9.550]Epoch 0:   0%|          | 539/535957 [05:45<95:15:59,  1.56it/s, v_num=full, train/loss_step=9.550]Epoch 0:   0%|          | 539/535957 [05:45<95:16:00,  1.56it/s, v_num=full, train/loss_step=6.680]Epoch 0:   0%|          | 540/535957 [05:45<95:14:39,  1.56it/s, v_num=full, train/loss_step=6.680]Epoch 0:   0%|          | 540/535957 [05:45<95:14:39,  1.56it/s, v_num=full, train/loss_step=3.820]
============================================================
Global Step 540
============================================================

[Losses]
  language_loss: 0.000272 (shape: torch.Size([4, 561]), count: 28)
  route_loss: 2.064453 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.634766 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 541/535957 [05:46<95:13:17,  1.56it/s, v_num=full, train/loss_step=3.820]Epoch 0:   0%|          | 541/535957 [05:46<95:13:17,  1.56it/s, v_num=full, train/loss_step=5.720]Epoch 0:   0%|          | 542/535957 [05:46<95:11:53,  1.56it/s, v_num=full, train/loss_step=5.720]Epoch 0:   0%|          | 542/535957 [05:46<95:11:54,  1.56it/s, v_num=full, train/loss_step=4.440]Epoch 0:   0%|          | 543/535957 [05:47<95:10:35,  1.56it/s, v_num=full, train/loss_step=4.440]Epoch 0:   0%|          | 543/535957 [05:47<95:10:36,  1.56it/s, v_num=full, train/loss_step=8.200]Epoch 0:   0%|          | 544/535957 [05:48<95:09:15,  1.56it/s, v_num=full, train/loss_step=8.200]Epoch 0:   0%|          | 544/535957 [05:48<95:09:15,  1.56it/s, v_num=full, train/loss_step=9.080]Epoch 0:   0%|          | 545/535957 [05:48<95:07:56,  1.56it/s, v_num=full, train/loss_step=9.080]Epoch 0:   0%|          | 545/535957 [05:48<95:07:57,  1.56it/s, v_num=full, train/loss_step=8.210]Epoch 0:   0%|          | 546/535957 [05:49<95:06:36,  1.56it/s, v_num=full, train/loss_step=8.210]Epoch 0:   0%|          | 546/535957 [05:49<95:06:37,  1.56it/s, v_num=full, train/loss_step=8.040]Epoch 0:   0%|          | 547/535957 [05:49<95:05:23,  1.56it/s, v_num=full, train/loss_step=8.040]Epoch 0:   0%|          | 547/535957 [05:49<95:05:24,  1.56it/s, v_num=full, train/loss_step=3.100]Epoch 0:   0%|          | 548/535957 [05:50<95:04:07,  1.56it/s, v_num=full, train/loss_step=3.100]Epoch 0:   0%|          | 548/535957 [05:50<95:04:08,  1.56it/s, v_num=full, train/loss_step=3.520]Epoch 0:   0%|          | 549/535957 [05:50<95:02:46,  1.56it/s, v_num=full, train/loss_step=3.520]Epoch 0:   0%|          | 549/535957 [05:50<95:02:47,  1.56it/s, v_num=full, train/loss_step=3.830]Epoch 0:   0%|          | 550/535957 [05:51<95:01:25,  1.57it/s, v_num=full, train/loss_step=3.830]Epoch 0:   0%|          | 550/535957 [05:51<95:01:26,  1.57it/s, v_num=full, train/loss_step=4.240]
============================================================
Global Step 550
============================================================

[Losses]
  language_loss: 0.000254 (shape: torch.Size([4, 552]), count: 28)
  route_loss: 0.802246 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 2.156250 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 551/535957 [05:51<95:00:09,  1.57it/s, v_num=full, train/loss_step=4.240]Epoch 0:   0%|          | 551/535957 [05:51<95:00:11,  1.57it/s, v_num=full, train/loss_step=2.980]Epoch 0:   0%|          | 552/535957 [05:52<94:58:51,  1.57it/s, v_num=full, train/loss_step=2.980]Epoch 0:   0%|          | 552/535957 [05:52<94:58:52,  1.57it/s, v_num=full, train/loss_step=4.200]Epoch 0:   0%|          | 553/535957 [05:53<94:57:32,  1.57it/s, v_num=full, train/loss_step=4.200]Epoch 0:   0%|          | 553/535957 [05:53<94:57:33,  1.57it/s, v_num=full, train/loss_step=9.230]Epoch 0:   0%|          | 554/535957 [05:53<94:56:13,  1.57it/s, v_num=full, train/loss_step=9.230]Epoch 0:   0%|          | 554/535957 [05:53<94:56:14,  1.57it/s, v_num=full, train/loss_step=6.110]Epoch 0:   0%|          | 555/535957 [05:54<94:54:57,  1.57it/s, v_num=full, train/loss_step=6.110]Epoch 0:   0%|          | 555/535957 [05:54<94:54:57,  1.57it/s, v_num=full, train/loss_step=4.380]Epoch 0:   0%|          | 556/535957 [05:54<94:53:35,  1.57it/s, v_num=full, train/loss_step=4.380]Epoch 0:   0%|          | 556/535957 [05:54<94:53:36,  1.57it/s, v_num=full, train/loss_step=9.650]Epoch 0:   0%|          | 557/535957 [05:55<94:52:22,  1.57it/s, v_num=full, train/loss_step=9.650]Epoch 0:   0%|          | 557/535957 [05:55<94:52:23,  1.57it/s, v_num=full, train/loss_step=6.110]Epoch 0:   0%|          | 558/535957 [05:55<94:51:19,  1.57it/s, v_num=full, train/loss_step=6.110]Epoch 0:   0%|          | 558/535957 [05:55<94:51:20,  1.57it/s, v_num=full, train/loss_step=7.880]Epoch 0:   0%|          | 559/535957 [05:56<94:50:03,  1.57it/s, v_num=full, train/loss_step=7.880]Epoch 0:   0%|          | 559/535957 [05:56<94:50:04,  1.57it/s, v_num=full, train/loss_step=7.130]Epoch 0:   0%|          | 560/535957 [05:57<94:48:44,  1.57it/s, v_num=full, train/loss_step=7.130]Epoch 0:   0%|          | 560/535957 [05:57<94:48:44,  1.57it/s, v_num=full, train/loss_step=5.610]
============================================================
Global Step 560
============================================================

[Losses]
  language_loss: 0.000185 (shape: torch.Size([4, 550]), count: 28)
  route_loss: 1.670898 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 7.750000 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 561/535957 [05:57<94:47:30,  1.57it/s, v_num=full, train/loss_step=5.610]Epoch 0:   0%|          | 561/535957 [05:57<94:47:31,  1.57it/s, v_num=full, train/loss_step=9.440]Epoch 0:   0%|          | 562/535957 [05:58<94:46:20,  1.57it/s, v_num=full, train/loss_step=9.440]Epoch 0:   0%|          | 562/535957 [05:58<94:46:20,  1.57it/s, v_num=full, train/loss_step=3.080]Epoch 0:   0%|          | 563/535957 [05:58<94:45:08,  1.57it/s, v_num=full, train/loss_step=3.080]Epoch 0:   0%|          | 563/535957 [05:58<94:45:09,  1.57it/s, v_num=full, train/loss_step=1.410]Epoch 0:   0%|          | 564/535957 [05:59<94:43:50,  1.57it/s, v_num=full, train/loss_step=1.410]Epoch 0:   0%|          | 564/535957 [05:59<94:43:50,  1.57it/s, v_num=full, train/loss_step=10.10]Epoch 0:   0%|          | 565/535957 [05:59<94:42:37,  1.57it/s, v_num=full, train/loss_step=10.10]Epoch 0:   0%|          | 565/535957 [05:59<94:42:37,  1.57it/s, v_num=full, train/loss_step=4.240]Epoch 0:   0%|          | 566/535957 [06:00<94:41:30,  1.57it/s, v_num=full, train/loss_step=4.240]Epoch 0:   0%|          | 566/535957 [06:00<94:41:31,  1.57it/s, v_num=full, train/loss_step=5.730]Epoch 0:   0%|          | 567/535957 [06:00<94:40:22,  1.57it/s, v_num=full, train/loss_step=5.730]Epoch 0:   0%|          | 567/535957 [06:00<94:40:23,  1.57it/s, v_num=full, train/loss_step=3.920]Epoch 0:   0%|          | 568/535957 [06:01<94:39:06,  1.57it/s, v_num=full, train/loss_step=3.920]Epoch 0:   0%|          | 568/535957 [06:01<94:39:07,  1.57it/s, v_num=full, train/loss_step=5.390]Epoch 0:   0%|          | 569/535957 [06:02<94:37:50,  1.57it/s, v_num=full, train/loss_step=5.390]Epoch 0:   0%|          | 569/535957 [06:02<94:37:51,  1.57it/s, v_num=full, train/loss_step=7.010]Epoch 0:   0%|          | 570/535957 [06:02<94:36:42,  1.57it/s, v_num=full, train/loss_step=7.010]Epoch 0:   0%|          | 570/535957 [06:02<94:36:43,  1.57it/s, v_num=full, train/loss_step=3.970]
============================================================
Global Step 570
============================================================

[Losses]
  language_loss: 0.000707 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 2.250000 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 1.378906 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 571/535957 [06:03<94:35:33,  1.57it/s, v_num=full, train/loss_step=3.970]Epoch 0:   0%|          | 571/535957 [06:03<94:35:33,  1.57it/s, v_num=full, train/loss_step=3.690]Epoch 0:   0%|          | 572/535957 [06:03<94:34:21,  1.57it/s, v_num=full, train/loss_step=3.690]Epoch 0:   0%|          | 572/535957 [06:03<94:34:22,  1.57it/s, v_num=full, train/loss_step=4.010]Epoch 0:   0%|          | 573/535957 [06:04<94:33:11,  1.57it/s, v_num=full, train/loss_step=4.010]Epoch 0:   0%|          | 573/535957 [06:04<94:33:12,  1.57it/s, v_num=full, train/loss_step=10.90]Epoch 0:   0%|          | 574/535957 [06:04<94:32:05,  1.57it/s, v_num=full, train/loss_step=10.90]Epoch 0:   0%|          | 574/535957 [06:04<94:32:05,  1.57it/s, v_num=full, train/loss_step=6.770]Epoch 0:   0%|          | 575/535957 [06:05<94:30:51,  1.57it/s, v_num=full, train/loss_step=6.770]Epoch 0:   0%|          | 575/535957 [06:05<94:30:52,  1.57it/s, v_num=full, train/loss_step=3.340]Epoch 0:   0%|          | 576/535957 [06:05<94:29:38,  1.57it/s, v_num=full, train/loss_step=3.340]Epoch 0:   0%|          | 576/535957 [06:05<94:29:39,  1.57it/s, v_num=full, train/loss_step=4.500]Epoch 0:   0%|          | 577/535957 [06:06<94:28:25,  1.57it/s, v_num=full, train/loss_step=4.500]Epoch 0:   0%|          | 577/535957 [06:06<94:28:26,  1.57it/s, v_num=full, train/loss_step=2.000]Epoch 0:   0%|          | 578/535957 [06:07<94:27:15,  1.57it/s, v_num=full, train/loss_step=2.000]Epoch 0:   0%|          | 578/535957 [06:07<94:27:16,  1.57it/s, v_num=full, train/loss_step=7.220]Epoch 0:   0%|          | 579/535957 [06:07<94:26:06,  1.57it/s, v_num=full, train/loss_step=7.220]Epoch 0:   0%|          | 579/535957 [06:07<94:26:06,  1.57it/s, v_num=full, train/loss_step=3.900]Epoch 0:   0%|          | 580/535957 [06:08<94:24:57,  1.58it/s, v_num=full, train/loss_step=3.900]Epoch 0:   0%|          | 580/535957 [06:08<94:24:57,  1.58it/s, v_num=full, train/loss_step=4.230]
============================================================
Global Step 580
============================================================

[Losses]
  language_loss: 0.000175 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 2.201172 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 2.412109 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 581/535957 [06:08<94:23:50,  1.58it/s, v_num=full, train/loss_step=4.230]Epoch 0:   0%|          | 581/535957 [06:08<94:23:51,  1.58it/s, v_num=full, train/loss_step=4.630]Epoch 0:   0%|          | 582/535957 [06:09<94:22:46,  1.58it/s, v_num=full, train/loss_step=4.630]Epoch 0:   0%|          | 582/535957 [06:09<94:22:47,  1.58it/s, v_num=full, train/loss_step=4.540]Epoch 0:   0%|          | 583/535957 [06:09<94:21:38,  1.58it/s, v_num=full, train/loss_step=4.540]Epoch 0:   0%|          | 583/535957 [06:09<94:21:39,  1.58it/s, v_num=full, train/loss_step=3.950]Epoch 0:   0%|          | 584/535957 [06:10<94:20:29,  1.58it/s, v_num=full, train/loss_step=3.950]Epoch 0:   0%|          | 584/535957 [06:10<94:20:30,  1.58it/s, v_num=full, train/loss_step=10.60]Epoch 0:   0%|          | 585/535957 [06:11<94:19:24,  1.58it/s, v_num=full, train/loss_step=10.60]Epoch 0:   0%|          | 585/535957 [06:11<94:19:24,  1.58it/s, v_num=full, train/loss_step=4.770]Epoch 0:   0%|          | 586/535957 [06:11<94:18:23,  1.58it/s, v_num=full, train/loss_step=4.770]Epoch 0:   0%|          | 586/535957 [06:11<94:18:24,  1.58it/s, v_num=full, train/loss_step=5.210]Epoch 0:   0%|          | 587/535957 [06:12<94:17:13,  1.58it/s, v_num=full, train/loss_step=5.210]Epoch 0:   0%|          | 587/535957 [06:12<94:17:13,  1.58it/s, v_num=full, train/loss_step=4.670]Epoch 0:   0%|          | 588/535957 [06:12<94:16:06,  1.58it/s, v_num=full, train/loss_step=4.670]Epoch 0:   0%|          | 588/535957 [06:12<94:16:06,  1.58it/s, v_num=full, train/loss_step=3.600]Epoch 0:   0%|          | 589/535957 [06:13<94:14:56,  1.58it/s, v_num=full, train/loss_step=3.600]Epoch 0:   0%|          | 589/535957 [06:13<94:14:57,  1.58it/s, v_num=full, train/loss_step=5.210]Epoch 0:   0%|          | 590/535957 [06:13<94:13:48,  1.58it/s, v_num=full, train/loss_step=5.210]Epoch 0:   0%|          | 590/535957 [06:13<94:13:48,  1.58it/s, v_num=full, train/loss_step=8.120]
============================================================
Global Step 590
============================================================

[Losses]
  language_loss: 0.000211 (shape: torch.Size([4, 547]), count: 28)
  route_loss: 1.233398 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.791016 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 591/535957 [06:14<94:12:40,  1.58it/s, v_num=full, train/loss_step=8.120]Epoch 0:   0%|          | 591/535957 [06:14<94:12:41,  1.58it/s, v_num=full, train/loss_step=5.040]Epoch 0:   0%|          | 592/535957 [06:14<94:11:33,  1.58it/s, v_num=full, train/loss_step=5.040]Epoch 0:   0%|          | 592/535957 [06:14<94:11:33,  1.58it/s, v_num=full, train/loss_step=8.990]Epoch 0:   0%|          | 593/535957 [06:15<94:10:27,  1.58it/s, v_num=full, train/loss_step=8.990]Epoch 0:   0%|          | 593/535957 [06:15<94:10:27,  1.58it/s, v_num=full, train/loss_step=5.240]Epoch 0:   0%|          | 594/535957 [06:16<94:09:18,  1.58it/s, v_num=full, train/loss_step=5.240]Epoch 0:   0%|          | 594/535957 [06:16<94:09:19,  1.58it/s, v_num=full, train/loss_step=5.290]Epoch 0:   0%|          | 595/535957 [06:16<94:08:09,  1.58it/s, v_num=full, train/loss_step=5.290]Epoch 0:   0%|          | 595/535957 [06:16<94:08:09,  1.58it/s, v_num=full, train/loss_step=5.350]Epoch 0:   0%|          | 596/535957 [06:17<94:07:03,  1.58it/s, v_num=full, train/loss_step=5.350]Epoch 0:   0%|          | 596/535957 [06:17<94:07:04,  1.58it/s, v_num=full, train/loss_step=3.060]Epoch 0:   0%|          | 597/535957 [06:17<94:06:01,  1.58it/s, v_num=full, train/loss_step=3.060]Epoch 0:   0%|          | 597/535957 [06:17<94:06:02,  1.58it/s, v_num=full, train/loss_step=4.650]Epoch 0:   0%|          | 598/535957 [06:18<94:04:56,  1.58it/s, v_num=full, train/loss_step=4.650]Epoch 0:   0%|          | 598/535957 [06:18<94:04:56,  1.58it/s, v_num=full, train/loss_step=7.110]Epoch 0:   0%|          | 599/535957 [06:18<94:03:49,  1.58it/s, v_num=full, train/loss_step=7.110]Epoch 0:   0%|          | 599/535957 [06:18<94:03:50,  1.58it/s, v_num=full, train/loss_step=8.130]Epoch 0:   0%|          | 600/535957 [06:24<95:17:35,  1.56it/s, v_num=full, train/loss_step=8.130]Epoch 0:   0%|          | 600/535957 [06:24<95:22:26,  1.56it/s, v_num=full, train/loss_step=3.460]
============================================================
[Input Before LLM] - Global Step 600
============================================================
  Adaptor embeddings shape: torch.Size([4, 590, 896])
  Input embeddings shape: torch.Size([4, 590, 896])
  Attention mask shape: torch.Size([4, 590])
  Input dtype: torch.float16
  Adaptor embeddings range: [-6.8984, 8.3438]
  Input embeddings range: [-6.8984, 8.3438]
  Input embeddings mean: 0.0008, std: 0.7651
  Language inputs shape: torch.Size([4, 560, 896])

============================================================
Global Step 600
============================================================

[Losses]
  language_loss: 0.000145 (shape: torch.Size([4, 559]), count: 28)
  route_loss: 1.108398 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.714844 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 601/535957 [06:27<95:58:01,  1.55it/s, v_num=full, train/loss_step=3.460]Epoch 0:   0%|          | 601/535957 [06:27<95:58:01,  1.55it/s, v_num=full, train/loss_step=5.830]Epoch 0:   0%|          | 602/535957 [06:28<95:56:40,  1.55it/s, v_num=full, train/loss_step=5.830]Epoch 0:   0%|          | 602/535957 [06:28<95:56:41,  1.55it/s, v_num=full, train/loss_step=2.010]Epoch 0:   0%|          | 603/535957 [06:28<95:55:17,  1.55it/s, v_num=full, train/loss_step=2.010]Epoch 0:   0%|          | 603/535957 [06:28<95:55:18,  1.55it/s, v_num=full, train/loss_step=2.100]Epoch 0:   0%|          | 604/535957 [06:29<95:54:02,  1.55it/s, v_num=full, train/loss_step=2.100]Epoch 0:   0%|          | 604/535957 [06:29<95:54:02,  1.55it/s, v_num=full, train/loss_step=3.650]Epoch 0:   0%|          | 605/535957 [06:30<95:52:46,  1.55it/s, v_num=full, train/loss_step=3.650]Epoch 0:   0%|          | 605/535957 [06:30<95:52:47,  1.55it/s, v_num=full, train/loss_step=2.930]Epoch 0:   0%|          | 606/535957 [06:30<95:51:30,  1.55it/s, v_num=full, train/loss_step=2.930]Epoch 0:   0%|          | 606/535957 [06:30<95:51:31,  1.55it/s, v_num=full, train/loss_step=5.180]Epoch 0:   0%|          | 607/535957 [06:31<95:50:13,  1.55it/s, v_num=full, train/loss_step=5.180]Epoch 0:   0%|          | 607/535957 [06:31<95:50:14,  1.55it/s, v_num=full, train/loss_step=3.810]Epoch 0:   0%|          | 608/535957 [06:31<95:48:54,  1.55it/s, v_num=full, train/loss_step=3.810]Epoch 0:   0%|          | 608/535957 [06:31<95:48:54,  1.55it/s, v_num=full, train/loss_step=4.860]Epoch 0:   0%|          | 609/535957 [06:32<95:47:39,  1.55it/s, v_num=full, train/loss_step=4.860]Epoch 0:   0%|          | 609/535957 [06:32<95:47:40,  1.55it/s, v_num=full, train/loss_step=4.910]Epoch 0:   0%|          | 610/535957 [06:32<95:46:24,  1.55it/s, v_num=full, train/loss_step=4.910]Epoch 0:   0%|          | 610/535957 [06:32<95:46:25,  1.55it/s, v_num=full, train/loss_step=5.540]
============================================================
Global Step 610
============================================================

[Losses]
  language_loss: 0.000154 (shape: torch.Size([4, 553]), count: 28)
  route_loss: 0.723633 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 2.578125 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 611/535957 [06:33<95:45:08,  1.55it/s, v_num=full, train/loss_step=5.540]Epoch 0:   0%|          | 611/535957 [06:33<95:45:08,  1.55it/s, v_num=full, train/loss_step=3.310]Epoch 0:   0%|          | 612/535957 [06:33<95:43:57,  1.55it/s, v_num=full, train/loss_step=3.310]Epoch 0:   0%|          | 612/535957 [06:33<95:43:58,  1.55it/s, v_num=full, train/loss_step=6.440]Epoch 0:   0%|          | 613/535957 [06:34<95:42:46,  1.55it/s, v_num=full, train/loss_step=6.440]Epoch 0:   0%|          | 613/535957 [06:34<95:42:47,  1.55it/s, v_num=full, train/loss_step=6.680]Epoch 0:   0%|          | 614/535957 [06:35<95:41:37,  1.55it/s, v_num=full, train/loss_step=6.680]Epoch 0:   0%|          | 614/535957 [06:35<95:41:37,  1.55it/s, v_num=full, train/loss_step=6.430]Epoch 0:   0%|          | 615/535957 [06:35<95:40:23,  1.55it/s, v_num=full, train/loss_step=6.430]Epoch 0:   0%|          | 615/535957 [06:35<95:40:24,  1.55it/s, v_num=full, train/loss_step=6.090]Epoch 0:   0%|          | 616/535957 [06:36<95:39:07,  1.55it/s, v_num=full, train/loss_step=6.090]Epoch 0:   0%|          | 616/535957 [06:36<95:39:07,  1.55it/s, v_num=full, train/loss_step=4.470]Epoch 0:   0%|          | 617/535957 [06:36<95:37:53,  1.55it/s, v_num=full, train/loss_step=4.470]Epoch 0:   0%|          | 617/535957 [06:36<95:37:53,  1.55it/s, v_num=full, train/loss_step=10.50]Epoch 0:   0%|          | 618/535957 [06:37<95:36:41,  1.56it/s, v_num=full, train/loss_step=10.50]Epoch 0:   0%|          | 618/535957 [06:37<95:36:42,  1.56it/s, v_num=full, train/loss_step=5.570]Epoch 0:   0%|          | 619/535957 [06:37<95:35:26,  1.56it/s, v_num=full, train/loss_step=5.570]Epoch 0:   0%|          | 619/535957 [06:37<95:35:26,  1.56it/s, v_num=full, train/loss_step=2.260]Epoch 0:   0%|          | 620/535957 [06:38<95:34:12,  1.56it/s, v_num=full, train/loss_step=2.260]Epoch 0:   0%|          | 620/535957 [06:38<95:34:13,  1.56it/s, v_num=full, train/loss_step=3.060]
============================================================
Global Step 620
============================================================

[Losses]
  language_loss: 0.000182 (shape: torch.Size([4, 560]), count: 28)
  route_loss: 0.766602 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.769531 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 621/535957 [06:39<95:32:58,  1.56it/s, v_num=full, train/loss_step=3.060]Epoch 0:   0%|          | 621/535957 [06:39<95:32:58,  1.56it/s, v_num=full, train/loss_step=5.550]Epoch 0:   0%|          | 622/535957 [06:39<95:31:46,  1.56it/s, v_num=full, train/loss_step=5.550]Epoch 0:   0%|          | 622/535957 [06:39<95:31:46,  1.56it/s, v_num=full, train/loss_step=5.820]Epoch 0:   0%|          | 623/535957 [06:40<95:30:33,  1.56it/s, v_num=full, train/loss_step=5.820]Epoch 0:   0%|          | 623/535957 [06:40<95:30:34,  1.56it/s, v_num=full, train/loss_step=4.680]Epoch 0:   0%|          | 624/535957 [06:40<95:29:22,  1.56it/s, v_num=full, train/loss_step=4.680]Epoch 0:   0%|          | 624/535957 [06:40<95:29:23,  1.56it/s, v_num=full, train/loss_step=4.620]Epoch 0:   0%|          | 625/535957 [06:41<95:28:10,  1.56it/s, v_num=full, train/loss_step=4.620]Epoch 0:   0%|          | 625/535957 [06:41<95:28:11,  1.56it/s, v_num=full, train/loss_step=11.70]Epoch 0:   0%|          | 626/535957 [06:41<95:26:53,  1.56it/s, v_num=full, train/loss_step=11.70]Epoch 0:   0%|          | 626/535957 [06:41<95:26:53,  1.56it/s, v_num=full, train/loss_step=4.200]Epoch 0:   0%|          | 627/535957 [06:42<95:25:35,  1.56it/s, v_num=full, train/loss_step=4.200]Epoch 0:   0%|          | 627/535957 [06:42<95:25:36,  1.56it/s, v_num=full, train/loss_step=8.010]Epoch 0:   0%|          | 628/535957 [06:42<95:24:21,  1.56it/s, v_num=full, train/loss_step=8.010]Epoch 0:   0%|          | 628/535957 [06:42<95:24:22,  1.56it/s, v_num=full, train/loss_step=3.210]Epoch 0:   0%|          | 629/535957 [06:43<95:23:09,  1.56it/s, v_num=full, train/loss_step=3.210]Epoch 0:   0%|          | 629/535957 [06:43<95:23:10,  1.56it/s, v_num=full, train/loss_step=4.800]Epoch 0:   0%|          | 630/535957 [06:44<95:22:02,  1.56it/s, v_num=full, train/loss_step=4.800]Epoch 0:   0%|          | 630/535957 [06:44<95:22:03,  1.56it/s, v_num=full, train/loss_step=4.860]
============================================================
Global Step 630
============================================================

[Losses]
  language_loss: 0.000353 (shape: torch.Size([4, 559]), count: 28)
  route_loss: 0.710938 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.816406 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 631/535957 [06:44<95:20:50,  1.56it/s, v_num=full, train/loss_step=4.860]Epoch 0:   0%|          | 631/535957 [06:44<95:20:50,  1.56it/s, v_num=full, train/loss_step=4.560]Epoch 0:   0%|          | 632/535957 [06:45<95:19:52,  1.56it/s, v_num=full, train/loss_step=4.560]Epoch 0:   0%|          | 632/535957 [06:45<95:19:53,  1.56it/s, v_num=full, train/loss_step=4.900]Epoch 0:   0%|          | 633/535957 [06:45<95:18:40,  1.56it/s, v_num=full, train/loss_step=4.900]Epoch 0:   0%|          | 633/535957 [06:45<95:18:40,  1.56it/s, v_num=full, train/loss_step=5.000]Epoch 0:   0%|          | 634/535957 [06:46<95:17:30,  1.56it/s, v_num=full, train/loss_step=5.000]Epoch 0:   0%|          | 634/535957 [06:46<95:17:30,  1.56it/s, v_num=full, train/loss_step=3.340]Epoch 0:   0%|          | 635/535957 [06:46<95:16:19,  1.56it/s, v_num=full, train/loss_step=3.340]Epoch 0:   0%|          | 635/535957 [06:46<95:16:19,  1.56it/s, v_num=full, train/loss_step=8.330]Epoch 0:   0%|          | 636/535957 [06:47<95:15:09,  1.56it/s, v_num=full, train/loss_step=8.330]Epoch 0:   0%|          | 636/535957 [06:47<95:15:10,  1.56it/s, v_num=full, train/loss_step=3.410]Epoch 0:   0%|          | 637/535957 [06:47<95:14:01,  1.56it/s, v_num=full, train/loss_step=3.410]Epoch 0:   0%|          | 637/535957 [06:47<95:14:01,  1.56it/s, v_num=full, train/loss_step=3.530]Epoch 0:   0%|          | 638/535957 [06:48<95:12:51,  1.56it/s, v_num=full, train/loss_step=3.530]Epoch 0:   0%|          | 638/535957 [06:48<95:12:51,  1.56it/s, v_num=full, train/loss_step=6.000]Epoch 0:   0%|          | 639/535957 [06:49<95:11:44,  1.56it/s, v_num=full, train/loss_step=6.000]Epoch 0:   0%|          | 639/535957 [06:49<95:11:45,  1.56it/s, v_num=full, train/loss_step=4.110]Epoch 0:   0%|          | 640/535957 [06:49<95:10:34,  1.56it/s, v_num=full, train/loss_step=4.110]Epoch 0:   0%|          | 640/535957 [06:49<95:10:34,  1.56it/s, v_num=full, train/loss_step=8.660]
============================================================
Global Step 640
============================================================

[Losses]
  language_loss: 0.000570 (shape: torch.Size([4, 556]), count: 28)
  route_loss: 2.621094 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 10.156250 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 641/535957 [06:50<95:09:35,  1.56it/s, v_num=full, train/loss_step=8.660]Epoch 0:   0%|          | 641/535957 [06:50<95:09:35,  1.56it/s, v_num=full, train/loss_step=12.80]Epoch 0:   0%|          | 642/535957 [06:50<95:08:29,  1.56it/s, v_num=full, train/loss_step=12.80]Epoch 0:   0%|          | 642/535957 [06:50<95:08:30,  1.56it/s, v_num=full, train/loss_step=5.780]Epoch 0:   0%|          | 643/535957 [06:51<95:07:20,  1.56it/s, v_num=full, train/loss_step=5.780]Epoch 0:   0%|          | 643/535957 [06:51<95:07:21,  1.56it/s, v_num=full, train/loss_step=4.090]Epoch 0:   0%|          | 644/535957 [06:51<95:06:13,  1.56it/s, v_num=full, train/loss_step=4.090]Epoch 0:   0%|          | 644/535957 [06:51<95:06:14,  1.56it/s, v_num=full, train/loss_step=3.220]Epoch 0:   0%|          | 645/535957 [06:52<95:05:06,  1.56it/s, v_num=full, train/loss_step=3.220]Epoch 0:   0%|          | 645/535957 [06:52<95:05:07,  1.56it/s, v_num=full, train/loss_step=8.160]Epoch 0:   0%|          | 646/535957 [06:53<95:03:58,  1.56it/s, v_num=full, train/loss_step=8.160]Epoch 0:   0%|          | 646/535957 [06:53<95:03:58,  1.56it/s, v_num=full, train/loss_step=4.950]Epoch 0:   0%|          | 647/535957 [06:53<95:02:50,  1.56it/s, v_num=full, train/loss_step=4.950]Epoch 0:   0%|          | 647/535957 [06:53<95:02:51,  1.56it/s, v_num=full, train/loss_step=5.180]Epoch 0:   0%|          | 648/535957 [06:54<95:01:47,  1.56it/s, v_num=full, train/loss_step=5.180]Epoch 0:   0%|          | 648/535957 [06:54<95:01:47,  1.56it/s, v_num=full, train/loss_step=4.220]Epoch 0:   0%|          | 649/535957 [06:54<95:00:37,  1.57it/s, v_num=full, train/loss_step=4.220]Epoch 0:   0%|          | 649/535957 [06:54<95:00:38,  1.57it/s, v_num=full, train/loss_step=3.500]Epoch 0:   0%|          | 650/535957 [06:55<94:59:31,  1.57it/s, v_num=full, train/loss_step=3.500]Epoch 0:   0%|          | 650/535957 [06:55<94:59:31,  1.57it/s, v_num=full, train/loss_step=8.160]
============================================================
Global Step 650
============================================================

[Losses]
  language_loss: 0.000318 (shape: torch.Size([4, 554]), count: 28)
  route_loss: 1.639648 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.824219 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 651/535957 [06:55<94:58:27,  1.57it/s, v_num=full, train/loss_step=8.160]Epoch 0:   0%|          | 651/535957 [06:55<94:58:28,  1.57it/s, v_num=full, train/loss_step=6.490]Epoch 0:   0%|          | 652/535957 [06:56<94:57:20,  1.57it/s, v_num=full, train/loss_step=6.490]Epoch 0:   0%|          | 652/535957 [06:56<94:57:20,  1.57it/s, v_num=full, train/loss_step=6.150]Epoch 0:   0%|          | 653/535957 [06:56<94:56:16,  1.57it/s, v_num=full, train/loss_step=6.150]Epoch 0:   0%|          | 653/535957 [06:56<94:56:17,  1.57it/s, v_num=full, train/loss_step=10.50]Epoch 0:   0%|          | 654/535957 [06:57<94:55:16,  1.57it/s, v_num=full, train/loss_step=10.50]Epoch 0:   0%|          | 654/535957 [06:57<94:55:17,  1.57it/s, v_num=full, train/loss_step=9.660]Epoch 0:   0%|          | 655/535957 [06:58<94:54:10,  1.57it/s, v_num=full, train/loss_step=9.660]Epoch 0:   0%|          | 655/535957 [06:58<94:54:11,  1.57it/s, v_num=full, train/loss_step=1.840]Epoch 0:   0%|          | 656/535957 [06:58<94:53:01,  1.57it/s, v_num=full, train/loss_step=1.840]Epoch 0:   0%|          | 656/535957 [06:58<94:53:01,  1.57it/s, v_num=full, train/loss_step=7.010]Epoch 0:   0%|          | 657/535957 [06:59<94:51:56,  1.57it/s, v_num=full, train/loss_step=7.010]Epoch 0:   0%|          | 657/535957 [06:59<94:51:57,  1.57it/s, v_num=full, train/loss_step=4.940]Epoch 0:   0%|          | 658/535957 [06:59<94:50:52,  1.57it/s, v_num=full, train/loss_step=4.940]Epoch 0:   0%|          | 658/535957 [06:59<94:50:53,  1.57it/s, v_num=full, train/loss_step=2.820]Epoch 0:   0%|          | 659/535957 [07:00<94:49:55,  1.57it/s, v_num=full, train/loss_step=2.820]Epoch 0:   0%|          | 659/535957 [07:00<94:49:55,  1.57it/s, v_num=full, train/loss_step=6.750]Epoch 0:   0%|          | 660/535957 [07:00<94:48:57,  1.57it/s, v_num=full, train/loss_step=6.750]Epoch 0:   0%|          | 660/535957 [07:00<94:48:57,  1.57it/s, v_num=full, train/loss_step=8.660]
============================================================
Global Step 660
============================================================

[Losses]
  language_loss: 0.000265 (shape: torch.Size([4, 547]), count: 28)
  route_loss: 2.103516 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 2.339844 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 661/535957 [07:01<94:48:00,  1.57it/s, v_num=full, train/loss_step=8.660]Epoch 0:   0%|          | 661/535957 [07:01<94:48:00,  1.57it/s, v_num=full, train/loss_step=4.460]Epoch 0:   0%|          | 662/535957 [07:01<94:47:03,  1.57it/s, v_num=full, train/loss_step=4.460]Epoch 0:   0%|          | 662/535957 [07:01<94:47:03,  1.57it/s, v_num=full, train/loss_step=4.100]Epoch 0:   0%|          | 663/535957 [07:02<94:46:06,  1.57it/s, v_num=full, train/loss_step=4.100]Epoch 0:   0%|          | 663/535957 [07:02<94:46:06,  1.57it/s, v_num=full, train/loss_step=7.500]Epoch 0:   0%|          | 664/535957 [07:03<94:45:28,  1.57it/s, v_num=full, train/loss_step=7.500]Epoch 0:   0%|          | 664/535957 [07:03<94:45:29,  1.57it/s, v_num=full, train/loss_step=1.790]Epoch 0:   0%|          | 665/535957 [07:03<94:44:37,  1.57it/s, v_num=full, train/loss_step=1.790]Epoch 0:   0%|          | 665/535957 [07:03<94:44:37,  1.57it/s, v_num=full, train/loss_step=4.580]Epoch 0:   0%|          | 666/535957 [07:04<94:43:35,  1.57it/s, v_num=full, train/loss_step=4.580]Epoch 0:   0%|          | 666/535957 [07:04<94:43:36,  1.57it/s, v_num=full, train/loss_step=4.240]Epoch 0:   0%|          | 667/535957 [07:04<94:42:38,  1.57it/s, v_num=full, train/loss_step=4.240]Epoch 0:   0%|          | 667/535957 [07:04<94:42:39,  1.57it/s, v_num=full, train/loss_step=5.650]Epoch 0:   0%|          | 668/535957 [07:05<94:41:43,  1.57it/s, v_num=full, train/loss_step=5.650]Epoch 0:   0%|          | 668/535957 [07:05<94:41:43,  1.57it/s, v_num=full, train/loss_step=4.880]Epoch 0:   0%|          | 669/535957 [07:05<94:40:42,  1.57it/s, v_num=full, train/loss_step=4.880]Epoch 0:   0%|          | 669/535957 [07:05<94:40:42,  1.57it/s, v_num=full, train/loss_step=3.840]Epoch 0:   0%|          | 670/535957 [07:06<94:39:41,  1.57it/s, v_num=full, train/loss_step=3.840]Epoch 0:   0%|          | 670/535957 [07:06<94:39:42,  1.57it/s, v_num=full, train/loss_step=5.390]
============================================================
Global Step 670
============================================================

[Losses]
  language_loss: 0.000526 (shape: torch.Size([4, 552]), count: 28)
  route_loss: 0.721191 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 9.609375 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 671/535957 [07:07<94:38:44,  1.57it/s, v_num=full, train/loss_step=5.390]Epoch 0:   0%|          | 671/535957 [07:07<94:38:45,  1.57it/s, v_num=full, train/loss_step=10.40]Epoch 0:   0%|          | 672/535957 [07:07<94:37:47,  1.57it/s, v_num=full, train/loss_step=10.40]Epoch 0:   0%|          | 672/535957 [07:07<94:37:48,  1.57it/s, v_num=full, train/loss_step=3.550]Epoch 0:   0%|          | 673/535957 [07:08<94:36:51,  1.57it/s, v_num=full, train/loss_step=3.550]Epoch 0:   0%|          | 673/535957 [07:08<94:36:52,  1.57it/s, v_num=full, train/loss_step=3.140]Epoch 0:   0%|          | 674/535957 [07:08<94:36:01,  1.57it/s, v_num=full, train/loss_step=3.140]Epoch 0:   0%|          | 674/535957 [07:08<94:36:01,  1.57it/s, v_num=full, train/loss_step=3.300]Epoch 0:   0%|          | 675/535957 [07:09<94:35:02,  1.57it/s, v_num=full, train/loss_step=3.300]Epoch 0:   0%|          | 675/535957 [07:09<94:35:02,  1.57it/s, v_num=full, train/loss_step=5.630]Epoch 0:   0%|          | 676/535957 [07:09<94:34:05,  1.57it/s, v_num=full, train/loss_step=5.630]Epoch 0:   0%|          | 676/535957 [07:09<94:34:06,  1.57it/s, v_num=full, train/loss_step=3.630]Epoch 0:   0%|          | 677/535957 [07:10<94:33:08,  1.57it/s, v_num=full, train/loss_step=3.630]Epoch 0:   0%|          | 677/535957 [07:10<94:33:09,  1.57it/s, v_num=full, train/loss_step=4.550]Epoch 0:   0%|          | 678/535957 [07:11<94:32:13,  1.57it/s, v_num=full, train/loss_step=4.550]Epoch 0:   0%|          | 678/535957 [07:11<94:32:14,  1.57it/s, v_num=full, train/loss_step=4.290]Epoch 0:   0%|          | 679/535957 [07:11<94:31:18,  1.57it/s, v_num=full, train/loss_step=4.290]Epoch 0:   0%|          | 679/535957 [07:11<94:31:18,  1.57it/s, v_num=full, train/loss_step=8.120]Epoch 0:   0%|          | 680/535957 [07:12<94:30:25,  1.57it/s, v_num=full, train/loss_step=8.120]Epoch 0:   0%|          | 680/535957 [07:12<94:30:25,  1.57it/s, v_num=full, train/loss_step=8.010]
============================================================
Global Step 680
============================================================

[Losses]
  language_loss: 0.000192 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 0.873535 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 2.988281 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 681/535957 [07:12<94:29:35,  1.57it/s, v_num=full, train/loss_step=8.010]Epoch 0:   0%|          | 681/535957 [07:12<94:29:36,  1.57it/s, v_num=full, train/loss_step=3.880]Epoch 0:   0%|          | 682/535957 [07:13<94:28:42,  1.57it/s, v_num=full, train/loss_step=3.880]Epoch 0:   0%|          | 682/535957 [07:13<94:28:43,  1.57it/s, v_num=full, train/loss_step=5.970]Epoch 0:   0%|          | 683/535957 [07:13<94:27:47,  1.57it/s, v_num=full, train/loss_step=5.970]Epoch 0:   0%|          | 683/535957 [07:13<94:27:47,  1.57it/s, v_num=full, train/loss_step=2.500]Epoch 0:   0%|          | 684/535957 [07:14<94:26:53,  1.57it/s, v_num=full, train/loss_step=2.500]Epoch 0:   0%|          | 684/535957 [07:14<94:26:54,  1.57it/s, v_num=full, train/loss_step=7.840]Epoch 0:   0%|          | 685/535957 [07:15<94:25:57,  1.57it/s, v_num=full, train/loss_step=7.840]Epoch 0:   0%|          | 685/535957 [07:15<94:25:57,  1.57it/s, v_num=full, train/loss_step=4.290]Epoch 0:   0%|          | 686/535957 [07:15<94:25:03,  1.57it/s, v_num=full, train/loss_step=4.290]Epoch 0:   0%|          | 686/535957 [07:15<94:25:04,  1.57it/s, v_num=full, train/loss_step=5.380]Epoch 0:   0%|          | 687/535957 [07:16<94:24:10,  1.58it/s, v_num=full, train/loss_step=5.380]Epoch 0:   0%|          | 687/535957 [07:16<94:24:11,  1.58it/s, v_num=full, train/loss_step=3.690]Epoch 0:   0%|          | 688/535957 [07:16<94:23:13,  1.58it/s, v_num=full, train/loss_step=3.690]Epoch 0:   0%|          | 688/535957 [07:16<94:23:14,  1.58it/s, v_num=full, train/loss_step=6.070]Epoch 0:   0%|          | 689/535957 [07:17<94:22:18,  1.58it/s, v_num=full, train/loss_step=6.070]Epoch 0:   0%|          | 689/535957 [07:17<94:22:18,  1.58it/s, v_num=full, train/loss_step=3.590]Epoch 0:   0%|          | 690/535957 [07:17<94:21:24,  1.58it/s, v_num=full, train/loss_step=3.590]Epoch 0:   0%|          | 690/535957 [07:17<94:21:24,  1.58it/s, v_num=full, train/loss_step=2.630]
============================================================
Global Step 690
============================================================

[Losses]
  language_loss: 0.000189 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 0.680664 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 2.070312 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 691/535957 [07:18<94:20:27,  1.58it/s, v_num=full, train/loss_step=2.630]Epoch 0:   0%|          | 691/535957 [07:18<94:20:28,  1.58it/s, v_num=full, train/loss_step=2.760]Epoch 0:   0%|          | 692/535957 [07:19<94:19:34,  1.58it/s, v_num=full, train/loss_step=2.760]Epoch 0:   0%|          | 692/535957 [07:19<94:19:35,  1.58it/s, v_num=full, train/loss_step=4.350]Epoch 0:   0%|          | 693/535957 [07:19<94:18:41,  1.58it/s, v_num=full, train/loss_step=4.350]Epoch 0:   0%|          | 693/535957 [07:19<94:18:42,  1.58it/s, v_num=full, train/loss_step=10.60]Epoch 0:   0%|          | 694/535957 [07:20<94:17:43,  1.58it/s, v_num=full, train/loss_step=10.60]Epoch 0:   0%|          | 694/535957 [07:20<94:17:44,  1.58it/s, v_num=full, train/loss_step=1.440]Epoch 0:   0%|          | 695/535957 [07:20<94:16:46,  1.58it/s, v_num=full, train/loss_step=1.440]Epoch 0:   0%|          | 695/535957 [07:20<94:16:46,  1.58it/s, v_num=full, train/loss_step=5.270]Epoch 0:   0%|          | 696/535957 [07:21<94:16:01,  1.58it/s, v_num=full, train/loss_step=5.270]Epoch 0:   0%|          | 696/535957 [07:21<94:16:01,  1.58it/s, v_num=full, train/loss_step=3.220]Epoch 0:   0%|          | 697/535957 [07:21<94:15:12,  1.58it/s, v_num=full, train/loss_step=3.220]Epoch 0:   0%|          | 697/535957 [07:21<94:15:12,  1.58it/s, v_num=full, train/loss_step=4.050]Epoch 0:   0%|          | 698/535957 [07:22<94:14:21,  1.58it/s, v_num=full, train/loss_step=4.050]Epoch 0:   0%|          | 698/535957 [07:22<94:14:21,  1.58it/s, v_num=full, train/loss_step=6.780]Epoch 0:   0%|          | 699/535957 [07:22<94:13:28,  1.58it/s, v_num=full, train/loss_step=6.780]Epoch 0:   0%|          | 699/535957 [07:22<94:13:29,  1.58it/s, v_num=full, train/loss_step=5.850]Epoch 0:   0%|          | 700/535957 [07:28<95:17:30,  1.56it/s, v_num=full, train/loss_step=5.850]Epoch 0:   0%|          | 700/535957 [07:28<95:17:31,  1.56it/s, v_num=full, train/loss_step=8.500]
============================================================
[Input Before LLM] - Global Step 700
============================================================
  Adaptor embeddings shape: torch.Size([4, 594, 896])
  Input embeddings shape: torch.Size([4, 594, 896])
  Attention mask shape: torch.Size([4, 594])
  Input dtype: torch.float16
  Adaptor embeddings range: [-7.1289, 8.5859]
  Input embeddings range: [-7.1289, 8.5859]
  Input embeddings mean: 0.0013, std: 0.7764
  Language inputs shape: torch.Size([4, 564, 896])

============================================================
Global Step 700
============================================================

[Losses]
  language_loss: 0.000200 (shape: torch.Size([4, 563]), count: 28)
  route_loss: 1.976562 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.058594 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 701/535957 [07:29<95:16:44,  1.56it/s, v_num=full, train/loss_step=8.500]Epoch 0:   0%|          | 701/535957 [07:29<95:16:45,  1.56it/s, v_num=full, train/loss_step=5.050]Epoch 0:   0%|          | 702/535957 [07:29<95:15:51,  1.56it/s, v_num=full, train/loss_step=5.050]Epoch 0:   0%|          | 702/535957 [07:29<95:15:52,  1.56it/s, v_num=full, train/loss_step=1.780]Epoch 0:   0%|          | 703/535957 [07:30<95:14:51,  1.56it/s, v_num=full, train/loss_step=1.780]Epoch 0:   0%|          | 703/535957 [07:30<95:14:51,  1.56it/s, v_num=full, train/loss_step=2.740]Epoch 0:   0%|          | 704/535957 [07:30<95:13:54,  1.56it/s, v_num=full, train/loss_step=2.740]Epoch 0:   0%|          | 704/535957 [07:30<95:13:54,  1.56it/s, v_num=full, train/loss_step=9.700]Epoch 0:   0%|          | 705/535957 [07:31<95:12:55,  1.56it/s, v_num=full, train/loss_step=9.700]Epoch 0:   0%|          | 705/535957 [07:31<95:12:55,  1.56it/s, v_num=full, train/loss_step=4.220]Epoch 0:   0%|          | 706/535957 [07:32<95:11:57,  1.56it/s, v_num=full, train/loss_step=4.220]Epoch 0:   0%|          | 706/535957 [07:32<95:11:57,  1.56it/s, v_num=full, train/loss_step=2.570]Epoch 0:   0%|          | 707/535957 [07:32<95:10:59,  1.56it/s, v_num=full, train/loss_step=2.570]Epoch 0:   0%|          | 707/535957 [07:32<95:11:00,  1.56it/s, v_num=full, train/loss_step=4.490]Epoch 0:   0%|          | 708/535957 [07:33<95:10:02,  1.56it/s, v_num=full, train/loss_step=4.490]Epoch 0:   0%|          | 708/535957 [07:33<95:10:03,  1.56it/s, v_num=full, train/loss_step=3.690]Epoch 0:   0%|          | 709/535957 [07:33<95:09:00,  1.56it/s, v_num=full, train/loss_step=3.690]Epoch 0:   0%|          | 709/535957 [07:33<95:09:00,  1.56it/s, v_num=full, train/loss_step=3.090]Epoch 0:   0%|          | 710/535957 [07:34<95:08:06,  1.56it/s, v_num=full, train/loss_step=3.090]Epoch 0:   0%|          | 710/535957 [07:34<95:08:07,  1.56it/s, v_num=full, train/loss_step=2.660]
============================================================
Global Step 710
============================================================

[Losses]
  language_loss: 0.000132 (shape: torch.Size([4, 558]), count: 28)
  route_loss: 1.547852 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.509766 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 711/535957 [07:34<95:07:16,  1.56it/s, v_num=full, train/loss_step=2.660]Epoch 0:   0%|          | 711/535957 [07:34<95:07:17,  1.56it/s, v_num=full, train/loss_step=5.070]Epoch 0:   0%|          | 712/535957 [07:35<95:06:18,  1.56it/s, v_num=full, train/loss_step=5.070]Epoch 0:   0%|          | 712/535957 [07:35<95:06:18,  1.56it/s, v_num=full, train/loss_step=3.760]Epoch 0:   0%|          | 713/535957 [07:36<95:05:30,  1.56it/s, v_num=full, train/loss_step=3.760]Epoch 0:   0%|          | 713/535957 [07:36<95:05:31,  1.56it/s, v_num=full, train/loss_step=9.410]Epoch 0:   0%|          | 714/535957 [07:36<95:04:42,  1.56it/s, v_num=full, train/loss_step=9.410]Epoch 0:   0%|          | 714/535957 [07:36<95:04:43,  1.56it/s, v_num=full, train/loss_step=4.550]Epoch 0:   0%|          | 715/535957 [07:37<95:03:47,  1.56it/s, v_num=full, train/loss_step=4.550]Epoch 0:   0%|          | 715/535957 [07:37<95:03:48,  1.56it/s, v_num=full, train/loss_step=6.030]Epoch 0:   0%|          | 716/535957 [07:37<95:02:50,  1.56it/s, v_num=full, train/loss_step=6.030]Epoch 0:   0%|          | 716/535957 [07:39<95:28:33,  1.56it/s, v_num=full, train/loss_step=8.400]Epoch 0:   0%|          | 717/535957 [07:42<95:58:00,  1.55it/s, v_num=full, train/loss_step=8.400]Epoch 0:   0%|          | 717/535957 [07:42<95:58:00,  1.55it/s, v_num=full, train/loss_step=7.480]Epoch 0:   0%|          | 718/535957 [07:43<95:56:52,  1.55it/s, v_num=full, train/loss_step=7.480]Epoch 0:   0%|          | 718/535957 [07:43<95:56:53,  1.55it/s, v_num=full, train/loss_step=1.650]Epoch 0:   0%|          | 719/535957 [07:43<95:55:48,  1.55it/s, v_num=full, train/loss_step=1.650]Epoch 0:   0%|          | 719/535957 [07:43<95:55:50,  1.55it/s, v_num=full, train/loss_step=6.320]Epoch 0:   0%|          | 720/535957 [07:44<95:54:45,  1.55it/s, v_num=full, train/loss_step=6.320]Epoch 0:   0%|          | 720/535957 [07:44<95:54:46,  1.55it/s, v_num=full, train/loss_step=3.250]
============================================================
Global Step 720
============================================================

[Losses]
  language_loss: 0.000152 (shape: torch.Size([4, 559]), count: 28)
  route_loss: 1.309570 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.117188 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 721/535957 [07:45<95:53:49,  1.55it/s, v_num=full, train/loss_step=3.250]Epoch 0:   0%|          | 721/535957 [07:45<95:53:49,  1.55it/s, v_num=full, train/loss_step=5.440]Epoch 0:   0%|          | 722/535957 [07:45<95:52:43,  1.55it/s, v_num=full, train/loss_step=5.440]Epoch 0:   0%|          | 722/535957 [07:45<95:52:44,  1.55it/s, v_num=full, train/loss_step=5.830]Epoch 0:   0%|          | 723/535957 [07:46<95:51:48,  1.55it/s, v_num=full, train/loss_step=5.830]Epoch 0:   0%|          | 723/535957 [07:46<95:51:49,  1.55it/s, v_num=full, train/loss_step=5.730]Epoch 0:   0%|          | 724/535957 [07:46<95:50:44,  1.55it/s, v_num=full, train/loss_step=5.730]Epoch 0:   0%|          | 724/535957 [07:46<95:50:44,  1.55it/s, v_num=full, train/loss_step=4.150]Epoch 0:   0%|          | 725/535957 [07:47<95:49:35,  1.55it/s, v_num=full, train/loss_step=4.150]Epoch 0:   0%|          | 725/535957 [07:47<95:49:35,  1.55it/s, v_num=full, train/loss_step=5.160]Epoch 0:   0%|          | 726/535957 [07:47<95:48:28,  1.55it/s, v_num=full, train/loss_step=5.160]Epoch 0:   0%|          | 726/535957 [07:47<95:48:29,  1.55it/s, v_num=full, train/loss_step=5.460]Epoch 0:   0%|          | 727/535957 [07:48<95:47:27,  1.55it/s, v_num=full, train/loss_step=5.460]Epoch 0:   0%|          | 727/535957 [07:48<95:47:28,  1.55it/s, v_num=full, train/loss_step=5.970]Epoch 0:   0%|          | 728/535957 [07:48<95:46:22,  1.55it/s, v_num=full, train/loss_step=5.970]Epoch 0:   0%|          | 728/535957 [07:48<95:46:23,  1.55it/s, v_num=full, train/loss_step=4.000]Epoch 0:   0%|          | 729/535957 [07:49<95:45:17,  1.55it/s, v_num=full, train/loss_step=4.000]Epoch 0:   0%|          | 729/535957 [07:49<95:45:17,  1.55it/s, v_num=full, train/loss_step=2.900]Epoch 0:   0%|          | 730/535957 [07:50<95:44:12,  1.55it/s, v_num=full, train/loss_step=2.900]Epoch 0:   0%|          | 730/535957 [07:50<95:44:12,  1.55it/s, v_num=full, train/loss_step=8.990]
============================================================
Global Step 730
============================================================

[Losses]
  language_loss: 0.000204 (shape: torch.Size([4, 555]), count: 28)
  route_loss: 1.578125 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 1.631836 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 731/535957 [07:50<95:43:08,  1.55it/s, v_num=full, train/loss_step=8.990]Epoch 0:   0%|          | 731/535957 [07:50<95:43:08,  1.55it/s, v_num=full, train/loss_step=3.220]Epoch 0:   0%|          | 732/535957 [07:51<95:45:46,  1.55it/s, v_num=full, train/loss_step=3.220]Epoch 0:   0%|          | 732/535957 [07:51<95:45:47,  1.55it/s, v_num=full, train/loss_step=6.820]Epoch 0:   0%|          | 733/535957 [07:52<95:44:39,  1.55it/s, v_num=full, train/loss_step=6.820]Epoch 0:   0%|          | 733/535957 [07:52<95:44:40,  1.55it/s, v_num=full, train/loss_step=2.060]Epoch 0:   0%|          | 734/535957 [07:52<95:43:35,  1.55it/s, v_num=full, train/loss_step=2.060]Epoch 0:   0%|          | 734/535957 [07:52<95:43:35,  1.55it/s, v_num=full, train/loss_step=4.860]Epoch 0:   0%|          | 735/535957 [07:53<95:42:36,  1.55it/s, v_num=full, train/loss_step=4.860]Epoch 0:   0%|          | 735/535957 [07:53<95:42:36,  1.55it/s, v_num=full, train/loss_step=3.430]Epoch 0:   0%|          | 736/535957 [07:53<95:41:35,  1.55it/s, v_num=full, train/loss_step=3.430]Epoch 0:   0%|          | 736/535957 [07:53<95:41:35,  1.55it/s, v_num=full, train/loss_step=3.450]Epoch 0:   0%|          | 737/535957 [07:54<95:40:37,  1.55it/s, v_num=full, train/loss_step=3.450]Epoch 0:   0%|          | 737/535957 [07:54<95:40:38,  1.55it/s, v_num=full, train/loss_step=5.570]Epoch 0:   0%|          | 738/535957 [07:54<95:40:01,  1.55it/s, v_num=full, train/loss_step=5.570]Epoch 0:   0%|          | 738/535957 [07:54<95:40:02,  1.55it/s, v_num=full, train/loss_step=4.250]Epoch 0:   0%|          | 739/535957 [07:55<95:39:03,  1.55it/s, v_num=full, train/loss_step=4.250]Epoch 0:   0%|          | 739/535957 [07:55<95:39:04,  1.55it/s, v_num=full, train/loss_step=6.030]Epoch 0:   0%|          | 740/535957 [07:56<95:38:06,  1.55it/s, v_num=full, train/loss_step=6.030]Epoch 0:   0%|          | 740/535957 [07:56<95:38:06,  1.55it/s, v_num=full, train/loss_step=4.570]
============================================================
Global Step 740
============================================================

[Losses]
  language_loss: 0.000207 (shape: torch.Size([4, 550]), count: 28)
  route_loss: 1.434570 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 2.544922 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 741/535957 [07:56<95:37:12,  1.55it/s, v_num=full, train/loss_step=4.570]Epoch 0:   0%|          | 741/535957 [07:56<95:37:12,  1.55it/s, v_num=full, train/loss_step=4.000]Epoch 0:   0%|          | 742/535957 [07:57<95:36:16,  1.56it/s, v_num=full, train/loss_step=4.000]Epoch 0:   0%|          | 742/535957 [07:57<95:36:17,  1.56it/s, v_num=full, train/loss_step=4.060]Epoch 0:   0%|          | 743/535957 [07:57<95:35:21,  1.56it/s, v_num=full, train/loss_step=4.060]Epoch 0:   0%|          | 743/535957 [07:57<95:35:21,  1.56it/s, v_num=full, train/loss_step=8.380]Epoch 0:   0%|          | 744/535957 [07:58<95:34:19,  1.56it/s, v_num=full, train/loss_step=8.380]Epoch 0:   0%|          | 744/535957 [07:58<95:34:19,  1.56it/s, v_num=full, train/loss_step=5.630]Epoch 0:   0%|          | 745/535957 [07:58<95:33:21,  1.56it/s, v_num=full, train/loss_step=5.630]Epoch 0:   0%|          | 745/535957 [07:58<95:33:21,  1.56it/s, v_num=full, train/loss_step=7.490]Epoch 0:   0%|          | 746/535957 [07:59<95:32:21,  1.56it/s, v_num=full, train/loss_step=7.490]Epoch 0:   0%|          | 746/535957 [07:59<95:32:21,  1.56it/s, v_num=full, train/loss_step=4.540]Epoch 0:   0%|          | 747/535957 [07:59<95:31:24,  1.56it/s, v_num=full, train/loss_step=4.540]Epoch 0:   0%|          | 747/535957 [07:59<95:31:24,  1.56it/s, v_num=full, train/loss_step=5.210]Epoch 0:   0%|          | 748/535957 [08:00<95:30:18,  1.56it/s, v_num=full, train/loss_step=5.210]Epoch 0:   0%|          | 748/535957 [08:00<95:30:18,  1.56it/s, v_num=full, train/loss_step=2.470]Epoch 0:   0%|          | 749/535957 [08:01<95:29:18,  1.56it/s, v_num=full, train/loss_step=2.470]Epoch 0:   0%|          | 749/535957 [08:01<95:29:18,  1.56it/s, v_num=full, train/loss_step=5.220]Epoch 0:   0%|          | 750/535957 [08:01<95:28:33,  1.56it/s, v_num=full, train/loss_step=5.220]Epoch 0:   0%|          | 750/535957 [08:01<95:28:33,  1.56it/s, v_num=full, train/loss_step=3.850]
============================================================
Global Step 750
============================================================

[Losses]
  language_loss: 0.000266 (shape: torch.Size([4, 553]), count: 28)
  route_loss: 0.331055 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.818359 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 751/535957 [08:02<95:27:35,  1.56it/s, v_num=full, train/loss_step=3.850]Epoch 0:   0%|          | 751/535957 [08:02<95:27:35,  1.56it/s, v_num=full, train/loss_step=4.170]Epoch 0:   0%|          | 752/535957 [08:02<95:26:34,  1.56it/s, v_num=full, train/loss_step=4.170]Epoch 0:   0%|          | 752/535957 [08:02<95:26:34,  1.56it/s, v_num=full, train/loss_step=5.210]Epoch 0:   0%|          | 753/535957 [08:03<95:25:38,  1.56it/s, v_num=full, train/loss_step=5.210]Epoch 0:   0%|          | 753/535957 [08:03<95:25:38,  1.56it/s, v_num=full, train/loss_step=7.530]Epoch 0:   0%|          | 754/535957 [08:03<95:24:38,  1.56it/s, v_num=full, train/loss_step=7.530]Epoch 0:   0%|          | 754/535957 [08:06<95:52:14,  1.55it/s, v_num=full, train/loss_step=2.120]Epoch 0:   0%|          | 755/535957 [08:09<96:20:14,  1.54it/s, v_num=full, train/loss_step=2.120]Epoch 0:   0%|          | 755/535957 [08:09<96:20:14,  1.54it/s, v_num=full, train/loss_step=6.380]Epoch 0:   0%|          | 756/535957 [08:09<96:19:04,  1.54it/s, v_num=full, train/loss_step=6.380]Epoch 0:   0%|          | 756/535957 [08:09<96:19:04,  1.54it/s, v_num=full, train/loss_step=4.000]Epoch 0:   0%|          | 757/535957 [08:10<96:18:03,  1.54it/s, v_num=full, train/loss_step=4.000]Epoch 0:   0%|          | 757/535957 [08:10<96:18:04,  1.54it/s, v_num=full, train/loss_step=4.050]Epoch 0:   0%|          | 758/535957 [08:10<96:17:21,  1.54it/s, v_num=full, train/loss_step=4.050]Epoch 0:   0%|          | 758/535957 [08:10<96:17:22,  1.54it/s, v_num=full, train/loss_step=2.680]Epoch 0:   0%|          | 759/535957 [08:11<96:16:30,  1.54it/s, v_num=full, train/loss_step=2.680]Epoch 0:   0%|          | 759/535957 [08:11<96:16:30,  1.54it/s, v_num=full, train/loss_step=7.300]Epoch 0:   0%|          | 760/535957 [08:12<96:15:26,  1.54it/s, v_num=full, train/loss_step=7.300]Epoch 0:   0%|          | 760/535957 [08:12<96:15:26,  1.54it/s, v_num=full, train/loss_step=3.380]
============================================================
Global Step 760
============================================================

[Losses]
  language_loss: 0.000281 (shape: torch.Size([4, 552]), count: 28)
  route_loss: 1.516602 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 0.328613 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 761/535957 [08:12<96:14:22,  1.54it/s, v_num=full, train/loss_step=3.380]Epoch 0:   0%|          | 761/535957 [08:12<96:14:23,  1.54it/s, v_num=full, train/loss_step=1.870]Epoch 0:   0%|          | 762/535957 [08:13<96:13:26,  1.54it/s, v_num=full, train/loss_step=1.870]Epoch 0:   0%|          | 762/535957 [08:13<96:13:27,  1.54it/s, v_num=full, train/loss_step=3.800]Epoch 0:   0%|          | 763/535957 [08:13<96:12:27,  1.55it/s, v_num=full, train/loss_step=3.800]Epoch 0:   0%|          | 763/535957 [08:13<96:12:28,  1.55it/s, v_num=full, train/loss_step=4.290]Epoch 0:   0%|          | 764/535957 [08:14<96:11:25,  1.55it/s, v_num=full, train/loss_step=4.290]Epoch 0:   0%|          | 764/535957 [08:14<96:11:25,  1.55it/s, v_num=full, train/loss_step=5.160]Epoch 0:   0%|          | 765/535957 [08:14<96:10:31,  1.55it/s, v_num=full, train/loss_step=5.160]Epoch 0:   0%|          | 765/535957 [08:14<96:10:32,  1.55it/s, v_num=full, train/loss_step=3.090]Epoch 0:   0%|          | 766/535957 [08:15<96:09:53,  1.55it/s, v_num=full, train/loss_step=3.090]Epoch 0:   0%|          | 766/535957 [08:15<96:09:54,  1.55it/s, v_num=full, train/loss_step=9.620]Epoch 0:   0%|          | 767/535957 [08:16<96:08:59,  1.55it/s, v_num=full, train/loss_step=9.620]Epoch 0:   0%|          | 767/535957 [08:16<96:08:59,  1.55it/s, v_num=full, train/loss_step=4.710]Epoch 0:   0%|          | 768/535957 [08:16<96:08:21,  1.55it/s, v_num=full, train/loss_step=4.710]Epoch 0:   0%|          | 768/535957 [08:16<96:08:23,  1.55it/s, v_num=full, train/loss_step=10.10]Epoch 0:   0%|          | 769/535957 [08:17<96:07:20,  1.55it/s, v_num=full, train/loss_step=10.10]Epoch 0:   0%|          | 769/535957 [08:17<96:07:20,  1.55it/s, v_num=full, train/loss_step=3.830]Epoch 0:   0%|          | 770/535957 [08:17<96:06:21,  1.55it/s, v_num=full, train/loss_step=3.830]Epoch 0:   0%|          | 770/535957 [08:17<96:06:22,  1.55it/s, v_num=full, train/loss_step=5.550]
============================================================
Global Step 770
============================================================

[Losses]
  language_loss: 0.000221 (shape: torch.Size([4, 558]), count: 28)
  route_loss: 1.219727 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 5.089844 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 771/535957 [08:18<96:05:27,  1.55it/s, v_num=full, train/loss_step=5.550]Epoch 0:   0%|          | 771/535957 [08:18<96:05:27,  1.55it/s, v_num=full, train/loss_step=6.330]Epoch 0:   0%|          | 772/535957 [08:18<96:04:26,  1.55it/s, v_num=full, train/loss_step=6.330]Epoch 0:   0%|          | 772/535957 [08:18<96:04:27,  1.55it/s, v_num=full, train/loss_step=5.600]Epoch 0:   0%|          | 773/535957 [08:19<96:03:30,  1.55it/s, v_num=full, train/loss_step=5.600]Epoch 0:   0%|          | 773/535957 [08:19<96:03:31,  1.55it/s, v_num=full, train/loss_step=2.100]Epoch 0:   0%|          | 774/535957 [08:20<96:02:29,  1.55it/s, v_num=full, train/loss_step=2.100]Epoch 0:   0%|          | 774/535957 [08:20<96:02:29,  1.55it/s, v_num=full, train/loss_step=7.250]Epoch 0:   0%|          | 775/535957 [08:20<96:01:27,  1.55it/s, v_num=full, train/loss_step=7.250]Epoch 0:   0%|          | 775/535957 [08:20<96:01:28,  1.55it/s, v_num=full, train/loss_step=1.660]Epoch 0:   0%|          | 776/535957 [08:21<96:00:26,  1.55it/s, v_num=full, train/loss_step=1.660]Epoch 0:   0%|          | 776/535957 [08:21<96:00:27,  1.55it/s, v_num=full, train/loss_step=3.300]Epoch 0:   0%|          | 777/535957 [08:21<95:59:29,  1.55it/s, v_num=full, train/loss_step=3.300]Epoch 0:   0%|          | 777/535957 [08:21<95:59:30,  1.55it/s, v_num=full, train/loss_step=7.320]Epoch 0:   0%|          | 778/535957 [08:22<95:58:36,  1.55it/s, v_num=full, train/loss_step=7.320]Epoch 0:   0%|          | 778/535957 [08:22<95:58:37,  1.55it/s, v_num=full, train/loss_step=5.020]Epoch 0:   0%|          | 779/535957 [08:22<95:57:45,  1.55it/s, v_num=full, train/loss_step=5.020]Epoch 0:   0%|          | 779/535957 [08:22<95:57:45,  1.55it/s, v_num=full, train/loss_step=1.410]Epoch 0:   0%|          | 780/535957 [08:23<95:56:51,  1.55it/s, v_num=full, train/loss_step=1.410]Epoch 0:   0%|          | 780/535957 [08:23<95:56:52,  1.55it/s, v_num=full, train/loss_step=5.120]
============================================================
Global Step 780
============================================================

[Losses]
  language_loss: 0.000184 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 1.123047 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 2.064453 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 781/535957 [08:23<95:55:54,  1.55it/s, v_num=full, train/loss_step=5.120]Epoch 0:   0%|          | 781/535957 [08:23<95:55:54,  1.55it/s, v_num=full, train/loss_step=3.200]Epoch 0:   0%|          | 782/535957 [08:24<95:54:58,  1.55it/s, v_num=full, train/loss_step=3.200]Epoch 0:   0%|          | 782/535957 [08:24<95:54:59,  1.55it/s, v_num=full, train/loss_step=3.630]Epoch 0:   0%|          | 783/535957 [08:25<95:54:27,  1.55it/s, v_num=full, train/loss_step=3.630]Epoch 0:   0%|          | 783/535957 [08:25<95:54:28,  1.55it/s, v_num=full, train/loss_step=3.180]Epoch 0:   0%|          | 784/535957 [08:25<95:53:36,  1.55it/s, v_num=full, train/loss_step=3.180]Epoch 0:   0%|          | 784/535957 [08:25<95:53:37,  1.55it/s, v_num=full, train/loss_step=2.530]Epoch 0:   0%|          | 785/535957 [08:26<95:52:39,  1.55it/s, v_num=full, train/loss_step=2.530]Epoch 0:   0%|          | 785/535957 [08:26<95:52:40,  1.55it/s, v_num=full, train/loss_step=5.800]Epoch 0:   0%|          | 786/535957 [08:26<95:51:50,  1.55it/s, v_num=full, train/loss_step=5.800]Epoch 0:   0%|          | 786/535957 [08:26<95:51:50,  1.55it/s, v_num=full, train/loss_step=4.840]Epoch 0:   0%|          | 787/535957 [08:27<95:50:58,  1.55it/s, v_num=full, train/loss_step=4.840]Epoch 0:   0%|          | 787/535957 [08:27<95:50:58,  1.55it/s, v_num=full, train/loss_step=4.550]Epoch 0:   0%|          | 788/535957 [08:27<95:50:03,  1.55it/s, v_num=full, train/loss_step=4.550]Epoch 0:   0%|          | 788/535957 [08:27<95:50:03,  1.55it/s, v_num=full, train/loss_step=6.520]Epoch 0:   0%|          | 789/535957 [08:28<95:49:14,  1.55it/s, v_num=full, train/loss_step=6.520]Epoch 0:   0%|          | 789/535957 [08:28<95:49:14,  1.55it/s, v_num=full, train/loss_step=4.800]Epoch 0:   0%|          | 790/535957 [08:29<95:48:25,  1.55it/s, v_num=full, train/loss_step=4.800]Epoch 0:   0%|          | 790/535957 [08:29<95:48:25,  1.55it/s, v_num=full, train/loss_step=2.780]
============================================================
Global Step 790
============================================================

[Losses]
  language_loss: 0.000100 (shape: torch.Size([4, 559]), count: 28)
  route_loss: 1.242188 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 1.896484 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 791/535957 [08:29<95:47:34,  1.55it/s, v_num=full, train/loss_step=2.780]Epoch 0:   0%|          | 791/535957 [08:29<95:47:34,  1.55it/s, v_num=full, train/loss_step=3.150]Epoch 0:   0%|          | 792/535957 [08:30<95:46:46,  1.55it/s, v_num=full, train/loss_step=3.150]Epoch 0:   0%|          | 792/535957 [08:30<95:46:46,  1.55it/s, v_num=full, train/loss_step=3.590]Epoch 0:   0%|          | 793/535957 [08:30<95:45:51,  1.55it/s, v_num=full, train/loss_step=3.590]Epoch 0:   0%|          | 793/535957 [08:30<95:45:52,  1.55it/s, v_num=full, train/loss_step=4.220]Epoch 0:   0%|          | 794/535957 [08:31<95:45:09,  1.55it/s, v_num=full, train/loss_step=4.220]Epoch 0:   0%|          | 794/535957 [08:31<95:45:10,  1.55it/s, v_num=full, train/loss_step=5.660]Epoch 0:   0%|          | 795/535957 [08:32<95:44:44,  1.55it/s, v_num=full, train/loss_step=5.660]Epoch 0:   0%|          | 795/535957 [08:32<95:44:45,  1.55it/s, v_num=full, train/loss_step=6.620]Epoch 0:   0%|          | 796/535957 [08:32<95:44:21,  1.55it/s, v_num=full, train/loss_step=6.620]Epoch 0:   0%|          | 796/535957 [08:32<95:44:22,  1.55it/s, v_num=full, train/loss_step=7.570]Epoch 0:   0%|          | 797/535957 [08:33<95:43:31,  1.55it/s, v_num=full, train/loss_step=7.570]Epoch 0:   0%|          | 797/535957 [08:33<95:43:32,  1.55it/s, v_num=full, train/loss_step=4.630]Epoch 0:   0%|          | 798/535957 [08:33<95:42:37,  1.55it/s, v_num=full, train/loss_step=4.630]Epoch 0:   0%|          | 798/535957 [08:33<95:42:38,  1.55it/s, v_num=full, train/loss_step=9.120]Epoch 0:   0%|          | 799/535957 [08:34<95:41:46,  1.55it/s, v_num=full, train/loss_step=9.120]Epoch 0:   0%|          | 799/535957 [08:34<95:41:47,  1.55it/s, v_num=full, train/loss_step=4.540]Epoch 0:   0%|          | 800/535957 [08:39<96:36:50,  1.54it/s, v_num=full, train/loss_step=4.540]Epoch 0:   0%|          | 800/535957 [08:39<96:36:51,  1.54it/s, v_num=full, train/loss_step=6.240]
============================================================
[Input Before LLM] - Global Step 800
============================================================
  Adaptor embeddings shape: torch.Size([4, 578, 896])
  Input embeddings shape: torch.Size([4, 578, 896])
  Attention mask shape: torch.Size([4, 578])
  Input dtype: torch.float16
  Adaptor embeddings range: [-66.5000, 48.8750]
  Input embeddings range: [-66.5000, 48.8750]
  Input embeddings mean: 0.0003, std: 0.9248
  Language inputs shape: torch.Size([4, 548, 896])

============================================================
Global Step 800
============================================================

[Losses]
  language_loss: 0.000138 (shape: torch.Size([4, 547]), count: 28)
  route_loss: 0.585938 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 1.834961 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 801/535957 [08:40<96:36:12,  1.54it/s, v_num=full, train/loss_step=6.240]Epoch 0:   0%|          | 801/535957 [08:40<96:36:12,  1.54it/s, v_num=full, train/loss_step=2.430]Epoch 0:   0%|          | 802/535957 [08:41<96:35:15,  1.54it/s, v_num=full, train/loss_step=2.430]Epoch 0:   0%|          | 802/535957 [08:41<96:35:16,  1.54it/s, v_num=full, train/loss_step=5.000]Epoch 0:   0%|          | 803/535957 [08:41<96:34:18,  1.54it/s, v_num=full, train/loss_step=5.000]Epoch 0:   0%|          | 803/535957 [08:41<96:34:18,  1.54it/s, v_num=full, train/loss_step=4.390]Epoch 0:   0%|          | 804/535957 [08:42<96:33:13,  1.54it/s, v_num=full, train/loss_step=4.390]Epoch 0:   0%|          | 804/535957 [08:42<96:33:13,  1.54it/s, v_num=full, train/loss_step=2.190]Epoch 0:   0%|          | 805/535957 [08:42<96:32:15,  1.54it/s, v_num=full, train/loss_step=2.190]Epoch 0:   0%|          | 805/535957 [08:42<96:32:15,  1.54it/s, v_num=full, train/loss_step=6.450]Epoch 0:   0%|          | 806/535957 [08:43<96:31:14,  1.54it/s, v_num=full, train/loss_step=6.450]Epoch 0:   0%|          | 806/535957 [08:43<96:31:14,  1.54it/s, v_num=full, train/loss_step=2.450]Epoch 0:   0%|          | 807/535957 [08:43<96:30:10,  1.54it/s, v_num=full, train/loss_step=2.450]Epoch 0:   0%|          | 807/535957 [08:43<96:30:11,  1.54it/s, v_num=full, train/loss_step=4.200]Epoch 0:   0%|          | 808/535957 [08:44<96:29:07,  1.54it/s, v_num=full, train/loss_step=4.200]Epoch 0:   0%|          | 808/535957 [08:44<96:29:07,  1.54it/s, v_num=full, train/loss_step=2.950]Epoch 0:   0%|          | 809/535957 [08:45<96:28:09,  1.54it/s, v_num=full, train/loss_step=2.950]Epoch 0:   0%|          | 809/535957 [08:45<96:28:10,  1.54it/s, v_num=full, train/loss_step=2.420]Epoch 0:   0%|          | 810/535957 [08:45<96:27:14,  1.54it/s, v_num=full, train/loss_step=2.420]Epoch 0:   0%|          | 810/535957 [08:45<96:27:15,  1.54it/s, v_num=full, train/loss_step=5.570]
============================================================
Global Step 810
============================================================

[Losses]
  language_loss: 0.000206 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 1.031250 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 5.558594 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 811/535957 [08:46<96:26:20,  1.54it/s, v_num=full, train/loss_step=5.570]Epoch 0:   0%|          | 811/535957 [08:46<96:26:20,  1.54it/s, v_num=full, train/loss_step=6.610]Epoch 0:   0%|          | 812/535957 [08:46<96:25:23,  1.54it/s, v_num=full, train/loss_step=6.610]Epoch 0:   0%|          | 812/535957 [08:46<96:25:24,  1.54it/s, v_num=full, train/loss_step=2.290]Epoch 0:   0%|          | 813/535957 [08:47<96:24:29,  1.54it/s, v_num=full, train/loss_step=2.290]Epoch 0:   0%|          | 813/535957 [08:47<96:24:29,  1.54it/s, v_num=full, train/loss_step=6.620]Epoch 0:   0%|          | 814/535957 [08:47<96:23:33,  1.54it/s, v_num=full, train/loss_step=6.620]Epoch 0:   0%|          | 814/535957 [08:47<96:23:33,  1.54it/s, v_num=full, train/loss_step=3.100]Epoch 0:   0%|          | 815/535957 [08:48<96:22:40,  1.54it/s, v_num=full, train/loss_step=3.100]Epoch 0:   0%|          | 815/535957 [08:48<96:22:40,  1.54it/s, v_num=full, train/loss_step=5.930]Epoch 0:   0%|          | 816/535957 [08:48<96:21:44,  1.54it/s, v_num=full, train/loss_step=5.930]Epoch 0:   0%|          | 816/535957 [08:48<96:21:44,  1.54it/s, v_num=full, train/loss_step=4.660]Epoch 0:   0%|          | 817/535957 [08:49<96:20:53,  1.54it/s, v_num=full, train/loss_step=4.660]Epoch 0:   0%|          | 817/535957 [08:49<96:20:53,  1.54it/s, v_num=full, train/loss_step=3.820]Epoch 0:   0%|          | 818/535957 [08:50<96:19:59,  1.54it/s, v_num=full, train/loss_step=3.820]Epoch 0:   0%|          | 818/535957 [08:50<96:20:00,  1.54it/s, v_num=full, train/loss_step=9.840]Epoch 0:   0%|          | 819/535957 [08:50<96:19:03,  1.54it/s, v_num=full, train/loss_step=9.840]Epoch 0:   0%|          | 819/535957 [08:50<96:19:04,  1.54it/s, v_num=full, train/loss_step=4.710]Epoch 0:   0%|          | 820/535957 [08:51<96:18:07,  1.54it/s, v_num=full, train/loss_step=4.710]Epoch 0:   0%|          | 820/535957 [08:51<96:18:07,  1.54it/s, v_num=full, train/loss_step=6.160]
============================================================
Global Step 820
============================================================

[Losses]
  language_loss: 0.000108 (shape: torch.Size([4, 556]), count: 28)
  route_loss: 1.687500 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 2.046875 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 821/535957 [08:51<96:17:14,  1.54it/s, v_num=full, train/loss_step=6.160]Epoch 0:   0%|          | 821/535957 [08:51<96:17:15,  1.54it/s, v_num=full, train/loss_step=3.740]Epoch 0:   0%|          | 822/535957 [08:52<96:16:19,  1.54it/s, v_num=full, train/loss_step=3.740]Epoch 0:   0%|          | 822/535957 [08:52<96:16:19,  1.54it/s, v_num=full, train/loss_step=2.500]Epoch 0:   0%|          | 823/535957 [08:52<96:15:21,  1.54it/s, v_num=full, train/loss_step=2.500]Epoch 0:   0%|          | 823/535957 [08:52<96:15:22,  1.54it/s, v_num=full, train/loss_step=5.140]Epoch 0:   0%|          | 824/535957 [08:53<96:14:29,  1.54it/s, v_num=full, train/loss_step=5.140]Epoch 0:   0%|          | 824/535957 [08:53<96:14:30,  1.54it/s, v_num=full, train/loss_step=3.730]Epoch 0:   0%|          | 825/535957 [08:54<96:13:34,  1.54it/s, v_num=full, train/loss_step=3.730]Epoch 0:   0%|          | 825/535957 [08:54<96:13:35,  1.54it/s, v_num=full, train/loss_step=7.460]Epoch 0:   0%|          | 826/535957 [08:54<96:12:42,  1.55it/s, v_num=full, train/loss_step=7.460]Epoch 0:   0%|          | 826/535957 [08:54<96:12:42,  1.55it/s, v_num=full, train/loss_step=7.390]Epoch 0:   0%|          | 827/535957 [08:55<96:11:43,  1.55it/s, v_num=full, train/loss_step=7.390]Epoch 0:   0%|          | 827/535957 [08:55<96:11:44,  1.55it/s, v_num=full, train/loss_step=7.780]Epoch 0:   0%|          | 828/535957 [08:55<96:10:45,  1.55it/s, v_num=full, train/loss_step=7.780]Epoch 0:   0%|          | 828/535957 [08:55<96:10:46,  1.55it/s, v_num=full, train/loss_step=2.980]Epoch 0:   0%|          | 829/535957 [08:56<96:09:51,  1.55it/s, v_num=full, train/loss_step=2.980]Epoch 0:   0%|          | 829/535957 [08:56<96:09:52,  1.55it/s, v_num=full, train/loss_step=6.650]Epoch 0:   0%|          | 830/535957 [08:56<96:08:56,  1.55it/s, v_num=full, train/loss_step=6.650]Epoch 0:   0%|          | 830/535957 [08:56<96:08:56,  1.55it/s, v_num=full, train/loss_step=4.290]
============================================================
Global Step 830
============================================================

[Losses]
  language_loss: 0.000097 (shape: torch.Size([4, 553]), count: 28)
  route_loss: 0.697266 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.468750 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 831/535957 [08:57<96:07:59,  1.55it/s, v_num=full, train/loss_step=4.290]Epoch 0:   0%|          | 831/535957 [08:57<96:08:00,  1.55it/s, v_num=full, train/loss_step=5.180]Epoch 0:   0%|          | 832/535957 [08:57<96:07:02,  1.55it/s, v_num=full, train/loss_step=5.180]Epoch 0:   0%|          | 832/535957 [08:57<96:07:03,  1.55it/s, v_num=full, train/loss_step=1.600]Epoch 0:   0%|          | 833/535957 [08:58<96:06:08,  1.55it/s, v_num=full, train/loss_step=1.600]Epoch 0:   0%|          | 833/535957 [08:58<96:06:09,  1.55it/s, v_num=full, train/loss_step=6.260]Epoch 0:   0%|          | 834/535957 [08:59<96:05:11,  1.55it/s, v_num=full, train/loss_step=6.260]Epoch 0:   0%|          | 834/535957 [08:59<96:05:11,  1.55it/s, v_num=full, train/loss_step=4.600]Epoch 0:   0%|          | 835/535957 [08:59<96:04:15,  1.55it/s, v_num=full, train/loss_step=4.600]Epoch 0:   0%|          | 835/535957 [08:59<96:04:15,  1.55it/s, v_num=full, train/loss_step=3.790]Epoch 0:   0%|          | 836/535957 [09:00<96:03:18,  1.55it/s, v_num=full, train/loss_step=3.790]Epoch 0:   0%|          | 836/535957 [09:00<96:03:19,  1.55it/s, v_num=full, train/loss_step=6.230]Epoch 0:   0%|          | 837/535957 [09:00<96:02:25,  1.55it/s, v_num=full, train/loss_step=6.230]Epoch 0:   0%|          | 837/535957 [09:00<96:02:26,  1.55it/s, v_num=full, train/loss_step=3.790]Epoch 0:   0%|          | 838/535957 [09:01<96:01:32,  1.55it/s, v_num=full, train/loss_step=3.790]Epoch 0:   0%|          | 838/535957 [09:01<96:01:32,  1.55it/s, v_num=full, train/loss_step=3.580]Epoch 0:   0%|          | 839/535957 [09:01<96:00:39,  1.55it/s, v_num=full, train/loss_step=3.580]Epoch 0:   0%|          | 839/535957 [09:01<96:00:39,  1.55it/s, v_num=full, train/loss_step=10.40]Epoch 0:   0%|          | 840/535957 [09:02<95:59:44,  1.55it/s, v_num=full, train/loss_step=10.40]Epoch 0:   0%|          | 840/535957 [09:02<95:59:44,  1.55it/s, v_num=full, train/loss_step=7.810]
============================================================
Global Step 840
============================================================

[Losses]
  language_loss: 0.000125 (shape: torch.Size([4, 556]), count: 28)
  route_loss: 1.630859 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 2.890625 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 841/535957 [09:03<95:58:55,  1.55it/s, v_num=full, train/loss_step=7.810]Epoch 0:   0%|          | 841/535957 [09:03<95:58:55,  1.55it/s, v_num=full, train/loss_step=4.530]Epoch 0:   0%|          | 842/535957 [09:03<95:57:57,  1.55it/s, v_num=full, train/loss_step=4.530]Epoch 0:   0%|          | 842/535957 [09:03<95:57:57,  1.55it/s, v_num=full, train/loss_step=3.910]Epoch 0:   0%|          | 843/535957 [09:04<95:57:02,  1.55it/s, v_num=full, train/loss_step=3.910]Epoch 0:   0%|          | 843/535957 [09:04<95:57:02,  1.55it/s, v_num=full, train/loss_step=8.590]Epoch 0:   0%|          | 844/535957 [09:04<95:56:09,  1.55it/s, v_num=full, train/loss_step=8.590]Epoch 0:   0%|          | 844/535957 [09:04<95:56:10,  1.55it/s, v_num=full, train/loss_step=4.090]Epoch 0:   0%|          | 845/535957 [09:05<95:55:16,  1.55it/s, v_num=full, train/loss_step=4.090]Epoch 0:   0%|          | 845/535957 [09:05<95:55:16,  1.55it/s, v_num=full, train/loss_step=6.350]Epoch 0:   0%|          | 846/535957 [09:05<95:54:20,  1.55it/s, v_num=full, train/loss_step=6.350]Epoch 0:   0%|          | 846/535957 [09:05<95:54:21,  1.55it/s, v_num=full, train/loss_step=4.980]Epoch 0:   0%|          | 847/535957 [09:06<95:53:28,  1.55it/s, v_num=full, train/loss_step=4.980]Epoch 0:   0%|          | 847/535957 [09:06<95:53:29,  1.55it/s, v_num=full, train/loss_step=2.450]Epoch 0:   0%|          | 848/535957 [09:06<95:52:35,  1.55it/s, v_num=full, train/loss_step=2.450]Epoch 0:   0%|          | 848/535957 [09:06<95:52:36,  1.55it/s, v_num=full, train/loss_step=4.340]Epoch 0:   0%|          | 849/535957 [09:07<95:51:41,  1.55it/s, v_num=full, train/loss_step=4.340]Epoch 0:   0%|          | 849/535957 [09:07<95:51:41,  1.55it/s, v_num=full, train/loss_step=2.640]Epoch 0:   0%|          | 850/535957 [09:08<95:50:48,  1.55it/s, v_num=full, train/loss_step=2.640]Epoch 0:   0%|          | 850/535957 [09:08<95:50:48,  1.55it/s, v_num=full, train/loss_step=7.230]
============================================================
Global Step 850
============================================================

[Losses]
  language_loss: 0.000123 (shape: torch.Size([4, 547]), count: 28)
  route_loss: 0.448486 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.111328 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 851/535957 [09:08<95:49:58,  1.55it/s, v_num=full, train/loss_step=7.230]Epoch 0:   0%|          | 851/535957 [09:08<95:49:58,  1.55it/s, v_num=full, train/loss_step=3.570]Epoch 0:   0%|          | 852/535957 [09:09<95:49:01,  1.55it/s, v_num=full, train/loss_step=3.570]Epoch 0:   0%|          | 852/535957 [09:09<95:49:02,  1.55it/s, v_num=full, train/loss_step=5.420]Epoch 0:   0%|          | 853/535957 [09:09<95:48:06,  1.55it/s, v_num=full, train/loss_step=5.420]Epoch 0:   0%|          | 853/535957 [09:09<95:48:07,  1.55it/s, v_num=full, train/loss_step=2.720]Epoch 0:   0%|          | 854/535957 [09:10<95:47:15,  1.55it/s, v_num=full, train/loss_step=2.720]Epoch 0:   0%|          | 854/535957 [09:10<95:47:16,  1.55it/s, v_num=full, train/loss_step=3.260]Epoch 0:   0%|          | 855/535957 [09:10<95:46:23,  1.55it/s, v_num=full, train/loss_step=3.260]Epoch 0:   0%|          | 855/535957 [09:10<95:46:24,  1.55it/s, v_num=full, train/loss_step=3.320]Epoch 0:   0%|          | 856/535957 [09:11<95:45:26,  1.55it/s, v_num=full, train/loss_step=3.320]Epoch 0:   0%|          | 856/535957 [09:11<95:45:26,  1.55it/s, v_num=full, train/loss_step=6.200]Epoch 0:   0%|          | 857/535957 [09:12<95:44:33,  1.55it/s, v_num=full, train/loss_step=6.200]Epoch 0:   0%|          | 857/535957 [09:12<95:44:33,  1.55it/s, v_num=full, train/loss_step=8.550]Epoch 0:   0%|          | 858/535957 [09:12<95:43:40,  1.55it/s, v_num=full, train/loss_step=8.550]Epoch 0:   0%|          | 858/535957 [09:12<95:43:41,  1.55it/s, v_num=full, train/loss_step=3.050]Epoch 0:   0%|          | 859/535957 [09:13<95:42:48,  1.55it/s, v_num=full, train/loss_step=3.050]Epoch 0:   0%|          | 859/535957 [09:13<95:42:49,  1.55it/s, v_num=full, train/loss_step=2.410]Epoch 0:   0%|          | 860/535957 [09:13<95:41:53,  1.55it/s, v_num=full, train/loss_step=2.410]Epoch 0:   0%|          | 860/535957 [09:13<95:41:54,  1.55it/s, v_num=full, train/loss_step=4.560]
============================================================
Global Step 860
============================================================

[Losses]
  language_loss: 0.000156 (shape: torch.Size([4, 553]), count: 28)
  route_loss: 1.228516 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 2.779297 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 861/535957 [09:14<95:41:03,  1.55it/s, v_num=full, train/loss_step=4.560]Epoch 0:   0%|          | 861/535957 [09:14<95:41:03,  1.55it/s, v_num=full, train/loss_step=4.020]Epoch 0:   0%|          | 862/535957 [09:14<95:40:10,  1.55it/s, v_num=full, train/loss_step=4.020]Epoch 0:   0%|          | 862/535957 [09:14<95:40:11,  1.55it/s, v_num=full, train/loss_step=7.940]Epoch 0:   0%|          | 863/535957 [09:15<95:39:16,  1.55it/s, v_num=full, train/loss_step=7.940]Epoch 0:   0%|          | 863/535957 [09:15<95:39:17,  1.55it/s, v_num=full, train/loss_step=5.200]Epoch 0:   0%|          | 864/535957 [09:15<95:38:22,  1.55it/s, v_num=full, train/loss_step=5.200]Epoch 0:   0%|          | 864/535957 [09:15<95:38:22,  1.55it/s, v_num=full, train/loss_step=2.550]Epoch 0:   0%|          | 865/535957 [09:16<95:37:34,  1.55it/s, v_num=full, train/loss_step=2.550]Epoch 0:   0%|          | 865/535957 [09:16<95:37:34,  1.55it/s, v_num=full, train/loss_step=7.130]Epoch 0:   0%|          | 866/535957 [09:17<95:36:43,  1.55it/s, v_num=full, train/loss_step=7.130]Epoch 0:   0%|          | 866/535957 [09:17<95:36:44,  1.55it/s, v_num=full, train/loss_step=2.800]Epoch 0:   0%|          | 867/535957 [09:17<95:35:54,  1.55it/s, v_num=full, train/loss_step=2.800]Epoch 0:   0%|          | 867/535957 [09:17<95:35:54,  1.55it/s, v_num=full, train/loss_step=3.380]Epoch 0:   0%|          | 868/535957 [09:18<95:35:14,  1.55it/s, v_num=full, train/loss_step=3.380]Epoch 0:   0%|          | 868/535957 [09:18<95:35:14,  1.55it/s, v_num=full, train/loss_step=5.140]Epoch 0:   0%|          | 869/535957 [09:18<95:34:26,  1.56it/s, v_num=full, train/loss_step=5.140]Epoch 0:   0%|          | 869/535957 [09:18<95:34:26,  1.56it/s, v_num=full, train/loss_step=3.360]Epoch 0:   0%|          | 870/535957 [09:19<95:33:32,  1.56it/s, v_num=full, train/loss_step=3.360]Epoch 0:   0%|          | 870/535957 [09:19<95:33:33,  1.56it/s, v_num=full, train/loss_step=3.000]
============================================================
Global Step 870
============================================================

[Losses]
  language_loss: 0.000907 (shape: torch.Size([4, 554]), count: 28)
  route_loss: 0.741699 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 6.519531 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 871/535957 [09:19<95:32:42,  1.56it/s, v_num=full, train/loss_step=3.000]Epoch 0:   0%|          | 871/535957 [09:19<95:32:42,  1.56it/s, v_num=full, train/loss_step=7.330]Epoch 0:   0%|          | 872/535957 [09:20<95:31:51,  1.56it/s, v_num=full, train/loss_step=7.330]Epoch 0:   0%|          | 872/535957 [09:20<95:31:51,  1.56it/s, v_num=full, train/loss_step=6.270]Epoch 0:   0%|          | 873/535957 [09:21<95:30:55,  1.56it/s, v_num=full, train/loss_step=6.270]Epoch 0:   0%|          | 873/535957 [09:21<95:30:56,  1.56it/s, v_num=full, train/loss_step=6.890]Epoch 0:   0%|          | 874/535957 [09:21<95:30:05,  1.56it/s, v_num=full, train/loss_step=6.890]Epoch 0:   0%|          | 874/535957 [09:21<95:30:06,  1.56it/s, v_num=full, train/loss_step=6.670]Epoch 0:   0%|          | 875/535957 [09:22<95:29:13,  1.56it/s, v_num=full, train/loss_step=6.670]Epoch 0:   0%|          | 875/535957 [09:22<95:29:14,  1.56it/s, v_num=full, train/loss_step=3.040]Epoch 0:   0%|          | 876/535957 [09:22<95:28:26,  1.56it/s, v_num=full, train/loss_step=3.040]Epoch 0:   0%|          | 876/535957 [09:22<95:28:27,  1.56it/s, v_num=full, train/loss_step=7.540]Epoch 0:   0%|          | 877/535957 [09:23<95:27:37,  1.56it/s, v_num=full, train/loss_step=7.540]Epoch 0:   0%|          | 877/535957 [09:23<95:27:37,  1.56it/s, v_num=full, train/loss_step=4.150]Epoch 0:   0%|          | 878/535957 [09:23<95:26:45,  1.56it/s, v_num=full, train/loss_step=4.150]Epoch 0:   0%|          | 878/535957 [09:23<95:26:45,  1.56it/s, v_num=full, train/loss_step=5.050]Epoch 0:   0%|          | 879/535957 [09:24<95:25:54,  1.56it/s, v_num=full, train/loss_step=5.050]Epoch 0:   0%|          | 879/535957 [09:24<95:25:54,  1.56it/s, v_num=full, train/loss_step=4.450]Epoch 0:   0%|          | 880/535957 [09:24<95:25:06,  1.56it/s, v_num=full, train/loss_step=4.450]Epoch 0:   0%|          | 880/535957 [09:24<95:25:06,  1.56it/s, v_num=full, train/loss_step=4.270]
============================================================
Global Step 880
============================================================

[Losses]
  language_loss: 0.000151 (shape: torch.Size([4, 558]), count: 28)
  route_loss: 0.524902 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 2.740234 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 881/535957 [09:25<95:24:12,  1.56it/s, v_num=full, train/loss_step=4.270]Epoch 0:   0%|          | 881/535957 [09:25<95:24:13,  1.56it/s, v_num=full, train/loss_step=3.280]Epoch 0:   0%|          | 882/535957 [09:26<95:23:22,  1.56it/s, v_num=full, train/loss_step=3.280]Epoch 0:   0%|          | 882/535957 [09:26<95:23:23,  1.56it/s, v_num=full, train/loss_step=7.800]Epoch 0:   0%|          | 883/535957 [09:26<95:22:32,  1.56it/s, v_num=full, train/loss_step=7.800]Epoch 0:   0%|          | 883/535957 [09:26<95:22:32,  1.56it/s, v_num=full, train/loss_step=4.460]Epoch 0:   0%|          | 884/535957 [09:27<95:21:42,  1.56it/s, v_num=full, train/loss_step=4.460]Epoch 0:   0%|          | 884/535957 [09:27<95:21:43,  1.56it/s, v_num=full, train/loss_step=4.960]Epoch 0:   0%|          | 885/535957 [09:27<95:20:53,  1.56it/s, v_num=full, train/loss_step=4.960]Epoch 0:   0%|          | 885/535957 [09:27<95:20:53,  1.56it/s, v_num=full, train/loss_step=2.960]Epoch 0:   0%|          | 886/535957 [09:28<95:20:04,  1.56it/s, v_num=full, train/loss_step=2.960]Epoch 0:   0%|          | 886/535957 [09:28<95:20:05,  1.56it/s, v_num=full, train/loss_step=7.060]Epoch 0:   0%|          | 887/535957 [09:28<95:19:13,  1.56it/s, v_num=full, train/loss_step=7.060]Epoch 0:   0%|          | 887/535957 [09:28<95:19:14,  1.56it/s, v_num=full, train/loss_step=1.520]Epoch 0:   0%|          | 888/535957 [09:29<95:18:26,  1.56it/s, v_num=full, train/loss_step=1.520]Epoch 0:   0%|          | 888/535957 [09:29<95:18:26,  1.56it/s, v_num=full, train/loss_step=8.070]Epoch 0:   0%|          | 889/535957 [09:29<95:17:34,  1.56it/s, v_num=full, train/loss_step=8.070]Epoch 0:   0%|          | 889/535957 [09:29<95:17:34,  1.56it/s, v_num=full, train/loss_step=4.050]Epoch 0:   0%|          | 890/535957 [09:30<95:16:47,  1.56it/s, v_num=full, train/loss_step=4.050]Epoch 0:   0%|          | 890/535957 [09:30<95:16:47,  1.56it/s, v_num=full, train/loss_step=4.350]
============================================================
Global Step 890
============================================================

[Losses]
  language_loss: 0.000173 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 2.246094 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.740234 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 891/535957 [09:31<95:15:57,  1.56it/s, v_num=full, train/loss_step=4.350]Epoch 0:   0%|          | 891/535957 [09:31<95:15:57,  1.56it/s, v_num=full, train/loss_step=6.000]Epoch 0:   0%|          | 892/535957 [09:31<95:15:08,  1.56it/s, v_num=full, train/loss_step=6.000]Epoch 0:   0%|          | 892/535957 [09:31<95:15:08,  1.56it/s, v_num=full, train/loss_step=4.510]Epoch 0:   0%|          | 893/535957 [09:32<95:14:18,  1.56it/s, v_num=full, train/loss_step=4.510]Epoch 0:   0%|          | 893/535957 [09:32<95:14:19,  1.56it/s, v_num=full, train/loss_step=2.270]Epoch 0:   0%|          | 894/535957 [09:32<95:13:30,  1.56it/s, v_num=full, train/loss_step=2.270]Epoch 0:   0%|          | 894/535957 [09:32<95:13:31,  1.56it/s, v_num=full, train/loss_step=3.050]Epoch 0:   0%|          | 895/535957 [09:33<95:12:41,  1.56it/s, v_num=full, train/loss_step=3.050]Epoch 0:   0%|          | 895/535957 [09:33<95:12:41,  1.56it/s, v_num=full, train/loss_step=4.810]Epoch 0:   0%|          | 896/535957 [09:33<95:11:52,  1.56it/s, v_num=full, train/loss_step=4.810]Epoch 0:   0%|          | 896/535957 [09:33<95:11:53,  1.56it/s, v_num=full, train/loss_step=4.720]Epoch 0:   0%|          | 897/535957 [09:34<95:10:56,  1.56it/s, v_num=full, train/loss_step=4.720]Epoch 0:   0%|          | 897/535957 [09:34<95:10:56,  1.56it/s, v_num=full, train/loss_step=2.630]Epoch 0:   0%|          | 898/535957 [09:35<95:10:07,  1.56it/s, v_num=full, train/loss_step=2.630]Epoch 0:   0%|          | 898/535957 [09:35<95:10:08,  1.56it/s, v_num=full, train/loss_step=4.590]Epoch 0:   0%|          | 899/535957 [09:35<95:09:18,  1.56it/s, v_num=full, train/loss_step=4.590]Epoch 0:   0%|          | 899/535957 [09:35<95:09:19,  1.56it/s, v_num=full, train/loss_step=9.890]Epoch 0:   0%|          | 900/535957 [09:41<95:57:23,  1.55it/s, v_num=full, train/loss_step=9.890]Epoch 0:   0%|          | 900/535957 [09:41<95:57:23,  1.55it/s, v_num=full, train/loss_step=9.310]
============================================================
[Input Before LLM] - Global Step 900
============================================================
  Adaptor embeddings shape: torch.Size([4, 581, 896])
  Input embeddings shape: torch.Size([4, 581, 896])
  Attention mask shape: torch.Size([4, 581])
  Input dtype: torch.float16
  Adaptor embeddings range: [-22.2656, 20.0625]
  Input embeddings range: [-22.2656, 20.0625]
  Input embeddings mean: -0.0006, std: 0.7954
  Language inputs shape: torch.Size([4, 551, 896])

============================================================
Global Step 900
============================================================

[Losses]
  language_loss: 0.000110 (shape: torch.Size([4, 550]), count: 28)
  route_loss: 0.626953 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 1.531250 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 901/535957 [09:41<95:56:42,  1.55it/s, v_num=full, train/loss_step=9.310]Epoch 0:   0%|          | 901/535957 [09:41<95:56:42,  1.55it/s, v_num=full, train/loss_step=2.170]Epoch 0:   0%|          | 902/535957 [09:42<95:55:46,  1.55it/s, v_num=full, train/loss_step=2.170]Epoch 0:   0%|          | 902/535957 [09:42<95:55:46,  1.55it/s, v_num=full, train/loss_step=6.550]Epoch 0:   0%|          | 903/535957 [09:42<95:54:53,  1.55it/s, v_num=full, train/loss_step=6.550]Epoch 0:   0%|          | 903/535957 [09:42<95:54:53,  1.55it/s, v_num=full, train/loss_step=4.550]Epoch 0:   0%|          | 904/535957 [09:43<95:53:58,  1.55it/s, v_num=full, train/loss_step=4.550]Epoch 0:   0%|          | 904/535957 [09:43<95:53:58,  1.55it/s, v_num=full, train/loss_step=4.710]Epoch 0:   0%|          | 905/535957 [09:43<95:53:07,  1.55it/s, v_num=full, train/loss_step=4.710]Epoch 0:   0%|          | 905/535957 [09:43<95:53:07,  1.55it/s, v_num=full, train/loss_step=3.600]Epoch 0:   0%|          | 906/535957 [09:44<95:52:16,  1.55it/s, v_num=full, train/loss_step=3.600]Epoch 0:   0%|          | 906/535957 [09:44<95:52:17,  1.55it/s, v_num=full, train/loss_step=3.640]Epoch 0:   0%|          | 907/535957 [09:44<95:51:24,  1.55it/s, v_num=full, train/loss_step=3.640]Epoch 0:   0%|          | 907/535957 [09:44<95:51:25,  1.55it/s, v_num=full, train/loss_step=4.000]Epoch 0:   0%|          | 908/535957 [09:45<95:50:33,  1.55it/s, v_num=full, train/loss_step=4.000]Epoch 0:   0%|          | 908/535957 [09:45<95:50:33,  1.55it/s, v_num=full, train/loss_step=2.650]Epoch 0:   0%|          | 909/535957 [09:46<95:49:40,  1.55it/s, v_num=full, train/loss_step=2.650]Epoch 0:   0%|          | 909/535957 [09:46<95:49:41,  1.55it/s, v_num=full, train/loss_step=3.520]Epoch 0:   0%|          | 910/535957 [09:46<95:48:51,  1.55it/s, v_num=full, train/loss_step=3.520]Epoch 0:   0%|          | 910/535957 [09:46<95:48:52,  1.55it/s, v_num=full, train/loss_step=3.800]
============================================================
Global Step 910
============================================================

[Losses]
  language_loss: 0.000073 (shape: torch.Size([4, 560]), count: 28)
  route_loss: 1.875977 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 6.191406 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 911/535957 [09:47<95:48:02,  1.55it/s, v_num=full, train/loss_step=3.800]Epoch 0:   0%|          | 911/535957 [09:47<95:48:02,  1.55it/s, v_num=full, train/loss_step=8.070]Epoch 0:   0%|          | 912/535957 [09:47<95:47:12,  1.55it/s, v_num=full, train/loss_step=8.070]Epoch 0:   0%|          | 912/535957 [09:47<95:47:13,  1.55it/s, v_num=full, train/loss_step=6.430]Epoch 0:   0%|          | 913/535957 [09:48<95:46:24,  1.55it/s, v_num=full, train/loss_step=6.430]Epoch 0:   0%|          | 913/535957 [09:48<95:46:24,  1.55it/s, v_num=full, train/loss_step=2.840]Epoch 0:   0%|          | 914/535957 [09:48<95:45:30,  1.55it/s, v_num=full, train/loss_step=2.840]Epoch 0:   0%|          | 914/535957 [09:48<95:45:31,  1.55it/s, v_num=full, train/loss_step=6.390]Epoch 0:   0%|          | 915/535957 [09:49<95:44:38,  1.55it/s, v_num=full, train/loss_step=6.390]Epoch 0:   0%|          | 915/535957 [09:49<95:44:39,  1.55it/s, v_num=full, train/loss_step=2.140]Epoch 0:   0%|          | 916/535957 [09:50<95:43:49,  1.55it/s, v_num=full, train/loss_step=2.140]Epoch 0:   0%|          | 916/535957 [09:50<95:43:50,  1.55it/s, v_num=full, train/loss_step=5.190]Epoch 0:   0%|          | 917/535957 [09:50<95:42:56,  1.55it/s, v_num=full, train/loss_step=5.190]Epoch 0:   0%|          | 917/535957 [09:50<95:42:57,  1.55it/s, v_num=full, train/loss_step=7.360]Epoch 0:   0%|          | 918/535957 [09:51<95:42:06,  1.55it/s, v_num=full, train/loss_step=7.360]Epoch 0:   0%|          | 918/535957 [09:51<95:42:06,  1.55it/s, v_num=full, train/loss_step=3.220]Epoch 0:   0%|          | 919/535957 [09:51<95:41:18,  1.55it/s, v_num=full, train/loss_step=3.220]Epoch 0:   0%|          | 919/535957 [09:51<95:41:18,  1.55it/s, v_num=full, train/loss_step=3.980]Epoch 0:   0%|          | 920/535957 [09:52<95:40:25,  1.55it/s, v_num=full, train/loss_step=3.980]Epoch 0:   0%|          | 920/535957 [09:52<95:40:25,  1.55it/s, v_num=full, train/loss_step=5.340]
============================================================
Global Step 920
============================================================

[Losses]
  language_loss: 0.000101 (shape: torch.Size([4, 553]), count: 28)
  route_loss: 0.750488 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 1.688477 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 921/535957 [09:52<95:39:36,  1.55it/s, v_num=full, train/loss_step=5.340]Epoch 0:   0%|          | 921/535957 [09:52<95:39:36,  1.55it/s, v_num=full, train/loss_step=2.450]Epoch 0:   0%|          | 922/535957 [09:53<95:38:45,  1.55it/s, v_num=full, train/loss_step=2.450]Epoch 0:   0%|          | 922/535957 [09:53<95:38:46,  1.55it/s, v_num=full, train/loss_step=6.380]Epoch 0:   0%|          | 923/535957 [09:53<95:37:54,  1.55it/s, v_num=full, train/loss_step=6.380]Epoch 0:   0%|          | 923/535957 [09:53<95:37:54,  1.55it/s, v_num=full, train/loss_step=5.910]Epoch 0:   0%|          | 924/535957 [09:54<95:37:04,  1.55it/s, v_num=full, train/loss_step=5.910]Epoch 0:   0%|          | 924/535957 [09:54<95:37:04,  1.55it/s, v_num=full, train/loss_step=7.910]Epoch 0:   0%|          | 925/535957 [09:55<95:36:13,  1.55it/s, v_num=full, train/loss_step=7.910]Epoch 0:   0%|          | 925/535957 [09:55<95:36:14,  1.55it/s, v_num=full, train/loss_step=3.900]Epoch 0:   0%|          | 926/535957 [09:55<95:35:26,  1.55it/s, v_num=full, train/loss_step=3.900]Epoch 0:   0%|          | 926/535957 [09:55<95:35:26,  1.55it/s, v_num=full, train/loss_step=7.320]Epoch 0:   0%|          | 927/535957 [09:56<95:34:36,  1.55it/s, v_num=full, train/loss_step=7.320]Epoch 0:   0%|          | 927/535957 [09:56<95:34:36,  1.55it/s, v_num=full, train/loss_step=3.420]Epoch 0:   0%|          | 928/535957 [09:56<95:33:45,  1.56it/s, v_num=full, train/loss_step=3.420]Epoch 0:   0%|          | 928/535957 [09:56<95:33:45,  1.56it/s, v_num=full, train/loss_step=4.370]Epoch 0:   0%|          | 929/535957 [09:57<95:32:55,  1.56it/s, v_num=full, train/loss_step=4.370]Epoch 0:   0%|          | 929/535957 [09:57<95:32:55,  1.56it/s, v_num=full, train/loss_step=2.600]Epoch 0:   0%|          | 930/535957 [09:57<95:32:08,  1.56it/s, v_num=full, train/loss_step=2.600]Epoch 0:   0%|          | 930/535957 [09:57<95:32:08,  1.56it/s, v_num=full, train/loss_step=3.200]
============================================================
Global Step 930
============================================================

[Losses]
  language_loss: 0.000082 (shape: torch.Size([4, 559]), count: 28)
  route_loss: 0.999512 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 7.425781 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 931/535957 [09:58<95:31:20,  1.56it/s, v_num=full, train/loss_step=3.200]Epoch 0:   0%|          | 931/535957 [09:58<95:31:21,  1.56it/s, v_num=full, train/loss_step=8.430]Epoch 0:   0%|          | 932/535957 [09:58<95:30:28,  1.56it/s, v_num=full, train/loss_step=8.430]Epoch 0:   0%|          | 932/535957 [09:58<95:30:29,  1.56it/s, v_num=full, train/loss_step=5.460]Epoch 0:   0%|          | 933/535957 [09:59<95:29:41,  1.56it/s, v_num=full, train/loss_step=5.460]Epoch 0:   0%|          | 933/535957 [09:59<95:29:42,  1.56it/s, v_num=full, train/loss_step=4.000]Epoch 0:   0%|          | 934/535957 [10:00<95:28:51,  1.56it/s, v_num=full, train/loss_step=4.000]Epoch 0:   0%|          | 934/535957 [10:00<95:28:51,  1.56it/s, v_num=full, train/loss_step=5.370]Epoch 0:   0%|          | 935/535957 [10:00<95:28:02,  1.56it/s, v_num=full, train/loss_step=5.370]Epoch 0:   0%|          | 935/535957 [10:00<95:28:02,  1.56it/s, v_num=full, train/loss_step=4.990]Epoch 0:   0%|          | 936/535957 [10:01<95:27:10,  1.56it/s, v_num=full, train/loss_step=4.990]Epoch 0:   0%|          | 936/535957 [10:01<95:27:11,  1.56it/s, v_num=full, train/loss_step=6.820]Epoch 0:   0%|          | 937/535957 [10:01<95:26:22,  1.56it/s, v_num=full, train/loss_step=6.820]Epoch 0:   0%|          | 937/535957 [10:01<95:26:22,  1.56it/s, v_num=full, train/loss_step=5.060]Epoch 0:   0%|          | 938/535957 [10:02<95:25:34,  1.56it/s, v_num=full, train/loss_step=5.060]Epoch 0:   0%|          | 938/535957 [10:02<95:25:34,  1.56it/s, v_num=full, train/loss_step=5.220]Epoch 0:   0%|          | 939/535957 [10:02<95:24:45,  1.56it/s, v_num=full, train/loss_step=5.220]Epoch 0:   0%|          | 939/535957 [10:02<95:24:45,  1.56it/s, v_num=full, train/loss_step=5.500]Epoch 0:   0%|          | 940/535957 [10:03<95:23:58,  1.56it/s, v_num=full, train/loss_step=5.500]Epoch 0:   0%|          | 940/535957 [10:03<95:23:58,  1.56it/s, v_num=full, train/loss_step=5.020]
============================================================
Global Step 940
============================================================

[Losses]
  language_loss: 0.000198 (shape: torch.Size([4, 549]), count: 28)
  route_loss: 0.300537 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 5.332031 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 941/535957 [10:03<95:23:11,  1.56it/s, v_num=full, train/loss_step=5.020]Epoch 0:   0%|          | 941/535957 [10:03<95:23:11,  1.56it/s, v_num=full, train/loss_step=5.650]Epoch 0:   0%|          | 942/535957 [10:04<95:22:26,  1.56it/s, v_num=full, train/loss_step=5.650]Epoch 0:   0%|          | 942/535957 [10:04<95:22:26,  1.56it/s, v_num=full, train/loss_step=6.380]Epoch 0:   0%|          | 943/535957 [10:05<95:21:38,  1.56it/s, v_num=full, train/loss_step=6.380]Epoch 0:   0%|          | 943/535957 [10:05<95:21:39,  1.56it/s, v_num=full, train/loss_step=5.720]Epoch 0:   0%|          | 944/535957 [10:05<95:20:50,  1.56it/s, v_num=full, train/loss_step=5.720]Epoch 0:   0%|          | 944/535957 [10:05<95:20:50,  1.56it/s, v_num=full, train/loss_step=3.440]Epoch 0:   0%|          | 945/535957 [10:06<95:20:03,  1.56it/s, v_num=full, train/loss_step=3.440]Epoch 0:   0%|          | 945/535957 [10:06<95:20:03,  1.56it/s, v_num=full, train/loss_step=5.710]Epoch 0:   0%|          | 946/535957 [10:06<95:19:20,  1.56it/s, v_num=full, train/loss_step=5.710]Epoch 0:   0%|          | 946/535957 [10:06<95:19:20,  1.56it/s, v_num=full, train/loss_step=10.00]Epoch 0:   0%|          | 947/535957 [10:07<95:18:29,  1.56it/s, v_num=full, train/loss_step=10.00]Epoch 0:   0%|          | 947/535957 [10:07<95:18:30,  1.56it/s, v_num=full, train/loss_step=3.260]Epoch 0:   0%|          | 948/535957 [10:07<95:17:43,  1.56it/s, v_num=full, train/loss_step=3.260]Epoch 0:   0%|          | 948/535957 [10:07<95:17:43,  1.56it/s, v_num=full, train/loss_step=4.120]Epoch 0:   0%|          | 949/535957 [10:08<95:16:56,  1.56it/s, v_num=full, train/loss_step=4.120]Epoch 0:   0%|          | 949/535957 [10:08<95:16:56,  1.56it/s, v_num=full, train/loss_step=3.690]Epoch 0:   0%|          | 950/535957 [10:09<95:16:12,  1.56it/s, v_num=full, train/loss_step=3.690]Epoch 0:   0%|          | 950/535957 [10:09<95:16:13,  1.56it/s, v_num=full, train/loss_step=2.370]
============================================================
Global Step 950
============================================================

[Losses]
  language_loss: 0.000155 (shape: torch.Size([4, 556]), count: 28)
  route_loss: 0.782715 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 1.446289 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 951/535957 [10:09<95:15:26,  1.56it/s, v_num=full, train/loss_step=2.370]Epoch 0:   0%|          | 951/535957 [10:09<95:15:26,  1.56it/s, v_num=full, train/loss_step=2.240]Epoch 0:   0%|          | 952/535957 [10:10<95:14:41,  1.56it/s, v_num=full, train/loss_step=2.240]Epoch 0:   0%|          | 952/535957 [10:10<95:14:41,  1.56it/s, v_num=full, train/loss_step=2.880]Epoch 0:   0%|          | 953/535957 [10:10<95:13:55,  1.56it/s, v_num=full, train/loss_step=2.880]Epoch 0:   0%|          | 953/535957 [10:10<95:13:56,  1.56it/s, v_num=full, train/loss_step=7.540]Epoch 0:   0%|          | 954/535957 [10:11<95:13:10,  1.56it/s, v_num=full, train/loss_step=7.540]Epoch 0:   0%|          | 954/535957 [10:11<95:13:10,  1.56it/s, v_num=full, train/loss_step=1.500]Epoch 0:   0%|          | 955/535957 [10:11<95:12:29,  1.56it/s, v_num=full, train/loss_step=1.500]Epoch 0:   0%|          | 955/535957 [10:11<95:12:29,  1.56it/s, v_num=full, train/loss_step=4.560]Epoch 0:   0%|          | 956/535957 [10:12<95:11:38,  1.56it/s, v_num=full, train/loss_step=4.560]Epoch 0:   0%|          | 956/535957 [10:12<95:11:38,  1.56it/s, v_num=full, train/loss_step=3.520]Epoch 0:   0%|          | 957/535957 [10:12<95:10:52,  1.56it/s, v_num=full, train/loss_step=3.520]Epoch 0:   0%|          | 957/535957 [10:12<95:10:53,  1.56it/s, v_num=full, train/loss_step=6.290]Epoch 0:   0%|          | 958/535957 [10:13<95:10:09,  1.56it/s, v_num=full, train/loss_step=6.290]Epoch 0:   0%|          | 958/535957 [10:13<95:10:10,  1.56it/s, v_num=full, train/loss_step=3.390]Epoch 0:   0%|          | 959/535957 [10:14<95:09:23,  1.56it/s, v_num=full, train/loss_step=3.390]Epoch 0:   0%|          | 959/535957 [10:14<95:09:23,  1.56it/s, v_num=full, train/loss_step=6.710]Epoch 0:   0%|          | 960/535957 [10:14<95:08:36,  1.56it/s, v_num=full, train/loss_step=6.710]Epoch 0:   0%|          | 960/535957 [10:14<95:08:37,  1.56it/s, v_num=full, train/loss_step=6.150]
============================================================
Global Step 960
============================================================

[Losses]
  language_loss: 0.000190 (shape: torch.Size([4, 554]), count: 28)
  route_loss: 1.445312 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.984375 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 961/535957 [10:15<95:07:52,  1.56it/s, v_num=full, train/loss_step=6.150]Epoch 0:   0%|          | 961/535957 [10:15<95:07:52,  1.56it/s, v_num=full, train/loss_step=5.450]Epoch 0:   0%|          | 962/535957 [10:15<95:07:06,  1.56it/s, v_num=full, train/loss_step=5.450]Epoch 0:   0%|          | 962/535957 [10:15<95:07:06,  1.56it/s, v_num=full, train/loss_step=5.910]Epoch 0:   0%|          | 963/535957 [10:16<95:06:19,  1.56it/s, v_num=full, train/loss_step=5.910]Epoch 0:   0%|          | 963/535957 [10:16<95:06:20,  1.56it/s, v_num=full, train/loss_step=3.740]Epoch 0:   0%|          | 964/535957 [10:16<95:05:29,  1.56it/s, v_num=full, train/loss_step=3.740]Epoch 0:   0%|          | 964/535957 [10:16<95:05:30,  1.56it/s, v_num=full, train/loss_step=3.170]Epoch 0:   0%|          | 965/535957 [10:17<95:04:42,  1.56it/s, v_num=full, train/loss_step=3.170]Epoch 0:   0%|          | 965/535957 [10:17<95:04:43,  1.56it/s, v_num=full, train/loss_step=6.450]Epoch 0:   0%|          | 966/535957 [10:17<95:03:55,  1.56it/s, v_num=full, train/loss_step=6.450]Epoch 0:   0%|          | 966/535957 [10:17<95:03:56,  1.56it/s, v_num=full, train/loss_step=3.190]Epoch 0:   0%|          | 967/535957 [10:18<95:03:08,  1.56it/s, v_num=full, train/loss_step=3.190]Epoch 0:   0%|          | 967/535957 [10:18<95:03:08,  1.56it/s, v_num=full, train/loss_step=6.310]Epoch 0:   0%|          | 968/535957 [10:19<95:02:22,  1.56it/s, v_num=full, train/loss_step=6.310]Epoch 0:   0%|          | 968/535957 [10:19<95:02:22,  1.56it/s, v_num=full, train/loss_step=6.170]Epoch 0:   0%|          | 969/535957 [10:19<95:01:37,  1.56it/s, v_num=full, train/loss_step=6.170]Epoch 0:   0%|          | 969/535957 [10:19<95:01:37,  1.56it/s, v_num=full, train/loss_step=4.210]Epoch 0:   0%|          | 970/535957 [10:20<95:00:52,  1.56it/s, v_num=full, train/loss_step=4.210]Epoch 0:   0%|          | 970/535957 [10:20<95:00:53,  1.56it/s, v_num=full, train/loss_step=2.850]
============================================================
Global Step 970
============================================================

[Losses]
  language_loss: 0.000126 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 1.731445 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.332031 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 971/535957 [10:20<95:00:05,  1.56it/s, v_num=full, train/loss_step=2.850]Epoch 0:   0%|          | 971/535957 [10:20<95:00:06,  1.56it/s, v_num=full, train/loss_step=6.070]Epoch 0:   0%|          | 972/535957 [10:21<94:59:19,  1.56it/s, v_num=full, train/loss_step=6.070]Epoch 0:   0%|          | 972/535957 [10:21<94:59:20,  1.56it/s, v_num=full, train/loss_step=2.840]Epoch 0:   0%|          | 973/535957 [10:21<94:58:34,  1.56it/s, v_num=full, train/loss_step=2.840]Epoch 0:   0%|          | 973/535957 [10:21<94:58:34,  1.56it/s, v_num=full, train/loss_step=4.550]Epoch 0:   0%|          | 974/535957 [10:22<94:57:51,  1.56it/s, v_num=full, train/loss_step=4.550]Epoch 0:   0%|          | 974/535957 [10:22<94:57:51,  1.56it/s, v_num=full, train/loss_step=5.040]Epoch 0:   0%|          | 975/535957 [10:22<94:57:04,  1.57it/s, v_num=full, train/loss_step=5.040]Epoch 0:   0%|          | 975/535957 [10:22<94:57:04,  1.57it/s, v_num=full, train/loss_step=2.990]Epoch 0:   0%|          | 976/535957 [10:23<94:56:18,  1.57it/s, v_num=full, train/loss_step=2.990]Epoch 0:   0%|          | 976/535957 [10:23<94:56:18,  1.57it/s, v_num=full, train/loss_step=4.870]Epoch 0:   0%|          | 977/535957 [10:24<94:55:29,  1.57it/s, v_num=full, train/loss_step=4.870]Epoch 0:   0%|          | 977/535957 [10:24<94:55:29,  1.57it/s, v_num=full, train/loss_step=5.380]Epoch 0:   0%|          | 978/535957 [10:24<94:54:45,  1.57it/s, v_num=full, train/loss_step=5.380]Epoch 0:   0%|          | 978/535957 [10:24<94:54:45,  1.57it/s, v_num=full, train/loss_step=5.220]Epoch 0:   0%|          | 979/535957 [10:25<94:54:03,  1.57it/s, v_num=full, train/loss_step=5.220]Epoch 0:   0%|          | 979/535957 [10:25<94:54:03,  1.57it/s, v_num=full, train/loss_step=3.910]Epoch 0:   0%|          | 980/535957 [10:25<94:53:17,  1.57it/s, v_num=full, train/loss_step=3.910]Epoch 0:   0%|          | 980/535957 [10:25<94:53:18,  1.57it/s, v_num=full, train/loss_step=3.920]
============================================================
Global Step 980
============================================================

[Losses]
  language_loss: 0.000125 (shape: torch.Size([4, 559]), count: 28)
  route_loss: 2.357422 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.994141 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 981/535957 [10:26<94:52:34,  1.57it/s, v_num=full, train/loss_step=3.920]Epoch 0:   0%|          | 981/535957 [10:26<94:52:34,  1.57it/s, v_num=full, train/loss_step=6.360]Epoch 0:   0%|          | 982/535957 [10:26<94:51:51,  1.57it/s, v_num=full, train/loss_step=6.360]Epoch 0:   0%|          | 982/535957 [10:26<94:51:51,  1.57it/s, v_num=full, train/loss_step=7.380]Epoch 0:   0%|          | 983/535957 [10:27<94:51:07,  1.57it/s, v_num=full, train/loss_step=7.380]Epoch 0:   0%|          | 983/535957 [10:27<94:51:07,  1.57it/s, v_num=full, train/loss_step=3.700]Epoch 0:   0%|          | 984/535957 [10:27<94:50:23,  1.57it/s, v_num=full, train/loss_step=3.700]Epoch 0:   0%|          | 984/535957 [10:27<94:50:23,  1.57it/s, v_num=full, train/loss_step=5.260]Epoch 0:   0%|          | 985/535957 [10:28<94:49:43,  1.57it/s, v_num=full, train/loss_step=5.260]Epoch 0:   0%|          | 985/535957 [10:28<94:49:43,  1.57it/s, v_num=full, train/loss_step=3.820]Epoch 0:   0%|          | 986/535957 [10:29<94:49:03,  1.57it/s, v_num=full, train/loss_step=3.820]Epoch 0:   0%|          | 986/535957 [10:29<94:49:04,  1.57it/s, v_num=full, train/loss_step=2.520]Epoch 0:   0%|          | 987/535957 [10:29<94:48:19,  1.57it/s, v_num=full, train/loss_step=2.520]Epoch 0:   0%|          | 987/535957 [10:29<94:48:20,  1.57it/s, v_num=full, train/loss_step=5.210]Epoch 0:   0%|          | 988/535957 [10:30<94:47:47,  1.57it/s, v_num=full, train/loss_step=5.210]Epoch 0:   0%|          | 988/535957 [10:30<94:47:47,  1.57it/s, v_num=full, train/loss_step=7.520]Epoch 0:   0%|          | 989/535957 [10:30<94:47:03,  1.57it/s, v_num=full, train/loss_step=7.520]Epoch 0:   0%|          | 989/535957 [10:30<94:47:03,  1.57it/s, v_num=full, train/loss_step=5.860]Epoch 0:   0%|          | 990/535957 [10:31<94:46:24,  1.57it/s, v_num=full, train/loss_step=5.860]Epoch 0:   0%|          | 990/535957 [10:31<94:46:24,  1.57it/s, v_num=full, train/loss_step=2.960]
============================================================
Global Step 990
============================================================

[Losses]
  language_loss: 0.000183 (shape: torch.Size([4, 558]), count: 28)
  route_loss: 0.681152 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 1.688477 (shape: torch.Size([4, 10]), count: 40)
Epoch 0:   0%|          | 991/535957 [10:31<94:45:41,  1.57it/s, v_num=full, train/loss_step=2.960]Epoch 0:   0%|          | 991/535957 [10:31<94:45:47,  1.57it/s, v_num=full, train/loss_step=2.380]Epoch 0:   0%|          | 992/535957 [10:32<94:45:06,  1.57it/s, v_num=full, train/loss_step=2.380]Epoch 0:   0%|          | 992/535957 [10:32<94:45:06,  1.57it/s, v_num=full, train/loss_step=3.210]Epoch 0:   0%|          | 993/535957 [10:33<94:44:20,  1.57it/s, v_num=full, train/loss_step=3.210]Epoch 0:   0%|          | 993/535957 [10:33<94:44:20,  1.57it/s, v_num=full, train/loss_step=1.900]Epoch 0:   0%|          | 994/535957 [10:33<94:43:38,  1.57it/s, v_num=full, train/loss_step=1.900]Epoch 0:   0%|          | 994/535957 [10:33<94:43:38,  1.57it/s, v_num=full, train/loss_step=3.380]Epoch 0:   0%|          | 995/535957 [10:34<94:42:55,  1.57it/s, v_num=full, train/loss_step=3.380]Epoch 0:   0%|          | 995/535957 [10:34<94:42:56,  1.57it/s, v_num=full, train/loss_step=3.520]Epoch 0:   0%|          | 996/535957 [10:34<94:42:10,  1.57it/s, v_num=full, train/loss_step=3.520]Epoch 0:   0%|          | 996/535957 [10:34<94:42:10,  1.57it/s, v_num=full, train/loss_step=6.450]Epoch 0:   0%|          | 997/535957 [10:35<94:41:26,  1.57it/s, v_num=full, train/loss_step=6.450]Epoch 0:   0%|          | 997/535957 [10:35<94:41:26,  1.57it/s, v_num=full, train/loss_step=5.590]Epoch 0:   0%|          | 998/535957 [10:35<94:40:47,  1.57it/s, v_num=full, train/loss_step=5.590]Epoch 0:   0%|          | 998/535957 [10:35<94:40:47,  1.57it/s, v_num=full, train/loss_step=7.890]Epoch 0:   0%|          | 999/535957 [10:36<94:40:05,  1.57it/s, v_num=full, train/loss_step=7.890]Epoch 0:   0%|          | 999/535957 [10:36<94:40:05,  1.57it/s, v_num=full, train/loss_step=2.370]
‚úÖ Training completed!
