Ë≠¶Âëä: Êú™Ê£ÄÊµãÂà∞ HF_TOKEN Êàñ HUGGING_FACE_HUB_TOKEN ÁéØÂ¢ÉÂèòÈáè
Â¶ÇÊûúÈÅáÂà∞ gated repo ÈîôËØØÔºåËØ∑ËÆæÁΩÆ: export HF_TOKEN=your_token
==========================================
üöÄ Starting SimLingo Full Training on Cluster
==========================================
Job ID: 21029654
Node: skl-a-26
GPUs: 1
Working Directory: /home/mh2803/projects/simlingo
Dataset Path: /shared/rc/llm-gen-agent/mhu/simlingo_dataset/database/simlingo_extracted
Bucket Path: /shared/rc/llm-gen-agent/mhu/simlingo_dataset/database/bucketsv2_simlingo
Training Args: experiment=cluster_training_full

Note: This is the full SimLingo model with language capabilities
Using simlingo_training (not simlingo_base_training)
==========================================
[2026-01-25 11:02:23,910] [INFO] [real_accelerator.py:222:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2026-01-25 11:02:57,393][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - vision_select_layer: -1
[2026-01-25 11:02:57,393][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - ps_version: v2
[2026-01-25 11:02:57,393][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - min_dynamic_patch: 1
[2026-01-25 11:02:57,393][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - max_dynamic_patch: 12
[2026-01-25 11:02:59,041][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - vision_select_layer: -1
[2026-01-25 11:02:59,041][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - ps_version: v2
[2026-01-25 11:02:59,041][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - min_dynamic_patch: 1
[2026-01-25 11:02:59,041][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - max_dynamic_patch: 12
[2026-01-25 11:02:59,732][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - vision_select_layer: -1
[2026-01-25 11:02:59,732][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - ps_version: v2
[2026-01-25 11:02:59,732][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - min_dynamic_patch: 1
[2026-01-25 11:02:59,732][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - max_dynamic_patch: 12
FlashAttention2 is not installed.
[2026-01-25 11:03:11,053][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.modeling_internvl_chat][INFO] - num_image_token: 256
[2026-01-25 11:03:11,053][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.modeling_internvl_chat][INFO] - ps_version: v2
[91mUsing OpenGVLab/InternVL2-1B as the image encoder.[0m
[2026-01-25 11:03:13,141][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - vision_select_layer: -1
[2026-01-25 11:03:13,141][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - ps_version: v2
[2026-01-25 11:03:13,141][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - min_dynamic_patch: 1
[2026-01-25 11:03:13,141][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.configuration_internvl_chat][INFO] - max_dynamic_patch: 12
[2026-01-25 11:03:13,220][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.modeling_internvl_chat][INFO] - num_image_token: 256
[2026-01-25 11:03:13,220][transformers_modules.OpenGVLab.InternVL2-1B.0d75ccd166b1d0b79446ae6c5d1a4a667f1e6187.modeling_internvl_chat][INFO] - ps_version: v2
Using PEFT model
trainable params: 17,596,416 || all params: 647,260,288 || trainable%: 2.7186
model:
  vision_model:
    variant: OpenGVLab/InternVL2-1B
    embed_dim: 512
    freeze: false
    _target_: simlingo_training.models.encoder.vlm.VLMEncoderModel
  language_model:
    variant: OpenGVLab/InternVL2-1B
    lora: true
    lora_alpha: 64
    lora_r: 32
    lora_dropout: 0.1
    _target_: simlingo_training.models.language_model.llm.LLM
  lr: 3.0e-05
  weight_decay: 0.1
  betas:
  - 0.9
  - 0.999
  pct_start: 0.05
  speed_wps_mode: 2d
  predict_route_as_wps: true
  _target_: simlingo_training.models.driving.DrivingModel
data_module:
  base_dataset:
    data_path: /shared/rc/llm-gen-agent/mhu/simlingo_dataset/database/simlingo_extracted
    bucket_path: /shared/rc/llm-gen-agent/mhu/simlingo_dataset/database/bucketsv2_simlingo
    cut_bottom_quarter: true
    use_1d_wps: false
    use_commentary: false
    use_qa: false
    qa_augmentation: false
    commentary_augmentation: true
    use_old_towns: true
    use_only_old_towns: false
    use_town13: true
    skip_first_n_frames: 10
    pred_len: 11
    hist_len: 1
    hist_len_commentary: 5
    img_augmentation: true
    img_augmentation_prob: 0.5
    img_shift_augmentation: true
    img_shift_augmentation_prob: 0.5
    use_safety_flag: true
    num_route_points: 20
    route_as: target_point_command
    use_lmdrive_commands: true
  driving_dataset:
    _target_: simlingo_training.dataloader.dataset_driving.Data_Driving
  dreamer_dataset: null
  qa_dataset:
    _target_: simlingo_training.dataloader.dataset_eval_qa_comm.Data_Eval
  insteval_dataset:
    _target_: simlingo_training.dataloader.dataset_eval_dreamer.Eval_Dreamer
  batch_size: 4
  num_workers: 8
  train_partitions: null
  train_partitions_dreamer: null
  use_global_img: false
  _target_: simlingo_training.dataloader.datamodule.DataModule
seed: 42
gpus: 1
resume: false
resume_path: null
debug: false
overfit: 0
fp16_loss_scale: 32.0
enable_wandb: true
wandb_project: simlingo
name: cluster_training_full
wandb_name: 2026_01_25_11_02_55_cluster_training_full
max_epochs: 15
precision: 16-mixed
strategy: deepspeed_stage_2
val_every_n_epochs: 2
checkpoint: null

Number of GPUS: 1
[Bucket: all] Scanning routes in /shared/rc/llm-gen-agent/mhu/simlingo_dataset/database/simlingo_extracted...
Found 9109 routes in /shared/rc/llm-gen-agent/mhu/simlingo_dataset/database/simlingo_extracted
Use 9017 routes.

  0%|          | 0/9017 [00:00<?, ?it/s]
  0%|          | 5/9017 [00:00<03:11, 47.09it/s]
  0%|          | 10/9017 [00:00<03:07, 48.14it/s]
  0%|          | 15/9017 [00:00<03:25, 43.77it/s]
  0%|          | 20/9017 [00:00<03:23, 44.19it/s]
  0%|          | 25/9017 [00:00<03:22, 44.33it/s]
  0%|          | 30/9017 [00:00<03:35, 41.73it/s]
  0%|          | 35/9017 [00:00<03:39, 40.89it/s]
  0%|          | 40/9017 [00:00<03:38, 41.08it/s]
  1%|          | 47/9017 [00:01<03:10, 47.08it/s]
  1%|          | 53/9017 [00:01<03:07, 47.92it/s]
  1%|          | 58/9017 [00:01<03:16, 45.56it/s]
  1%|          | 63/9017 [00:01<03:39, 40.77it/s]
  1%|          | 68/9017 [00:01<03:36, 41.32it/s]
  1%|          | 74/9017 [00:01<03:25, 43.42it/s]
  1%|          | 80/9017 [00:01<03:14, 45.89it/s]
  1%|          | 85/9017 [00:01<03:13, 46.25it/s]
  1%|          | 91/9017 [00:02<03:06, 47.98it/s]
  1%|          | 96/9017 [00:02<03:07, 47.70it/s]
  1%|          | 101/9017 [00:02<03:05, 48.12it/s]
  1%|          | 106/9017 [00:02<03:12, 46.21it/s]
  1%|          | 111/9017 [00:02<03:18, 44.83it/s]
  1%|‚ñè         | 116/9017 [00:02<03:14, 45.83it/s]
  1%|‚ñè         | 121/9017 [00:02<03:13, 46.03it/s]
  1%|‚ñè         | 128/9017 [00:02<02:57, 50.20it/s]
  1%|‚ñè         | 134/9017 [00:02<02:53, 51.31it/s]
  2%|‚ñè         | 140/9017 [00:03<02:57, 50.14it/s]
  2%|‚ñè         | 146/9017 [00:03<03:07, 47.22it/s]
  2%|‚ñè         | 152/9017 [00:03<03:00, 49.09it/s]
  2%|‚ñè         | 157/9017 [00:03<03:02, 48.50it/s]
  2%|‚ñè         | 162/9017 [00:03<03:19, 44.29it/s]
  2%|‚ñè         | 167/9017 [00:03<03:16, 45.08it/s]
  2%|‚ñè         | 172/9017 [00:03<03:14, 45.52it/s]
  2%|‚ñè         | 177/9017 [00:03<03:55, 37.50it/s]
  2%|‚ñè         | 182/9017 [00:04<06:22, 23.07it/s]
  2%|‚ñè         | 187/9017 [00:04<05:35, 26.28it/s]
  2%|‚ñè         | 192/9017 [00:04<04:57, 29.62it/s]
  2%|‚ñè         | 198/9017 [00:04<04:15, 34.46it/s]
  2%|‚ñè         | 204/9017 [00:04<03:41, 39.85it/s]
  2%|‚ñè         | 209/9017 [00:04<03:35, 40.81it/s]
  2%|‚ñè         | 214/9017 [00:05<03:36, 40.70it/s]
  2%|‚ñè         | 219/9017 [00:05<03:45, 38.99it/s]
  2%|‚ñè         | 224/9017 [00:05<03:33, 41.14it/s]
  3%|‚ñé         | 230/9017 [00:05<03:15, 44.85it/s]
  3%|‚ñé         | 235/9017 [00:05<03:13, 45.50it/s]
  3%|‚ñé         | 240/9017 [00:05<03:15, 45.00it/s]
  3%|‚ñé         | 245/9017 [00:05<03:11, 45.78it/s]
  3%|‚ñé         | 250/9017 [00:05<03:09, 46.37it/s]
  3%|‚ñé         | 255/9017 [00:05<03:05, 47.25it/s]
  3%|‚ñé         | 261/9017 [00:06<03:00, 48.60it/s]
  3%|‚ñé         | 266/9017 [00:06<03:14, 44.96it/s]
  3%|‚ñé         | 271/9017 [00:06<03:13, 45.27it/s]
  3%|‚ñé         | 276/9017 [00:06<03:18, 44.12it/s]
  3%|‚ñé         | 281/9017 [00:06<03:43, 39.09it/s]
  3%|‚ñé         | 286/9017 [00:06<03:39, 39.76it/s]
  3%|‚ñé         | 292/9017 [00:06<03:21, 43.26it/s]
  3%|‚ñé         | 297/9017 [00:06<03:14, 44.90it/s]
  3%|‚ñé         | 302/9017 [00:07<03:30, 41.34it/s]
  3%|‚ñé         | 307/9017 [00:07<03:42, 39.21it/s]
  3%|‚ñé         | 312/9017 [00:07<03:33, 40.72it/s]
  4%|‚ñé         | 317/9017 [00:07<03:34, 40.55it/s]
  4%|‚ñé         | 322/9017 [00:07<03:32, 40.89it/s]
  4%|‚ñé         | 328/9017 [00:07<03:15, 44.37it/s]
  4%|‚ñé         | 334/9017 [00:07<03:02, 47.46it/s]
  4%|‚ñç         | 339/9017 [00:07<03:11, 45.21it/s]
  4%|‚ñç         | 344/9017 [00:08<03:17, 43.91it/s]
  4%|‚ñç         | 349/9017 [00:08<03:16, 44.06it/s]
  4%|‚ñç         | 355/9017 [00:08<03:00, 48.00it/s]
  4%|‚ñç         | 361/9017 [00:08<02:53, 49.79it/s]
  4%|‚ñç         | 367/9017 [00:08<02:57, 48.83it/s]
  4%|‚ñç         | 372/9017 [00:08<03:07, 46.11it/s]
  4%|‚ñç         | 377/9017 [00:08<03:17, 43.85it/s]
  4%|‚ñç         | 383/9017 [00:08<03:33, 40.42it/s]
  4%|‚ñç         | 388/9017 [00:09<03:36, 39.93it/s]
  4%|‚ñç         | 394/9017 [00:09<03:16, 43.83it/s]
  4%|‚ñç         | 400/9017 [00:09<03:09, 45.41it/s]
  5%|‚ñç         | 406/9017 [00:09<02:58, 48.19it/s]
  5%|‚ñç         | 411/9017 [00:09<03:09, 45.51it/s]
  5%|‚ñç         | 416/9017 [00:09<03:05, 46.29it/s]
  5%|‚ñç         | 421/9017 [00:09<03:03, 46.95it/s]
  5%|‚ñç         | 426/9017 [00:09<03:05, 46.27it/s]
  5%|‚ñç         | 432/9017 [00:09<02:58, 47.98it/s]
  5%|‚ñç         | 438/9017 [00:10<03:00, 47.47it/s]
  5%|‚ñç         | 443/9017 [00:10<03:03, 46.68it/s]
  5%|‚ñç         | 448/9017 [00:10<03:02, 47.02it/s]
  5%|‚ñå         | 453/9017 [00:10<03:07, 45.71it/s]
  5%|‚ñå         | 458/9017 [00:10<03:20, 42.79it/s]
  5%|‚ñå         | 463/9017 [00:10<03:21, 42.42it/s]
  5%|‚ñå         | 468/9017 [00:10<03:16, 43.55it/s]
  5%|‚ñå         | 473/9017 [00:10<03:10, 44.78it/s]
  5%|‚ñå         | 478/9017 [00:10<03:14, 43.89it/s]
  5%|‚ñå         | 483/9017 [00:11<03:08, 45.27it/s]
  5%|‚ñå         | 488/9017 [00:11<03:18, 42.97it/s]
  5%|‚ñå         | 493/9017 [00:11<03:43, 38.11it/s]
  6%|‚ñå         | 499/9017 [00:11<03:19, 42.70it/s]
  6%|‚ñå         | 505/9017 [00:11<03:05, 45.97it/s]
  6%|‚ñå         | 511/9017 [00:11<02:56, 48.30it/s]
  6%|‚ñå         | 516/9017 [00:11<03:01, 46.91it/s]
  6%|‚ñå         | 522/9017 [00:11<02:52, 49.29it/s]
  6%|‚ñå         | 527/9017 [00:12<02:57, 47.91it/s]
  6%|‚ñå         | 532/9017 [00:12<03:06, 45.62it/s]
  6%|‚ñå         | 537/9017 [00:12<03:11, 44.21it/s]
  6%|‚ñå         | 542/9017 [00:12<03:16, 43.06it/s]
  6%|‚ñå         | 547/9017 [00:12<03:13, 43.67it/s]
  6%|‚ñå         | 552/9017 [00:12<03:19, 42.39it/s]
  6%|‚ñå         | 557/9017 [00:12<03:21, 42.01it/s]
  6%|‚ñå         | 562/9017 [00:12<03:26, 40.89it/s]
  6%|‚ñã         | 567/9017 [00:13<03:22, 41.73it/s]
  6%|‚ñã         | 572/9017 [00:13<03:12, 43.87it/s]
  6%|‚ñã         | 577/9017 [00:13<03:06, 45.18it/s]
  6%|‚ñã         | 583/9017 [00:13<03:00, 46.76it/s]
  7%|‚ñã         | 588/9017 [00:13<03:02, 46.11it/s]
  7%|‚ñã         | 593/9017 [00:13<02:58, 47.14it/s]
  7%|‚ñã         | 598/9017 [00:13<03:05, 45.41it/s]
  7%|‚ñã         | 603/9017 [00:13<03:04, 45.50it/s]
  7%|‚ñã         | 608/9017 [00:13<03:36, 38.88it/s]
  7%|‚ñã         | 613/9017 [00:14<03:25, 40.80it/s]
  7%|‚ñã         | 618/9017 [00:14<03:29, 40.03it/s]
  7%|‚ñã         | 623/9017 [00:14<03:17, 42.51it/s]
  7%|‚ñã         | 628/9017 [00:14<03:10, 43.97it/s]
  7%|‚ñã         | 633/9017 [00:14<03:26, 40.66it/s]
  7%|‚ñã         | 638/9017 [00:14<03:39, 38.10it/s]
  7%|‚ñã         | 645/9017 [00:14<03:02, 45.76it/s]
  7%|‚ñã         | 650/9017 [00:14<03:06, 44.83it/s]
  7%|‚ñã         | 655/9017 [00:15<05:03, 27.57it/s]
  7%|‚ñã         | 660/9017 [00:15<04:32, 30.70it/s]
  7%|‚ñã         | 664/9017 [00:15<04:21, 31.91it/s]
  7%|‚ñã         | 669/9017 [00:15<03:56, 35.35it/s]
  7%|‚ñã         | 674/9017 [00:15<03:43, 37.40it/s]
  8%|‚ñä         | 679/9017 [00:15<03:35, 38.77it/s]
  8%|‚ñä         | 684/9017 [00:16<03:45, 36.90it/s]
  8%|‚ñä         | 689/9017 [00:16<03:39, 37.97it/s]
  8%|‚ñä         | 694/9017 [00:16<03:30, 39.46it/s]
  8%|‚ñä         | 700/9017 [00:16<03:13, 42.89it/s]
  8%|‚ñä         | 705/9017 [00:16<03:30, 39.50it/s]
  8%|‚ñä         | 710/9017 [00:16<03:20, 41.42it/s]
  8%|‚ñä         | 715/9017 [00:16<03:12, 43.07it/s]
  8%|‚ñä         | 720/9017 [00:16<03:16, 42.24it/s]
  8%|‚ñä         | 726/9017 [00:16<03:03, 45.19it/s]
  8%|‚ñä         | 731/9017 [00:17<02:59, 46.13it/s]
  8%|‚ñä         | 736/9017 [00:17<03:14, 42.64it/s]
  8%|‚ñä         | 741/9017 [00:17<03:28, 39.76it/s]
  8%|‚ñä         | 746/9017 [00:17<03:27, 39.86it/s]
  8%|‚ñä         | 751/9017 [00:17<03:18, 41.58it/s]
  8%|‚ñä         | 757/9017 [00:17<03:00, 45.87it/s]
  8%|‚ñä         | 762/9017 [00:17<03:13, 42.59it/s]
  9%|‚ñä         | 767/9017 [00:17<03:10, 43.25it/s]
  9%|‚ñä         | 773/9017 [00:18<03:02, 45.21it/s]
  9%|‚ñä         | 778/9017 [00:18<02:59, 46.03it/s]
  9%|‚ñä         | 784/9017 [00:18<02:50, 48.16it/s]
  9%|‚ñâ         | 789/9017 [00:18<03:03, 44.89it/s]
  9%|‚ñâ         | 794/9017 [00:18<03:04, 44.59it/s]
  9%|‚ñâ         | 799/9017 [00:18<03:04, 44.59it/s]
  9%|‚ñâ         | 804/9017 [00:18<02:59, 45.84it/s]
  9%|‚ñâ         | 809/9017 [00:18<03:01, 45.29it/s]
  9%|‚ñâ         | 814/9017 [00:19<03:34, 38.27it/s]
  9%|‚ñâ         | 819/9017 [00:19<03:27, 39.48it/s]
  9%|‚ñâ         | 824/9017 [00:19<03:22, 40.44it/s]
  9%|‚ñâ         | 830/9017 [00:19<03:11, 42.71it/s]
  9%|‚ñâ         | 835/9017 [00:19<03:29, 39.07it/s]
  9%|‚ñâ         | 840/9017 [00:19<03:18, 41.14it/s]
  9%|‚ñâ         | 845/9017 [00:19<03:15, 41.86it/s]
  9%|‚ñâ         | 851/9017 [00:19<03:03, 44.38it/s]
  9%|‚ñâ         | 856/9017 [00:19<03:00, 45.23it/s]
 10%|‚ñâ         | 861/9017 [00:20<02:57, 45.89it/s]
 10%|‚ñâ         | 867/9017 [00:20<02:50, 47.75it/s]
 10%|‚ñâ         | 872/9017 [00:20<02:58, 45.72it/s]
 10%|‚ñâ         | 878/9017 [00:20<02:49, 47.90it/s]
 10%|‚ñâ         | 883/9017 [00:20<03:05, 43.81it/s]
 10%|‚ñâ         | 888/9017 [00:20<03:05, 43.82it/s]
 10%|‚ñâ         | 894/9017 [00:20<02:50, 47.59it/s]
 10%|‚ñâ         | 899/9017 [00:20<02:52, 47.11it/s]
 10%|‚ñà         | 904/9017 [00:21<03:08, 42.94it/s]
 10%|‚ñà         | 909/9017 [00:21<03:06, 43.44it/s]
 10%|‚ñà         | 914/9017 [00:21<03:02, 44.40it/s]
 10%|‚ñà         | 919/9017 [00:21<02:59, 45.12it/s]
 10%|‚ñà         | 924/9017 [00:21<04:01, 33.49it/s]
 10%|‚ñà         | 929/9017 [00:21<03:38, 37.02it/s]
 10%|‚ñà         | 934/9017 [00:21<03:21, 40.13it/s]
 10%|‚ñà         | 939/9017 [00:21<03:09, 42.57it/s]
 10%|‚ñà         | 944/9017 [00:22<03:02, 44.21it/s]
 11%|‚ñà         | 949/9017 [00:22<02:58, 45.11it/s]
 11%|‚ñà         | 954/9017 [00:22<03:07, 43.05it/s]
 11%|‚ñà         | 959/9017 [00:22<03:00, 44.66it/s]
 11%|‚ñà         | 964/9017 [00:22<02:59, 44.92it/s]
 11%|‚ñà         | 969/9017 [00:22<03:03, 43.89it/s]
 11%|‚ñà         | 975/9017 [00:22<02:50, 47.25it/s]
 11%|‚ñà         | 980/9017 [00:22<02:55, 45.79it/s]
 11%|‚ñà         | 985/9017 [00:22<02:58, 44.94it/s]
 11%|‚ñà         | 990/9017 [00:23<03:03, 43.69it/s]
 11%|‚ñà         | 995/9017 [00:23<03:00, 44.50it/s]
 11%|‚ñà         | 1001/9017 [00:23<02:52, 46.34it/s]
 11%|‚ñà         | 1006/9017 [00:23<03:04, 43.38it/s]
 11%|‚ñà         | 1011/9017 [00:23<03:27, 38.50it/s]
 11%|‚ñà‚ñè        | 1017/9017 [00:23<03:07, 42.65it/s]
 11%|‚ñà‚ñè        | 1022/9017 [00:23<03:03, 43.51it/s]
 11%|‚ñà‚ñè        | 1027/9017 [00:23<03:21, 39.75it/s]
 11%|‚ñà‚ñè        | 1032/9017 [00:24<03:16, 40.57it/s]
 12%|‚ñà‚ñè        | 1037/9017 [00:24<03:09, 42.06it/s]
 12%|‚ñà‚ñè        | 1043/9017 [00:24<02:59, 44.52it/s]
 12%|‚ñà‚ñè        | 1049/9017 [00:24<02:49, 47.03it/s]
 12%|‚ñà‚ñè        | 1054/9017 [00:24<02:50, 46.76it/s]
 12%|‚ñà‚ñè        | 1059/9017 [00:24<02:51, 46.29it/s]
 12%|‚ñà‚ñè        | 1065/9017 [00:24<02:45, 48.08it/s]
 12%|‚ñà‚ñè        | 1070/9017 [00:24<02:53, 45.90it/s]
 12%|‚ñà‚ñè        | 1075/9017 [00:24<02:53, 45.87it/s]
 12%|‚ñà‚ñè        | 1081/9017 [00:25<02:44, 48.14it/s]
 12%|‚ñà‚ñè        | 1086/9017 [00:25<02:49, 46.86it/s]
 12%|‚ñà‚ñè        | 1091/9017 [00:25<02:52, 46.00it/s]
 12%|‚ñà‚ñè        | 1096/9017 [00:25<02:50, 46.44it/s]
 12%|‚ñà‚ñè        | 1102/9017 [00:25<02:45, 47.83it/s]
 12%|‚ñà‚ñè        | 1107/9017 [00:25<03:08, 41.90it/s]
 12%|‚ñà‚ñè        | 1112/9017 [00:25<03:13, 40.85it/s]
 12%|‚ñà‚ñè        | 1117/9017 [00:25<03:08, 41.93it/s]
 12%|‚ñà‚ñè        | 1122/9017 [00:26<03:31, 37.30it/s]
 12%|‚ñà‚ñè        | 1126/9017 [00:26<03:41, 35.61it/s]
 13%|‚ñà‚ñé        | 1131/9017 [00:26<03:23, 38.81it/s]
 13%|‚ñà‚ñé        | 1136/9017 [00:26<03:20, 39.24it/s]
 13%|‚ñà‚ñé        | 1141/9017 [00:26<03:09, 41.60it/s]
 13%|‚ñà‚ñé        | 1146/9017 [00:26<03:13, 40.74it/s]
 13%|‚ñà‚ñé        | 1151/9017 [00:26<03:05, 42.48it/s]
 13%|‚ñà‚ñé        | 1156/9017 [00:26<03:09, 41.59it/s]
 13%|‚ñà‚ñé        | 1162/9017 [00:27<02:50, 46.08it/s]
 13%|‚ñà‚ñé        | 1167/9017 [00:27<02:52, 45.45it/s]
 13%|‚ñà‚ñé        | 1173/9017 [00:27<02:46, 47.01it/s]
 13%|‚ñà‚ñé        | 1178/9017 [00:27<03:01, 43.24it/s]
 13%|‚ñà‚ñé        | 1183/9017 [00:27<02:58, 43.92it/s]
 13%|‚ñà‚ñé        | 1188/9017 [00:27<03:07, 41.70it/s]
 13%|‚ñà‚ñé        | 1193/9017 [00:27<03:10, 40.98it/s]
 13%|‚ñà‚ñé        | 1198/9017 [00:27<03:08, 41.40it/s]
 13%|‚ñà‚ñé        | 1203/9017 [00:27<03:00, 43.37it/s]
 13%|‚ñà‚ñé        | 1208/9017 [00:28<02:55, 44.62it/s]
 13%|‚ñà‚ñé        | 1213/9017 [00:28<02:53, 45.00it/s]
 14%|‚ñà‚ñé        | 1219/9017 [00:28<02:43, 47.71it/s]
 14%|‚ñà‚ñé        | 1224/9017 [00:28<05:00, 25.90it/s]
 14%|‚ñà‚ñé        | 1228/9017 [00:28<04:34, 28.37it/s]
 14%|‚ñà‚ñé        | 1232/9017 [00:28<04:49, 26.88it/s]
 14%|‚ñà‚ñé        | 1237/9017 [00:29<04:16, 30.34it/s]
 14%|‚ñà‚ñç        | 1242/9017 [00:29<03:52, 33.44it/s]
 14%|‚ñà‚ñç        | 1248/9017 [00:29<03:27, 37.45it/s]
 14%|‚ñà‚ñç        | 1254/9017 [00:29<03:05, 41.75it/s]
 14%|‚ñà‚ñç        | 1259/9017 [00:29<03:06, 41.59it/s]
 14%|‚ñà‚ñç        | 1264/9017 [00:29<03:30, 36.89it/s]
 14%|‚ñà‚ñç        | 1269/9017 [00:29<03:14, 39.75it/s]
 14%|‚ñà‚ñç        | 1275/9017 [00:29<02:57, 43.57it/s]
 14%|‚ñà‚ñç        | 1280/9017 [00:30<02:51, 45.11it/s]
 14%|‚ñà‚ñç        | 1286/9017 [00:30<02:48, 45.98it/s]
 14%|‚ñà‚ñç        | 1291/9017 [00:30<02:48, 45.94it/s]
 14%|‚ñà‚ñç        | 1296/9017 [00:30<02:52, 44.85it/s]
 14%|‚ñà‚ñç        | 1301/9017 [00:30<03:04, 41.91it/s]
 14%|‚ñà‚ñç        | 1306/9017 [00:30<03:01, 42.56it/s]
 15%|‚ñà‚ñç        | 1311/9017 [00:30<03:01, 42.39it/s]
 15%|‚ñà‚ñç        | 1316/9017 [00:30<03:15, 39.49it/s]
 15%|‚ñà‚ñç        | 1321/9017 [00:31<03:08, 40.76it/s]
 15%|‚ñà‚ñç        | 1327/9017 [00:31<02:50, 44.99it/s]
 15%|‚ñà‚ñç        | 1332/9017 [00:31<02:54, 43.94it/s]
 15%|‚ñà‚ñç        | 1337/9017 [00:31<02:51, 44.79it/s]
 15%|‚ñà‚ñç        | 1342/9017 [00:31<02:50, 45.03it/s]
 15%|‚ñà‚ñç        | 1348/9017 [00:31<02:40, 47.88it/s]
 15%|‚ñà‚ñå        | 1353/9017 [00:31<02:41, 47.59it/s]
 15%|‚ñà‚ñå        | 1359/9017 [00:31<02:33, 50.03it/s]
 15%|‚ñà‚ñå        | 1365/9017 [00:31<02:28, 51.36it/s]
 15%|‚ñà‚ñå        | 1371/9017 [00:32<02:25, 52.50it/s]
 15%|‚ñà‚ñå        | 1377/9017 [00:32<02:32, 50.02it/s]
 15%|‚ñà‚ñå        | 1383/9017 [00:32<02:26, 52.19it/s]
 15%|‚ñà‚ñå        | 1389/9017 [00:32<02:35, 49.01it/s]
 15%|‚ñà‚ñå        | 1395/9017 [00:32<02:35, 48.88it/s]
 16%|‚ñà‚ñå        | 1400/9017 [00:32<02:36, 48.68it/s]
 16%|‚ñà‚ñå        | 1405/9017 [00:32<02:41, 47.27it/s]
 16%|‚ñà‚ñå        | 1410/9017 [00:32<02:42, 46.84it/s]
 16%|‚ñà‚ñå        | 1415/9017 [00:32<02:45, 45.87it/s]
 16%|‚ñà‚ñå        | 1421/9017 [00:33<02:36, 48.60it/s]
 16%|‚ñà‚ñå        | 1427/9017 [00:33<02:30, 50.29it/s]
 16%|‚ñà‚ñå        | 1433/9017 [00:33<02:39, 47.69it/s]
 16%|‚ñà‚ñå        | 1438/9017 [00:33<02:39, 47.49it/s]
 16%|‚ñà‚ñå        | 1444/9017 [00:33<02:29, 50.78it/s]
 16%|‚ñà‚ñå        | 1450/9017 [00:33<02:23, 52.63it/s]
 16%|‚ñà‚ñå        | 1456/9017 [00:33<02:25, 52.01it/s]
 16%|‚ñà‚ñå        | 1462/9017 [00:34<03:25, 36.80it/s]
 16%|‚ñà‚ñã        | 1467/9017 [00:34<03:20, 37.67it/s]
 16%|‚ñà‚ñã        | 1473/9017 [00:34<03:00, 41.83it/s]
 16%|‚ñà‚ñã        | 1478/9017 [00:34<03:09, 39.85it/s]
 16%|‚ñà‚ñã        | 1483/9017 [00:34<03:19, 37.74it/s]
 17%|‚ñà‚ñã        | 1489/9017 [00:34<03:04, 40.88it/s]
 17%|‚ñà‚ñã        | 1495/9017 [00:34<02:49, 44.28it/s]
 17%|‚ñà‚ñã        | 1500/9017 [00:34<02:55, 42.89it/s]
 17%|‚ñà‚ñã        | 1505/9017 [00:35<02:49, 44.43it/s]
 17%|‚ñà‚ñã        | 1510/9017 [00:35<02:46, 45.21it/s]
 17%|‚ñà‚ñã        | 1515/9017 [00:35<02:48, 44.45it/s]
 17%|‚ñà‚ñã        | 1520/9017 [00:35<02:50, 43.92it/s]
 17%|‚ñà‚ñã        | 1525/9017 [00:35<02:52, 43.49it/s]
 17%|‚ñà‚ñã        | 1530/9017 [00:35<03:00, 41.52it/s]
 17%|‚ñà‚ñã        | 1535/9017 [00:35<02:55, 42.56it/s]
 17%|‚ñà‚ñã        | 1540/9017 [00:35<02:57, 42.11it/s]
 17%|‚ñà‚ñã        | 1546/9017 [00:35<02:43, 45.60it/s]
 17%|‚ñà‚ñã        | 1552/9017 [00:36<02:42, 45.93it/s]
 17%|‚ñà‚ñã        | 1558/9017 [00:36<02:30, 49.58it/s]
 17%|‚ñà‚ñã        | 1564/9017 [00:36<02:27, 50.62it/s]
 17%|‚ñà‚ñã        | 1570/9017 [00:36<02:37, 47.41it/s]
 17%|‚ñà‚ñã        | 1576/9017 [00:36<02:28, 49.97it/s]
 18%|‚ñà‚ñä        | 1582/9017 [00:36<02:40, 46.36it/s]
 18%|‚ñà‚ñä        | 1587/9017 [00:36<02:48, 44.16it/s]
 18%|‚ñà‚ñä        | 1593/9017 [00:36<02:34, 48.06it/s]
 18%|‚ñà‚ñä        | 1598/9017 [00:37<02:35, 47.83it/s]
 18%|‚ñà‚ñä        | 1603/9017 [00:37<02:39, 46.42it/s]
 18%|‚ñà‚ñä        | 1610/9017 [00:37<02:25, 50.96it/s]
 18%|‚ñà‚ñä        | 1616/9017 [00:37<02:29, 49.42it/s]
 18%|‚ñà‚ñä        | 1621/9017 [00:37<02:30, 49.12it/s]
 18%|‚ñà‚ñä        | 1626/9017 [00:37<02:32, 48.60it/s]
 18%|‚ñà‚ñä        | 1632/9017 [00:37<02:28, 49.59it/s]
 18%|‚ñà‚ñä        | 1637/9017 [00:37<02:34, 47.91it/s]
 18%|‚ñà‚ñä        | 1642/9017 [00:37<02:37, 46.94it/s]
 18%|‚ñà‚ñä        | 1647/9017 [00:38<03:55, 31.23it/s]
 18%|‚ñà‚ñä        | 1652/9017 [00:38<03:36, 34.05it/s]
 18%|‚ñà‚ñä        | 1657/9017 [00:38<03:18, 36.99it/s]
 18%|‚ñà‚ñä        | 1663/9017 [00:38<02:56, 41.60it/s]
 18%|‚ñà‚ñä        | 1668/9017 [00:38<02:53, 42.29it/s]
 19%|‚ñà‚ñä        | 1674/9017 [00:38<02:44, 44.60it/s]
 19%|‚ñà‚ñä        | 1679/9017 [00:39<03:34, 34.14it/s]
 19%|‚ñà‚ñä        | 1683/9017 [00:39<04:19, 28.30it/s]
 19%|‚ñà‚ñä        | 1688/9017 [00:39<03:49, 31.96it/s]
 19%|‚ñà‚ñâ        | 1692/9017 [00:39<03:49, 31.85it/s]
 19%|‚ñà‚ñâ        | 1698/9017 [00:39<03:21, 36.36it/s]
 19%|‚ñà‚ñâ        | 1704/9017 [00:39<02:59, 40.79it/s]
 19%|‚ñà‚ñâ        | 1709/9017 [00:39<02:55, 41.67it/s]
 19%|‚ñà‚ñâ        | 1714/9017 [00:39<03:00, 40.52it/s]
 19%|‚ñà‚ñâ        | 1720/9017 [00:40<02:47, 43.47it/s]
 19%|‚ñà‚ñâ        | 1726/9017 [00:40<02:44, 44.27it/s]
 19%|‚ñà‚ñâ        | 1731/9017 [00:40<02:42, 44.90it/s]
 19%|‚ñà‚ñâ        | 1737/9017 [00:40<02:32, 47.84it/s]
 19%|‚ñà‚ñâ        | 1742/9017 [00:40<02:38, 45.85it/s]
 19%|‚ñà‚ñâ        | 1747/9017 [00:40<02:36, 46.42it/s]
 19%|‚ñà‚ñâ        | 1752/9017 [00:40<02:44, 44.05it/s]
 19%|‚ñà‚ñâ        | 1758/9017 [00:40<02:34, 46.96it/s]
 20%|‚ñà‚ñâ        | 1763/9017 [00:41<02:50, 42.52it/s]
 20%|‚ñà‚ñâ        | 1768/9017 [00:41<02:45, 43.75it/s]
 20%|‚ñà‚ñâ        | 1773/9017 [00:41<02:46, 43.57it/s]
 20%|‚ñà‚ñâ        | 1778/9017 [00:41<02:45, 43.69it/s]
 20%|‚ñà‚ñâ        | 1783/9017 [00:41<02:39, 45.25it/s]
 20%|‚ñà‚ñâ        | 1788/9017 [00:41<02:39, 45.31it/s]
 20%|‚ñà‚ñâ        | 1793/9017 [00:41<02:36, 46.13it/s]
 20%|‚ñà‚ñâ        | 1799/9017 [00:41<02:36, 45.98it/s]
 20%|‚ñà‚ñà        | 1805/9017 [00:41<02:48, 42.84it/s]
 20%|‚ñà‚ñà        | 1810/9017 [00:42<02:51, 42.00it/s]
 20%|‚ñà‚ñà        | 1815/9017 [00:42<02:53, 41.40it/s]
 20%|‚ñà‚ñà        | 1820/9017 [00:42<02:52, 41.80it/s]
 20%|‚ñà‚ñà        | 1826/9017 [00:42<02:36, 46.03it/s]
 20%|‚ñà‚ñà        | 1831/9017 [00:42<02:48, 42.70it/s]
 20%|‚ñà‚ñà        | 1837/9017 [00:42<02:40, 44.79it/s]
 20%|‚ñà‚ñà        | 1843/9017 [00:42<02:30, 47.56it/s]
 20%|‚ñà‚ñà        | 1848/9017 [00:42<02:30, 47.54it/s]
 21%|‚ñà‚ñà        | 1853/9017 [00:43<02:33, 46.66it/s]
 21%|‚ñà‚ñà        | 1858/9017 [00:43<02:30, 47.55it/s]
 21%|‚ñà‚ñà        | 1864/9017 [00:43<02:22, 50.13it/s]
 21%|‚ñà‚ñà        | 1870/9017 [00:43<02:22, 50.20it/s]
 21%|‚ñà‚ñà        | 1876/9017 [00:43<02:15, 52.74it/s]
 21%|‚ñà‚ñà        | 1882/9017 [00:43<02:18, 51.54it/s]
 21%|‚ñà‚ñà        | 1888/9017 [00:43<02:34, 46.21it/s]
 21%|‚ñà‚ñà        | 1893/9017 [00:43<02:35, 45.82it/s]
 21%|‚ñà‚ñà        | 1898/9017 [00:43<02:48, 42.16it/s]
 21%|‚ñà‚ñà        | 1903/9017 [00:44<02:45, 42.91it/s]
 21%|‚ñà‚ñà        | 1908/9017 [00:44<02:44, 43.32it/s]
 21%|‚ñà‚ñà        | 1913/9017 [00:44<02:39, 44.67it/s]
 21%|‚ñà‚ñà‚ñè       | 1918/9017 [00:44<02:35, 45.68it/s]
 21%|‚ñà‚ñà‚ñè       | 1924/9017 [00:44<02:27, 48.03it/s]
 21%|‚ñà‚ñà‚ñè       | 1929/9017 [00:44<02:30, 46.96it/s]
 21%|‚ñà‚ñà‚ñè       | 1934/9017 [00:44<02:43, 43.41it/s]
 22%|‚ñà‚ñà‚ñè       | 1939/9017 [00:44<02:40, 44.02it/s]
 22%|‚ñà‚ñà‚ñè       | 1945/9017 [00:45<02:39, 44.43it/s]
 22%|‚ñà‚ñà‚ñè       | 1950/9017 [00:45<02:38, 44.53it/s]
 22%|‚ñà‚ñà‚ñè       | 1956/9017 [00:45<02:40, 43.88it/s]
 22%|‚ñà‚ñà‚ñè       | 1962/9017 [00:45<02:31, 46.58it/s]
 22%|‚ñà‚ñà‚ñè       | 1967/9017 [00:45<02:31, 46.66it/s]
 22%|‚ñà‚ñà‚ñè       | 1972/9017 [00:45<02:37, 44.81it/s]
 22%|‚ñà‚ñà‚ñè       | 1977/9017 [00:45<02:35, 45.17it/s]
 22%|‚ñà‚ñà‚ñè       | 1983/9017 [00:45<02:27, 47.55it/s]
 22%|‚ñà‚ñà‚ñè       | 1988/9017 [00:45<02:37, 44.60it/s]
 22%|‚ñà‚ñà‚ñè       | 1993/9017 [00:46<05:02, 23.25it/s]
 22%|‚ñà‚ñà‚ñè       | 1999/9017 [00:46<04:04, 28.66it/s]
 22%|‚ñà‚ñà‚ñè       | 2005/9017 [00:46<03:27, 33.82it/s]
 22%|‚ñà‚ñà‚ñè       | 2010/9017 [00:46<03:09, 37.03it/s]
 22%|‚ñà‚ñà‚ñè       | 2015/9017 [00:46<03:09, 37.03it/s]
 22%|‚ñà‚ñà‚ñè       | 2020/9017 [00:47<02:59, 38.93it/s]
 22%|‚ñà‚ñà‚ñè       | 2025/9017 [00:47<03:29, 33.43it/s]
 23%|‚ñà‚ñà‚ñé       | 2029/9017 [00:47<03:26, 33.90it/s]
 23%|‚ñà‚ñà‚ñé       | 2033/9017 [00:47<03:19, 35.00it/s]
 23%|‚ñà‚ñà‚ñé       | 2037/9017 [00:47<03:14, 35.90it/s]
 23%|‚ñà‚ñà‚ñé       | 2043/9017 [00:47<02:48, 41.40it/s]
 23%|‚ñà‚ñà‚ñé       | 2048/9017 [00:47<02:49, 41.20it/s]
 23%|‚ñà‚ñà‚ñé       | 2053/9017 [00:47<02:45, 42.11it/s]
 23%|‚ñà‚ñà‚ñé       | 2059/9017 [00:48<02:35, 44.62it/s]
 23%|‚ñà‚ñà‚ñé       | 2064/9017 [00:48<02:39, 43.61it/s]
 23%|‚ñà‚ñà‚ñé       | 2069/9017 [00:48<02:41, 43.14it/s]
 23%|‚ñà‚ñà‚ñé       | 2074/9017 [00:48<02:41, 43.04it/s]
 23%|‚ñà‚ñà‚ñé       | 2079/9017 [00:48<02:36, 44.29it/s]
 23%|‚ñà‚ñà‚ñé       | 2084/9017 [00:48<02:32, 45.39it/s]
 23%|‚ñà‚ñà‚ñé       | 2089/9017 [00:48<02:30, 45.91it/s]
 23%|‚ñà‚ñà‚ñé       | 2095/9017 [00:48<02:23, 48.33it/s]
 23%|‚ñà‚ñà‚ñé       | 2100/9017 [00:48<02:48, 41.07it/s]
 23%|‚ñà‚ñà‚ñé       | 2106/9017 [00:49<02:39, 43.35it/s]
 23%|‚ñà‚ñà‚ñé       | 2111/9017 [00:49<02:53, 39.90it/s]
 23%|‚ñà‚ñà‚ñé       | 2118/9017 [00:49<02:29, 46.04it/s]
 24%|‚ñà‚ñà‚ñé       | 2124/9017 [00:49<02:24, 47.87it/s]
 24%|‚ñà‚ñà‚ñé       | 2129/9017 [00:49<02:25, 47.26it/s]
 24%|‚ñà‚ñà‚ñé       | 2134/9017 [00:49<02:24, 47.75it/s]
 24%|‚ñà‚ñà‚ñé       | 2140/9017 [00:49<02:17, 49.90it/s]
 24%|‚ñà‚ñà‚ñç       | 2146/9017 [00:49<02:18, 49.55it/s]
 24%|‚ñà‚ñà‚ñç       | 2152/9017 [00:50<02:14, 50.92it/s]
 24%|‚ñà‚ñà‚ñç       | 2158/9017 [00:50<03:20, 34.25it/s]
 24%|‚ñà‚ñà‚ñç       | 2163/9017 [00:50<03:07, 36.56it/s]
 24%|‚ñà‚ñà‚ñç       | 2168/9017 [00:50<02:57, 38.68it/s]
 24%|‚ñà‚ñà‚ñç       | 2173/9017 [00:50<02:53, 39.39it/s]
 24%|‚ñà‚ñà‚ñç       | 2178/9017 [00:50<02:44, 41.69it/s]
 24%|‚ñà‚ñà‚ñç       | 2183/9017 [00:50<02:39, 42.88it/s]
 24%|‚ñà‚ñà‚ñç       | 2188/9017 [00:50<02:33, 44.41it/s]
 24%|‚ñà‚ñà‚ñç       | 2194/9017 [00:51<02:33, 44.49it/s]
 24%|‚ñà‚ñà‚ñç       | 2199/9017 [00:51<02:34, 44.11it/s]
 24%|‚ñà‚ñà‚ñç       | 2205/9017 [00:51<02:23, 47.52it/s]
 25%|‚ñà‚ñà‚ñç       | 2211/9017 [00:51<02:16, 49.96it/s]
 25%|‚ñà‚ñà‚ñç       | 2217/9017 [00:51<02:24, 47.07it/s]
 25%|‚ñà‚ñà‚ñç       | 2223/9017 [00:51<02:18, 48.93it/s]
 25%|‚ñà‚ñà‚ñç       | 2228/9017 [00:51<02:26, 46.43it/s]
 25%|‚ñà‚ñà‚ñç       | 2233/9017 [00:51<02:26, 46.35it/s]
 25%|‚ñà‚ñà‚ñç       | 2238/9017 [00:52<02:35, 43.57it/s]
 25%|‚ñà‚ñà‚ñç       | 2243/9017 [00:52<02:42, 41.67it/s]
 25%|‚ñà‚ñà‚ñç       | 2249/9017 [00:52<02:33, 44.12it/s]
 25%|‚ñà‚ñà‚ñç       | 2254/9017 [00:52<02:31, 44.78it/s]
 25%|‚ñà‚ñà‚ñå       | 2259/9017 [00:52<02:29, 45.30it/s]
 25%|‚ñà‚ñà‚ñå       | 2264/9017 [00:52<02:36, 43.26it/s]
 25%|‚ñà‚ñà‚ñå       | 2270/9017 [00:52<02:28, 45.59it/s]
 25%|‚ñà‚ñà‚ñå       | 2275/9017 [00:52<02:28, 45.41it/s]
 25%|‚ñà‚ñà‚ñå       | 2280/9017 [00:52<02:33, 43.97it/s]
 25%|‚ñà‚ñà‚ñå       | 2286/9017 [00:53<02:26, 45.92it/s]
 25%|‚ñà‚ñà‚ñå       | 2291/9017 [00:53<02:29, 44.92it/s]
 25%|‚ñà‚ñà‚ñå       | 2296/9017 [00:53<02:36, 43.06it/s]
 26%|‚ñà‚ñà‚ñå       | 2302/9017 [00:53<02:27, 45.38it/s]
 26%|‚ñà‚ñà‚ñå       | 2307/9017 [00:53<02:25, 46.08it/s]
 26%|‚ñà‚ñà‚ñå       | 2312/9017 [00:53<02:22, 46.89it/s]
 26%|‚ñà‚ñà‚ñå       | 2317/9017 [00:53<02:23, 46.85it/s]
 26%|‚ñà‚ñà‚ñå       | 2322/9017 [00:53<02:29, 44.70it/s]
 26%|‚ñà‚ñà‚ñå       | 2329/9017 [00:54<02:16, 49.08it/s]
 26%|‚ñà‚ñà‚ñå       | 2335/9017 [00:54<02:11, 50.65it/s]
 26%|‚ñà‚ñà‚ñå       | 2341/9017 [00:54<02:09, 51.43it/s]
 26%|‚ñà‚ñà‚ñå       | 2347/9017 [00:54<02:06, 52.64it/s]
 26%|‚ñà‚ñà‚ñå       | 2353/9017 [00:54<02:12, 50.20it/s]
 26%|‚ñà‚ñà‚ñå       | 2359/9017 [00:54<02:11, 50.49it/s]
 26%|‚ñà‚ñà‚ñå       | 2365/9017 [00:54<02:10, 50.95it/s]
 26%|‚ñà‚ñà‚ñã       | 2371/9017 [00:54<02:14, 49.29it/s]
 26%|‚ñà‚ñà‚ñã       | 2376/9017 [00:54<02:15, 49.18it/s]
 26%|‚ñà‚ñà‚ñã       | 2381/9017 [00:55<02:20, 47.15it/s]
 26%|‚ñà‚ñà‚ñã       | 2386/9017 [00:55<02:23, 46.21it/s]
 27%|‚ñà‚ñà‚ñã       | 2391/9017 [00:55<02:30, 43.93it/s]
 27%|‚ñà‚ñà‚ñã       | 2398/9017 [00:55<02:12, 49.87it/s]
 27%|‚ñà‚ñà‚ñã       | 2404/9017 [00:55<02:11, 50.30it/s]
 27%|‚ñà‚ñà‚ñã       | 2410/9017 [00:55<02:09, 50.82it/s]
 27%|‚ñà‚ñà‚ñã       | 2416/9017 [00:55<02:05, 52.54it/s]
 27%|‚ñà‚ñà‚ñã       | 2422/9017 [00:55<02:07, 51.62it/s]
 27%|‚ñà‚ñà‚ñã       | 2428/9017 [00:56<02:16, 48.25it/s]
 27%|‚ñà‚ñà‚ñã       | 2433/9017 [00:56<02:22, 46.33it/s]
 27%|‚ñà‚ñà‚ñã       | 2438/9017 [00:56<02:38, 41.39it/s]
 27%|‚ñà‚ñà‚ñã       | 2444/9017 [00:56<02:23, 45.71it/s]
 27%|‚ñà‚ñà‚ñã       | 2449/9017 [00:56<02:23, 45.81it/s]
 27%|‚ñà‚ñà‚ñã       | 2454/9017 [00:56<02:25, 45.21it/s]
 27%|‚ñà‚ñà‚ñã       | 2461/9017 [00:56<02:13, 49.10it/s]
 27%|‚ñà‚ñà‚ñã       | 2467/9017 [00:56<02:12, 49.38it/s]
 27%|‚ñà‚ñà‚ñã       | 2472/9017 [00:56<02:12, 49.24it/s]
 27%|‚ñà‚ñà‚ñã       | 2477/9017 [00:57<02:15, 48.19it/s]
 28%|‚ñà‚ñà‚ñä       | 2482/9017 [00:57<02:16, 48.02it/s]
 28%|‚ñà‚ñà‚ñä       | 2487/9017 [00:57<02:37, 41.52it/s]
 28%|‚ñà‚ñà‚ñä       | 2492/9017 [00:57<02:29, 43.59it/s]
 28%|‚ñà‚ñà‚ñä       | 2498/9017 [00:57<02:16, 47.86it/s]
 28%|‚ñà‚ñà‚ñä       | 2503/9017 [00:57<02:19, 46.83it/s]
 28%|‚ñà‚ñà‚ñä       | 2509/9017 [00:57<02:14, 48.35it/s]
 28%|‚ñà‚ñà‚ñä       | 2514/9017 [00:57<02:16, 47.74it/s]
 28%|‚ñà‚ñà‚ñä       | 2519/9017 [00:57<02:16, 47.71it/s]
 28%|‚ñà‚ñà‚ñä       | 2525/9017 [00:58<02:07, 51.09it/s]
 28%|‚ñà‚ñà‚ñä       | 2531/9017 [00:58<02:11, 49.34it/s]
 28%|‚ñà‚ñà‚ñä       | 2536/9017 [00:58<02:11, 49.42it/s]
 28%|‚ñà‚ñà‚ñä       | 2541/9017 [00:58<02:15, 47.69it/s]
 28%|‚ñà‚ñà‚ñä       | 2546/9017 [00:58<02:25, 44.42it/s]
 28%|‚ñà‚ñà‚ñä       | 2552/9017 [00:58<02:18, 46.59it/s]
 28%|‚ñà‚ñà‚ñä       | 2557/9017 [00:58<02:20, 45.97it/s]
 28%|‚ñà‚ñà‚ñä       | 2562/9017 [00:58<02:52, 37.32it/s]
 28%|‚ñà‚ñà‚ñä       | 2567/9017 [00:59<02:46, 38.70it/s]
 29%|‚ñà‚ñà‚ñä       | 2573/9017 [00:59<02:36, 41.11it/s]
 29%|‚ñà‚ñà‚ñä       | 2578/9017 [00:59<02:36, 41.25it/s]
 29%|‚ñà‚ñà‚ñä       | 2584/9017 [00:59<02:24, 44.45it/s]
 29%|‚ñà‚ñà‚ñä       | 2589/9017 [00:59<02:28, 43.19it/s]
 29%|‚ñà‚ñà‚ñâ       | 2595/9017 [00:59<02:18, 46.31it/s]
 29%|‚ñà‚ñà‚ñâ       | 2601/9017 [00:59<02:15, 47.52it/s]
 29%|‚ñà‚ñà‚ñâ       | 2606/9017 [00:59<02:14, 47.50it/s]
 29%|‚ñà‚ñà‚ñâ       | 2612/9017 [01:00<02:13, 48.12it/s]
 29%|‚ñà‚ñà‚ñâ       | 2617/9017 [01:00<02:16, 46.76it/s]
 29%|‚ñà‚ñà‚ñâ       | 2622/9017 [01:00<02:18, 46.22it/s]
 29%|‚ñà‚ñà‚ñâ       | 2627/9017 [01:00<02:23, 44.42it/s]
 29%|‚ñà‚ñà‚ñâ       | 2632/9017 [01:00<02:22, 44.66it/s]
 29%|‚ñà‚ñà‚ñâ       | 2637/9017 [01:00<02:19, 45.87it/s]
 29%|‚ñà‚ñà‚ñâ       | 2642/9017 [01:00<02:24, 44.08it/s]
 29%|‚ñà‚ñà‚ñâ       | 2647/9017 [01:00<02:32, 41.71it/s]
 29%|‚ñà‚ñà‚ñâ       | 2652/9017 [01:00<02:26, 43.37it/s]
 29%|‚ñà‚ñà‚ñâ       | 2657/9017 [01:01<02:30, 42.33it/s]
 30%|‚ñà‚ñà‚ñâ       | 2663/9017 [01:01<02:27, 43.07it/s]
 30%|‚ñà‚ñà‚ñâ       | 2668/9017 [01:01<02:23, 44.37it/s]
 30%|‚ñà‚ñà‚ñâ       | 2673/9017 [01:01<02:21, 44.80it/s]
 30%|‚ñà‚ñà‚ñâ       | 2678/9017 [01:01<02:17, 46.13it/s]
 30%|‚ñà‚ñà‚ñâ       | 2683/9017 [01:01<02:19, 45.53it/s]
 30%|‚ñà‚ñà‚ñâ       | 2688/9017 [01:01<02:39, 39.76it/s]
 30%|‚ñà‚ñà‚ñâ       | 2693/9017 [01:01<02:32, 41.51it/s]
 30%|‚ñà‚ñà‚ñâ       | 2698/9017 [01:02<02:30, 42.02it/s]
 30%|‚ñà‚ñà‚ñâ       | 2704/9017 [01:02<02:21, 44.67it/s]
 30%|‚ñà‚ñà‚ñà       | 2709/9017 [01:02<02:23, 43.87it/s]
 30%|‚ñà‚ñà‚ñà       | 2715/9017 [01:02<02:15, 46.54it/s]
 30%|‚ñà‚ñà‚ñà       | 2720/9017 [01:02<02:19, 45.25it/s]
 30%|‚ñà‚ñà‚ñà       | 2725/9017 [01:02<02:30, 41.93it/s]
 30%|‚ñà‚ñà‚ñà       | 2730/9017 [01:02<02:24, 43.62it/s]
 30%|‚ñà‚ñà‚ñà       | 2736/9017 [01:02<02:16, 46.16it/s]
 30%|‚ñà‚ñà‚ñà       | 2741/9017 [01:03<02:31, 41.45it/s]
 30%|‚ñà‚ñà‚ñà       | 2746/9017 [01:03<02:31, 41.35it/s]
 31%|‚ñà‚ñà‚ñà       | 2751/9017 [01:03<02:55, 35.64it/s]
 31%|‚ñà‚ñà‚ñà       | 2755/9017 [01:03<02:57, 35.28it/s]
 31%|‚ñà‚ñà‚ñà       | 2760/9017 [01:03<02:44, 38.06it/s]
 31%|‚ñà‚ñà‚ñà       | 2767/9017 [01:03<02:17, 45.50it/s]
 31%|‚ñà‚ñà‚ñà       | 2772/9017 [01:03<02:17, 45.48it/s]
 31%|‚ñà‚ñà‚ñà       | 2777/9017 [01:03<02:47, 37.31it/s]
 31%|‚ñà‚ñà‚ñà       | 2782/9017 [01:04<02:36, 39.80it/s]
 31%|‚ñà‚ñà‚ñà       | 2788/9017 [01:04<02:23, 43.48it/s]
 31%|‚ñà‚ñà‚ñà       | 2794/9017 [01:04<02:13, 46.55it/s]
 31%|‚ñà‚ñà‚ñà       | 2800/9017 [01:04<02:11, 47.11it/s]
 31%|‚ñà‚ñà‚ñà       | 2806/9017 [01:04<02:07, 48.67it/s]
 31%|‚ñà‚ñà‚ñà       | 2811/9017 [01:04<02:14, 46.05it/s]
 31%|‚ñà‚ñà‚ñà       | 2817/9017 [01:04<02:09, 47.77it/s]
 31%|‚ñà‚ñà‚ñà‚ñè      | 2822/9017 [01:04<02:14, 46.01it/s]
 31%|‚ñà‚ñà‚ñà‚ñè      | 2827/9017 [01:05<02:36, 39.56it/s]
 31%|‚ñà‚ñà‚ñà‚ñè      | 2832/9017 [01:05<02:31, 40.95it/s]
 31%|‚ñà‚ñà‚ñà‚ñè      | 2838/9017 [01:05<02:20, 44.09it/s]
 32%|‚ñà‚ñà‚ñà‚ñè      | 2843/9017 [01:05<02:16, 45.40it/s]
 32%|‚ñà‚ñà‚ñà‚ñè      | 2848/9017 [01:05<02:19, 44.27it/s]
 32%|‚ñà‚ñà‚ñà‚ñè      | 2854/9017 [01:05<02:13, 46.17it/s]
 32%|‚ñà‚ñà‚ñà‚ñè      | 2859/9017 [01:05<02:12, 46.35it/s]
 32%|‚ñà‚ñà‚ñà‚ñè      | 2864/9017 [01:05<02:22, 43.28it/s]
 32%|‚ñà‚ñà‚ñà‚ñè      | 2870/9017 [01:05<02:09, 47.37it/s]
 32%|‚ñà‚ñà‚ñà‚ñè      | 2875/9017 [01:06<04:42, 21.74it/s]
 32%|‚ñà‚ñà‚ñà‚ñè      | 2879/9017 [01:06<04:10, 24.46it/s]
 32%|‚ñà‚ñà‚ñà‚ñè      | 2885/9017 [01:06<03:21, 30.37it/s]
 32%|‚ñà‚ñà‚ñà‚ñè      | 2890/9017 [01:06<03:01, 33.75it/s]
 32%|‚ñà‚ñà‚ñà‚ñè      | 2896/9017 [01:06<02:46, 36.85it/s]
 32%|‚ñà‚ñà‚ñà‚ñè      | 2901/9017 [01:07<02:37, 38.87it/s]
 32%|‚ñà‚ñà‚ñà‚ñè      | 2907/9017 [01:07<02:22, 43.03it/s]
 32%|‚ñà‚ñà‚ñà‚ñè      | 2912/9017 [01:07<02:17, 44.30it/s]
 32%|‚ñà‚ñà‚ñà‚ñè      | 2917/9017 [01:07<02:13, 45.56it/s]
 32%|‚ñà‚ñà‚ñà‚ñè      | 2922/9017 [01:07<02:12, 45.91it/s]
 32%|‚ñà‚ñà‚ñà‚ñè      | 2927/9017 [01:07<02:09, 46.92it/s]
 33%|‚ñà‚ñà‚ñà‚ñé      | 2932/9017 [01:07<02:16, 44.55it/s]
 33%|‚ñà‚ñà‚ñà‚ñé      | 2938/9017 [01:07<02:14, 45.05it/s]
 33%|‚ñà‚ñà‚ñà‚ñé      | 2943/9017 [01:07<02:15, 44.98it/s]
 33%|‚ñà‚ñà‚ñà‚ñé      | 2949/9017 [01:08<02:08, 47.37it/s]
 33%|‚ñà‚ñà‚ñà‚ñé      | 2954/9017 [01:08<02:07, 47.70it/s]
 33%|‚ñà‚ñà‚ñà‚ñé      | 2960/9017 [01:08<02:02, 49.52it/s]
 33%|‚ñà‚ñà‚ñà‚ñé      | 2965/9017 [01:08<02:06, 47.74it/s]
 33%|‚ñà‚ñà‚ñà‚ñé      | 2971/9017 [01:08<02:03, 49.13it/s]
 33%|‚ñà‚ñà‚ñà‚ñé      | 2977/9017 [01:08<01:57, 51.30it/s]
 33%|‚ñà‚ñà‚ñà‚ñé      | 2983/9017 [01:08<01:55, 52.33it/s]
 33%|‚ñà‚ñà‚ñà‚ñé      | 2989/9017 [01:08<02:17, 43.87it/s]
 33%|‚ñà‚ñà‚ñà‚ñé      | 2994/9017 [01:09<02:16, 44.17it/s]
 33%|‚ñà‚ñà‚ñà‚ñé      | 2999/9017 [01:09<02:14, 44.81it/s]
 33%|‚ñà‚ñà‚ñà‚ñé      | 3005/9017 [01:09<02:09, 46.49it/s]
 33%|‚ñà‚ñà‚ñà‚ñé      | 3010/9017 [01:09<02:06, 47.37it/s]
 33%|‚ñà‚ñà‚ñà‚ñé      | 3015/9017 [01:09<02:07, 47.14it/s]
 33%|‚ñà‚ñà‚ñà‚ñé      | 3020/9017 [01:09<02:12, 45.36it/s]
 34%|‚ñà‚ñà‚ñà‚ñé      | 3026/9017 [01:09<02:05, 47.64it/s]
 34%|‚ñà‚ñà‚ñà‚ñé      | 3032/9017 [01:09<02:01, 49.37it/s]
 34%|‚ñà‚ñà‚ñà‚ñé      | 3037/9017 [01:09<02:02, 48.79it/s]
 34%|‚ñà‚ñà‚ñà‚ñé      | 3042/9017 [01:10<02:04, 47.87it/s]
 34%|‚ñà‚ñà‚ñà‚ñç      | 3049/9017 [01:10<01:55, 51.45it/s]
 34%|‚ñà‚ñà‚ñà‚ñç      | 3055/9017 [01:10<01:57, 50.81it/s]
 34%|‚ñà‚ñà‚ñà‚ñç      | 3061/9017 [01:10<02:08, 46.36it/s]
 34%|‚ñà‚ñà‚ñà‚ñç      | 3066/9017 [01:10<02:11, 45.38it/s]
 34%|‚ñà‚ñà‚ñà‚ñç      | 3071/9017 [01:10<02:16, 43.69it/s]
 34%|‚ñà‚ñà‚ñà‚ñç      | 3077/9017 [01:10<02:04, 47.69it/s]
 34%|‚ñà‚ñà‚ñà‚ñç      | 3082/9017 [01:10<02:04, 47.58it/s]
 34%|‚ñà‚ñà‚ñà‚ñç      | 3087/9017 [01:10<02:07, 46.64it/s]
 34%|‚ñà‚ñà‚ñà‚ñç      | 3094/9017 [01:11<01:55, 51.15it/s]
 34%|‚ñà‚ñà‚ñà‚ñç      | 3100/9017 [01:11<02:06, 46.85it/s]
 34%|‚ñà‚ñà‚ñà‚ñç      | 3105/9017 [01:11<02:11, 45.12it/s]
 34%|‚ñà‚ñà‚ñà‚ñç      | 3110/9017 [01:11<02:10, 45.38it/s]
 35%|‚ñà‚ñà‚ñà‚ñç      | 3115/9017 [01:11<02:08, 45.81it/s]
 35%|‚ñà‚ñà‚ñà‚ñç      | 3120/9017 [01:11<02:05, 46.83it/s]
 35%|‚ñà‚ñà‚ñà‚ñç      | 3125/9017 [01:11<02:08, 45.91it/s]
 35%|‚ñà‚ñà‚ñà‚ñç      | 3131/9017 [01:11<02:00, 49.05it/s]
 35%|‚ñà‚ñà‚ñà‚ñç      | 3136/9017 [01:12<02:00, 48.65it/s]
 35%|‚ñà‚ñà‚ñà‚ñç      | 3141/9017 [01:12<02:07, 45.96it/s]
 35%|‚ñà‚ñà‚ñà‚ñç      | 3146/9017 [01:12<02:05, 46.64it/s]
 35%|‚ñà‚ñà‚ñà‚ñç      | 3152/9017 [01:12<02:00, 48.80it/s]
 35%|‚ñà‚ñà‚ñà‚ñå      | 3158/9017 [01:12<01:58, 49.44it/s]
 35%|‚ñà‚ñà‚ñà‚ñå      | 3163/9017 [01:12<01:58, 49.34it/s]
 35%|‚ñà‚ñà‚ñà‚ñå      | 3168/9017 [01:12<01:59, 48.83it/s]
 35%|‚ñà‚ñà‚ñà‚ñå      | 3173/9017 [01:12<01:59, 49.00it/s]
 35%|‚ñà‚ñà‚ñà‚ñå      | 3179/9017 [01:12<01:58, 49.46it/s]
 35%|‚ñà‚ñà‚ñà‚ñå      | 3185/9017 [01:13<01:57, 49.69it/s]
 35%|‚ñà‚ñà‚ñà‚ñå      | 3190/9017 [01:13<02:00, 48.36it/s]
 35%|‚ñà‚ñà‚ñà‚ñå      | 3195/9017 [01:13<02:04, 46.66it/s]
 35%|‚ñà‚ñà‚ñà‚ñå      | 3201/9017 [01:13<02:02, 47.39it/s]
 36%|‚ñà‚ñà‚ñà‚ñå      | 3207/9017 [01:13<01:54, 50.77it/s]
 36%|‚ñà‚ñà‚ñà‚ñå      | 3213/9017 [01:13<01:58, 48.94it/s]
 36%|‚ñà‚ñà‚ñà‚ñå      | 3218/9017 [01:13<02:11, 44.07it/s]
 36%|‚ñà‚ñà‚ñà‚ñå      | 3223/9017 [01:13<02:21, 40.95it/s]
 36%|‚ñà‚ñà‚ñà‚ñå      | 3229/9017 [01:14<02:09, 44.74it/s]
 36%|‚ñà‚ñà‚ñà‚ñå      | 3234/9017 [01:14<02:16, 42.48it/s]
 36%|‚ñà‚ñà‚ñà‚ñå      | 3240/9017 [01:14<02:09, 44.53it/s]
 36%|‚ñà‚ñà‚ñà‚ñå      | 3245/9017 [01:14<02:14, 42.94it/s]
 36%|‚ñà‚ñà‚ñà‚ñå      | 3250/9017 [01:14<02:12, 43.62it/s]
 36%|‚ñà‚ñà‚ñà‚ñå      | 3256/9017 [01:14<02:08, 44.86it/s]
 36%|‚ñà‚ñà‚ñà‚ñå      | 3261/9017 [01:14<02:11, 43.61it/s]
 36%|‚ñà‚ñà‚ñà‚ñå      | 3267/9017 [01:14<02:05, 45.66it/s]
 36%|‚ñà‚ñà‚ñà‚ñã      | 3273/9017 [01:14<02:02, 46.83it/s]
 36%|‚ñà‚ñà‚ñà‚ñã      | 3279/9017 [01:15<01:57, 49.00it/s]
 36%|‚ñà‚ñà‚ñà‚ñã      | 3284/9017 [01:15<02:00, 47.73it/s]
 36%|‚ñà‚ñà‚ñà‚ñã      | 3290/9017 [01:15<02:04, 45.96it/s]
 37%|‚ñà‚ñà‚ñà‚ñã      | 3295/9017 [01:15<02:02, 46.58it/s]
 37%|‚ñà‚ñà‚ñà‚ñã      | 3300/9017 [01:15<02:04, 45.88it/s]
 37%|‚ñà‚ñà‚ñà‚ñã      | 3306/9017 [01:15<01:55, 49.40it/s]
 37%|‚ñà‚ñà‚ñà‚ñã      | 3311/9017 [01:15<02:05, 45.62it/s]
 37%|‚ñà‚ñà‚ñà‚ñã      | 3317/9017 [01:15<02:00, 47.16it/s]
 37%|‚ñà‚ñà‚ñà‚ñã      | 3323/9017 [01:16<01:59, 47.66it/s]
 37%|‚ñà‚ñà‚ñà‚ñã      | 3329/9017 [01:16<01:57, 48.44it/s]
 37%|‚ñà‚ñà‚ñà‚ñã      | 3334/9017 [01:16<01:58, 48.05it/s]
 37%|‚ñà‚ñà‚ñà‚ñã      | 3340/9017 [01:16<01:53, 49.80it/s]
 37%|‚ñà‚ñà‚ñà‚ñã      | 3345/9017 [01:16<01:55, 48.99it/s]
 37%|‚ñà‚ñà‚ñà‚ñã      | 3350/9017 [01:16<01:58, 47.94it/s]
 37%|‚ñà‚ñà‚ñà‚ñã      | 3356/9017 [01:16<01:53, 50.04it/s]
 37%|‚ñà‚ñà‚ñà‚ñã      | 3362/9017 [01:16<01:56, 48.39it/s]
 37%|‚ñà‚ñà‚ñà‚ñã      | 3367/9017 [01:16<01:56, 48.47it/s]
 37%|‚ñà‚ñà‚ñà‚ñã      | 3372/9017 [01:17<02:07, 44.27it/s]
 37%|‚ñà‚ñà‚ñà‚ñã      | 3377/9017 [01:17<02:12, 42.60it/s]
 38%|‚ñà‚ñà‚ñà‚ñä      | 3382/9017 [01:17<02:12, 42.61it/s]
 38%|‚ñà‚ñà‚ñà‚ñä      | 3387/9017 [01:17<02:08, 43.84it/s]
 38%|‚ñà‚ñà‚ñà‚ñä      | 3393/9017 [01:17<01:56, 48.14it/s]
 38%|‚ñà‚ñà‚ñà‚ñä      | 3400/9017 [01:17<01:46, 52.60it/s]
 38%|‚ñà‚ñà‚ñà‚ñä      | 3406/9017 [01:17<02:03, 45.59it/s]
 38%|‚ñà‚ñà‚ñà‚ñä      | 3411/9017 [01:17<02:04, 45.01it/s]
 38%|‚ñà‚ñà‚ñà‚ñä      | 3416/9017 [01:18<02:05, 44.77it/s]
 38%|‚ñà‚ñà‚ñà‚ñä      | 3421/9017 [01:18<02:09, 43.30it/s]
 38%|‚ñà‚ñà‚ñà‚ñä      | 3426/9017 [01:18<02:08, 43.66it/s]
 38%|‚ñà‚ñà‚ñà‚ñä      | 3431/9017 [01:18<02:08, 43.38it/s]
 38%|‚ñà‚ñà‚ñà‚ñä      | 3436/9017 [01:18<02:07, 43.83it/s]
 38%|‚ñà‚ñà‚ñà‚ñä      | 3443/9017 [01:18<01:53, 49.02it/s]
 38%|‚ñà‚ñà‚ñà‚ñä      | 3448/9017 [01:18<01:53, 49.23it/s]
 38%|‚ñà‚ñà‚ñà‚ñä      | 3453/9017 [01:18<01:59, 46.38it/s]
 38%|‚ñà‚ñà‚ñà‚ñä      | 3458/9017 [01:18<02:10, 42.46it/s]
 38%|‚ñà‚ñà‚ñà‚ñä      | 3463/9017 [01:19<02:10, 42.61it/s]
 38%|‚ñà‚ñà‚ñà‚ñä      | 3468/9017 [01:19<02:18, 40.14it/s]
 39%|‚ñà‚ñà‚ñà‚ñä      | 3474/9017 [01:19<02:04, 44.42it/s]
 39%|‚ñà‚ñà‚ñà‚ñä      | 3480/9017 [01:19<01:56, 47.54it/s]
 39%|‚ñà‚ñà‚ñà‚ñä      | 3487/9017 [01:19<01:49, 50.59it/s]
 39%|‚ñà‚ñà‚ñà‚ñä      | 3493/9017 [01:19<01:47, 51.19it/s]
 39%|‚ñà‚ñà‚ñà‚ñâ      | 3499/9017 [01:19<01:59, 46.05it/s]
 39%|‚ñà‚ñà‚ñà‚ñâ      | 3504/9017 [01:19<01:58, 46.70it/s]
 39%|‚ñà‚ñà‚ñà‚ñâ      | 3509/9017 [01:20<01:56, 47.18it/s]
 39%|‚ñà‚ñà‚ñà‚ñâ      | 3514/9017 [01:20<02:03, 44.70it/s]
 39%|‚ñà‚ñà‚ñà‚ñâ      | 3519/9017 [01:20<02:04, 44.11it/s]
 39%|‚ñà‚ñà‚ñà‚ñâ      | 3525/9017 [01:20<01:57, 46.73it/s]
 39%|‚ñà‚ñà‚ñà‚ñâ      | 3530/9017 [01:20<01:59, 45.88it/s]
 39%|‚ñà‚ñà‚ñà‚ñâ      | 3535/9017 [01:20<02:00, 45.56it/s]
 39%|‚ñà‚ñà‚ñà‚ñâ      | 3540/9017 [01:20<02:17, 39.88it/s]
 39%|‚ñà‚ñà‚ñà‚ñâ      | 3545/9017 [01:20<02:19, 39.30it/s]
 39%|‚ñà‚ñà‚ñà‚ñâ      | 3550/9017 [01:21<02:11, 41.61it/s]
 39%|‚ñà‚ñà‚ñà‚ñâ      | 3555/9017 [01:21<02:05, 43.56it/s]
 39%|‚ñà‚ñà‚ñà‚ñâ      | 3561/9017 [01:21<01:56, 46.80it/s]
 40%|‚ñà‚ñà‚ñà‚ñâ      | 3567/9017 [01:21<01:52, 48.41it/s]
 40%|‚ñà‚ñà‚ñà‚ñâ      | 3574/9017 [01:21<01:44, 52.09it/s]
 40%|‚ñà‚ñà‚ñà‚ñâ      | 3580/9017 [01:21<01:50, 49.32it/s]
 40%|‚ñà‚ñà‚ñà‚ñâ      | 3585/9017 [01:21<01:55, 47.10it/s]
 40%|‚ñà‚ñà‚ñà‚ñâ      | 3591/9017 [01:21<01:59, 45.33it/s]
 40%|‚ñà‚ñà‚ñà‚ñâ      | 3597/9017 [01:21<01:52, 48.05it/s]
 40%|‚ñà‚ñà‚ñà‚ñâ      | 3602/9017 [01:22<01:55, 46.89it/s]
 40%|‚ñà‚ñà‚ñà‚ñà      | 3608/9017 [01:22<01:48, 49.67it/s]
 40%|‚ñà‚ñà‚ñà‚ñà      | 3614/9017 [01:22<01:55, 46.75it/s]
 40%|‚ñà‚ñà‚ñà‚ñà      | 3620/9017 [01:22<01:47, 50.13it/s]
 40%|‚ñà‚ñà‚ñà‚ñà      | 3626/9017 [01:22<01:42, 52.63it/s]
 40%|‚ñà‚ñà‚ñà‚ñà      | 3633/9017 [01:22<01:38, 54.59it/s]
 40%|‚ñà‚ñà‚ñà‚ñà      | 3639/9017 [01:22<01:36, 55.80it/s]
 40%|‚ñà‚ñà‚ñà‚ñà      | 3645/9017 [01:22<01:41, 52.75it/s]
 40%|‚ñà‚ñà‚ñà‚ñà      | 3651/9017 [01:23<01:43, 51.69it/s]
 41%|‚ñà‚ñà‚ñà‚ñà      | 3657/9017 [01:23<01:50, 48.30it/s]
 41%|‚ñà‚ñà‚ñà‚ñà      | 3663/9017 [01:23<01:48, 49.31it/s]
 41%|‚ñà‚ñà‚ñà‚ñà      | 3668/9017 [01:23<01:52, 47.37it/s]
 41%|‚ñà‚ñà‚ñà‚ñà      | 3674/9017 [01:23<01:48, 49.45it/s]
 41%|‚ñà‚ñà‚ñà‚ñà      | 3680/9017 [01:23<01:47, 49.77it/s]
 41%|‚ñà‚ñà‚ñà‚ñà      | 3686/9017 [01:23<01:51, 47.68it/s]
 41%|‚ñà‚ñà‚ñà‚ñà      | 3692/9017 [01:23<02:06, 41.99it/s]
 41%|‚ñà‚ñà‚ñà‚ñà      | 3698/9017 [01:24<01:59, 44.39it/s]
 41%|‚ñà‚ñà‚ñà‚ñà      | 3703/9017 [01:24<02:02, 43.30it/s]
 41%|‚ñà‚ñà‚ñà‚ñà      | 3708/9017 [01:24<02:00, 43.94it/s]
 41%|‚ñà‚ñà‚ñà‚ñà      | 3713/9017 [01:24<01:57, 44.95it/s]
 41%|‚ñà‚ñà‚ñà‚ñà      | 3719/9017 [01:24<01:51, 47.53it/s]
 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3725/9017 [01:24<01:46, 49.58it/s]
 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3731/9017 [01:24<01:54, 46.29it/s]
 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3736/9017 [01:24<01:57, 44.99it/s]
 41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3741/9017 [01:24<01:55, 45.85it/s]
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3746/9017 [01:25<01:59, 44.01it/s]
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3751/9017 [01:25<01:56, 45.36it/s]
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3756/9017 [01:25<01:56, 45.10it/s]
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3762/9017 [01:25<01:51, 47.27it/s]
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3767/9017 [01:25<01:52, 46.77it/s]
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3773/9017 [01:25<01:47, 48.70it/s]
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3779/9017 [01:25<01:43, 50.64it/s]
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3785/9017 [01:25<01:46, 48.92it/s]
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3791/9017 [01:26<01:43, 50.49it/s]
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3797/9017 [01:26<01:40, 52.06it/s]
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3803/9017 [01:26<01:38, 52.99it/s]
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3809/9017 [01:26<01:41, 51.55it/s]
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3815/9017 [01:26<01:39, 52.10it/s]
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3821/9017 [01:26<01:38, 52.88it/s]
 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 3827/9017 [01:26<01:44, 49.80it/s]
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3833/9017 [01:26<01:43, 50.22it/s]
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3839/9017 [01:26<01:40, 51.37it/s]
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3845/9017 [01:27<01:41, 50.77it/s]
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3851/9017 [01:27<01:45, 48.85it/s]
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3857/9017 [01:27<01:43, 49.92it/s]
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3863/9017 [01:27<01:40, 51.31it/s]
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3869/9017 [01:27<01:43, 49.91it/s]
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3875/9017 [01:27<01:41, 50.90it/s]
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3881/9017 [01:27<01:47, 47.60it/s]
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3886/9017 [01:28<02:13, 38.33it/s]
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3892/9017 [01:28<02:01, 42.21it/s]
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3897/9017 [01:28<01:57, 43.56it/s]
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3902/9017 [01:28<01:57, 43.43it/s]
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3908/9017 [01:28<01:49, 46.58it/s]
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3914/9017 [01:28<01:42, 49.73it/s]
 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3920/9017 [01:28<01:46, 47.77it/s]
 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3926/9017 [01:28<01:45, 48.28it/s]
 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3931/9017 [01:28<02:03, 41.35it/s]
 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3936/9017 [01:29<02:07, 39.88it/s]
 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 3941/9017 [01:29<02:07, 39.84it/s]
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 3948/9017 [01:29<01:52, 45.04it/s]
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 3953/9017 [01:29<01:52, 44.89it/s]
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 3959/9017 [01:29<01:49, 46.24it/s]
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 3964/9017 [01:29<01:48, 46.68it/s]
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 3969/9017 [01:29<01:49, 46.31it/s]
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 3974/9017 [01:29<01:47, 47.10it/s]
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 3979/9017 [01:30<02:02, 41.25it/s]
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 3984/9017 [01:30<01:57, 42.88it/s]
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 3990/9017 [01:30<01:49, 45.78it/s]
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 3995/9017 [01:30<01:50, 45.38it/s]
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4000/9017 [01:30<01:56, 43.09it/s]
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4005/9017 [01:30<01:53, 44.30it/s]
 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4010/9017 [01:30<01:49, 45.71it/s]
 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4015/9017 [01:30<01:46, 46.90it/s]
 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4022/9017 [01:30<01:34, 53.01it/s]
 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4028/9017 [01:31<01:42, 48.83it/s]
 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4033/9017 [01:31<01:41, 49.09it/s]
 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4038/9017 [01:31<01:44, 47.69it/s]
 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4043/9017 [01:31<01:45, 46.94it/s]
 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4048/9017 [01:31<01:44, 47.37it/s]
 45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4053/9017 [01:31<03:33, 23.26it/s]
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4058/9017 [01:32<03:07, 26.52it/s]
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4064/9017 [01:32<02:35, 31.79it/s]
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4069/9017 [01:32<02:22, 34.80it/s]
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4074/9017 [01:32<02:10, 37.92it/s]
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4079/9017 [01:32<02:03, 39.88it/s]
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4086/9017 [01:32<01:45, 46.68it/s]
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4092/9017 [01:32<01:40, 48.85it/s]
 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4098/9017 [01:32<01:42, 47.93it/s]
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4104/9017 [01:33<01:40, 49.10it/s]
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4110/9017 [01:33<01:42, 48.02it/s]
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4115/9017 [01:33<01:51, 43.99it/s]
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4120/9017 [01:33<01:49, 44.62it/s]
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4125/9017 [01:33<01:47, 45.49it/s]
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4131/9017 [01:33<01:45, 46.42it/s]
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4136/9017 [01:33<01:48, 45.06it/s]
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4142/9017 [01:33<01:42, 47.70it/s]
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4147/9017 [01:34<02:23, 33.99it/s]
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4151/9017 [01:34<02:18, 35.20it/s]
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4158/9017 [01:34<01:55, 41.99it/s]
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4163/9017 [01:34<01:53, 42.61it/s]
 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 4168/9017 [01:34<01:52, 42.95it/s]
 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4174/9017 [01:34<01:48, 44.51it/s]
 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4179/9017 [01:34<01:49, 44.19it/s]
 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4184/9017 [01:34<01:48, 44.52it/s]
 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4189/9017 [01:35<01:48, 44.61it/s]
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4194/9017 [01:35<01:48, 44.52it/s]
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4199/9017 [01:35<01:50, 43.65it/s]
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4204/9017 [01:35<01:50, 43.46it/s]
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4209/9017 [01:35<01:46, 45.22it/s]
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4214/9017 [01:35<01:52, 42.86it/s]
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4219/9017 [01:35<01:52, 42.62it/s]
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4225/9017 [01:35<01:43, 46.20it/s]
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4230/9017 [01:35<01:45, 45.22it/s]
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4235/9017 [01:36<01:42, 46.49it/s]
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4240/9017 [01:36<01:45, 45.14it/s]
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4245/9017 [01:36<01:45, 45.40it/s]
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4251/9017 [01:36<01:38, 48.56it/s]
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4256/9017 [01:36<01:42, 46.60it/s]
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4262/9017 [01:36<01:38, 48.10it/s]
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4268/9017 [01:36<01:34, 50.37it/s]
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4274/9017 [01:36<01:35, 49.59it/s]
 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 4279/9017 [01:36<01:36, 48.87it/s]
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4284/9017 [01:37<01:39, 47.59it/s]
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4290/9017 [01:37<01:37, 48.62it/s]
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4295/9017 [01:37<01:40, 46.75it/s]
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4301/9017 [01:37<01:35, 49.44it/s]
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4306/9017 [01:37<01:37, 48.26it/s]
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4311/9017 [01:37<01:39, 47.45it/s]
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4317/9017 [01:37<01:33, 50.36it/s]
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4323/9017 [01:37<01:36, 48.48it/s]
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4329/9017 [01:37<01:32, 50.44it/s]
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4335/9017 [01:38<01:30, 52.00it/s]
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4341/9017 [01:38<01:27, 53.37it/s]
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4347/9017 [01:38<01:37, 47.67it/s]
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4353/9017 [01:38<01:34, 49.51it/s]
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4359/9017 [01:38<01:37, 47.73it/s]
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4364/9017 [01:38<01:43, 44.79it/s]
 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4370/9017 [01:38<01:44, 44.42it/s]
 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4375/9017 [01:39<01:54, 40.68it/s]
 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4380/9017 [01:39<01:52, 41.24it/s]
 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4385/9017 [01:39<01:47, 43.28it/s]
 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4390/9017 [01:39<01:48, 42.77it/s]
 49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 4395/9017 [01:39<01:49, 42.16it/s]
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4400/9017 [01:39<01:45, 43.68it/s]
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4406/9017 [01:39<01:39, 46.50it/s]
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4412/9017 [01:39<01:33, 49.44it/s]
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4418/9017 [01:39<01:32, 49.84it/s]
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4424/9017 [01:40<01:36, 47.63it/s]
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4429/9017 [01:40<01:35, 47.87it/s]
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4434/9017 [01:40<01:40, 45.74it/s]
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4439/9017 [01:40<01:46, 43.07it/s]
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4445/9017 [01:40<01:38, 46.36it/s]
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4450/9017 [01:40<01:39, 46.06it/s]
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4455/9017 [01:40<01:37, 47.00it/s]
 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4460/9017 [01:40<01:38, 46.21it/s]
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4466/9017 [01:40<01:34, 48.22it/s]
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4471/9017 [01:41<01:36, 46.97it/s]
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4478/9017 [01:41<01:27, 51.59it/s]
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4484/9017 [01:41<01:41, 44.52it/s]
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4491/9017 [01:41<01:32, 48.93it/s]
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4497/9017 [01:41<01:36, 46.90it/s]
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4502/9017 [01:41<01:34, 47.56it/s]
 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 4507/9017 [01:41<01:40, 45.04it/s]
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4512/9017 [01:41<01:41, 44.37it/s]
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4517/9017 [01:42<01:42, 43.70it/s]
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4524/9017 [01:42<01:31, 49.34it/s]
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4530/9017 [01:42<01:30, 49.64it/s]
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4536/9017 [01:42<01:38, 45.67it/s]
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4542/9017 [01:42<01:38, 45.39it/s]
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4548/9017 [01:42<01:32, 48.22it/s]
 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4553/9017 [01:47<20:37,  3.61it/s]
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4558/9017 [01:47<15:21,  4.84it/s]
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4563/9017 [01:47<11:29,  6.46it/s]
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4568/9017 [01:47<08:37,  8.60it/s]
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4573/9017 [01:48<06:32, 11.32it/s]
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4578/9017 [01:48<05:09, 14.36it/s]
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4583/9017 [01:48<04:09, 17.76it/s]
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4588/9017 [01:48<03:27, 21.32it/s]
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4593/9017 [01:48<02:58, 24.76it/s]
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4599/9017 [01:48<02:25, 30.27it/s]
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4604/9017 [01:48<02:10, 33.84it/s]
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4609/9017 [01:48<02:08, 34.35it/s]
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4615/9017 [01:49<01:51, 39.31it/s]
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4621/9017 [01:49<01:45, 41.65it/s]
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4626/9017 [01:49<01:46, 41.20it/s]
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4631/9017 [01:49<01:46, 41.12it/s]
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4636/9017 [01:49<01:45, 41.66it/s]
 51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4641/9017 [01:49<01:40, 43.35it/s]
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4647/9017 [01:49<01:31, 47.68it/s]
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4652/9017 [01:49<01:32, 47.06it/s]
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4657/9017 [01:49<01:34, 45.96it/s]
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4662/9017 [01:50<01:35, 45.52it/s]
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4668/9017 [01:50<01:31, 47.76it/s]
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4674/9017 [01:50<01:26, 50.24it/s]
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4680/9017 [01:50<01:34, 45.76it/s]
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4685/9017 [01:50<01:41, 42.86it/s]
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4690/9017 [01:50<01:39, 43.56it/s]
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4695/9017 [01:50<01:43, 41.92it/s]
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4700/9017 [01:50<01:39, 43.53it/s]
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4705/9017 [01:51<01:41, 42.56it/s]
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4711/9017 [01:51<01:34, 45.74it/s]
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4717/9017 [01:51<01:28, 48.85it/s]
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4722/9017 [01:51<01:34, 45.49it/s]
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4727/9017 [01:51<01:34, 45.31it/s]
 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 4732/9017 [01:51<01:32, 46.08it/s]
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4737/9017 [01:51<01:34, 45.40it/s]
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4742/9017 [01:51<01:36, 44.42it/s]
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4747/9017 [01:51<01:44, 40.93it/s]
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4752/9017 [01:52<01:50, 38.52it/s]
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4756/9017 [01:52<01:54, 37.32it/s]
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4762/9017 [01:52<01:42, 41.51it/s]
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4768/9017 [01:52<01:34, 44.92it/s]
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4773/9017 [01:52<01:34, 44.79it/s]
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4778/9017 [01:52<01:36, 44.02it/s]
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4783/9017 [01:52<01:34, 44.85it/s]
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4788/9017 [01:52<01:32, 45.72it/s]
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4793/9017 [01:53<01:32, 45.61it/s]
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4799/9017 [01:53<01:30, 46.64it/s]
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4805/9017 [01:53<01:24, 49.82it/s]
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4811/9017 [01:53<01:29, 46.89it/s]
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4817/9017 [01:53<01:30, 46.64it/s]
 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4822/9017 [01:53<01:34, 44.19it/s]
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4828/9017 [01:53<01:30, 46.33it/s]
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4833/9017 [01:53<01:30, 46.45it/s]
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4838/9017 [01:54<01:57, 35.59it/s]
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 4844/9017 [01:54<01:45, 39.49it/s]
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4850/9017 [01:54<01:36, 43.19it/s]
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4856/9017 [01:54<01:29, 46.40it/s]
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4861/9017 [01:54<01:28, 46.79it/s]
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4866/9017 [01:54<01:34, 44.13it/s]
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4872/9017 [01:54<01:30, 45.72it/s]
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4878/9017 [01:54<01:25, 48.18it/s]
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4884/9017 [01:54<01:20, 51.06it/s]
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4890/9017 [01:55<01:25, 48.15it/s]
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4895/9017 [01:55<01:25, 48.19it/s]
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4900/9017 [01:55<01:32, 44.31it/s]
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4905/9017 [01:55<01:33, 43.93it/s]
 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4912/9017 [01:55<01:25, 47.93it/s]
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4918/9017 [01:55<01:21, 50.34it/s]
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4924/9017 [01:55<01:19, 51.71it/s]
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4930/9017 [01:55<01:19, 51.09it/s]
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4937/9017 [01:56<01:18, 51.87it/s]
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4943/9017 [01:56<01:16, 52.99it/s]
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4950/9017 [01:56<01:12, 55.73it/s]
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 4956/9017 [01:56<01:20, 50.62it/s]
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 4962/9017 [01:56<01:21, 49.58it/s]
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 4968/9017 [01:56<01:26, 46.69it/s]
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 4973/9017 [01:56<01:27, 46.39it/s]
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 4979/9017 [01:56<01:23, 48.44it/s]
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 4985/9017 [01:57<01:19, 50.93it/s]
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 4991/9017 [01:57<01:18, 51.14it/s]
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 4997/9017 [01:57<01:23, 47.99it/s]
 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5003/9017 [01:57<01:22, 48.73it/s]
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5010/9017 [01:57<01:27, 45.73it/s]
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5015/9017 [01:57<01:32, 43.22it/s]
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5020/9017 [01:57<01:33, 42.60it/s]
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5026/9017 [01:57<01:26, 46.31it/s]
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5032/9017 [01:58<01:21, 48.66it/s]
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5039/9017 [01:58<01:17, 51.18it/s]
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5045/9017 [01:58<01:23, 47.51it/s]
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5051/9017 [01:58<01:21, 48.60it/s]
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5058/9017 [01:58<01:15, 52.19it/s]
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5064/9017 [01:58<01:18, 50.37it/s]
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5070/9017 [01:58<01:21, 48.58it/s]
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5075/9017 [01:59<01:39, 39.49it/s]
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5080/9017 [01:59<01:37, 40.54it/s]
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5085/9017 [01:59<01:34, 41.78it/s]
 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5090/9017 [01:59<01:30, 43.40it/s]
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5096/9017 [01:59<01:26, 45.46it/s]
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5101/9017 [01:59<01:27, 44.69it/s]
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5106/9017 [01:59<01:29, 43.88it/s]
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5112/9017 [01:59<01:23, 46.83it/s]
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5118/9017 [01:59<01:20, 48.52it/s]
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5124/9017 [02:00<01:20, 48.51it/s]
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5130/9017 [02:00<01:19, 48.62it/s]
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5135/9017 [02:00<01:20, 48.04it/s]
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5140/9017 [02:00<01:23, 46.20it/s]
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5145/9017 [02:00<01:25, 45.23it/s]
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5151/9017 [02:00<01:19, 48.91it/s]
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5156/9017 [02:00<01:38, 39.02it/s]
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5161/9017 [02:00<01:36, 40.08it/s]
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5166/9017 [02:01<01:32, 41.65it/s]
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5171/9017 [02:01<01:34, 40.82it/s]
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5177/9017 [02:01<01:24, 45.70it/s]
 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 5182/9017 [02:01<01:22, 46.46it/s]
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5188/9017 [02:01<01:17, 49.24it/s]
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5196/9017 [02:01<01:09, 55.07it/s]
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5202/9017 [02:01<01:17, 49.42it/s]
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5208/9017 [02:01<01:16, 49.90it/s]
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5214/9017 [02:01<01:18, 48.72it/s]
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5219/9017 [02:02<01:19, 47.64it/s]
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5224/9017 [02:02<01:22, 46.04it/s]
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5229/9017 [02:02<01:23, 45.31it/s]
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5234/9017 [02:02<01:30, 41.97it/s]
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5239/9017 [02:02<01:27, 43.21it/s]
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5244/9017 [02:02<01:25, 44.36it/s]
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5249/9017 [02:02<01:27, 43.16it/s]
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5255/9017 [02:02<01:20, 46.57it/s]
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5261/9017 [02:03<01:14, 50.14it/s]
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5267/9017 [02:03<01:11, 52.28it/s]
 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5273/9017 [02:03<01:15, 49.78it/s]
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5279/9017 [02:03<01:17, 48.36it/s]
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5285/9017 [02:03<01:15, 49.15it/s]
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5291/9017 [02:03<01:11, 51.77it/s]
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 5297/9017 [02:03<01:11, 51.69it/s]
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5303/9017 [02:03<01:13, 50.64it/s]
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5309/9017 [02:04<01:21, 45.39it/s]
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5315/9017 [02:04<01:18, 47.38it/s]
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5320/9017 [02:04<01:16, 48.03it/s]
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5327/9017 [02:04<01:11, 51.76it/s]
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5333/9017 [02:04<01:13, 49.97it/s]
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5339/9017 [02:04<01:13, 49.82it/s]
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5345/9017 [02:04<01:14, 49.14it/s]
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5350/9017 [02:04<01:15, 48.41it/s]
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5356/9017 [02:04<01:12, 50.21it/s]
 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5362/9017 [02:05<01:16, 47.82it/s]
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5369/9017 [02:05<01:11, 51.16it/s]
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5375/9017 [02:05<01:12, 50.40it/s]
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5381/9017 [02:05<01:13, 49.47it/s]
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5387/9017 [02:05<01:10, 51.76it/s]
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5393/9017 [02:05<01:12, 49.81it/s]
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5399/9017 [02:05<01:19, 45.35it/s]
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5404/9017 [02:05<01:25, 42.23it/s]
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 5409/9017 [02:06<01:22, 43.56it/s]
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5414/9017 [02:06<01:21, 43.98it/s]
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5420/9017 [02:06<01:17, 46.59it/s]
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5425/9017 [02:06<01:19, 44.93it/s]
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5430/9017 [02:06<02:49, 21.14it/s]
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5435/9017 [02:07<02:22, 25.09it/s]
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5440/9017 [02:07<02:06, 28.37it/s]
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5446/9017 [02:07<01:46, 33.43it/s]
 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5451/9017 [02:07<01:37, 36.53it/s]
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5456/9017 [02:07<01:32, 38.35it/s]
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5461/9017 [02:07<01:28, 40.16it/s]
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5467/9017 [02:07<01:18, 45.03it/s]
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5472/9017 [02:07<01:16, 46.31it/s]
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5477/9017 [02:07<01:20, 43.85it/s]
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5482/9017 [02:08<01:20, 43.68it/s]
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5488/9017 [02:08<01:16, 46.21it/s]
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5493/9017 [02:08<01:17, 45.37it/s]
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5499/9017 [02:08<01:13, 47.79it/s]
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5505/9017 [02:08<01:13, 48.10it/s]
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5510/9017 [02:08<01:17, 45.50it/s]
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5516/9017 [02:08<01:14, 47.13it/s]
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 5521/9017 [02:09<01:30, 38.78it/s]
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5526/9017 [02:09<01:30, 38.41it/s]
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5532/9017 [02:09<01:22, 42.04it/s]
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5537/9017 [02:09<01:20, 42.98it/s]
 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5542/9017 [02:09<01:21, 42.84it/s]
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5548/9017 [02:09<01:14, 46.31it/s]
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5554/9017 [02:09<01:12, 47.98it/s]
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5560/9017 [02:09<01:11, 48.25it/s]
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5565/9017 [02:09<01:19, 43.22it/s]
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5570/9017 [02:10<01:18, 44.08it/s]
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5575/9017 [02:10<01:17, 44.29it/s]
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5580/9017 [02:10<01:15, 45.69it/s]
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5585/9017 [02:10<01:14, 46.21it/s]
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5592/9017 [02:10<01:05, 52.34it/s]
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5598/9017 [02:10<01:05, 52.24it/s]
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5604/9017 [02:10<01:10, 48.57it/s]
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5610/9017 [02:10<01:07, 50.71it/s]
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5616/9017 [02:11<01:11, 47.89it/s]
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5621/9017 [02:11<01:12, 47.07it/s]
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5627/9017 [02:11<01:11, 47.53it/s]
 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 5632/9017 [02:11<01:10, 47.84it/s]
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5638/9017 [02:11<01:07, 49.95it/s]
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5644/9017 [02:11<01:09, 48.85it/s]
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5649/9017 [02:11<01:09, 48.63it/s]
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5654/9017 [02:11<01:11, 46.93it/s]
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5659/9017 [02:11<01:13, 45.83it/s]
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5665/9017 [02:12<01:12, 46.19it/s]
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5670/9017 [02:12<01:11, 47.03it/s]
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5676/9017 [02:12<01:14, 44.89it/s]
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5682/9017 [02:12<01:12, 45.78it/s]
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5687/9017 [02:12<01:13, 45.23it/s]
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5692/9017 [02:12<01:14, 44.92it/s]
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5697/9017 [02:12<01:14, 44.43it/s]
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5702/9017 [02:12<01:12, 45.73it/s]
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5707/9017 [02:12<01:10, 46.86it/s]
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5712/9017 [02:13<01:11, 46.40it/s]
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5717/9017 [02:13<01:14, 44.44it/s]
 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5722/9017 [02:13<01:14, 44.31it/s]
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5727/9017 [02:13<01:14, 44.26it/s]
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5732/9017 [02:13<01:15, 43.77it/s]
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5738/9017 [02:13<01:10, 46.19it/s]
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5743/9017 [02:13<01:09, 47.08it/s]
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5749/9017 [02:13<01:14, 44.01it/s]
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5754/9017 [02:14<01:24, 38.73it/s]
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5759/9017 [02:14<01:20, 40.44it/s]
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5764/9017 [02:14<01:18, 41.63it/s]
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5770/9017 [02:14<01:14, 43.69it/s]
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5775/9017 [02:14<01:15, 42.99it/s]
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5780/9017 [02:14<01:22, 39.18it/s]
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5786/9017 [02:14<01:17, 41.91it/s]
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5792/9017 [02:14<01:11, 44.85it/s]
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5797/9017 [02:15<01:13, 43.52it/s]
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5802/9017 [02:15<01:12, 44.25it/s]
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5807/9017 [02:15<01:12, 44.16it/s]
 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5813/9017 [02:15<01:07, 47.31it/s]
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5818/9017 [02:15<01:11, 44.94it/s]
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5823/9017 [02:15<01:14, 42.59it/s]
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5829/9017 [02:15<01:11, 44.89it/s]
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5834/9017 [02:15<01:12, 44.12it/s]
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5839/9017 [02:16<01:14, 42.78it/s]
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5844/9017 [02:16<01:21, 38.74it/s]
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5849/9017 [02:16<01:17, 41.03it/s]
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5854/9017 [02:16<01:15, 41.74it/s]
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 5859/9017 [02:16<01:17, 40.87it/s]
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5864/9017 [02:16<01:16, 40.98it/s]
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5871/9017 [02:16<01:08, 45.97it/s]
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5877/9017 [02:16<01:04, 48.56it/s]
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5882/9017 [02:17<01:09, 44.91it/s]
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5887/9017 [02:17<01:08, 45.40it/s]
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5893/9017 [02:17<01:06, 46.76it/s]
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5898/9017 [02:17<01:06, 46.98it/s]
 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5903/9017 [02:17<01:12, 43.03it/s]
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5909/9017 [02:17<01:08, 45.31it/s]
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5914/9017 [02:17<01:06, 46.41it/s]
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5920/9017 [02:17<01:03, 48.77it/s]
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5925/9017 [02:17<01:04, 47.70it/s]
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5930/9017 [02:18<01:05, 46.89it/s]
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5935/9017 [02:18<01:08, 44.91it/s]
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5940/9017 [02:18<01:11, 43.21it/s]
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5945/9017 [02:18<01:12, 42.12it/s]
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5950/9017 [02:18<01:10, 43.33it/s]
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5957/9017 [02:18<01:05, 46.87it/s]
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5962/9017 [02:18<01:07, 45.42it/s]
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5968/9017 [02:18<01:22, 36.75it/s]
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 5973/9017 [02:19<01:18, 38.54it/s]
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 5978/9017 [02:19<01:15, 40.28it/s]
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 5984/9017 [02:19<01:07, 45.06it/s]
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 5990/9017 [02:19<01:02, 48.58it/s]
 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 5996/9017 [02:19<01:01, 49.36it/s]
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6002/9017 [02:19<01:01, 48.84it/s]
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6007/9017 [02:19<01:01, 48.84it/s]
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6012/9017 [02:19<01:01, 48.70it/s]
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6017/9017 [02:19<01:04, 46.23it/s]
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6024/9017 [02:20<01:03, 47.18it/s]
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6029/9017 [02:20<01:05, 45.93it/s]
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6035/9017 [02:20<01:02, 47.46it/s]
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6041/9017 [02:20<01:02, 47.92it/s]
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6046/9017 [02:20<01:14, 40.01it/s]
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6051/9017 [02:20<01:16, 38.97it/s]
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6056/9017 [02:20<01:12, 41.10it/s]
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6061/9017 [02:21<01:12, 41.00it/s]
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6066/9017 [02:21<01:10, 41.96it/s]
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6072/9017 [02:21<01:06, 44.34it/s]
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6077/9017 [02:21<01:06, 43.90it/s]
 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6082/9017 [02:21<01:05, 44.53it/s]
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6087/9017 [02:21<01:07, 43.69it/s]
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6092/9017 [02:21<01:22, 35.36it/s]
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6097/9017 [02:21<01:16, 38.15it/s]
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6103/9017 [02:22<01:09, 42.14it/s]
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6108/9017 [02:22<01:06, 43.67it/s]
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6113/9017 [02:22<01:10, 41.03it/s]
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6119/9017 [02:22<01:05, 44.21it/s]
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6124/9017 [02:22<01:05, 43.95it/s]
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6129/9017 [02:22<01:05, 43.95it/s]
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6134/9017 [02:22<01:03, 45.20it/s]
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6140/9017 [02:22<00:59, 48.66it/s]
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6145/9017 [02:22<00:58, 48.95it/s]
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6150/9017 [02:23<01:00, 47.53it/s]
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6155/9017 [02:23<01:00, 47.41it/s]
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6160/9017 [02:23<01:07, 42.29it/s]
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6165/9017 [02:23<01:05, 43.72it/s]
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6170/9017 [02:23<01:07, 42.20it/s]
 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6175/9017 [02:23<01:05, 43.69it/s]
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6180/9017 [02:23<01:05, 43.28it/s]
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6186/9017 [02:23<01:00, 46.83it/s]
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6191/9017 [02:24<01:11, 39.51it/s]
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 6196/9017 [02:24<01:09, 40.54it/s]
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6201/9017 [02:24<01:07, 41.94it/s]
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6206/9017 [02:24<01:06, 42.02it/s]
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6211/9017 [02:24<01:05, 42.58it/s]
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6216/9017 [02:24<01:03, 44.28it/s]
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6221/9017 [02:24<01:03, 43.87it/s]
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6226/9017 [02:24<01:01, 45.34it/s]
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6231/9017 [02:24<01:01, 45.03it/s]
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6237/9017 [02:25<01:00, 45.93it/s]
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6242/9017 [02:25<01:03, 43.94it/s]
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6248/9017 [02:25<00:59, 46.31it/s]
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6254/9017 [02:25<00:55, 49.47it/s]
 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6261/9017 [02:25<00:51, 53.16it/s]
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6267/9017 [02:25<00:50, 54.33it/s]
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6273/9017 [02:25<00:50, 54.32it/s]
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6279/9017 [02:25<00:50, 54.12it/s]
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6285/9017 [02:25<00:54, 50.05it/s]
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6291/9017 [02:26<00:54, 49.96it/s]
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6297/9017 [02:26<00:55, 48.80it/s]
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6302/9017 [02:26<01:00, 44.97it/s]
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 6308/9017 [02:26<00:56, 47.91it/s]
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6314/9017 [02:26<00:55, 48.89it/s]
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6319/9017 [02:26<00:58, 45.98it/s]
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6325/9017 [02:26<00:54, 48.96it/s]
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6330/9017 [02:26<00:54, 49.08it/s]
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6336/9017 [02:27<00:53, 50.53it/s]
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6342/9017 [02:27<00:57, 46.51it/s]
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6347/9017 [02:27<00:58, 45.75it/s]
 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6352/9017 [02:27<00:59, 44.81it/s]
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6357/9017 [02:27<00:59, 44.83it/s]
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6362/9017 [02:27<01:06, 39.66it/s]
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6367/9017 [02:27<01:03, 41.47it/s]
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6374/9017 [02:27<00:57, 46.04it/s]
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6379/9017 [02:28<00:58, 45.38it/s]
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6385/9017 [02:28<00:54, 48.13it/s]
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6390/9017 [02:28<00:59, 44.44it/s]
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6395/9017 [02:28<01:05, 40.24it/s]
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6401/9017 [02:28<00:58, 45.06it/s]
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6406/9017 [02:28<00:57, 45.43it/s]
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6411/9017 [02:28<00:57, 45.46it/s]
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6416/9017 [02:28<00:57, 45.44it/s]
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 6421/9017 [02:29<01:08, 37.89it/s]
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6426/9017 [02:29<01:08, 37.96it/s]
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6431/9017 [02:29<01:05, 39.21it/s]
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6436/9017 [02:29<01:05, 39.37it/s]
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6442/9017 [02:29<01:00, 42.49it/s]
 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6447/9017 [02:29<00:58, 43.75it/s]
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6452/9017 [02:29<00:58, 43.85it/s]
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6459/9017 [02:29<00:51, 49.98it/s]
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6465/9017 [02:29<00:51, 49.83it/s]
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6471/9017 [02:30<00:59, 42.73it/s]
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6476/9017 [02:30<00:59, 42.62it/s]
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6481/9017 [02:30<00:57, 44.37it/s]
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6486/9017 [02:30<00:57, 44.19it/s]
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6491/9017 [02:30<00:56, 44.91it/s]
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6496/9017 [02:30<00:55, 45.61it/s]
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6502/9017 [02:30<00:52, 47.78it/s]
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6507/9017 [02:30<00:53, 46.51it/s]
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6513/9017 [02:31<00:51, 48.67it/s]
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6518/9017 [02:31<00:52, 47.85it/s]
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6524/9017 [02:31<00:51, 48.77it/s]
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6529/9017 [02:31<00:54, 45.70it/s]
 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 6534/9017 [02:31<00:57, 43.42it/s]
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6539/9017 [02:31<00:55, 44.35it/s]
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6544/9017 [02:31<01:00, 40.76it/s]
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6549/9017 [02:31<00:57, 42.79it/s]
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6555/9017 [02:32<00:53, 45.77it/s]
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6560/9017 [02:32<00:52, 46.63it/s]
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6566/9017 [02:32<00:48, 50.11it/s]
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6572/9017 [02:32<00:51, 47.54it/s]
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6577/9017 [02:32<00:50, 47.89it/s]
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6582/9017 [02:32<01:00, 40.17it/s]
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6587/9017 [02:32<00:58, 41.67it/s]
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6592/9017 [02:32<00:58, 41.46it/s]
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6598/9017 [02:32<00:52, 45.87it/s]
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6603/9017 [02:33<00:52, 45.57it/s]
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6609/9017 [02:33<00:50, 48.05it/s]
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6615/9017 [02:33<00:48, 49.22it/s]
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6621/9017 [02:33<00:46, 51.25it/s]
 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6627/9017 [02:33<00:51, 46.15it/s]
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6632/9017 [02:33<00:51, 46.30it/s]
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6637/9017 [02:33<00:51, 46.25it/s]
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6642/9017 [02:33<00:55, 42.67it/s]
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 6648/9017 [02:34<00:53, 44.48it/s]
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6653/9017 [02:34<00:52, 44.80it/s]
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6659/9017 [02:34<00:54, 42.92it/s]
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6665/9017 [02:34<00:51, 45.83it/s]
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6671/9017 [02:34<00:50, 46.21it/s]
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6676/9017 [02:34<01:12, 32.28it/s]
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6681/9017 [02:34<01:07, 34.75it/s]
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6687/9017 [02:35<00:58, 40.04it/s]
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6693/9017 [02:35<00:53, 43.51it/s]
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6698/9017 [02:35<00:54, 42.51it/s]
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6703/9017 [02:35<00:52, 43.74it/s]
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6708/9017 [02:35<00:51, 44.45it/s]
 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6714/9017 [02:35<00:50, 45.60it/s]
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6719/9017 [02:35<00:49, 46.04it/s]
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6724/9017 [02:35<00:51, 44.96it/s]
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6730/9017 [02:35<00:48, 47.42it/s]
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6736/9017 [02:36<00:47, 48.16it/s]
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6742/9017 [02:36<00:47, 48.37it/s]
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6748/9017 [02:36<00:46, 48.57it/s]
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6753/9017 [02:36<00:47, 47.64it/s]
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 6758/9017 [02:36<00:53, 41.85it/s]
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6764/9017 [02:36<00:51, 44.13it/s]
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6769/9017 [02:36<00:51, 44.05it/s]
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6774/9017 [02:36<00:49, 45.32it/s]
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6779/9017 [02:37<00:50, 44.25it/s]
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6784/9017 [02:37<00:49, 44.82it/s]
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6789/9017 [02:37<00:48, 46.15it/s]
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6795/9017 [02:37<00:46, 47.37it/s]
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6800/9017 [02:37<00:48, 45.41it/s]
 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6806/9017 [02:37<00:46, 47.36it/s]
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6811/9017 [02:37<00:47, 46.59it/s]
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6816/9017 [02:37<00:47, 46.75it/s]
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6822/9017 [02:37<00:46, 47.16it/s]
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6827/9017 [02:38<00:47, 46.03it/s]
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6832/9017 [02:38<00:51, 42.75it/s]
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6838/9017 [02:38<00:53, 40.80it/s]
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6845/9017 [02:38<00:47, 45.96it/s]
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6850/9017 [02:38<00:47, 45.51it/s]
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6855/9017 [02:38<00:50, 42.80it/s]
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6861/9017 [02:38<00:46, 46.22it/s]
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6866/9017 [02:39<00:53, 40.36it/s]
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 6872/9017 [02:39<00:48, 44.43it/s]
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6877/9017 [02:39<00:49, 43.06it/s]
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6883/9017 [02:39<00:46, 46.36it/s]
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6889/9017 [02:39<00:43, 48.97it/s]
 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6895/9017 [02:39<00:43, 48.65it/s]
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6900/9017 [02:39<00:44, 47.41it/s]
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6906/9017 [02:39<00:43, 48.87it/s]
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6911/9017 [02:39<00:43, 48.09it/s]
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6917/9017 [02:40<00:41, 51.20it/s]
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6923/9017 [02:40<00:44, 46.95it/s]
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6928/9017 [02:40<00:45, 46.10it/s]
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6934/9017 [02:40<00:43, 47.59it/s]
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6940/9017 [02:40<00:41, 50.25it/s]
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6946/9017 [02:40<00:42, 48.30it/s]
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6951/9017 [02:40<00:43, 47.29it/s]
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6956/9017 [02:40<00:43, 47.48it/s]
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6961/9017 [02:40<00:43, 46.87it/s]
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6967/9017 [02:41<00:42, 47.93it/s]
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6973/9017 [02:41<00:41, 49.38it/s]
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6979/9017 [02:41<00:46, 43.84it/s]
 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 6984/9017 [02:41<00:45, 44.38it/s]
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 6990/9017 [02:41<00:43, 46.30it/s]
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 6995/9017 [02:41<00:46, 43.38it/s]
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7000/9017 [02:41<00:49, 41.03it/s]
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7006/9017 [02:41<00:45, 43.84it/s]
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7011/9017 [02:42<00:44, 45.01it/s]
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7016/9017 [02:42<00:53, 37.21it/s]
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7021/9017 [02:42<00:51, 38.86it/s]
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7026/9017 [02:42<00:48, 41.06it/s]
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7032/9017 [02:42<00:44, 44.50it/s]
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7037/9017 [02:42<00:44, 44.33it/s]
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7043/9017 [02:42<00:41, 47.85it/s]
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7049/9017 [02:42<00:40, 48.20it/s]
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7054/9017 [02:43<00:40, 48.64it/s]
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7059/9017 [02:43<00:40, 48.86it/s]
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7064/9017 [02:43<00:40, 48.34it/s]
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7069/9017 [02:43<00:45, 42.55it/s]
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7075/9017 [02:43<00:41, 46.42it/s]
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7080/9017 [02:43<00:43, 44.42it/s]
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7085/9017 [02:43<00:43, 44.55it/s]
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7090/9017 [02:43<00:42, 45.34it/s]
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7095/9017 [02:44<00:51, 37.50it/s]
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7100/9017 [02:44<00:48, 39.54it/s]
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7105/9017 [02:44<00:49, 38.51it/s]
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7111/9017 [02:44<00:43, 43.52it/s]
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7117/9017 [02:44<00:40, 47.41it/s]
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7124/9017 [02:44<00:36, 52.48it/s]
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7130/9017 [02:44<00:35, 52.72it/s]
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7136/9017 [02:44<00:35, 52.87it/s]
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7142/9017 [02:44<00:38, 49.19it/s]
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7148/9017 [02:45<00:36, 51.00it/s]
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7154/9017 [02:45<00:35, 53.20it/s]
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7160/9017 [02:45<00:35, 52.09it/s]
 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7166/9017 [02:45<00:36, 50.35it/s]
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7173/9017 [02:45<00:34, 53.00it/s]
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7180/9017 [02:45<00:33, 54.97it/s]
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7186/9017 [02:45<00:35, 52.02it/s]
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7192/9017 [02:45<00:34, 53.22it/s]
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7198/9017 [02:46<00:36, 49.31it/s]
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7204/9017 [02:46<00:37, 48.51it/s]
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 7209/9017 [02:46<00:38, 47.39it/s]
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7214/9017 [02:46<01:31, 19.71it/s]
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7219/9017 [02:47<01:16, 23.59it/s]
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7223/9017 [02:47<01:08, 26.02it/s]
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7228/9017 [02:47<00:59, 30.09it/s]
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7233/9017 [02:47<00:57, 31.18it/s]
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7238/9017 [02:47<00:52, 34.11it/s]
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7244/9017 [02:48<01:25, 20.86it/s]
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7248/9017 [02:48<01:14, 23.60it/s]
 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7254/9017 [02:48<01:01, 28.59it/s]
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7259/9017 [02:48<00:54, 32.14it/s]
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7265/9017 [02:48<00:46, 37.44it/s]
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7270/9017 [02:48<00:43, 40.15it/s]
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7275/9017 [02:48<00:41, 41.87it/s]
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7281/9017 [02:48<00:38, 44.74it/s]
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7286/9017 [02:49<00:58, 29.47it/s]
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7291/9017 [02:49<00:51, 33.25it/s]
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7297/9017 [02:49<00:45, 38.09it/s]
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7302/9017 [02:49<00:42, 40.63it/s]
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7308/9017 [02:49<00:38, 44.37it/s]
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7314/9017 [02:49<00:36, 46.10it/s]
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7319/9017 [02:49<00:39, 42.66it/s]
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 7324/9017 [02:49<00:39, 42.94it/s]
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7330/9017 [02:50<00:36, 46.41it/s]
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7335/9017 [02:50<00:37, 44.77it/s]
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7340/9017 [02:50<00:36, 45.81it/s]
 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7346/9017 [02:50<00:35, 47.72it/s]
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7352/9017 [02:50<00:34, 48.83it/s]
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7358/9017 [02:50<00:32, 51.01it/s]
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7364/9017 [02:50<00:32, 50.65it/s]
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7370/9017 [02:50<00:33, 49.56it/s]
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7375/9017 [02:50<00:34, 48.13it/s]
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7381/9017 [02:51<00:32, 50.21it/s]
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7387/9017 [02:51<00:32, 50.51it/s]
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7393/9017 [02:51<00:33, 48.35it/s]
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7399/9017 [02:51<00:32, 50.16it/s]
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7406/9017 [02:51<00:30, 52.74it/s]
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7412/9017 [02:51<00:29, 53.68it/s]
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7418/9017 [02:51<00:29, 55.05it/s]
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7424/9017 [02:51<00:30, 51.68it/s]
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7430/9017 [02:52<00:31, 49.89it/s]
 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 7436/9017 [02:52<00:31, 50.78it/s]
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7442/9017 [02:52<00:32, 47.98it/s]
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7447/9017 [02:52<00:32, 47.59it/s]
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7452/9017 [02:52<00:33, 46.58it/s]
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7457/9017 [02:52<00:34, 44.92it/s]
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7462/9017 [02:52<00:33, 46.02it/s]
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7467/9017 [02:52<00:35, 43.91it/s]
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7472/9017 [02:53<00:40, 38.23it/s]
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7477/9017 [02:53<00:39, 38.95it/s]
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7482/9017 [02:53<00:36, 41.64it/s]
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7487/9017 [02:53<00:36, 42.04it/s]
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7492/9017 [02:53<00:35, 43.05it/s]
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7497/9017 [02:53<00:34, 43.67it/s]
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7502/9017 [02:53<00:34, 44.52it/s]
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7507/9017 [02:53<00:32, 45.93it/s]
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7513/9017 [02:54<00:52, 28.42it/s]
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7518/9017 [02:54<00:47, 31.34it/s]
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7522/9017 [02:54<00:46, 32.13it/s]
 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7526/9017 [02:54<00:45, 32.88it/s]
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7531/9017 [02:54<00:40, 36.83it/s]
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7536/9017 [02:54<00:38, 38.06it/s]
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7541/9017 [02:54<00:36, 40.69it/s]
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7546/9017 [02:54<00:35, 40.89it/s]
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 7551/9017 [02:55<00:34, 42.22it/s]
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7556/9017 [02:55<00:34, 41.96it/s]
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7561/9017 [02:55<00:34, 42.32it/s]
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7567/9017 [02:55<00:31, 46.03it/s]
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7573/9017 [02:55<00:29, 48.24it/s]
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7578/9017 [02:55<00:30, 47.87it/s]
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7583/9017 [02:55<00:30, 47.58it/s]
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7590/9017 [02:55<00:26, 53.53it/s]
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7596/9017 [02:55<00:27, 52.24it/s]
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7602/9017 [02:56<00:27, 51.22it/s]
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7608/9017 [02:56<00:27, 50.38it/s]
 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7614/9017 [02:56<00:27, 50.79it/s]
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7620/9017 [02:56<00:27, 50.62it/s]
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7626/9017 [02:56<00:28, 48.22it/s]
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7631/9017 [02:56<00:29, 46.67it/s]
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7636/9017 [02:56<00:29, 46.99it/s]
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7642/9017 [02:56<00:28, 48.58it/s]
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7647/9017 [02:57<00:28, 47.33it/s]
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7653/9017 [02:57<00:26, 50.73it/s]
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 7659/9017 [02:57<00:26, 52.14it/s]
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7665/9017 [02:57<00:26, 51.72it/s]
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7671/9017 [02:57<00:27, 49.74it/s]
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7677/9017 [02:57<00:26, 50.05it/s]
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7683/9017 [02:57<00:25, 51.74it/s]
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7689/9017 [02:57<00:26, 50.37it/s]
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7696/9017 [02:57<00:24, 55.03it/s]
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7702/9017 [02:58<00:40, 32.80it/s]
 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7708/9017 [02:58<00:35, 36.86it/s]
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7713/9017 [02:58<00:35, 37.04it/s]
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7718/9017 [02:58<00:33, 38.36it/s]
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7723/9017 [02:58<00:31, 40.88it/s]
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7728/9017 [02:58<00:30, 42.42it/s]
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7733/9017 [02:59<00:39, 32.76it/s]
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7738/9017 [02:59<00:36, 35.10it/s]
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7743/9017 [02:59<00:33, 37.97it/s]
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7749/9017 [02:59<00:30, 41.64it/s]
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7754/9017 [02:59<00:32, 38.74it/s]
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7759/9017 [02:59<00:31, 40.37it/s]
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7764/9017 [02:59<00:29, 42.42it/s]
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7769/9017 [02:59<00:29, 42.36it/s]
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 7774/9017 [03:00<00:29, 41.50it/s]
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7781/9017 [03:00<00:26, 46.37it/s]
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7787/9017 [03:00<00:25, 49.12it/s]
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7792/9017 [03:00<00:25, 48.56it/s]
 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7797/9017 [03:00<00:25, 48.19it/s]
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7803/9017 [03:00<00:24, 50.10it/s]
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7809/9017 [03:00<00:24, 49.94it/s]
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7815/9017 [03:00<00:23, 50.12it/s]
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7821/9017 [03:00<00:24, 49.78it/s]
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7826/9017 [03:01<00:24, 48.21it/s]
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7832/9017 [03:01<00:24, 48.91it/s]
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7837/9017 [03:01<00:25, 45.47it/s]
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7842/9017 [03:01<00:26, 44.66it/s]
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7847/9017 [03:01<00:25, 45.13it/s]
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7852/9017 [03:01<00:25, 45.22it/s]
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7857/9017 [03:01<00:26, 44.26it/s]
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7862/9017 [03:01<00:25, 44.84it/s]
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7867/9017 [03:02<00:28, 40.55it/s]
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7875/9017 [03:02<00:23, 48.92it/s]
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7881/9017 [03:02<00:23, 47.63it/s]
 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 7887/9017 [03:02<00:23, 48.75it/s]
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7893/9017 [03:02<00:22, 49.60it/s]
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7899/9017 [03:02<00:24, 45.84it/s]
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7905/9017 [03:02<00:23, 47.11it/s]
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7910/9017 [03:02<00:24, 45.67it/s]
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7915/9017 [03:03<00:24, 44.58it/s]
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7920/9017 [03:03<00:38, 28.78it/s]
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7925/9017 [03:03<00:34, 32.05it/s]
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7929/9017 [03:03<00:32, 33.39it/s]
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7935/9017 [03:03<00:28, 37.53it/s]
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7940/9017 [03:03<00:27, 39.32it/s]
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7945/9017 [03:03<00:29, 36.07it/s]
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7950/9017 [03:04<00:27, 38.11it/s]
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7955/9017 [03:04<00:26, 40.47it/s]
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7961/9017 [03:04<00:24, 43.36it/s]
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7967/9017 [03:04<00:23, 44.73it/s]
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7972/9017 [03:04<00:24, 43.08it/s]
 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7978/9017 [03:04<00:22, 45.77it/s]
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7983/9017 [03:04<00:22, 45.27it/s]
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7988/9017 [03:04<00:23, 44.09it/s]
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7993/9017 [03:05<00:23, 43.70it/s]
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 7999/9017 [03:05<00:21, 46.29it/s]
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8005/9017 [03:05<00:21, 47.73it/s]
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8011/9017 [03:05<00:20, 48.29it/s]
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8016/9017 [03:05<00:21, 47.02it/s]
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8021/9017 [03:05<00:21, 46.26it/s]
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8026/9017 [03:05<00:21, 46.63it/s]
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8032/9017 [03:05<00:20, 48.78it/s]
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8037/9017 [03:05<00:20, 47.47it/s]
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8042/9017 [03:06<00:22, 42.72it/s]
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8047/9017 [03:06<00:22, 43.79it/s]
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8052/9017 [03:06<00:22, 42.64it/s]
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8057/9017 [03:06<00:22, 43.48it/s]
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8062/9017 [03:06<00:22, 42.74it/s]
 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8067/9017 [03:06<00:21, 44.10it/s]
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8072/9017 [03:06<00:22, 42.74it/s]
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8077/9017 [03:06<00:21, 43.65it/s]
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8082/9017 [03:07<00:21, 43.48it/s]
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8087/9017 [03:07<00:20, 44.35it/s]
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8092/9017 [03:07<00:20, 45.03it/s]
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8098/9017 [03:07<00:19, 48.02it/s]
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8103/9017 [03:07<00:19, 47.23it/s]
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8108/9017 [03:07<00:20, 45.40it/s]
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8114/9017 [03:07<00:19, 46.80it/s]
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8121/9017 [03:07<00:17, 51.17it/s]
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8127/9017 [03:07<00:18, 49.40it/s]
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8132/9017 [03:08<00:18, 47.41it/s]
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8137/9017 [03:08<00:28, 31.25it/s]
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8142/9017 [03:08<00:25, 34.70it/s]
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8148/9017 [03:08<00:21, 39.53it/s]
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8153/9017 [03:08<00:21, 40.38it/s]
 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8158/9017 [03:08<00:20, 41.18it/s]
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8163/9017 [03:09<00:26, 32.02it/s]
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8167/9017 [03:09<00:25, 33.43it/s]
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8172/9017 [03:09<00:22, 37.21it/s]
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8177/9017 [03:09<00:21, 39.30it/s]
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8182/9017 [03:09<00:20, 40.49it/s]
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8187/9017 [03:09<00:19, 41.70it/s]
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8193/9017 [03:09<00:18, 44.74it/s]
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8199/9017 [03:09<00:17, 47.19it/s]
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8205/9017 [03:09<00:16, 48.70it/s]
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8210/9017 [03:10<00:16, 48.95it/s]
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8215/9017 [03:10<00:17, 46.45it/s]
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8220/9017 [03:10<00:17, 44.71it/s]
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 8226/9017 [03:10<00:16, 46.90it/s]
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8231/9017 [03:10<00:16, 47.11it/s]
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8236/9017 [03:10<00:16, 47.42it/s]
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8242/9017 [03:10<00:15, 48.91it/s]
 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8247/9017 [03:10<00:16, 47.02it/s]
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8253/9017 [03:10<00:15, 49.23it/s]
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8258/9017 [03:11<00:15, 47.56it/s]
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8263/9017 [03:11<00:16, 45.21it/s]
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8269/9017 [03:11<00:15, 48.06it/s]
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8274/9017 [03:11<00:15, 48.19it/s]
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8279/9017 [03:11<00:15, 46.86it/s]
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8285/9017 [03:11<00:14, 49.84it/s]
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8291/9017 [03:11<00:14, 49.23it/s]
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8296/9017 [03:11<00:15, 47.25it/s]
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8302/9017 [03:11<00:14, 48.56it/s]
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8307/9017 [03:12<00:15, 47.31it/s]
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8312/9017 [03:12<00:15, 44.98it/s]
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8317/9017 [03:12<00:15, 44.51it/s]
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8322/9017 [03:12<00:15, 45.52it/s]
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8327/9017 [03:12<00:15, 44.89it/s]
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8333/9017 [03:12<00:14, 46.64it/s]
 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 8338/9017 [03:12<00:15, 44.90it/s]
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8343/9017 [03:12<00:14, 45.29it/s]
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8349/9017 [03:12<00:13, 47.85it/s]
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8354/9017 [03:13<00:14, 46.02it/s]
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8359/9017 [03:13<00:22, 29.88it/s]
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8364/9017 [03:13<00:19, 33.08it/s]
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8369/9017 [03:13<00:18, 34.65it/s]
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8374/9017 [03:13<00:17, 37.16it/s]
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8379/9017 [03:13<00:17, 36.28it/s]
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8384/9017 [03:14<00:16, 37.97it/s]
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8390/9017 [03:14<00:14, 42.82it/s]
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8395/9017 [03:14<00:14, 43.33it/s]
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8401/9017 [03:14<00:13, 45.16it/s]
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8406/9017 [03:14<00:14, 42.90it/s]
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8412/9017 [03:14<00:13, 45.13it/s]
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8418/9017 [03:14<00:13, 45.64it/s]
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8424/9017 [03:14<00:12, 48.68it/s]
 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8429/9017 [03:14<00:12, 47.88it/s]
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8435/9017 [03:15<00:12, 48.04it/s]
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8440/9017 [03:15<00:12, 46.79it/s]
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8445/9017 [03:15<00:12, 45.45it/s]
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 8450/9017 [03:15<00:12, 43.95it/s]
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8457/9017 [03:15<00:11, 49.06it/s]
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8462/9017 [03:15<00:11, 48.33it/s]
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8468/9017 [03:15<00:11, 49.52it/s]
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8474/9017 [03:15<00:11, 49.12it/s]
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8479/9017 [03:15<00:10, 49.33it/s]
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8485/9017 [03:16<00:10, 50.56it/s]
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8491/9017 [03:16<00:10, 48.53it/s]
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8497/9017 [03:16<00:10, 48.45it/s]
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8502/9017 [03:16<00:10, 48.81it/s]
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8507/9017 [03:16<00:10, 47.21it/s]
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8513/9017 [03:16<00:10, 48.56it/s]
 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8520/9017 [03:16<00:09, 51.92it/s]
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8526/9017 [03:16<00:09, 54.01it/s]
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8532/9017 [03:17<00:09, 52.24it/s]
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8538/9017 [03:17<00:10, 44.34it/s]
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8543/9017 [03:17<00:10, 44.02it/s]
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8548/9017 [03:17<00:12, 38.96it/s]
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8553/9017 [03:17<00:11, 40.57it/s]
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8558/9017 [03:17<00:11, 41.60it/s]
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 8563/9017 [03:17<00:10, 42.56it/s]
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8568/9017 [03:17<00:10, 42.53it/s]
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8573/9017 [03:18<00:10, 44.02it/s]
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8578/9017 [03:18<00:09, 44.40it/s]
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8583/9017 [03:18<00:15, 28.37it/s]
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8589/9017 [03:18<00:12, 33.78it/s]
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8594/9017 [03:18<00:11, 36.98it/s]
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8599/9017 [03:18<00:10, 38.20it/s]
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8604/9017 [03:19<00:12, 34.19it/s]
 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8608/9017 [03:19<00:11, 34.52it/s]
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8614/9017 [03:19<00:10, 39.87it/s]
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8619/9017 [03:19<00:09, 41.95it/s]
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8626/9017 [03:19<00:08, 45.52it/s]
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8631/9017 [03:19<00:10, 36.79it/s]
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8636/9017 [03:19<00:09, 39.64it/s]
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8641/9017 [03:19<00:09, 41.08it/s]
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8646/9017 [03:20<00:09, 39.61it/s]
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8652/9017 [03:20<00:08, 43.90it/s]
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8658/9017 [03:20<00:07, 45.81it/s]
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8664/9017 [03:20<00:07, 47.73it/s]
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8670/9017 [03:20<00:07, 49.44it/s]
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 8676/9017 [03:20<00:06, 52.05it/s]
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8682/9017 [03:20<00:06, 50.44it/s]
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8688/9017 [03:20<00:07, 46.11it/s]
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8694/9017 [03:20<00:06, 49.55it/s]
 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8700/9017 [03:21<00:06, 50.28it/s]
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8706/9017 [03:21<00:06, 51.00it/s]
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8712/9017 [03:21<00:05, 51.35it/s]
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8718/9017 [03:21<00:05, 50.25it/s]
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8724/9017 [03:21<00:05, 49.31it/s]
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8729/9017 [03:21<00:05, 49.18it/s]
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8734/9017 [03:21<00:05, 48.78it/s]
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8740/9017 [03:21<00:05, 49.43it/s]
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8746/9017 [03:22<00:05, 49.00it/s]
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8751/9017 [03:22<00:05, 49.13it/s]
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8756/9017 [03:22<00:05, 48.59it/s]
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8761/9017 [03:22<00:05, 43.13it/s]
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8768/9017 [03:22<00:05, 49.59it/s]
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8774/9017 [03:22<00:04, 49.79it/s]
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8780/9017 [03:22<00:04, 47.56it/s]
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8785/9017 [03:22<00:04, 47.80it/s]
 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 8791/9017 [03:22<00:04, 48.56it/s]
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8797/9017 [03:23<00:04, 50.28it/s]
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8803/9017 [03:23<00:04, 51.13it/s]
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8809/9017 [03:23<00:04, 51.03it/s]
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8815/9017 [03:23<00:06, 30.98it/s]
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8820/9017 [03:23<00:05, 34.26it/s]
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8825/9017 [03:23<00:05, 34.31it/s]
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8830/9017 [03:24<00:05, 36.95it/s]
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8835/9017 [03:24<00:04, 38.72it/s]
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8840/9017 [03:24<00:04, 41.43it/s]
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8845/9017 [03:24<00:04, 42.00it/s]
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8850/9017 [03:24<00:04, 40.77it/s]
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8855/9017 [03:24<00:03, 40.93it/s]
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8862/9017 [03:24<00:03, 47.43it/s]
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8867/9017 [03:24<00:03, 46.07it/s]
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8873/9017 [03:24<00:02, 48.23it/s]
 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8878/9017 [03:25<00:02, 47.23it/s]
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8883/9017 [03:25<00:03, 43.83it/s]
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8888/9017 [03:25<00:02, 44.72it/s]
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8893/9017 [03:25<00:02, 46.06it/s]
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8898/9017 [03:25<00:02, 45.76it/s]
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 8904/9017 [03:25<00:02, 49.06it/s]
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8910/9017 [03:25<00:02, 49.26it/s]
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8916/9017 [03:25<00:02, 50.31it/s]
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8922/9017 [03:25<00:02, 47.10it/s]
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8927/9017 [03:26<00:01, 46.15it/s]
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8932/9017 [03:26<00:01, 42.76it/s]
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8937/9017 [03:26<00:01, 40.82it/s]
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8942/9017 [03:26<00:01, 41.51it/s]
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8947/9017 [03:26<00:01, 42.14it/s]
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8952/9017 [03:26<00:01, 42.04it/s]
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8957/9017 [03:26<00:01, 43.44it/s]
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8962/9017 [03:26<00:01, 44.05it/s]
 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8967/9017 [03:27<00:01, 45.47it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8972/9017 [03:27<00:01, 44.04it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8977/9017 [03:27<00:00, 44.12it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8982/9017 [03:27<00:00, 44.19it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8987/9017 [03:27<00:00, 44.57it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8992/9017 [03:27<00:00, 43.38it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 8998/9017 [03:27<00:00, 46.97it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 9003/9017 [03:27<00:00, 46.10it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 9008/9017 [03:27<00:00, 42.46it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 9013/9017 [03:28<00:00, 39.52it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9017/9017 [03:28<00:00, 43.30it/s]
[train samples]: Loading 1071915 images from /shared/rc/llm-gen-agent/mhu/simlingo_dataset/database/simlingo_extracted for bucket all
Total amount of routes: 18034
Crashed routes: 704
Perfect routes: 8313
Fail reasons: {'route_crashed': 694, 'no_results.json': 10}
[Bucket: all] Scanning routes in /shared/rc/llm-gen-agent/mhu/simlingo_dataset/database/simlingo_extracted...
Found 9109 routes in /shared/rc/llm-gen-agent/mhu/simlingo_dataset/database/simlingo_extracted
Use 92 routes.

  0%|          | 0/92 [00:00<?, ?it/s]
 39%|‚ñà‚ñà‚ñà‚ñâ      | 36/92 [00:00<00:00, 359.76it/s]
 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 72/92 [00:00<00:00, 261.74it/s]
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 92/92 [00:00<00:00, 274.52it/s]
[val samples]: Loading 10407 images from /shared/rc/llm-gen-agent/mhu/simlingo_dataset/database/simlingo_extracted for bucket all
Total amount of routes: 184
Crashed routes: 10
Perfect routes: 82
Fail reasons: {'route_crashed': 9, 'no_results.json': 1}
Num samples: 1071915
Num samples all: 1071915

Sanity Checking: |          | 0/? [00:00<?, ?it/s]
Sanity Checking:   0%|          | 0/2 [00:00<?, ?it/s]
Sanity Checking DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]
============================================================
[Input Before LLM] - Global Step 0
============================================================
  Adaptor embeddings shape: torch.Size([4, 577, 896])
  Input embeddings shape: torch.Size([4, 577, 896])
  Attention mask shape: torch.Size([4, 577])
  Input dtype: torch.float16
  Adaptor embeddings range: [-34.8125, 31.8750]
  Input embeddings range: [-34.8125, 31.8750]
  Input embeddings mean: 0.0110, std: 0.9009
  Language inputs shape: torch.Size([4, 547, 896])

============================================================
Global Step 0
============================================================

[Losses]
  language_loss: 0.095398 (shape: torch.Size([4, 546]), count: 28)
  route_loss: 15.828125 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 8.812500 (shape: torch.Size([4, 10]), count: 40)
Validation visualization!
visualise_training_examples cannot open resource

Sanity Checking DataLoader 0:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [00:29<00:29,  0.03it/s]
============================================================
[Input Before LLM] - Global Step 0
============================================================
  Adaptor embeddings shape: torch.Size([4, 580, 896])
  Input embeddings shape: torch.Size([4, 580, 896])
  Attention mask shape: torch.Size([4, 580])
  Input dtype: torch.float16
  Adaptor embeddings range: [-43.9375, 34.2500]
  Input embeddings range: [-43.9375, 34.2500]
  Input embeddings mean: 0.0099, std: 0.8301
  Language inputs shape: torch.Size([4, 550, 896])

============================================================
Global Step 0
============================================================

[Losses]
  language_loss: 0.095520 (shape: torch.Size([4, 549]), count: 28)
  route_loss: 16.218750 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 5.546875 (shape: torch.Size([4, 10]), count: 40)
Validation visualization!
visualise_training_examples cannot open resource

Sanity Checking DataLoader 0: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:54<00:00,  0.04it/s]
                                                                           

Training: |          | 0/? [00:00<?, ?it/s]
Training:   0%|          | 0/267978 [00:00<?, ?it/s]
Epoch 0:   0%|          | 0/267978 [00:00<?, ?it/s] 
============================================================
[Input Before LLM] - Global Step 0
============================================================
  Adaptor embeddings shape: torch.Size([4, 592, 896])
  Input embeddings shape: torch.Size([4, 592, 896])
  Attention mask shape: torch.Size([4, 592])
  Input dtype: torch.float16
  Adaptor embeddings range: [-7.3398, 9.4219]
  Input embeddings range: [-7.3398, 9.4219]
  Input embeddings mean: 0.0099, std: 0.8145
  Language inputs shape: torch.Size([4, 562, 896])

============================================================
Global Step 0
============================================================

[Losses]
  language_loss: 0.101440 (shape: torch.Size([4, 561]), count: 28)
  route_loss: 15.890625 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 11.984375 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 1/267978 [00:02<172:14:19,  0.43it/s]
Epoch 0:   0%|          | 1/267978 [00:02<172:18:15,  0.43it/s, v_num=full, train/loss_step=36.00]
Epoch 0:   0%|          | 2/267978 [00:03<112:33:31,  0.66it/s, v_num=full, train/loss_step=36.00]
Epoch 0:   0%|          | 2/267978 [00:03<113:17:56,  0.66it/s, v_num=full, train/loss_step=39.20]
Epoch 0:   0%|          | 3/267978 [00:03<91:00:41,  0.82it/s, v_num=full, train/loss_step=39.20] 
Epoch 0:   0%|          | 3/267978 [00:03<91:02:13,  0.82it/s, v_num=full, train/loss_step=27.60]
Epoch 0:   0%|          | 4/267978 [00:04<79:44:51,  0.93it/s, v_num=full, train/loss_step=27.60]
Epoch 0:   0%|          | 4/267978 [00:04<79:45:57,  0.93it/s, v_num=full, train/loss_step=35.20]
Epoch 0:   0%|          | 5/267978 [00:04<72:50:34,  1.02it/s, v_num=full, train/loss_step=35.20]
Epoch 0:   0%|          | 5/267978 [00:04<72:51:26,  1.02it/s, v_num=full, train/loss_step=36.10]
Epoch 0:   0%|          | 6/267978 [00:05<68:23:32,  1.09it/s, v_num=full, train/loss_step=36.10]
Epoch 0:   0%|          | 6/267978 [00:05<68:24:14,  1.09it/s, v_num=full, train/loss_step=32.90]
Epoch 0:   0%|          | 7/267978 [00:06<65:13:36,  1.14it/s, v_num=full, train/loss_step=32.90]
Epoch 0:   0%|          | 7/267978 [00:06<65:14:22,  1.14it/s, v_num=full, train/loss_step=28.70]
Epoch 0:   0%|          | 8/267978 [00:06<62:57:48,  1.18it/s, v_num=full, train/loss_step=28.70]
Epoch 0:   0%|          | 8/267978 [00:06<62:58:25,  1.18it/s, v_num=full, train/loss_step=32.20]
Epoch 0:   0%|          | 9/267978 [00:07<61:06:44,  1.22it/s, v_num=full, train/loss_step=32.20]
Epoch 0:   0%|          | 9/267978 [00:07<61:07:13,  1.22it/s, v_num=full, train/loss_step=29.40]
Epoch 0:   0%|          | 10/267978 [00:08<59:37:35,  1.25it/s, v_num=full, train/loss_step=29.40]
Epoch 0:   0%|          | 10/267978 [00:08<59:38:01,  1.25it/s, v_num=full, train/loss_step=29.20]
============================================================
Global Step 10
============================================================

[Losses]
  language_loss: 0.091919 (shape: torch.Size([4, 561]), count: 28)
  route_loss: 11.812500 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 10.367188 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 11/267978 [00:08<58:26:47,  1.27it/s, v_num=full, train/loss_step=29.20]
Epoch 0:   0%|          | 11/267978 [00:08<58:27:13,  1.27it/s, v_num=full, train/loss_step=29.50]
Epoch 0:   0%|          | 12/267978 [00:09<57:27:35,  1.30it/s, v_num=full, train/loss_step=29.50]
Epoch 0:   0%|          | 12/267978 [00:09<57:27:58,  1.30it/s, v_num=full, train/loss_step=24.80]
Epoch 0:   0%|          | 13/267978 [00:09<56:37:23,  1.31it/s, v_num=full, train/loss_step=24.80]
Epoch 0:   0%|          | 13/267978 [00:09<56:37:43,  1.31it/s, v_num=full, train/loss_step=24.30]
Epoch 0:   0%|          | 14/267978 [00:10<55:56:11,  1.33it/s, v_num=full, train/loss_step=24.30]
Epoch 0:   0%|          | 14/267978 [00:10<55:56:32,  1.33it/s, v_num=full, train/loss_step=24.10]
Epoch 0:   0%|          | 15/267978 [00:11<55:18:20,  1.35it/s, v_num=full, train/loss_step=24.10]
Epoch 0:   0%|          | 15/267978 [00:11<55:18:39,  1.35it/s, v_num=full, train/loss_step=25.00]
Epoch 0:   0%|          | 16/267978 [00:11<54:50:52,  1.36it/s, v_num=full, train/loss_step=25.00]
Epoch 0:   0%|          | 16/267978 [00:11<54:51:11,  1.36it/s, v_num=full, train/loss_step=24.80]
Epoch 0:   0%|          | 17/267978 [00:12<54:20:08,  1.37it/s, v_num=full, train/loss_step=24.80]
Epoch 0:   0%|          | 17/267978 [00:12<54:20:24,  1.37it/s, v_num=full, train/loss_step=23.50]
Epoch 0:   0%|          | 18/267978 [00:13<53:49:50,  1.38it/s, v_num=full, train/loss_step=23.50]
Epoch 0:   0%|          | 18/267978 [00:13<53:50:03,  1.38it/s, v_num=full, train/loss_step=19.90]
Epoch 0:   0%|          | 19/267978 [00:13<53:28:52,  1.39it/s, v_num=full, train/loss_step=19.90]
Epoch 0:   0%|          | 19/267978 [00:13<53:29:06,  1.39it/s, v_num=full, train/loss_step=25.80]
Epoch 0:   0%|          | 20/267978 [00:14<53:07:37,  1.40it/s, v_num=full, train/loss_step=25.80]
Epoch 0:   0%|          | 20/267978 [00:14<53:07:51,  1.40it/s, v_num=full, train/loss_step=19.80]
============================================================
Global Step 20
============================================================

[Losses]
  language_loss: 0.079651 (shape: torch.Size([4, 562]), count: 28)
  route_loss: 8.289062 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 11.773438 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 21/267978 [00:14<52:52:37,  1.41it/s, v_num=full, train/loss_step=19.80]
Epoch 0:   0%|          | 21/267978 [00:14<52:52:49,  1.41it/s, v_num=full, train/loss_step=26.50]
Epoch 0:   0%|          | 22/267978 [00:15<52:39:59,  1.41it/s, v_num=full, train/loss_step=26.50]
Epoch 0:   0%|          | 22/267978 [00:15<52:40:09,  1.41it/s, v_num=full, train/loss_step=18.20]
Epoch 0:   0%|          | 23/267978 [00:16<52:26:36,  1.42it/s, v_num=full, train/loss_step=18.20]
Epoch 0:   0%|          | 23/267978 [00:16<52:26:48,  1.42it/s, v_num=full, train/loss_step=23.30]
Epoch 0:   0%|          | 24/267978 [00:16<52:17:29,  1.42it/s, v_num=full, train/loss_step=23.30]
Epoch 0:   0%|          | 24/267978 [00:16<52:17:41,  1.42it/s, v_num=full, train/loss_step=24.50]
Epoch 0:   0%|          | 25/267978 [00:17<52:06:36,  1.43it/s, v_num=full, train/loss_step=24.50]
Epoch 0:   0%|          | 25/267978 [00:17<52:06:49,  1.43it/s, v_num=full, train/loss_step=17.70]
Epoch 0:   0%|          | 26/267978 [00:18<51:55:23,  1.43it/s, v_num=full, train/loss_step=17.70]
Epoch 0:   0%|          | 26/267978 [00:18<51:55:33,  1.43it/s, v_num=full, train/loss_step=17.90]
Epoch 0:   0%|          | 27/267978 [00:18<51:44:07,  1.44it/s, v_num=full, train/loss_step=17.90]
Epoch 0:   0%|          | 27/267978 [00:18<51:44:16,  1.44it/s, v_num=full, train/loss_step=19.70]
Epoch 0:   0%|          | 28/267978 [00:19<51:31:40,  1.44it/s, v_num=full, train/loss_step=19.70]
Epoch 0:   0%|          | 28/267978 [00:19<51:31:50,  1.44it/s, v_num=full, train/loss_step=20.00]
Epoch 0:   0%|          | 29/267978 [00:20<51:22:07,  1.45it/s, v_num=full, train/loss_step=20.00]
Epoch 0:   0%|          | 29/267978 [00:20<51:22:16,  1.45it/s, v_num=full, train/loss_step=20.60]
Epoch 0:   0%|          | 30/267978 [00:20<51:13:47,  1.45it/s, v_num=full, train/loss_step=20.60]
Epoch 0:   0%|          | 30/267978 [00:20<51:13:57,  1.45it/s, v_num=full, train/loss_step=19.60]
============================================================
Global Step 30
============================================================

[Losses]
  language_loss: 0.069153 (shape: torch.Size([4, 553]), count: 28)
  route_loss: 4.863281 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 7.492188 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 31/267978 [00:21<51:05:38,  1.46it/s, v_num=full, train/loss_step=19.60]
Epoch 0:   0%|          | 31/267978 [00:21<51:05:47,  1.46it/s, v_num=full, train/loss_step=17.80]
Epoch 0:   0%|          | 32/267978 [00:21<50:59:05,  1.46it/s, v_num=full, train/loss_step=17.80]
Epoch 0:   0%|          | 32/267978 [00:21<50:59:14,  1.46it/s, v_num=full, train/loss_step=18.60]
Epoch 0:   0%|          | 33/267978 [00:22<50:51:13,  1.46it/s, v_num=full, train/loss_step=18.60]
Epoch 0:   0%|          | 33/267978 [00:22<50:51:22,  1.46it/s, v_num=full, train/loss_step=16.10]
Epoch 0:   0%|          | 34/267978 [00:23<50:43:06,  1.47it/s, v_num=full, train/loss_step=16.10]
Epoch 0:   0%|          | 34/267978 [00:23<50:43:14,  1.47it/s, v_num=full, train/loss_step=18.80]
Epoch 0:   0%|          | 35/267978 [00:23<50:35:08,  1.47it/s, v_num=full, train/loss_step=18.80]
Epoch 0:   0%|          | 35/267978 [00:23<50:35:16,  1.47it/s, v_num=full, train/loss_step=15.60]
Epoch 0:   0%|          | 36/267978 [00:24<50:30:43,  1.47it/s, v_num=full, train/loss_step=15.60]
Epoch 0:   0%|          | 36/267978 [00:24<50:30:52,  1.47it/s, v_num=full, train/loss_step=13.90]
Epoch 0:   0%|          | 37/267978 [00:25<50:24:39,  1.48it/s, v_num=full, train/loss_step=13.90]
Epoch 0:   0%|          | 37/267978 [00:25<50:24:46,  1.48it/s, v_num=full, train/loss_step=21.50]
Epoch 0:   0%|          | 38/267978 [00:25<50:17:49,  1.48it/s, v_num=full, train/loss_step=21.50]
Epoch 0:   0%|          | 38/267978 [00:25<50:17:56,  1.48it/s, v_num=full, train/loss_step=17.60]
Epoch 0:   0%|          | 39/267978 [00:26<50:11:17,  1.48it/s, v_num=full, train/loss_step=17.60]
Epoch 0:   0%|          | 39/267978 [00:26<50:11:24,  1.48it/s, v_num=full, train/loss_step=11.70]
Epoch 0:   0%|          | 40/267978 [00:26<50:05:23,  1.49it/s, v_num=full, train/loss_step=11.70]
Epoch 0:   0%|          | 40/267978 [00:26<50:05:29,  1.49it/s, v_num=full, train/loss_step=15.90]
============================================================
Global Step 40
============================================================

[Losses]
  language_loss: 0.062347 (shape: torch.Size([4, 546]), count: 28)
  route_loss: 2.216797 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.345703 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 41/267978 [00:27<50:00:24,  1.49it/s, v_num=full, train/loss_step=15.90]
Epoch 0:   0%|          | 41/267978 [00:27<50:00:30,  1.49it/s, v_num=full, train/loss_step=10.40]
Epoch 0:   0%|          | 42/267978 [00:28<49:56:02,  1.49it/s, v_num=full, train/loss_step=10.40]
Epoch 0:   0%|          | 42/267978 [00:28<49:56:09,  1.49it/s, v_num=full, train/loss_step=12.90]
Epoch 0:   0%|          | 43/267978 [00:28<49:50:48,  1.49it/s, v_num=full, train/loss_step=12.90]
Epoch 0:   0%|          | 43/267978 [00:28<49:50:54,  1.49it/s, v_num=full, train/loss_step=15.70]
Epoch 0:   0%|          | 44/267978 [00:29<49:48:58,  1.49it/s, v_num=full, train/loss_step=15.70]
Epoch 0:   0%|          | 44/267978 [00:29<49:49:05,  1.49it/s, v_num=full, train/loss_step=15.00]
Epoch 0:   0%|          | 45/267978 [00:30<49:46:52,  1.50it/s, v_num=full, train/loss_step=15.00]
Epoch 0:   0%|          | 45/267978 [00:30<49:46:59,  1.49it/s, v_num=full, train/loss_step=9.280]
Epoch 0:   0%|          | 46/267978 [00:30<49:42:59,  1.50it/s, v_num=full, train/loss_step=9.280]
Epoch 0:   0%|          | 46/267978 [00:30<49:43:05,  1.50it/s, v_num=full, train/loss_step=17.50]
Epoch 0:   0%|          | 47/267978 [00:31<49:39:50,  1.50it/s, v_num=full, train/loss_step=17.50]
Epoch 0:   0%|          | 47/267978 [00:31<49:39:56,  1.50it/s, v_num=full, train/loss_step=11.80]
Epoch 0:   0%|          | 48/267978 [00:32<49:37:35,  1.50it/s, v_num=full, train/loss_step=11.80]
Epoch 0:   0%|          | 48/267978 [00:32<49:37:41,  1.50it/s, v_num=full, train/loss_step=11.40]
Epoch 0:   0%|          | 49/267978 [00:32<49:33:49,  1.50it/s, v_num=full, train/loss_step=11.40]
Epoch 0:   0%|          | 49/267978 [00:32<49:33:55,  1.50it/s, v_num=full, train/loss_step=13.60]
Epoch 0:   0%|          | 50/267978 [00:33<49:31:45,  1.50it/s, v_num=full, train/loss_step=13.60]
Epoch 0:   0%|          | 50/267978 [00:33<49:31:50,  1.50it/s, v_num=full, train/loss_step=16.10]
============================================================
Global Step 50
============================================================

[Losses]
  language_loss: 0.050049 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 1.809570 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 5.757812 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 51/267978 [00:33<49:28:39,  1.50it/s, v_num=full, train/loss_step=16.10]
Epoch 0:   0%|          | 51/267978 [00:33<49:28:45,  1.50it/s, v_num=full, train/loss_step=11.50]
Epoch 0:   0%|          | 52/267978 [00:34<49:26:06,  1.51it/s, v_num=full, train/loss_step=11.50]
Epoch 0:   0%|          | 52/267978 [00:34<49:26:11,  1.51it/s, v_num=full, train/loss_step=10.50]
Epoch 0:   0%|          | 53/267978 [00:35<49:24:20,  1.51it/s, v_num=full, train/loss_step=10.50]
Epoch 0:   0%|          | 53/267978 [00:35<49:24:25,  1.51it/s, v_num=full, train/loss_step=9.690]
Epoch 0:   0%|          | 54/267978 [00:35<49:22:00,  1.51it/s, v_num=full, train/loss_step=9.690]
Epoch 0:   0%|          | 54/267978 [00:35<49:22:06,  1.51it/s, v_num=full, train/loss_step=13.70]
Epoch 0:   0%|          | 55/267978 [00:36<49:20:25,  1.51it/s, v_num=full, train/loss_step=13.70]
Epoch 0:   0%|          | 55/267978 [00:36<49:20:30,  1.51it/s, v_num=full, train/loss_step=11.60]
Epoch 0:   0%|          | 56/267978 [00:37<49:17:31,  1.51it/s, v_num=full, train/loss_step=11.60]
Epoch 0:   0%|          | 56/267978 [00:37<49:17:36,  1.51it/s, v_num=full, train/loss_step=12.50]
Epoch 0:   0%|          | 57/267978 [00:37<49:14:19,  1.51it/s, v_num=full, train/loss_step=12.50]
Epoch 0:   0%|          | 57/267978 [00:37<49:14:23,  1.51it/s, v_num=full, train/loss_step=15.00]
Epoch 0:   0%|          | 58/267978 [00:38<49:11:06,  1.51it/s, v_num=full, train/loss_step=15.00]
Epoch 0:   0%|          | 58/267978 [00:38<49:11:11,  1.51it/s, v_num=full, train/loss_step=12.50]
Epoch 0:   0%|          | 59/267978 [00:38<49:08:34,  1.51it/s, v_num=full, train/loss_step=12.50]
Epoch 0:   0%|          | 59/267978 [00:38<49:08:39,  1.51it/s, v_num=full, train/loss_step=13.20]
Epoch 0:   0%|          | 60/267978 [00:39<49:05:49,  1.52it/s, v_num=full, train/loss_step=13.20]
Epoch 0:   0%|          | 60/267978 [00:39<49:05:53,  1.52it/s, v_num=full, train/loss_step=12.70]
============================================================
Global Step 60
============================================================

[Losses]
  language_loss: 0.045074 (shape: torch.Size([4, 553]), count: 28)
  route_loss: 2.187500 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 5.101562 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 61/267978 [00:40<49:03:49,  1.52it/s, v_num=full, train/loss_step=12.70]
Epoch 0:   0%|          | 61/267978 [00:40<49:03:54,  1.52it/s, v_num=full, train/loss_step=10.90]
Epoch 0:   0%|          | 62/267978 [00:40<49:01:30,  1.52it/s, v_num=full, train/loss_step=10.90]
Epoch 0:   0%|          | 62/267978 [00:40<49:01:34,  1.52it/s, v_num=full, train/loss_step=14.00]
Epoch 0:   0%|          | 63/267978 [00:41<48:59:29,  1.52it/s, v_num=full, train/loss_step=14.00]
Epoch 0:   0%|          | 63/267978 [00:41<48:59:34,  1.52it/s, v_num=full, train/loss_step=15.20]
Epoch 0:   0%|          | 64/267978 [00:42<48:58:06,  1.52it/s, v_num=full, train/loss_step=15.20]
Epoch 0:   0%|          | 64/267978 [00:42<48:58:10,  1.52it/s, v_num=full, train/loss_step=11.10]
Epoch 0:   0%|          | 65/267978 [00:42<48:57:41,  1.52it/s, v_num=full, train/loss_step=11.10]
Epoch 0:   0%|          | 65/267978 [00:42<48:57:45,  1.52it/s, v_num=full, train/loss_step=10.30]
Epoch 0:   0%|          | 66/267978 [00:43<48:55:10,  1.52it/s, v_num=full, train/loss_step=10.30]
Epoch 0:   0%|          | 66/267978 [00:43<48:55:30,  1.52it/s, v_num=full, train/loss_step=11.60]
Epoch 0:   0%|          | 67/267978 [00:44<48:53:56,  1.52it/s, v_num=full, train/loss_step=11.60]
Epoch 0:   0%|          | 67/267978 [00:44<48:54:03,  1.52it/s, v_num=full, train/loss_step=14.50]
Epoch 0:   0%|          | 68/267978 [00:44<48:51:06,  1.52it/s, v_num=full, train/loss_step=14.50]
Epoch 0:   0%|          | 68/267978 [00:44<48:51:10,  1.52it/s, v_num=full, train/loss_step=8.570]
Epoch 0:   0%|          | 69/267978 [00:45<48:48:44,  1.52it/s, v_num=full, train/loss_step=8.570]
Epoch 0:   0%|          | 69/267978 [00:45<48:48:48,  1.52it/s, v_num=full, train/loss_step=13.00]
Epoch 0:   0%|          | 70/267978 [00:45<48:46:53,  1.53it/s, v_num=full, train/loss_step=13.00]
Epoch 0:   0%|          | 70/267978 [00:45<48:46:57,  1.53it/s, v_num=full, train/loss_step=10.00]
============================================================
Global Step 70
============================================================

[Losses]
  language_loss: 0.034485 (shape: torch.Size([4, 556]), count: 28)
  route_loss: 2.638672 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 6.539062 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 71/267978 [00:46<48:44:21,  1.53it/s, v_num=full, train/loss_step=10.00]
Epoch 0:   0%|          | 71/267978 [00:46<48:44:29,  1.53it/s, v_num=full, train/loss_step=11.90]
Epoch 0:   0%|          | 72/267978 [00:47<48:43:10,  1.53it/s, v_num=full, train/loss_step=11.90]
Epoch 0:   0%|          | 72/267978 [00:47<48:43:14,  1.53it/s, v_num=full, train/loss_step=11.90]
Epoch 0:   0%|          | 73/267978 [00:47<48:40:17,  1.53it/s, v_num=full, train/loss_step=11.90]
Epoch 0:   0%|          | 73/267978 [00:47<48:40:21,  1.53it/s, v_num=full, train/loss_step=9.170]
Epoch 0:   0%|          | 74/267978 [00:48<48:38:25,  1.53it/s, v_num=full, train/loss_step=9.170]
Epoch 0:   0%|          | 74/267978 [00:48<48:38:29,  1.53it/s, v_num=full, train/loss_step=9.560]
Epoch 0:   0%|          | 75/267978 [00:48<48:36:40,  1.53it/s, v_num=full, train/loss_step=9.560]
Epoch 0:   0%|          | 75/267978 [00:48<48:36:44,  1.53it/s, v_num=full, train/loss_step=13.90]
Epoch 0:   0%|          | 76/267978 [00:49<48:35:13,  1.53it/s, v_num=full, train/loss_step=13.90]
Epoch 0:   0%|          | 76/267978 [00:49<48:35:18,  1.53it/s, v_num=full, train/loss_step=9.930]
Epoch 0:   0%|          | 77/267978 [00:50<48:33:35,  1.53it/s, v_num=full, train/loss_step=9.930]
Epoch 0:   0%|          | 77/267978 [00:50<48:33:38,  1.53it/s, v_num=full, train/loss_step=9.630]
Epoch 0:   0%|          | 78/267978 [00:50<48:32:28,  1.53it/s, v_num=full, train/loss_step=9.630]
Epoch 0:   0%|          | 78/267978 [00:50<48:32:31,  1.53it/s, v_num=full, train/loss_step=7.060]
Epoch 0:   0%|          | 79/267978 [00:51<48:30:55,  1.53it/s, v_num=full, train/loss_step=7.060]
Epoch 0:   0%|          | 79/267978 [00:53<50:47:01,  1.47it/s, v_num=full, train/loss_step=10.60]
Epoch 0:   0%|          | 80/267978 [00:57<53:05:30,  1.40it/s, v_num=full, train/loss_step=10.60]
Epoch 0:   0%|          | 80/267978 [00:57<53:05:33,  1.40it/s, v_num=full, train/loss_step=14.50]
============================================================
Global Step 80
============================================================

[Losses]
  language_loss: 0.029892 (shape: torch.Size([4, 546]), count: 28)
  route_loss: 2.476562 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 6.582031 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 81/267978 [00:57<53:00:48,  1.40it/s, v_num=full, train/loss_step=14.50]
Epoch 0:   0%|          | 81/267978 [00:57<53:00:51,  1.40it/s, v_num=full, train/loss_step=11.40]
Epoch 0:   0%|          | 82/267978 [00:58<52:56:02,  1.41it/s, v_num=full, train/loss_step=11.40]
Epoch 0:   0%|          | 82/267978 [00:58<52:56:05,  1.41it/s, v_num=full, train/loss_step=16.70]
Epoch 0:   0%|          | 83/267978 [00:58<52:50:51,  1.41it/s, v_num=full, train/loss_step=16.70]
Epoch 0:   0%|          | 83/267978 [00:58<52:50:54,  1.41it/s, v_num=full, train/loss_step=10.60]
Epoch 0:   0%|          | 84/267978 [00:59<52:45:36,  1.41it/s, v_num=full, train/loss_step=10.60]
Epoch 0:   0%|          | 84/267978 [00:59<52:45:40,  1.41it/s, v_num=full, train/loss_step=12.30]
Epoch 0:   0%|          | 85/267978 [01:00<52:40:26,  1.41it/s, v_num=full, train/loss_step=12.30]
Epoch 0:   0%|          | 85/267978 [01:00<52:40:29,  1.41it/s, v_num=full, train/loss_step=18.40]
Epoch 0:   0%|          | 86/267978 [01:00<52:35:11,  1.42it/s, v_num=full, train/loss_step=18.40]
Epoch 0:   0%|          | 86/267978 [01:00<52:35:13,  1.42it/s, v_num=full, train/loss_step=11.90]
Epoch 0:   0%|          | 87/267978 [01:01<52:28:56,  1.42it/s, v_num=full, train/loss_step=11.90]
Epoch 0:   0%|          | 87/267978 [01:01<52:28:59,  1.42it/s, v_num=full, train/loss_step=10.70]
Epoch 0:   0%|          | 88/267978 [01:01<52:23:03,  1.42it/s, v_num=full, train/loss_step=10.70]
Epoch 0:   0%|          | 88/267978 [01:01<52:23:06,  1.42it/s, v_num=full, train/loss_step=12.40]
Epoch 0:   0%|          | 89/267978 [01:02<52:16:58,  1.42it/s, v_num=full, train/loss_step=12.40]
Epoch 0:   0%|          | 89/267978 [01:02<52:17:00,  1.42it/s, v_num=full, train/loss_step=10.10]
Epoch 0:   0%|          | 90/267978 [01:03<52:10:56,  1.43it/s, v_num=full, train/loss_step=10.10]
Epoch 0:   0%|          | 90/267978 [01:03<52:10:58,  1.43it/s, v_num=full, train/loss_step=6.430]
============================================================
Global Step 90
============================================================

[Losses]
  language_loss: 0.026779 (shape: torch.Size([4, 552]), count: 28)
  route_loss: 1.915039 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 7.011719 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 91/267978 [01:03<52:04:43,  1.43it/s, v_num=full, train/loss_step=6.430]
Epoch 0:   0%|          | 91/267978 [01:03<52:04:45,  1.43it/s, v_num=full, train/loss_step=11.00]
Epoch 0:   0%|          | 92/267978 [01:04<51:59:08,  1.43it/s, v_num=full, train/loss_step=11.00]
Epoch 0:   0%|          | 92/267978 [01:04<51:59:11,  1.43it/s, v_num=full, train/loss_step=10.80]
Epoch 0:   0%|          | 93/267978 [01:04<51:52:45,  1.43it/s, v_num=full, train/loss_step=10.80]
Epoch 0:   0%|          | 93/267978 [01:04<51:52:47,  1.43it/s, v_num=full, train/loss_step=10.40]
Epoch 0:   0%|          | 94/267978 [01:05<51:46:15,  1.44it/s, v_num=full, train/loss_step=10.40]
Epoch 0:   0%|          | 94/267978 [01:05<51:46:18,  1.44it/s, v_num=full, train/loss_step=8.000]
Epoch 0:   0%|          | 95/267978 [01:05<51:40:03,  1.44it/s, v_num=full, train/loss_step=8.000]
Epoch 0:   0%|          | 95/267978 [01:05<51:40:05,  1.44it/s, v_num=full, train/loss_step=10.10]
Epoch 0:   0%|          | 96/267978 [01:06<51:33:50,  1.44it/s, v_num=full, train/loss_step=10.10]
Epoch 0:   0%|          | 96/267978 [01:06<51:33:52,  1.44it/s, v_num=full, train/loss_step=11.30]
Epoch 0:   0%|          | 97/267978 [01:07<51:27:56,  1.45it/s, v_num=full, train/loss_step=11.30]
Epoch 0:   0%|          | 97/267978 [01:07<51:27:58,  1.45it/s, v_num=full, train/loss_step=8.060]
Epoch 0:   0%|          | 98/267978 [01:07<51:22:17,  1.45it/s, v_num=full, train/loss_step=8.060]
Epoch 0:   0%|          | 98/267978 [01:07<51:22:19,  1.45it/s, v_num=full, train/loss_step=10.80]
Epoch 0:   0%|          | 99/267978 [01:08<51:16:37,  1.45it/s, v_num=full, train/loss_step=10.80]
Epoch 0:   0%|          | 99/267978 [01:08<51:16:39,  1.45it/s, v_num=full, train/loss_step=14.30]
Epoch 0:   0%|          | 100/267978 [01:21<60:32:40,  1.23it/s, v_num=full, train/loss_step=14.30]
Epoch 0:   0%|          | 100/267978 [01:21<60:32:42,  1.23it/s, v_num=full, train/loss_step=11.20]
============================================================
[Input Before LLM] - Global Step 100
============================================================
  Adaptor embeddings shape: torch.Size([4, 583, 896])
  Input embeddings shape: torch.Size([4, 583, 896])
  Attention mask shape: torch.Size([4, 583])
  Input dtype: torch.float16
  Adaptor embeddings range: [-13.7109, 11.0781]
  Input embeddings range: [-13.7109, 11.0781]
  Input embeddings mean: 0.0008, std: 0.7686
  Language inputs shape: torch.Size([4, 553, 896])

============================================================
Global Step 100
============================================================

[Losses]
  language_loss: 0.018295 (shape: torch.Size([4, 552]), count: 28)
  route_loss: 2.394531 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 7.285156 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 101/267978 [01:21<60:23:43,  1.23it/s, v_num=full, train/loss_step=11.20]
Epoch 0:   0%|          | 101/267978 [01:21<60:23:45,  1.23it/s, v_num=full, train/loss_step=11.10]
Epoch 0:   0%|          | 102/267978 [01:22<60:12:22,  1.24it/s, v_num=full, train/loss_step=11.10]
Epoch 0:   0%|          | 102/267978 [01:22<60:12:24,  1.24it/s, v_num=full, train/loss_step=10.20]
Epoch 0:   0%|          | 103/267978 [01:23<60:00:55,  1.24it/s, v_num=full, train/loss_step=10.20]
Epoch 0:   0%|          | 103/267978 [01:23<60:00:56,  1.24it/s, v_num=full, train/loss_step=8.380]
Epoch 0:   0%|          | 104/267978 [01:23<59:49:53,  1.24it/s, v_num=full, train/loss_step=8.380]
Epoch 0:   0%|          | 104/267978 [01:23<59:49:55,  1.24it/s, v_num=full, train/loss_step=12.60]
Epoch 0:   0%|          | 105/267978 [01:24<59:39:58,  1.25it/s, v_num=full, train/loss_step=12.60]
Epoch 0:   0%|          | 105/267978 [01:24<59:40:00,  1.25it/s, v_num=full, train/loss_step=9.820]
Epoch 0:   0%|          | 106/267978 [01:24<59:29:27,  1.25it/s, v_num=full, train/loss_step=9.820]
Epoch 0:   0%|          | 106/267978 [01:24<59:29:29,  1.25it/s, v_num=full, train/loss_step=10.10]
Epoch 0:   0%|          | 107/267978 [01:25<59:18:55,  1.25it/s, v_num=full, train/loss_step=10.10]
Epoch 0:   0%|          | 107/267978 [01:25<59:18:57,  1.25it/s, v_num=full, train/loss_step=7.480]
Epoch 0:   0%|          | 108/267978 [01:25<59:08:59,  1.26it/s, v_num=full, train/loss_step=7.480]
Epoch 0:   0%|          | 108/267978 [01:25<59:09:02,  1.26it/s, v_num=full, train/loss_step=8.510]
Epoch 0:   0%|          | 109/267978 [01:26<58:59:37,  1.26it/s, v_num=full, train/loss_step=8.510]
Epoch 0:   0%|          | 109/267978 [01:26<58:59:39,  1.26it/s, v_num=full, train/loss_step=11.80]
Epoch 0:   0%|          | 110/267978 [01:26<58:49:50,  1.26it/s, v_num=full, train/loss_step=11.80]
Epoch 0:   0%|          | 110/267978 [01:26<58:49:51,  1.26it/s, v_num=full, train/loss_step=10.40]
============================================================
Global Step 110
============================================================

[Losses]
  language_loss: 0.015976 (shape: torch.Size([4, 554]), count: 28)
  route_loss: 2.490234 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 5.308594 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 111/267978 [01:27<58:40:05,  1.27it/s, v_num=full, train/loss_step=10.40]
Epoch 0:   0%|          | 111/267978 [01:27<58:40:06,  1.27it/s, v_num=full, train/loss_step=9.050]
Epoch 0:   0%|          | 112/267978 [01:28<58:30:35,  1.27it/s, v_num=full, train/loss_step=9.050]
Epoch 0:   0%|          | 112/267978 [01:28<58:30:36,  1.27it/s, v_num=full, train/loss_step=10.80]
Epoch 0:   0%|          | 113/267978 [01:28<58:21:24,  1.28it/s, v_num=full, train/loss_step=10.80]
Epoch 0:   0%|          | 113/267978 [01:28<58:21:25,  1.28it/s, v_num=full, train/loss_step=6.850]
Epoch 0:   0%|          | 114/267978 [01:29<58:12:22,  1.28it/s, v_num=full, train/loss_step=6.850]
Epoch 0:   0%|          | 114/267978 [01:29<58:12:23,  1.28it/s, v_num=full, train/loss_step=5.360]
Epoch 0:   0%|          | 115/267978 [01:29<58:03:41,  1.28it/s, v_num=full, train/loss_step=5.360]
Epoch 0:   0%|          | 115/267978 [01:29<58:03:43,  1.28it/s, v_num=full, train/loss_step=10.70]
Epoch 0:   0%|          | 116/267978 [01:30<57:55:03,  1.28it/s, v_num=full, train/loss_step=10.70]
Epoch 0:   0%|          | 116/267978 [01:30<57:55:05,  1.28it/s, v_num=full, train/loss_step=13.80]
Epoch 0:   0%|          | 117/267978 [01:30<57:46:33,  1.29it/s, v_num=full, train/loss_step=13.80]
Epoch 0:   0%|          | 117/267978 [01:30<57:46:35,  1.29it/s, v_num=full, train/loss_step=11.00]
Epoch 0:   0%|          | 118/267978 [01:31<57:38:20,  1.29it/s, v_num=full, train/loss_step=11.00]
Epoch 0:   0%|          | 118/267978 [01:31<57:38:22,  1.29it/s, v_num=full, train/loss_step=8.000]
Epoch 0:   0%|          | 119/267978 [01:31<57:29:58,  1.29it/s, v_num=full, train/loss_step=8.000]
Epoch 0:   0%|          | 119/267978 [01:31<57:29:59,  1.29it/s, v_num=full, train/loss_step=10.50]
Epoch 0:   0%|          | 120/267978 [01:32<57:21:57,  1.30it/s, v_num=full, train/loss_step=10.50]
Epoch 0:   0%|          | 120/267978 [01:32<57:21:58,  1.30it/s, v_num=full, train/loss_step=11.30]
============================================================
Global Step 120
============================================================

[Losses]
  language_loss: 0.011429 (shape: torch.Size([4, 561]), count: 28)
  route_loss: 0.712402 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 9.523438 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 121/267978 [01:33<57:13:54,  1.30it/s, v_num=full, train/loss_step=11.30]
Epoch 0:   0%|          | 121/267978 [01:33<57:13:55,  1.30it/s, v_num=full, train/loss_step=11.10]
Epoch 0:   0%|          | 122/267978 [01:33<57:05:49,  1.30it/s, v_num=full, train/loss_step=11.10]
Epoch 0:   0%|          | 122/267978 [01:33<57:05:50,  1.30it/s, v_num=full, train/loss_step=10.50]
Epoch 0:   0%|          | 123/267978 [01:34<56:58:02,  1.31it/s, v_num=full, train/loss_step=10.50]
Epoch 0:   0%|          | 123/267978 [01:34<56:58:04,  1.31it/s, v_num=full, train/loss_step=7.600]
Epoch 0:   0%|          | 124/267978 [01:34<56:50:21,  1.31it/s, v_num=full, train/loss_step=7.600]
Epoch 0:   0%|          | 124/267978 [01:34<56:50:23,  1.31it/s, v_num=full, train/loss_step=6.610]
Epoch 0:   0%|          | 125/267978 [01:35<56:42:49,  1.31it/s, v_num=full, train/loss_step=6.610]
Epoch 0:   0%|          | 125/267978 [01:35<56:42:50,  1.31it/s, v_num=full, train/loss_step=12.00]
Epoch 0:   0%|          | 126/267978 [01:35<56:35:20,  1.31it/s, v_num=full, train/loss_step=12.00]
Epoch 0:   0%|          | 126/267978 [01:35<56:35:22,  1.31it/s, v_num=full, train/loss_step=8.980]
Epoch 0:   0%|          | 127/267978 [01:36<56:27:52,  1.32it/s, v_num=full, train/loss_step=8.980]
Epoch 0:   0%|          | 127/267978 [01:36<56:27:54,  1.32it/s, v_num=full, train/loss_step=8.300]
Epoch 0:   0%|          | 128/267978 [01:36<56:20:51,  1.32it/s, v_num=full, train/loss_step=8.300]
Epoch 0:   0%|          | 128/267978 [01:36<56:20:53,  1.32it/s, v_num=full, train/loss_step=8.560]
Epoch 0:   0%|          | 129/267978 [01:37<56:13:47,  1.32it/s, v_num=full, train/loss_step=8.560]
Epoch 0:   0%|          | 129/267978 [01:37<56:13:48,  1.32it/s, v_num=full, train/loss_step=6.660]
Epoch 0:   0%|          | 130/267978 [01:38<56:06:40,  1.33it/s, v_num=full, train/loss_step=6.660]
Epoch 0:   0%|          | 130/267978 [01:38<56:06:42,  1.33it/s, v_num=full, train/loss_step=6.090]
============================================================
Global Step 130
============================================================

[Losses]
  language_loss: 0.006615 (shape: torch.Size([4, 565]), count: 28)
  route_loss: 2.595703 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.351562 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 131/267978 [01:38<55:59:59,  1.33it/s, v_num=full, train/loss_step=6.090]
Epoch 0:   0%|          | 131/267978 [01:38<56:00:00,  1.33it/s, v_num=full, train/loss_step=7.480]
Epoch 0:   0%|          | 132/267978 [01:39<55:53:13,  1.33it/s, v_num=full, train/loss_step=7.480]
Epoch 0:   0%|          | 132/267978 [01:39<55:53:14,  1.33it/s, v_num=full, train/loss_step=6.840]
Epoch 0:   0%|          | 133/267978 [01:39<55:47:17,  1.33it/s, v_num=full, train/loss_step=6.840]
Epoch 0:   0%|          | 133/267978 [01:39<55:47:18,  1.33it/s, v_num=full, train/loss_step=12.80]
Epoch 0:   0%|          | 134/267978 [01:40<55:40:51,  1.34it/s, v_num=full, train/loss_step=12.80]
Epoch 0:   0%|          | 134/267978 [01:40<55:40:52,  1.34it/s, v_num=full, train/loss_step=6.340]
Epoch 0:   0%|          | 135/267978 [01:40<55:34:14,  1.34it/s, v_num=full, train/loss_step=6.340]
Epoch 0:   0%|          | 135/267978 [01:40<55:34:15,  1.34it/s, v_num=full, train/loss_step=5.760]
Epoch 0:   0%|          | 136/267978 [01:41<55:27:45,  1.34it/s, v_num=full, train/loss_step=5.760]
Epoch 0:   0%|          | 136/267978 [01:41<55:27:46,  1.34it/s, v_num=full, train/loss_step=8.000]
Epoch 0:   0%|          | 137/267978 [01:41<55:21:26,  1.34it/s, v_num=full, train/loss_step=8.000]
Epoch 0:   0%|          | 137/267978 [01:41<55:21:27,  1.34it/s, v_num=full, train/loss_step=7.140]
Epoch 0:   0%|          | 138/267978 [01:42<55:15:28,  1.35it/s, v_num=full, train/loss_step=7.140]
Epoch 0:   0%|          | 138/267978 [01:42<55:15:29,  1.35it/s, v_num=full, train/loss_step=8.300]
Epoch 0:   0%|          | 139/267978 [01:43<55:09:20,  1.35it/s, v_num=full, train/loss_step=8.300]
Epoch 0:   0%|          | 139/267978 [01:43<55:09:21,  1.35it/s, v_num=full, train/loss_step=13.10]
Epoch 0:   0%|          | 140/267978 [01:43<55:03:12,  1.35it/s, v_num=full, train/loss_step=13.10]
Epoch 0:   0%|          | 140/267978 [01:43<55:03:13,  1.35it/s, v_num=full, train/loss_step=11.10]
============================================================
Global Step 140
============================================================

[Losses]
  language_loss: 0.005390 (shape: torch.Size([4, 553]), count: 28)
  route_loss: 2.373047 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 5.812500 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 141/267978 [01:44<54:57:20,  1.35it/s, v_num=full, train/loss_step=11.10]
Epoch 0:   0%|          | 141/267978 [01:44<54:57:22,  1.35it/s, v_num=full, train/loss_step=8.610]
Epoch 0:   0%|          | 142/267978 [01:44<54:51:33,  1.36it/s, v_num=full, train/loss_step=8.610]
Epoch 0:   0%|          | 142/267978 [01:44<54:51:34,  1.36it/s, v_num=full, train/loss_step=8.020]
Epoch 0:   0%|          | 143/267978 [01:45<54:45:48,  1.36it/s, v_num=full, train/loss_step=8.020]
Epoch 0:   0%|          | 143/267978 [01:45<54:45:49,  1.36it/s, v_num=full, train/loss_step=7.110]
Epoch 0:   0%|          | 144/267978 [01:45<54:40:12,  1.36it/s, v_num=full, train/loss_step=7.110]
Epoch 0:   0%|          | 144/267978 [01:45<54:40:13,  1.36it/s, v_num=full, train/loss_step=8.040]
Epoch 0:   0%|          | 145/267978 [01:46<54:34:27,  1.36it/s, v_num=full, train/loss_step=8.040]
Epoch 0:   0%|          | 145/267978 [01:46<54:34:28,  1.36it/s, v_num=full, train/loss_step=4.950]
Epoch 0:   0%|          | 146/267978 [01:46<54:28:42,  1.37it/s, v_num=full, train/loss_step=4.950]
Epoch 0:   0%|          | 146/267978 [01:46<54:28:43,  1.37it/s, v_num=full, train/loss_step=7.820]
Epoch 0:   0%|          | 147/267978 [01:47<54:23:15,  1.37it/s, v_num=full, train/loss_step=7.820]
Epoch 0:   0%|          | 147/267978 [01:47<54:23:17,  1.37it/s, v_num=full, train/loss_step=4.610]
Epoch 0:   0%|          | 148/267978 [01:48<54:17:55,  1.37it/s, v_num=full, train/loss_step=4.610]
Epoch 0:   0%|          | 148/267978 [01:48<54:17:57,  1.37it/s, v_num=full, train/loss_step=6.310]
Epoch 0:   0%|          | 149/267978 [01:48<54:12:41,  1.37it/s, v_num=full, train/loss_step=6.310]
Epoch 0:   0%|          | 149/267978 [01:48<54:12:42,  1.37it/s, v_num=full, train/loss_step=5.340]
Epoch 0:   0%|          | 150/267978 [01:49<54:07:24,  1.37it/s, v_num=full, train/loss_step=5.340]
Epoch 0:   0%|          | 150/267978 [01:49<54:07:25,  1.37it/s, v_num=full, train/loss_step=5.890]
============================================================
Global Step 150
============================================================

[Losses]
  language_loss: 0.005550 (shape: torch.Size([4, 555]), count: 28)
  route_loss: 1.600586 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.710938 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 151/267978 [01:49<54:02:26,  1.38it/s, v_num=full, train/loss_step=5.890]
Epoch 0:   0%|          | 151/267978 [01:49<54:02:28,  1.38it/s, v_num=full, train/loss_step=6.750]
Epoch 0:   0%|          | 152/267978 [01:50<53:57:29,  1.38it/s, v_num=full, train/loss_step=6.750]
Epoch 0:   0%|          | 152/267978 [01:50<53:57:30,  1.38it/s, v_num=full, train/loss_step=5.620]
Epoch 0:   0%|          | 153/267978 [01:50<53:52:26,  1.38it/s, v_num=full, train/loss_step=5.620]
Epoch 0:   0%|          | 153/267978 [01:50<53:52:27,  1.38it/s, v_num=full, train/loss_step=9.150]
Epoch 0:   0%|          | 154/267978 [01:51<53:47:35,  1.38it/s, v_num=full, train/loss_step=9.150]
Epoch 0:   0%|          | 154/267978 [01:51<53:47:37,  1.38it/s, v_num=full, train/loss_step=5.320]
Epoch 0:   0%|          | 155/267978 [01:51<53:42:58,  1.38it/s, v_num=full, train/loss_step=5.320]
Epoch 0:   0%|          | 155/267978 [01:51<53:42:59,  1.38it/s, v_num=full, train/loss_step=4.460]
Epoch 0:   0%|          | 156/267978 [01:52<53:38:14,  1.39it/s, v_num=full, train/loss_step=4.460]
Epoch 0:   0%|          | 156/267978 [01:52<53:38:15,  1.39it/s, v_num=full, train/loss_step=6.100]
Epoch 0:   0%|          | 157/267978 [01:53<53:33:25,  1.39it/s, v_num=full, train/loss_step=6.100]
Epoch 0:   0%|          | 157/267978 [01:55<54:40:31,  1.36it/s, v_num=full, train/loss_step=10.10]
Epoch 0:   0%|          | 158/267978 [01:58<55:46:47,  1.33it/s, v_num=full, train/loss_step=10.10]
Epoch 0:   0%|          | 158/267978 [01:58<55:46:48,  1.33it/s, v_num=full, train/loss_step=7.790]
Epoch 0:   0%|          | 159/267978 [01:59<55:41:00,  1.34it/s, v_num=full, train/loss_step=7.790]
Epoch 0:   0%|          | 159/267978 [01:59<55:41:01,  1.34it/s, v_num=full, train/loss_step=6.820]
Epoch 0:   0%|          | 160/267978 [01:59<55:35:34,  1.34it/s, v_num=full, train/loss_step=6.820]
Epoch 0:   0%|          | 160/267978 [01:59<55:35:35,  1.34it/s, v_num=full, train/loss_step=7.320]
============================================================
Global Step 160
============================================================

[Losses]
  language_loss: 0.003929 (shape: torch.Size([4, 553]), count: 28)
  route_loss: 1.635742 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 5.730469 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 161/267978 [02:00<55:30:15,  1.34it/s, v_num=full, train/loss_step=7.320]
Epoch 0:   0%|          | 161/267978 [02:00<55:30:17,  1.34it/s, v_num=full, train/loss_step=7.680]
Epoch 0:   0%|          | 162/267978 [02:00<55:25:07,  1.34it/s, v_num=full, train/loss_step=7.680]
Epoch 0:   0%|          | 162/267978 [02:00<55:25:08,  1.34it/s, v_num=full, train/loss_step=9.380]
Epoch 0:   0%|          | 163/267978 [02:01<55:19:51,  1.34it/s, v_num=full, train/loss_step=9.380]
Epoch 0:   0%|          | 163/267978 [02:01<55:19:52,  1.34it/s, v_num=full, train/loss_step=9.700]
Epoch 0:   0%|          | 164/267978 [02:01<55:14:45,  1.35it/s, v_num=full, train/loss_step=9.700]
Epoch 0:   0%|          | 164/267978 [02:01<55:14:46,  1.35it/s, v_num=full, train/loss_step=10.30]
Epoch 0:   0%|          | 165/267978 [02:02<55:09:39,  1.35it/s, v_num=full, train/loss_step=10.30]
Epoch 0:   0%|          | 165/267978 [02:02<55:09:40,  1.35it/s, v_num=full, train/loss_step=11.00]
Epoch 0:   0%|          | 166/267978 [02:02<55:04:38,  1.35it/s, v_num=full, train/loss_step=11.00]
Epoch 0:   0%|          | 166/267978 [02:02<55:04:39,  1.35it/s, v_num=full, train/loss_step=8.030]
Epoch 0:   0%|          | 167/267978 [02:03<54:59:37,  1.35it/s, v_num=full, train/loss_step=8.030]
Epoch 0:   0%|          | 167/267978 [02:03<54:59:38,  1.35it/s, v_num=full, train/loss_step=7.880]
Epoch 0:   0%|          | 168/267978 [02:04<54:54:29,  1.35it/s, v_num=full, train/loss_step=7.880]
Epoch 0:   0%|          | 168/267978 [02:04<54:54:30,  1.35it/s, v_num=full, train/loss_step=4.710]
Epoch 0:   0%|          | 169/267978 [02:04<54:49:34,  1.36it/s, v_num=full, train/loss_step=4.710]
Epoch 0:   0%|          | 169/267978 [02:04<54:49:35,  1.36it/s, v_num=full, train/loss_step=8.590]
Epoch 0:   0%|          | 170/267978 [02:05<54:44:59,  1.36it/s, v_num=full, train/loss_step=8.590]
Epoch 0:   0%|          | 170/267978 [02:05<54:45:00,  1.36it/s, v_num=full, train/loss_step=6.690]
============================================================
Global Step 170
============================================================

[Losses]
  language_loss: 0.003017 (shape: torch.Size([4, 555]), count: 28)
  route_loss: 0.699707 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 2.398438 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 171/267978 [02:05<54:40:02,  1.36it/s, v_num=full, train/loss_step=6.690]
Epoch 0:   0%|          | 171/267978 [02:05<54:40:02,  1.36it/s, v_num=full, train/loss_step=3.340]
Epoch 0:   0%|          | 172/267978 [02:06<54:35:26,  1.36it/s, v_num=full, train/loss_step=3.340]
Epoch 0:   0%|          | 172/267978 [02:06<54:35:27,  1.36it/s, v_num=full, train/loss_step=5.560]
Epoch 0:   0%|          | 173/267978 [02:06<54:30:54,  1.36it/s, v_num=full, train/loss_step=5.560]
Epoch 0:   0%|          | 173/267978 [02:06<54:30:55,  1.36it/s, v_num=full, train/loss_step=9.270]
Epoch 0:   0%|          | 174/267978 [02:07<54:26:35,  1.37it/s, v_num=full, train/loss_step=9.270]
Epoch 0:   0%|          | 174/267978 [02:07<54:26:36,  1.37it/s, v_num=full, train/loss_step=9.070]
Epoch 0:   0%|          | 175/267978 [02:07<54:22:07,  1.37it/s, v_num=full, train/loss_step=9.070]
Epoch 0:   0%|          | 175/267978 [02:07<54:22:08,  1.37it/s, v_num=full, train/loss_step=9.980]
Epoch 0:   0%|          | 176/267978 [02:08<54:17:30,  1.37it/s, v_num=full, train/loss_step=9.980]
Epoch 0:   0%|          | 176/267978 [02:08<54:17:31,  1.37it/s, v_num=full, train/loss_step=7.090]
Epoch 0:   0%|          | 177/267978 [02:09<54:13:06,  1.37it/s, v_num=full, train/loss_step=7.090]
Epoch 0:   0%|          | 177/267978 [02:09<54:13:07,  1.37it/s, v_num=full, train/loss_step=10.40]
Epoch 0:   0%|          | 178/267978 [02:09<54:08:58,  1.37it/s, v_num=full, train/loss_step=10.40]
Epoch 0:   0%|          | 178/267978 [02:09<54:08:58,  1.37it/s, v_num=full, train/loss_step=11.30]
Epoch 0:   0%|          | 179/267978 [02:10<54:04:40,  1.38it/s, v_num=full, train/loss_step=11.30]
Epoch 0:   0%|          | 179/267978 [02:10<54:04:40,  1.38it/s, v_num=full, train/loss_step=6.820]
Epoch 0:   0%|          | 180/267978 [02:11<54:09:22,  1.37it/s, v_num=full, train/loss_step=6.820]
Epoch 0:   0%|          | 180/267978 [02:11<54:09:23,  1.37it/s, v_num=full, train/loss_step=4.490]
============================================================
Global Step 180
============================================================

[Losses]
  language_loss: 0.003082 (shape: torch.Size([4, 555]), count: 28)
  route_loss: 2.548828 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 9.015625 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 181/267978 [02:11<54:04:59,  1.38it/s, v_num=full, train/loss_step=4.490]
Epoch 0:   0%|          | 181/267978 [02:11<54:05:00,  1.38it/s, v_num=full, train/loss_step=11.80]
Epoch 0:   0%|          | 182/267978 [02:12<54:00:40,  1.38it/s, v_num=full, train/loss_step=11.80]
Epoch 0:   0%|          | 182/267978 [02:12<54:00:41,  1.38it/s, v_num=full, train/loss_step=9.390]
Epoch 0:   0%|          | 183/267978 [02:12<53:56:34,  1.38it/s, v_num=full, train/loss_step=9.390]
Epoch 0:   0%|          | 183/267978 [02:12<53:56:35,  1.38it/s, v_num=full, train/loss_step=6.990]
Epoch 0:   0%|          | 184/267978 [02:13<53:52:27,  1.38it/s, v_num=full, train/loss_step=6.990]
Epoch 0:   0%|          | 184/267978 [02:13<53:52:29,  1.38it/s, v_num=full, train/loss_step=6.860]
Epoch 0:   0%|          | 185/267978 [02:13<53:48:52,  1.38it/s, v_num=full, train/loss_step=6.860]
Epoch 0:   0%|          | 185/267978 [02:13<53:48:54,  1.38it/s, v_num=full, train/loss_step=11.70]
Epoch 0:   0%|          | 186/267978 [02:14<53:44:52,  1.38it/s, v_num=full, train/loss_step=11.70]
Epoch 0:   0%|          | 186/267978 [02:14<53:44:53,  1.38it/s, v_num=full, train/loss_step=6.480]
Epoch 0:   0%|          | 187/267978 [02:14<53:40:54,  1.39it/s, v_num=full, train/loss_step=6.480]
Epoch 0:   0%|          | 187/267978 [02:14<53:40:54,  1.39it/s, v_num=full, train/loss_step=6.960]
Epoch 0:   0%|          | 188/267978 [02:15<53:36:57,  1.39it/s, v_num=full, train/loss_step=6.960]
Epoch 0:   0%|          | 188/267978 [02:15<53:36:58,  1.39it/s, v_num=full, train/loss_step=12.90]
Epoch 0:   0%|          | 189/267978 [02:16<53:32:58,  1.39it/s, v_num=full, train/loss_step=12.90]
Epoch 0:   0%|          | 189/267978 [02:16<53:32:59,  1.39it/s, v_num=full, train/loss_step=9.610]
Epoch 0:   0%|          | 190/267978 [02:16<53:29:06,  1.39it/s, v_num=full, train/loss_step=9.610]
Epoch 0:   0%|          | 190/267978 [02:16<53:29:07,  1.39it/s, v_num=full, train/loss_step=6.910]
============================================================
Global Step 190
============================================================

[Losses]
  language_loss: 0.002420 (shape: torch.Size([4, 548]), count: 28)
  route_loss: 2.390625 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 6.710938 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 191/267978 [02:17<53:25:21,  1.39it/s, v_num=full, train/loss_step=6.910]
Epoch 0:   0%|          | 191/267978 [02:17<53:25:22,  1.39it/s, v_num=full, train/loss_step=9.290]
Epoch 0:   0%|          | 192/267978 [02:17<53:21:34,  1.39it/s, v_num=full, train/loss_step=9.290]
Epoch 0:   0%|          | 192/267978 [02:17<53:21:34,  1.39it/s, v_num=full, train/loss_step=6.560]
Epoch 0:   0%|          | 193/267978 [02:18<53:17:50,  1.40it/s, v_num=full, train/loss_step=6.560]
Epoch 0:   0%|          | 193/267978 [02:18<53:17:51,  1.40it/s, v_num=full, train/loss_step=11.60]
Epoch 0:   0%|          | 194/267978 [02:18<53:14:08,  1.40it/s, v_num=full, train/loss_step=11.60]
Epoch 0:   0%|          | 194/267978 [02:18<53:14:09,  1.40it/s, v_num=full, train/loss_step=7.580]
Epoch 0:   0%|          | 195/267978 [02:19<53:10:22,  1.40it/s, v_num=full, train/loss_step=7.580]
Epoch 0:   0%|          | 195/267978 [02:19<53:10:23,  1.40it/s, v_num=full, train/loss_step=5.230]
Epoch 0:   0%|          | 196/267978 [02:19<53:06:43,  1.40it/s, v_num=full, train/loss_step=5.230]
Epoch 0:   0%|          | 196/267978 [02:19<53:06:44,  1.40it/s, v_num=full, train/loss_step=5.390]
Epoch 0:   0%|          | 197/267978 [02:20<53:03:11,  1.40it/s, v_num=full, train/loss_step=5.390]
Epoch 0:   0%|          | 197/267978 [02:20<53:03:12,  1.40it/s, v_num=full, train/loss_step=9.650]
Epoch 0:   0%|          | 198/267978 [02:21<52:59:36,  1.40it/s, v_num=full, train/loss_step=9.650]
Epoch 0:   0%|          | 198/267978 [02:21<52:59:37,  1.40it/s, v_num=full, train/loss_step=7.250]
Epoch 0:   0%|          | 199/267978 [02:21<52:56:06,  1.41it/s, v_num=full, train/loss_step=7.250]
Epoch 0:   0%|          | 199/267978 [02:21<52:56:07,  1.41it/s, v_num=full, train/loss_step=5.560]
Epoch 0:   0%|          | 200/267978 [02:27<54:45:17,  1.36it/s, v_num=full, train/loss_step=5.560]
Epoch 0:   0%|          | 200/267978 [02:27<54:45:17,  1.36it/s, v_num=full, train/loss_step=7.230]
============================================================
[Input Before LLM] - Global Step 200
============================================================
  Adaptor embeddings shape: torch.Size([4, 581, 896])
  Input embeddings shape: torch.Size([4, 581, 896])
  Attention mask shape: torch.Size([4, 581])
  Input dtype: torch.float16
  Adaptor embeddings range: [-40.7812, 32.0312]
  Input embeddings range: [-40.7812, 32.0312]
  Input embeddings mean: 0.0004, std: 0.7749
  Language inputs shape: torch.Size([4, 551, 896])

============================================================
Global Step 200
============================================================

[Losses]
  language_loss: 0.002522 (shape: torch.Size([4, 550]), count: 28)
  route_loss: 2.380859 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.984375 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 201/267978 [02:27<54:42:35,  1.36it/s, v_num=full, train/loss_step=7.230]
Epoch 0:   0%|          | 201/267978 [02:27<54:42:35,  1.36it/s, v_num=full, train/loss_step=7.560]
Epoch 0:   0%|          | 202/267978 [02:28<54:38:28,  1.36it/s, v_num=full, train/loss_step=7.560]
Epoch 0:   0%|          | 202/267978 [02:28<54:38:29,  1.36it/s, v_num=full, train/loss_step=5.630]
Epoch 0:   0%|          | 203/267978 [02:28<54:34:40,  1.36it/s, v_num=full, train/loss_step=5.630]
Epoch 0:   0%|          | 203/267978 [02:28<54:34:41,  1.36it/s, v_num=full, train/loss_step=7.000]
Epoch 0:   0%|          | 204/267978 [02:29<54:30:36,  1.36it/s, v_num=full, train/loss_step=7.000]
Epoch 0:   0%|          | 204/267978 [02:29<54:30:37,  1.36it/s, v_num=full, train/loss_step=7.080]
Epoch 0:   0%|          | 205/267978 [02:30<54:26:42,  1.37it/s, v_num=full, train/loss_step=7.080]
Epoch 0:   0%|          | 205/267978 [02:30<54:26:43,  1.37it/s, v_num=full, train/loss_step=10.50]
Epoch 0:   0%|          | 206/267978 [02:30<54:22:46,  1.37it/s, v_num=full, train/loss_step=10.50]
Epoch 0:   0%|          | 206/267978 [02:30<54:22:46,  1.37it/s, v_num=full, train/loss_step=10.30]
Epoch 0:   0%|          | 207/267978 [02:31<54:18:54,  1.37it/s, v_num=full, train/loss_step=10.30]
Epoch 0:   0%|          | 207/267978 [02:31<54:18:55,  1.37it/s, v_num=full, train/loss_step=6.690]
Epoch 0:   0%|          | 208/267978 [02:31<54:15:11,  1.37it/s, v_num=full, train/loss_step=6.690]
Epoch 0:   0%|          | 208/267978 [02:31<54:15:12,  1.37it/s, v_num=full, train/loss_step=10.10]
Epoch 0:   0%|          | 209/267978 [02:32<54:11:34,  1.37it/s, v_num=full, train/loss_step=10.10]
Epoch 0:   0%|          | 209/267978 [02:32<54:11:35,  1.37it/s, v_num=full, train/loss_step=6.490]
Epoch 0:   0%|          | 210/267978 [02:32<54:07:53,  1.37it/s, v_num=full, train/loss_step=6.490]
Epoch 0:   0%|          | 210/267978 [02:32<54:07:54,  1.37it/s, v_num=full, train/loss_step=8.530]
============================================================
Global Step 210
============================================================

[Losses]
  language_loss: 0.001594 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 1.026367 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 6.941406 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 211/267978 [02:33<54:04:08,  1.38it/s, v_num=full, train/loss_step=8.530]
Epoch 0:   0%|          | 211/267978 [02:33<54:04:09,  1.38it/s, v_num=full, train/loss_step=8.100]
Epoch 0:   0%|          | 212/267978 [02:33<54:00:30,  1.38it/s, v_num=full, train/loss_step=8.100]
Epoch 0:   0%|          | 212/267978 [02:33<54:00:31,  1.38it/s, v_num=full, train/loss_step=4.000]
Epoch 0:   0%|          | 213/267978 [02:34<53:56:48,  1.38it/s, v_num=full, train/loss_step=4.000]
Epoch 0:   0%|          | 213/267978 [02:34<53:56:49,  1.38it/s, v_num=full, train/loss_step=7.950]
Epoch 0:   0%|          | 214/267978 [02:35<53:53:13,  1.38it/s, v_num=full, train/loss_step=7.950]
Epoch 0:   0%|          | 214/267978 [02:35<53:53:13,  1.38it/s, v_num=full, train/loss_step=8.800]
Epoch 0:   0%|          | 215/267978 [02:35<53:49:36,  1.38it/s, v_num=full, train/loss_step=8.800]
Epoch 0:   0%|          | 215/267978 [02:35<53:49:36,  1.38it/s, v_num=full, train/loss_step=5.660]
Epoch 0:   0%|          | 216/267978 [02:36<53:46:11,  1.38it/s, v_num=full, train/loss_step=5.660]
Epoch 0:   0%|          | 216/267978 [02:36<53:46:12,  1.38it/s, v_num=full, train/loss_step=5.600]
Epoch 0:   0%|          | 217/267978 [02:36<53:42:30,  1.38it/s, v_num=full, train/loss_step=5.600]
Epoch 0:   0%|          | 217/267978 [02:36<53:42:30,  1.38it/s, v_num=full, train/loss_step=4.380]
Epoch 0:   0%|          | 218/267978 [02:37<53:38:53,  1.39it/s, v_num=full, train/loss_step=4.380]
Epoch 0:   0%|          | 218/267978 [02:37<53:38:53,  1.39it/s, v_num=full, train/loss_step=5.430]
Epoch 0:   0%|          | 219/267978 [02:37<53:35:21,  1.39it/s, v_num=full, train/loss_step=5.430]
Epoch 0:   0%|          | 219/267978 [02:37<53:35:22,  1.39it/s, v_num=full, train/loss_step=3.460]
Epoch 0:   0%|          | 220/267978 [02:38<53:31:58,  1.39it/s, v_num=full, train/loss_step=3.460]
Epoch 0:   0%|          | 220/267978 [02:38<53:32:00,  1.39it/s, v_num=full, train/loss_step=5.890]
============================================================
Global Step 220
============================================================

[Losses]
  language_loss: 0.001703 (shape: torch.Size([4, 559]), count: 28)
  route_loss: 1.980469 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 10.453125 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 221/267978 [02:38<53:28:47,  1.39it/s, v_num=full, train/loss_step=5.890]
Epoch 0:   0%|          | 221/267978 [02:38<53:28:48,  1.39it/s, v_num=full, train/loss_step=12.60]
Epoch 0:   0%|          | 222/267978 [02:39<53:25:29,  1.39it/s, v_num=full, train/loss_step=12.60]
Epoch 0:   0%|          | 222/267978 [02:39<53:25:30,  1.39it/s, v_num=full, train/loss_step=7.160]
Epoch 0:   0%|          | 223/267978 [02:40<53:22:09,  1.39it/s, v_num=full, train/loss_step=7.160]
Epoch 0:   0%|          | 223/267978 [02:40<53:22:10,  1.39it/s, v_num=full, train/loss_step=5.090]
Epoch 0:   0%|          | 224/267978 [02:40<53:18:51,  1.40it/s, v_num=full, train/loss_step=5.090]
Epoch 0:   0%|          | 224/267978 [02:40<53:18:52,  1.40it/s, v_num=full, train/loss_step=4.510]
Epoch 0:   0%|          | 225/267978 [02:41<53:15:44,  1.40it/s, v_num=full, train/loss_step=4.510]
Epoch 0:   0%|          | 225/267978 [02:41<53:15:45,  1.40it/s, v_num=full, train/loss_step=7.260]
Epoch 0:   0%|          | 226/267978 [02:41<53:12:36,  1.40it/s, v_num=full, train/loss_step=7.260]
Epoch 0:   0%|          | 226/267978 [02:41<53:12:37,  1.40it/s, v_num=full, train/loss_step=3.980]
Epoch 0:   0%|          | 227/267978 [02:42<53:09:25,  1.40it/s, v_num=full, train/loss_step=3.980]
Epoch 0:   0%|          | 227/267978 [02:42<53:09:26,  1.40it/s, v_num=full, train/loss_step=3.360]
Epoch 0:   0%|          | 228/267978 [02:42<53:06:23,  1.40it/s, v_num=full, train/loss_step=3.360]
Epoch 0:   0%|          | 228/267978 [02:42<53:06:24,  1.40it/s, v_num=full, train/loss_step=9.120]
Epoch 0:   0%|          | 229/267978 [02:43<53:03:19,  1.40it/s, v_num=full, train/loss_step=9.120]
Epoch 0:   0%|          | 229/267978 [02:43<53:03:20,  1.40it/s, v_num=full, train/loss_step=8.270]
Epoch 0:   0%|          | 230/267978 [02:43<53:00:09,  1.40it/s, v_num=full, train/loss_step=8.270]
Epoch 0:   0%|          | 230/267978 [02:43<53:00:10,  1.40it/s, v_num=full, train/loss_step=4.220]
============================================================
Global Step 230
============================================================

[Losses]
  language_loss: 0.000940 (shape: torch.Size([4, 550]), count: 28)
  route_loss: 2.193359 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 11.695312 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 231/267978 [02:44<52:57:08,  1.40it/s, v_num=full, train/loss_step=4.220]
Epoch 0:   0%|          | 231/267978 [02:44<52:57:10,  1.40it/s, v_num=full, train/loss_step=14.00]
Epoch 0:   0%|          | 232/267978 [02:45<52:54:12,  1.41it/s, v_num=full, train/loss_step=14.00]
Epoch 0:   0%|          | 232/267978 [02:45<52:54:13,  1.41it/s, v_num=full, train/loss_step=5.000]
Epoch 0:   0%|          | 233/267978 [02:45<52:51:15,  1.41it/s, v_num=full, train/loss_step=5.000]
Epoch 0:   0%|          | 233/267978 [02:45<52:51:16,  1.41it/s, v_num=full, train/loss_step=6.620]
Epoch 0:   0%|          | 234/267978 [02:46<52:48:16,  1.41it/s, v_num=full, train/loss_step=6.620]
Epoch 0:   0%|          | 234/267978 [02:46<52:48:17,  1.41it/s, v_num=full, train/loss_step=4.910]
Epoch 0:   0%|          | 235/267978 [02:46<52:45:16,  1.41it/s, v_num=full, train/loss_step=4.910]
Epoch 0:   0%|          | 235/267978 [02:46<52:45:16,  1.41it/s, v_num=full, train/loss_step=3.660]
Epoch 0:   0%|          | 236/267978 [02:47<52:42:19,  1.41it/s, v_num=full, train/loss_step=3.660]
Epoch 0:   0%|          | 236/267978 [02:47<52:42:19,  1.41it/s, v_num=full, train/loss_step=7.350]
Epoch 0:   0%|          | 237/267978 [02:47<52:39:27,  1.41it/s, v_num=full, train/loss_step=7.350]
Epoch 0:   0%|          | 237/267978 [02:47<52:39:28,  1.41it/s, v_num=full, train/loss_step=8.170]
Epoch 0:   0%|          | 238/267978 [02:48<52:36:28,  1.41it/s, v_num=full, train/loss_step=8.170]
Epoch 0:   0%|          | 238/267978 [02:48<52:36:28,  1.41it/s, v_num=full, train/loss_step=5.750]
Epoch 0:   0%|          | 239/267978 [02:48<52:33:29,  1.42it/s, v_num=full, train/loss_step=5.750]
Epoch 0:   0%|          | 239/267978 [02:48<52:33:30,  1.42it/s, v_num=full, train/loss_step=8.300]
Epoch 0:   0%|          | 240/267978 [02:49<52:30:41,  1.42it/s, v_num=full, train/loss_step=8.300]
Epoch 0:   0%|          | 240/267978 [02:49<52:30:41,  1.42it/s, v_num=full, train/loss_step=7.570]
============================================================
Global Step 240
============================================================

[Losses]
  language_loss: 0.001641 (shape: torch.Size([4, 553]), count: 28)
  route_loss: 1.000000 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 6.535156 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 241/267978 [02:50<52:27:57,  1.42it/s, v_num=full, train/loss_step=7.570]
Epoch 0:   0%|          | 241/267978 [02:50<52:27:58,  1.42it/s, v_num=full, train/loss_step=7.670]
Epoch 0:   0%|          | 242/267978 [02:50<52:25:04,  1.42it/s, v_num=full, train/loss_step=7.670]
Epoch 0:   0%|          | 242/267978 [02:50<52:25:05,  1.42it/s, v_num=full, train/loss_step=6.630]
Epoch 0:   0%|          | 243/267978 [02:51<52:22:26,  1.42it/s, v_num=full, train/loss_step=6.630]
Epoch 0:   0%|          | 243/267978 [02:51<52:22:27,  1.42it/s, v_num=full, train/loss_step=6.170]
Epoch 0:   0%|          | 244/267978 [02:51<52:19:46,  1.42it/s, v_num=full, train/loss_step=6.170]
Epoch 0:   0%|          | 244/267978 [02:51<52:19:47,  1.42it/s, v_num=full, train/loss_step=5.510]
Epoch 0:   0%|          | 245/267978 [02:52<52:17:00,  1.42it/s, v_num=full, train/loss_step=5.510]
Epoch 0:   0%|          | 245/267978 [02:52<52:17:01,  1.42it/s, v_num=full, train/loss_step=7.760]
Epoch 0:   0%|          | 246/267978 [02:52<52:14:24,  1.42it/s, v_num=full, train/loss_step=7.760]
Epoch 0:   0%|          | 246/267978 [02:52<52:14:25,  1.42it/s, v_num=full, train/loss_step=5.240]
Epoch 0:   0%|          | 247/267978 [02:53<52:11:53,  1.42it/s, v_num=full, train/loss_step=5.240]
Epoch 0:   0%|          | 247/267978 [02:53<52:11:53,  1.42it/s, v_num=full, train/loss_step=5.240]
Epoch 0:   0%|          | 248/267978 [02:53<52:09:07,  1.43it/s, v_num=full, train/loss_step=5.240]
Epoch 0:   0%|          | 248/267978 [02:53<52:09:08,  1.43it/s, v_num=full, train/loss_step=4.070]
Epoch 0:   0%|          | 249/267978 [02:54<52:06:33,  1.43it/s, v_num=full, train/loss_step=4.070]
Epoch 0:   0%|          | 249/267978 [02:54<52:06:34,  1.43it/s, v_num=full, train/loss_step=5.900]
Epoch 0:   0%|          | 250/267978 [02:55<52:03:58,  1.43it/s, v_num=full, train/loss_step=5.900]
Epoch 0:   0%|          | 250/267978 [02:55<52:03:58,  1.43it/s, v_num=full, train/loss_step=4.840]
============================================================
Global Step 250
============================================================

[Losses]
  language_loss: 0.001536 (shape: torch.Size([4, 552]), count: 28)
  route_loss: 0.678223 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.628906 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 251/267978 [02:55<52:01:33,  1.43it/s, v_num=full, train/loss_step=4.840]
Epoch 0:   0%|          | 251/267978 [02:57<52:37:34,  1.41it/s, v_num=full, train/loss_step=5.430]
Epoch 0:   0%|          | 252/267978 [03:00<53:19:40,  1.39it/s, v_num=full, train/loss_step=5.430]
Epoch 0:   0%|          | 252/267978 [03:00<53:19:40,  1.39it/s, v_num=full, train/loss_step=8.260]
Epoch 0:   0%|          | 253/267978 [03:01<53:16:39,  1.40it/s, v_num=full, train/loss_step=8.260]
Epoch 0:   0%|          | 253/267978 [03:01<53:16:40,  1.40it/s, v_num=full, train/loss_step=6.950]
Epoch 0:   0%|          | 254/267978 [03:01<53:13:50,  1.40it/s, v_num=full, train/loss_step=6.950]
Epoch 0:   0%|          | 254/267978 [03:01<53:13:51,  1.40it/s, v_num=full, train/loss_step=5.320]
Epoch 0:   0%|          | 255/267978 [03:02<53:10:59,  1.40it/s, v_num=full, train/loss_step=5.320]
Epoch 0:   0%|          | 255/267978 [03:02<53:10:59,  1.40it/s, v_num=full, train/loss_step=11.50]
Epoch 0:   0%|          | 256/267978 [03:02<53:08:09,  1.40it/s, v_num=full, train/loss_step=11.50]
Epoch 0:   0%|          | 256/267978 [03:02<53:08:10,  1.40it/s, v_num=full, train/loss_step=9.510]
Epoch 0:   0%|          | 257/267978 [03:03<53:05:25,  1.40it/s, v_num=full, train/loss_step=9.510]
Epoch 0:   0%|          | 257/267978 [03:03<53:05:25,  1.40it/s, v_num=full, train/loss_step=6.390]
Epoch 0:   0%|          | 258/267978 [03:04<53:02:38,  1.40it/s, v_num=full, train/loss_step=6.390]
Epoch 0:   0%|          | 258/267978 [03:04<53:02:39,  1.40it/s, v_num=full, train/loss_step=7.910]
Epoch 0:   0%|          | 259/267978 [03:04<53:00:19,  1.40it/s, v_num=full, train/loss_step=7.910]
Epoch 0:   0%|          | 259/267978 [03:04<53:00:20,  1.40it/s, v_num=full, train/loss_step=9.820]
Epoch 0:   0%|          | 260/267978 [03:05<52:57:40,  1.40it/s, v_num=full, train/loss_step=9.820]
Epoch 0:   0%|          | 260/267978 [03:05<52:57:41,  1.40it/s, v_num=full, train/loss_step=11.30]
============================================================
Global Step 260
============================================================

[Losses]
  language_loss: 0.000710 (shape: torch.Size([4, 558]), count: 28)
  route_loss: 2.033203 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.724609 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 261/267978 [03:05<52:55:00,  1.41it/s, v_num=full, train/loss_step=11.30]
Epoch 0:   0%|          | 261/267978 [03:05<52:55:00,  1.41it/s, v_num=full, train/loss_step=5.820]
Epoch 0:   0%|          | 262/267978 [03:06<52:52:21,  1.41it/s, v_num=full, train/loss_step=5.820]
Epoch 0:   0%|          | 262/267978 [03:06<52:52:22,  1.41it/s, v_num=full, train/loss_step=8.790]
Epoch 0:   0%|          | 263/267978 [03:06<52:49:43,  1.41it/s, v_num=full, train/loss_step=8.790]
Epoch 0:   0%|          | 263/267978 [03:06<52:49:44,  1.41it/s, v_num=full, train/loss_step=7.480]
Epoch 0:   0%|          | 264/267978 [03:07<52:47:10,  1.41it/s, v_num=full, train/loss_step=7.480]
Epoch 0:   0%|          | 264/267978 [03:07<52:47:11,  1.41it/s, v_num=full, train/loss_step=4.000]
Epoch 0:   0%|          | 265/267978 [03:07<52:44:37,  1.41it/s, v_num=full, train/loss_step=4.000]
Epoch 0:   0%|          | 265/267978 [03:07<52:44:38,  1.41it/s, v_num=full, train/loss_step=5.170]
Epoch 0:   0%|          | 266/267978 [03:08<52:42:04,  1.41it/s, v_num=full, train/loss_step=5.170]
Epoch 0:   0%|          | 266/267978 [03:08<52:42:05,  1.41it/s, v_num=full, train/loss_step=5.540]
Epoch 0:   0%|          | 267/267978 [03:09<52:39:31,  1.41it/s, v_num=full, train/loss_step=5.540]
Epoch 0:   0%|          | 267/267978 [03:09<52:39:32,  1.41it/s, v_num=full, train/loss_step=7.750]
Epoch 0:   0%|          | 268/267978 [03:09<52:37:00,  1.41it/s, v_num=full, train/loss_step=7.750]
Epoch 0:   0%|          | 268/267978 [03:09<52:37:00,  1.41it/s, v_num=full, train/loss_step=4.610]
Epoch 0:   0%|          | 269/267978 [03:10<52:34:17,  1.41it/s, v_num=full, train/loss_step=4.610]
Epoch 0:   0%|          | 269/267978 [03:10<52:34:18,  1.41it/s, v_num=full, train/loss_step=5.580]
Epoch 0:   0%|          | 270/267978 [03:10<52:31:45,  1.42it/s, v_num=full, train/loss_step=5.580]
Epoch 0:   0%|          | 270/267978 [03:10<52:31:46,  1.42it/s, v_num=full, train/loss_step=6.490]
============================================================
Global Step 270
============================================================

[Losses]
  language_loss: 0.001132 (shape: torch.Size([4, 547]), count: 28)
  route_loss: 2.474609 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 5.980469 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 271/267978 [03:11<52:29:22,  1.42it/s, v_num=full, train/loss_step=6.490]
Epoch 0:   0%|          | 271/267978 [03:11<52:29:22,  1.42it/s, v_num=full, train/loss_step=8.540]
Epoch 0:   0%|          | 272/267978 [03:11<52:26:55,  1.42it/s, v_num=full, train/loss_step=8.540]
Epoch 0:   0%|          | 272/267978 [03:11<52:26:55,  1.42it/s, v_num=full, train/loss_step=6.230]
Epoch 0:   0%|          | 273/267978 [03:12<52:24:31,  1.42it/s, v_num=full, train/loss_step=6.230]
Epoch 0:   0%|          | 273/267978 [03:12<52:24:32,  1.42it/s, v_num=full, train/loss_step=3.490]
Epoch 0:   0%|          | 274/267978 [03:12<52:22:11,  1.42it/s, v_num=full, train/loss_step=3.490]
Epoch 0:   0%|          | 274/267978 [03:12<52:22:12,  1.42it/s, v_num=full, train/loss_step=5.360]
Epoch 0:   0%|          | 275/267978 [03:13<52:19:44,  1.42it/s, v_num=full, train/loss_step=5.360]
Epoch 0:   0%|          | 275/267978 [03:13<52:19:44,  1.42it/s, v_num=full, train/loss_step=2.120]
Epoch 0:   0%|          | 276/267978 [03:14<52:17:16,  1.42it/s, v_num=full, train/loss_step=2.120]
Epoch 0:   0%|          | 276/267978 [03:14<52:17:17,  1.42it/s, v_num=full, train/loss_step=4.390]
Epoch 0:   0%|          | 277/267978 [03:14<52:15:02,  1.42it/s, v_num=full, train/loss_step=4.390]
Epoch 0:   0%|          | 277/267978 [03:14<52:15:03,  1.42it/s, v_num=full, train/loss_step=7.750]
Epoch 0:   0%|          | 278/267978 [03:15<52:12:48,  1.42it/s, v_num=full, train/loss_step=7.750]
Epoch 0:   0%|          | 278/267978 [03:15<52:12:48,  1.42it/s, v_num=full, train/loss_step=5.120]
Epoch 0:   0%|          | 279/267978 [03:15<52:10:26,  1.43it/s, v_num=full, train/loss_step=5.120]
Epoch 0:   0%|          | 279/267978 [03:15<52:10:27,  1.43it/s, v_num=full, train/loss_step=6.910]
Epoch 0:   0%|          | 280/267978 [03:16<52:08:09,  1.43it/s, v_num=full, train/loss_step=6.910]
Epoch 0:   0%|          | 280/267978 [03:16<52:08:10,  1.43it/s, v_num=full, train/loss_step=3.040]
============================================================
Global Step 280
============================================================

[Losses]
  language_loss: 0.000915 (shape: torch.Size([4, 556]), count: 28)
  route_loss: 1.784180 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.005859 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 281/267978 [03:16<52:05:47,  1.43it/s, v_num=full, train/loss_step=3.040]
Epoch 0:   0%|          | 281/267978 [03:16<52:05:48,  1.43it/s, v_num=full, train/loss_step=4.860]
Epoch 0:   0%|          | 282/267978 [03:17<52:03:35,  1.43it/s, v_num=full, train/loss_step=4.860]
Epoch 0:   0%|          | 282/267978 [03:17<52:03:35,  1.43it/s, v_num=full, train/loss_step=3.830]
Epoch 0:   0%|          | 283/267978 [03:17<52:01:22,  1.43it/s, v_num=full, train/loss_step=3.830]
Epoch 0:   0%|          | 283/267978 [03:17<52:01:22,  1.43it/s, v_num=full, train/loss_step=4.840]
Epoch 0:   0%|          | 284/267978 [03:18<51:59:09,  1.43it/s, v_num=full, train/loss_step=4.840]
Epoch 0:   0%|          | 284/267978 [03:18<51:59:10,  1.43it/s, v_num=full, train/loss_step=7.840]
Epoch 0:   0%|          | 285/267978 [03:19<51:56:50,  1.43it/s, v_num=full, train/loss_step=7.840]
Epoch 0:   0%|          | 285/267978 [03:19<51:56:50,  1.43it/s, v_num=full, train/loss_step=7.090]
Epoch 0:   0%|          | 286/267978 [03:19<51:54:23,  1.43it/s, v_num=full, train/loss_step=7.090]
Epoch 0:   0%|          | 286/267978 [03:19<51:54:23,  1.43it/s, v_num=full, train/loss_step=9.750]
Epoch 0:   0%|          | 287/267978 [03:20<51:52:02,  1.43it/s, v_num=full, train/loss_step=9.750]
Epoch 0:   0%|          | 287/267978 [03:20<51:52:02,  1.43it/s, v_num=full, train/loss_step=4.430]
Epoch 0:   0%|          | 288/267978 [03:20<51:49:50,  1.43it/s, v_num=full, train/loss_step=4.430]
Epoch 0:   0%|          | 288/267978 [03:20<51:49:51,  1.43it/s, v_num=full, train/loss_step=6.210]
Epoch 0:   0%|          | 289/267978 [03:21<51:47:40,  1.44it/s, v_num=full, train/loss_step=6.210]
Epoch 0:   0%|          | 289/267978 [03:21<51:47:40,  1.44it/s, v_num=full, train/loss_step=3.320]
Epoch 0:   0%|          | 290/267978 [03:21<51:45:31,  1.44it/s, v_num=full, train/loss_step=3.320]
Epoch 0:   0%|          | 290/267978 [03:21<51:45:32,  1.44it/s, v_num=full, train/loss_step=5.830]
============================================================
Global Step 290
============================================================

[Losses]
  language_loss: 0.000733 (shape: torch.Size([4, 556]), count: 28)
  route_loss: 1.281250 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.019531 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 291/267978 [03:22<51:43:31,  1.44it/s, v_num=full, train/loss_step=5.830]
Epoch 0:   0%|          | 291/267978 [03:22<51:43:32,  1.44it/s, v_num=full, train/loss_step=5.360]
Epoch 0:   0%|          | 292/267978 [03:22<51:41:26,  1.44it/s, v_num=full, train/loss_step=5.360]
Epoch 0:   0%|          | 292/267978 [03:22<51:41:27,  1.44it/s, v_num=full, train/loss_step=6.080]
Epoch 0:   0%|          | 293/267978 [03:23<51:39:20,  1.44it/s, v_num=full, train/loss_step=6.080]
Epoch 0:   0%|          | 293/267978 [03:23<51:39:21,  1.44it/s, v_num=full, train/loss_step=4.800]
Epoch 0:   0%|          | 294/267978 [03:24<51:37:16,  1.44it/s, v_num=full, train/loss_step=4.800]
Epoch 0:   0%|          | 294/267978 [03:24<51:37:17,  1.44it/s, v_num=full, train/loss_step=5.240]
Epoch 0:   0%|          | 295/267978 [03:24<51:35:33,  1.44it/s, v_num=full, train/loss_step=5.240]
Epoch 0:   0%|          | 295/267978 [03:24<51:35:34,  1.44it/s, v_num=full, train/loss_step=5.920]
Epoch 0:   0%|          | 296/267978 [03:25<51:33:55,  1.44it/s, v_num=full, train/loss_step=5.920]
Epoch 0:   0%|          | 296/267978 [03:25<51:33:56,  1.44it/s, v_num=full, train/loss_step=7.160]
Epoch 0:   0%|          | 297/267978 [03:25<51:32:05,  1.44it/s, v_num=full, train/loss_step=7.160]
Epoch 0:   0%|          | 297/267978 [03:25<51:32:05,  1.44it/s, v_num=full, train/loss_step=7.110]
Epoch 0:   0%|          | 298/267978 [03:26<51:30:15,  1.44it/s, v_num=full, train/loss_step=7.110]
Epoch 0:   0%|          | 298/267978 [03:26<51:30:16,  1.44it/s, v_num=full, train/loss_step=7.030]
Epoch 0:   0%|          | 299/267978 [03:27<51:28:40,  1.44it/s, v_num=full, train/loss_step=7.030]
Epoch 0:   0%|          | 299/267978 [03:27<51:28:41,  1.44it/s, v_num=full, train/loss_step=4.370]
Epoch 0:   0%|          | 300/267978 [03:32<52:43:24,  1.41it/s, v_num=full, train/loss_step=4.370]
Epoch 0:   0%|          | 300/267978 [03:32<52:43:24,  1.41it/s, v_num=full, train/loss_step=5.160]
============================================================
[Input Before LLM] - Global Step 300
============================================================
  Adaptor embeddings shape: torch.Size([4, 586, 896])
  Input embeddings shape: torch.Size([4, 586, 896])
  Attention mask shape: torch.Size([4, 586])
  Input dtype: torch.float16
  Adaptor embeddings range: [-31.7500, 27.3906]
  Input embeddings range: [-31.7500, 27.3906]
  Input embeddings mean: -0.0003, std: 0.7725
  Language inputs shape: torch.Size([4, 556, 896])

============================================================
Global Step 300
============================================================

[Losses]
  language_loss: 0.000881 (shape: torch.Size([4, 555]), count: 28)
  route_loss: 1.583008 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 5.699219 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 301/267978 [03:33<52:41:51,  1.41it/s, v_num=full, train/loss_step=5.160]
Epoch 0:   0%|          | 301/267978 [03:33<52:41:51,  1.41it/s, v_num=full, train/loss_step=7.350]
Epoch 0:   0%|          | 302/267978 [03:33<52:39:35,  1.41it/s, v_num=full, train/loss_step=7.350]
Epoch 0:   0%|          | 302/267978 [03:33<52:39:36,  1.41it/s, v_num=full, train/loss_step=5.290]
Epoch 0:   0%|          | 303/267978 [03:34<52:37:27,  1.41it/s, v_num=full, train/loss_step=5.290]
Epoch 0:   0%|          | 303/267978 [03:34<52:37:27,  1.41it/s, v_num=full, train/loss_step=8.440]
Epoch 0:   0%|          | 304/267978 [03:35<52:35:28,  1.41it/s, v_num=full, train/loss_step=8.440]
Epoch 0:   0%|          | 304/267978 [03:35<52:35:29,  1.41it/s, v_num=full, train/loss_step=5.090]
Epoch 0:   0%|          | 305/267978 [03:35<52:33:23,  1.41it/s, v_num=full, train/loss_step=5.090]
Epoch 0:   0%|          | 305/267978 [03:35<52:33:24,  1.41it/s, v_num=full, train/loss_step=2.960]
Epoch 0:   0%|          | 306/267978 [03:36<52:31:13,  1.42it/s, v_num=full, train/loss_step=2.960]
Epoch 0:   0%|          | 306/267978 [03:36<52:31:13,  1.42it/s, v_num=full, train/loss_step=6.230]
Epoch 0:   0%|          | 307/267978 [03:36<52:29:10,  1.42it/s, v_num=full, train/loss_step=6.230]
Epoch 0:   0%|          | 307/267978 [03:36<52:29:10,  1.42it/s, v_num=full, train/loss_step=5.990]
Epoch 0:   0%|          | 308/267978 [03:37<52:27:04,  1.42it/s, v_num=full, train/loss_step=5.990]
Epoch 0:   0%|          | 308/267978 [03:37<52:27:04,  1.42it/s, v_num=full, train/loss_step=3.630]
Epoch 0:   0%|          | 309/267978 [03:37<52:24:57,  1.42it/s, v_num=full, train/loss_step=3.630]
Epoch 0:   0%|          | 309/267978 [03:37<52:24:58,  1.42it/s, v_num=full, train/loss_step=4.570]
Epoch 0:   0%|          | 310/267978 [03:38<52:22:56,  1.42it/s, v_num=full, train/loss_step=4.570]
Epoch 0:   0%|          | 310/267978 [03:38<52:22:57,  1.42it/s, v_num=full, train/loss_step=6.750]
============================================================
Global Step 310
============================================================

[Losses]
  language_loss: 0.000778 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 1.939453 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 1.916992 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 311/267978 [03:38<52:20:55,  1.42it/s, v_num=full, train/loss_step=6.750]
Epoch 0:   0%|          | 311/267978 [03:38<52:20:55,  1.42it/s, v_num=full, train/loss_step=3.920]
Epoch 0:   0%|          | 312/267978 [03:39<52:18:44,  1.42it/s, v_num=full, train/loss_step=3.920]
Epoch 0:   0%|          | 312/267978 [03:39<52:18:45,  1.42it/s, v_num=full, train/loss_step=5.590]
Epoch 0:   0%|          | 313/267978 [03:40<52:16:42,  1.42it/s, v_num=full, train/loss_step=5.590]
Epoch 0:   0%|          | 313/267978 [03:40<52:16:43,  1.42it/s, v_num=full, train/loss_step=3.490]
Epoch 0:   0%|          | 314/267978 [03:40<52:14:55,  1.42it/s, v_num=full, train/loss_step=3.490]
Epoch 0:   0%|          | 314/267978 [03:40<52:14:56,  1.42it/s, v_num=full, train/loss_step=4.310]
Epoch 0:   0%|          | 315/267978 [03:41<52:13:04,  1.42it/s, v_num=full, train/loss_step=4.310]
Epoch 0:   0%|          | 315/267978 [03:41<52:13:04,  1.42it/s, v_num=full, train/loss_step=6.140]
Epoch 0:   0%|          | 316/267978 [03:41<52:11:17,  1.42it/s, v_num=full, train/loss_step=6.140]
Epoch 0:   0%|          | 316/267978 [03:41<52:11:17,  1.42it/s, v_num=full, train/loss_step=6.820]
Epoch 0:   0%|          | 317/267978 [03:42<52:09:19,  1.43it/s, v_num=full, train/loss_step=6.820]
Epoch 0:   0%|          | 317/267978 [03:42<52:09:20,  1.43it/s, v_num=full, train/loss_step=11.40]
Epoch 0:   0%|          | 318/267978 [03:42<52:07:33,  1.43it/s, v_num=full, train/loss_step=11.40]
Epoch 0:   0%|          | 318/267978 [03:42<52:07:33,  1.43it/s, v_num=full, train/loss_step=4.830]
Epoch 0:   0%|          | 319/267978 [03:43<52:05:28,  1.43it/s, v_num=full, train/loss_step=4.830]
Epoch 0:   0%|          | 319/267978 [03:43<52:05:29,  1.43it/s, v_num=full, train/loss_step=13.00]
Epoch 0:   0%|          | 320/267978 [03:44<52:03:24,  1.43it/s, v_num=full, train/loss_step=13.00]
Epoch 0:   0%|          | 320/267978 [03:44<52:03:24,  1.43it/s, v_num=full, train/loss_step=11.80]
============================================================
Global Step 320
============================================================

[Losses]
  language_loss: 0.001134 (shape: torch.Size([4, 553]), count: 28)
  route_loss: 1.235352 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 8.695312 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 321/267978 [03:44<52:01:26,  1.43it/s, v_num=full, train/loss_step=11.80]
Epoch 0:   0%|          | 321/267978 [03:44<52:01:26,  1.43it/s, v_num=full, train/loss_step=10.00]
Epoch 0:   0%|          | 322/267978 [03:45<51:59:30,  1.43it/s, v_num=full, train/loss_step=10.00]
Epoch 0:   0%|          | 322/267978 [03:45<51:59:30,  1.43it/s, v_num=full, train/loss_step=16.40]
Epoch 0:   0%|          | 323/267978 [03:45<51:57:38,  1.43it/s, v_num=full, train/loss_step=16.40]
Epoch 0:   0%|          | 323/267978 [03:45<51:57:38,  1.43it/s, v_num=full, train/loss_step=5.440]
Epoch 0:   0%|          | 324/267978 [03:46<51:56:05,  1.43it/s, v_num=full, train/loss_step=5.440]
Epoch 0:   0%|          | 324/267978 [03:46<51:56:06,  1.43it/s, v_num=full, train/loss_step=7.320]
Epoch 0:   0%|          | 325/267978 [03:46<51:54:22,  1.43it/s, v_num=full, train/loss_step=7.320]
Epoch 0:   0%|          | 325/267978 [03:46<51:54:23,  1.43it/s, v_num=full, train/loss_step=2.950]
Epoch 0:   0%|          | 326/267978 [03:47<51:52:32,  1.43it/s, v_num=full, train/loss_step=2.950]
Epoch 0:   0%|          | 326/267978 [03:47<51:52:33,  1.43it/s, v_num=full, train/loss_step=8.400]
Epoch 0:   0%|          | 327/267978 [03:48<51:50:58,  1.43it/s, v_num=full, train/loss_step=8.400]
Epoch 0:   0%|          | 327/267978 [03:48<51:50:59,  1.43it/s, v_num=full, train/loss_step=4.200]
Epoch 0:   0%|          | 328/267978 [03:48<51:49:06,  1.43it/s, v_num=full, train/loss_step=4.200]
Epoch 0:   0%|          | 328/267978 [03:48<51:49:06,  1.43it/s, v_num=full, train/loss_step=8.800]
Epoch 0:   0%|          | 329/267978 [03:49<51:47:07,  1.44it/s, v_num=full, train/loss_step=8.800]
Epoch 0:   0%|          | 329/267978 [03:49<51:47:07,  1.44it/s, v_num=full, train/loss_step=2.420]
Epoch 0:   0%|          | 330/267978 [03:49<51:45:12,  1.44it/s, v_num=full, train/loss_step=2.420]
Epoch 0:   0%|          | 330/267978 [03:49<51:45:13,  1.44it/s, v_num=full, train/loss_step=3.650]
============================================================
Global Step 330
============================================================

[Losses]
  language_loss: 0.000615 (shape: torch.Size([4, 553]), count: 28)
  route_loss: 1.887695 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 2.042969 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 331/267978 [03:50<51:43:32,  1.44it/s, v_num=full, train/loss_step=3.650]
Epoch 0:   0%|          | 331/267978 [03:50<51:43:33,  1.44it/s, v_num=full, train/loss_step=3.980]
Epoch 0:   0%|          | 332/267978 [03:50<51:41:41,  1.44it/s, v_num=full, train/loss_step=3.980]
Epoch 0:   0%|          | 332/267978 [03:50<51:41:42,  1.44it/s, v_num=full, train/loss_step=3.940]
Epoch 0:   0%|          | 333/267978 [03:51<51:39:52,  1.44it/s, v_num=full, train/loss_step=3.940]
Epoch 0:   0%|          | 333/267978 [03:51<51:39:53,  1.44it/s, v_num=full, train/loss_step=4.040]
Epoch 0:   0%|          | 334/267978 [03:51<51:38:04,  1.44it/s, v_num=full, train/loss_step=4.040]
Epoch 0:   0%|          | 334/267978 [03:51<51:38:04,  1.44it/s, v_num=full, train/loss_step=4.360]
Epoch 0:   0%|          | 335/267978 [03:52<51:36:13,  1.44it/s, v_num=full, train/loss_step=4.360]
Epoch 0:   0%|          | 335/267978 [03:52<51:36:14,  1.44it/s, v_num=full, train/loss_step=7.270]
Epoch 0:   0%|          | 336/267978 [03:53<51:34:19,  1.44it/s, v_num=full, train/loss_step=7.270]
Epoch 0:   0%|          | 336/267978 [03:53<51:34:19,  1.44it/s, v_num=full, train/loss_step=9.360]
Epoch 0:   0%|          | 337/267978 [03:53<51:32:26,  1.44it/s, v_num=full, train/loss_step=9.360]
Epoch 0:   0%|          | 337/267978 [03:53<51:32:27,  1.44it/s, v_num=full, train/loss_step=5.900]
Epoch 0:   0%|          | 338/267978 [03:54<51:30:44,  1.44it/s, v_num=full, train/loss_step=5.900]
Epoch 0:   0%|          | 338/267978 [03:54<51:30:45,  1.44it/s, v_num=full, train/loss_step=4.040]
Epoch 0:   0%|          | 339/267978 [03:54<51:29:01,  1.44it/s, v_num=full, train/loss_step=4.040]
Epoch 0:   0%|          | 339/267978 [03:54<51:29:02,  1.44it/s, v_num=full, train/loss_step=8.900]
Epoch 0:   0%|          | 340/267978 [03:55<51:27:10,  1.44it/s, v_num=full, train/loss_step=8.900]
Epoch 0:   0%|          | 340/267978 [03:55<51:27:11,  1.44it/s, v_num=full, train/loss_step=3.730]
============================================================
Global Step 340
============================================================

[Losses]
  language_loss: 0.001066 (shape: torch.Size([4, 547]), count: 28)
  route_loss: 1.898438 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 6.445312 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 341/267978 [03:55<51:25:31,  1.45it/s, v_num=full, train/loss_step=3.730]
Epoch 0:   0%|          | 341/267978 [03:55<51:25:32,  1.45it/s, v_num=full, train/loss_step=8.430]
Epoch 0:   0%|          | 342/267978 [03:56<51:23:35,  1.45it/s, v_num=full, train/loss_step=8.430]
Epoch 0:   0%|          | 342/267978 [03:56<51:23:36,  1.45it/s, v_num=full, train/loss_step=10.10]
Epoch 0:   0%|          | 343/267978 [03:56<51:21:51,  1.45it/s, v_num=full, train/loss_step=10.10]
Epoch 0:   0%|          | 343/267978 [03:56<51:21:51,  1.45it/s, v_num=full, train/loss_step=9.100]
Epoch 0:   0%|          | 344/267978 [03:57<51:20:09,  1.45it/s, v_num=full, train/loss_step=9.100]
Epoch 0:   0%|          | 344/267978 [03:57<51:20:10,  1.45it/s, v_num=full, train/loss_step=4.810]
Epoch 0:   0%|          | 345/267978 [03:58<51:18:27,  1.45it/s, v_num=full, train/loss_step=4.810]
Epoch 0:   0%|          | 345/267978 [03:58<51:18:27,  1.45it/s, v_num=full, train/loss_step=6.850]
Epoch 0:   0%|          | 346/267978 [03:58<51:16:39,  1.45it/s, v_num=full, train/loss_step=6.850]
Epoch 0:   0%|          | 346/267978 [03:58<51:16:40,  1.45it/s, v_num=full, train/loss_step=4.360]
Epoch 0:   0%|          | 347/267978 [03:59<51:14:53,  1.45it/s, v_num=full, train/loss_step=4.360]
Epoch 0:   0%|          | 347/267978 [03:59<51:14:54,  1.45it/s, v_num=full, train/loss_step=7.900]
Epoch 0:   0%|          | 348/267978 [03:59<51:13:13,  1.45it/s, v_num=full, train/loss_step=7.900]
Epoch 0:   0%|          | 348/267978 [03:59<51:13:14,  1.45it/s, v_num=full, train/loss_step=6.150]
Epoch 0:   0%|          | 349/267978 [04:00<51:11:31,  1.45it/s, v_num=full, train/loss_step=6.150]
Epoch 0:   0%|          | 349/267978 [04:00<51:11:31,  1.45it/s, v_num=full, train/loss_step=5.710]
Epoch 0:   0%|          | 350/267978 [04:00<51:09:52,  1.45it/s, v_num=full, train/loss_step=5.710]
Epoch 0:   0%|          | 350/267978 [04:00<51:09:52,  1.45it/s, v_num=full, train/loss_step=5.110]
============================================================
Global Step 350
============================================================

[Losses]
  language_loss: 0.001095 (shape: torch.Size([4, 555]), count: 28)
  route_loss: 1.765625 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 6.867188 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 351/267978 [04:01<51:08:20,  1.45it/s, v_num=full, train/loss_step=5.110]
Epoch 0:   0%|          | 351/267978 [04:01<51:08:21,  1.45it/s, v_num=full, train/loss_step=8.720]
Epoch 0:   0%|          | 352/267978 [04:02<51:06:47,  1.45it/s, v_num=full, train/loss_step=8.720]
Epoch 0:   0%|          | 352/267978 [04:02<51:06:48,  1.45it/s, v_num=full, train/loss_step=8.910]
Epoch 0:   0%|          | 353/267978 [04:02<51:05:08,  1.46it/s, v_num=full, train/loss_step=8.910]
Epoch 0:   0%|          | 353/267978 [04:02<51:05:09,  1.46it/s, v_num=full, train/loss_step=4.670]
Epoch 0:   0%|          | 354/267978 [04:03<51:03:28,  1.46it/s, v_num=full, train/loss_step=4.670]
Epoch 0:   0%|          | 354/267978 [04:03<51:03:29,  1.46it/s, v_num=full, train/loss_step=5.620]
Epoch 0:   0%|          | 355/267978 [04:03<51:01:50,  1.46it/s, v_num=full, train/loss_step=5.620]
Epoch 0:   0%|          | 355/267978 [04:03<51:01:50,  1.46it/s, v_num=full, train/loss_step=4.820]
Epoch 0:   0%|          | 356/267978 [04:04<51:00:09,  1.46it/s, v_num=full, train/loss_step=4.820]
Epoch 0:   0%|          | 356/267978 [04:04<51:00:09,  1.46it/s, v_num=full, train/loss_step=4.930]
Epoch 0:   0%|          | 357/267978 [04:04<50:58:32,  1.46it/s, v_num=full, train/loss_step=4.930]
Epoch 0:   0%|          | 357/267978 [04:04<50:58:32,  1.46it/s, v_num=full, train/loss_step=4.110]
Epoch 0:   0%|          | 358/267978 [04:05<50:56:55,  1.46it/s, v_num=full, train/loss_step=4.110]
Epoch 0:   0%|          | 358/267978 [04:05<50:56:55,  1.46it/s, v_num=full, train/loss_step=3.110]
Epoch 0:   0%|          | 359/267978 [04:05<50:55:16,  1.46it/s, v_num=full, train/loss_step=3.110]
Epoch 0:   0%|          | 359/267978 [04:05<50:55:17,  1.46it/s, v_num=full, train/loss_step=8.170]
Epoch 0:   0%|          | 360/267978 [04:06<50:53:38,  1.46it/s, v_num=full, train/loss_step=8.170]
Epoch 0:   0%|          | 360/267978 [04:06<50:53:38,  1.46it/s, v_num=full, train/loss_step=8.600]
============================================================
Global Step 360
============================================================

[Losses]
  language_loss: 0.001043 (shape: torch.Size([4, 547]), count: 28)
  route_loss: 3.474609 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 1.154297 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 361/267978 [04:07<50:52:03,  1.46it/s, v_num=full, train/loss_step=8.600]
Epoch 0:   0%|          | 361/267978 [04:07<50:52:03,  1.46it/s, v_num=full, train/loss_step=4.710]
Epoch 0:   0%|          | 362/267978 [04:07<50:50:24,  1.46it/s, v_num=full, train/loss_step=4.710]
Epoch 0:   0%|          | 362/267978 [04:07<50:50:24,  1.46it/s, v_num=full, train/loss_step=4.200]
Epoch 0:   0%|          | 363/267978 [04:08<50:48:47,  1.46it/s, v_num=full, train/loss_step=4.200]
Epoch 0:   0%|          | 363/267978 [04:08<50:48:47,  1.46it/s, v_num=full, train/loss_step=3.870]
Epoch 0:   0%|          | 364/267978 [04:08<50:47:14,  1.46it/s, v_num=full, train/loss_step=3.870]
Epoch 0:   0%|          | 364/267978 [04:08<50:47:14,  1.46it/s, v_num=full, train/loss_step=5.330]
Epoch 0:   0%|          | 365/267978 [04:09<50:45:41,  1.46it/s, v_num=full, train/loss_step=5.330]
Epoch 0:   0%|          | 365/267978 [04:09<50:45:42,  1.46it/s, v_num=full, train/loss_step=3.670]
Epoch 0:   0%|          | 366/267978 [04:09<50:44:10,  1.47it/s, v_num=full, train/loss_step=3.670]
Epoch 0:   0%|          | 366/267978 [04:09<50:44:10,  1.47it/s, v_num=full, train/loss_step=9.040]
Epoch 0:   0%|          | 367/267978 [04:10<50:42:32,  1.47it/s, v_num=full, train/loss_step=9.040]
Epoch 0:   0%|          | 367/267978 [04:10<50:42:32,  1.47it/s, v_num=full, train/loss_step=5.510]
Epoch 0:   0%|          | 368/267978 [04:10<50:41:00,  1.47it/s, v_num=full, train/loss_step=5.510]
Epoch 0:   0%|          | 368/267978 [04:10<50:41:01,  1.47it/s, v_num=full, train/loss_step=8.060]
Epoch 0:   0%|          | 369/267978 [04:11<50:39:31,  1.47it/s, v_num=full, train/loss_step=8.060]
Epoch 0:   0%|          | 369/267978 [04:11<50:39:31,  1.47it/s, v_num=full, train/loss_step=10.70]
Epoch 0:   0%|          | 370/267978 [04:12<50:38:05,  1.47it/s, v_num=full, train/loss_step=10.70]
Epoch 0:   0%|          | 370/267978 [04:12<50:38:05,  1.47it/s, v_num=full, train/loss_step=5.300]
============================================================
Global Step 370
============================================================

[Losses]
  language_loss: 0.000445 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 2.394531 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.796875 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 371/267978 [04:12<50:36:36,  1.47it/s, v_num=full, train/loss_step=5.300]
Epoch 0:   0%|          | 371/267978 [04:12<50:36:36,  1.47it/s, v_num=full, train/loss_step=7.230]
Epoch 0:   0%|          | 372/267978 [04:13<50:35:09,  1.47it/s, v_num=full, train/loss_step=7.230]
Epoch 0:   0%|          | 372/267978 [04:13<50:35:10,  1.47it/s, v_num=full, train/loss_step=5.450]
Epoch 0:   0%|          | 373/267978 [04:13<50:33:42,  1.47it/s, v_num=full, train/loss_step=5.450]
Epoch 0:   0%|          | 373/267978 [04:13<50:33:43,  1.47it/s, v_num=full, train/loss_step=3.830]
Epoch 0:   0%|          | 374/267978 [04:14<50:32:19,  1.47it/s, v_num=full, train/loss_step=3.830]
Epoch 0:   0%|          | 374/267978 [04:14<50:32:19,  1.47it/s, v_num=full, train/loss_step=12.20]
Epoch 0:   0%|          | 375/267978 [04:14<50:30:54,  1.47it/s, v_num=full, train/loss_step=12.20]
Epoch 0:   0%|          | 375/267978 [04:14<50:30:55,  1.47it/s, v_num=full, train/loss_step=6.220]
Epoch 0:   0%|          | 376/267978 [04:15<50:29:25,  1.47it/s, v_num=full, train/loss_step=6.220]
Epoch 0:   0%|          | 376/267978 [04:15<50:29:25,  1.47it/s, v_num=full, train/loss_step=8.230]
Epoch 0:   0%|          | 377/267978 [04:15<50:27:53,  1.47it/s, v_num=full, train/loss_step=8.230]
Epoch 0:   0%|          | 377/267978 [04:15<50:27:53,  1.47it/s, v_num=full, train/loss_step=4.120]
Epoch 0:   0%|          | 378/267978 [04:16<50:26:46,  1.47it/s, v_num=full, train/loss_step=4.120]
Epoch 0:   0%|          | 378/267978 [04:16<50:26:47,  1.47it/s, v_num=full, train/loss_step=4.800]
Epoch 0:   0%|          | 379/267978 [04:17<50:25:18,  1.47it/s, v_num=full, train/loss_step=4.800]
Epoch 0:   0%|          | 379/267978 [04:17<50:25:18,  1.47it/s, v_num=full, train/loss_step=6.350]
Epoch 0:   0%|          | 380/267978 [04:17<50:23:50,  1.47it/s, v_num=full, train/loss_step=6.350]
Epoch 0:   0%|          | 380/267978 [04:17<50:23:51,  1.47it/s, v_num=full, train/loss_step=8.230]
============================================================
Global Step 380
============================================================

[Losses]
  language_loss: 0.000484 (shape: torch.Size([4, 547]), count: 28)
  route_loss: 1.531250 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.384766 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 381/267978 [04:18<50:22:25,  1.48it/s, v_num=full, train/loss_step=8.230]
Epoch 0:   0%|          | 381/267978 [04:18<50:22:25,  1.48it/s, v_num=full, train/loss_step=4.950]
Epoch 0:   0%|          | 382/267978 [04:18<50:21:03,  1.48it/s, v_num=full, train/loss_step=4.950]
Epoch 0:   0%|          | 382/267978 [04:18<50:21:03,  1.48it/s, v_num=full, train/loss_step=6.060]
Epoch 0:   0%|          | 383/267978 [04:19<50:19:32,  1.48it/s, v_num=full, train/loss_step=6.060]
Epoch 0:   0%|          | 383/267978 [04:19<50:19:32,  1.48it/s, v_num=full, train/loss_step=6.290]
Epoch 0:   0%|          | 384/267978 [04:19<50:18:04,  1.48it/s, v_num=full, train/loss_step=6.290]
Epoch 0:   0%|          | 384/267978 [04:19<50:18:04,  1.48it/s, v_num=full, train/loss_step=7.260]
Epoch 0:   0%|          | 385/267978 [04:20<50:16:39,  1.48it/s, v_num=full, train/loss_step=7.260]
Epoch 0:   0%|          | 385/267978 [04:20<50:16:39,  1.48it/s, v_num=full, train/loss_step=11.30]
Epoch 0:   0%|          | 386/267978 [04:20<50:15:20,  1.48it/s, v_num=full, train/loss_step=11.30]
Epoch 0:   0%|          | 386/267978 [04:20<50:15:21,  1.48it/s, v_num=full, train/loss_step=8.920]
Epoch 0:   0%|          | 387/267978 [04:21<50:14:01,  1.48it/s, v_num=full, train/loss_step=8.920]
Epoch 0:   0%|          | 387/267978 [04:21<50:14:01,  1.48it/s, v_num=full, train/loss_step=6.200]
Epoch 0:   0%|          | 388/267978 [04:22<50:12:46,  1.48it/s, v_num=full, train/loss_step=6.200]
Epoch 0:   0%|          | 388/267978 [04:22<50:12:46,  1.48it/s, v_num=full, train/loss_step=5.410]
Epoch 0:   0%|          | 389/267978 [04:22<50:11:30,  1.48it/s, v_num=full, train/loss_step=5.410]
Epoch 0:   0%|          | 389/267978 [04:22<50:11:31,  1.48it/s, v_num=full, train/loss_step=5.630]
Epoch 0:   0%|          | 390/267978 [04:23<50:10:17,  1.48it/s, v_num=full, train/loss_step=5.630]
Epoch 0:   0%|          | 390/267978 [04:23<50:10:17,  1.48it/s, v_num=full, train/loss_step=4.860]
============================================================
Global Step 390
============================================================

[Losses]
  language_loss: 0.000506 (shape: torch.Size([4, 555]), count: 28)
  route_loss: 1.135742 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.308594 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 391/267978 [04:23<50:08:58,  1.48it/s, v_num=full, train/loss_step=4.860]
Epoch 0:   0%|          | 391/267978 [04:23<50:08:58,  1.48it/s, v_num=full, train/loss_step=5.480]
Epoch 0:   0%|          | 392/267978 [04:24<50:07:35,  1.48it/s, v_num=full, train/loss_step=5.480]
Epoch 0:   0%|          | 392/267978 [04:24<50:07:36,  1.48it/s, v_num=full, train/loss_step=11.10]
Epoch 0:   0%|          | 393/267978 [04:24<50:06:15,  1.48it/s, v_num=full, train/loss_step=11.10]
Epoch 0:   0%|          | 393/267978 [04:24<50:06:16,  1.48it/s, v_num=full, train/loss_step=4.090]
Epoch 0:   0%|          | 394/267978 [04:25<50:04:54,  1.48it/s, v_num=full, train/loss_step=4.090]
Epoch 0:   0%|          | 394/267978 [04:25<50:04:55,  1.48it/s, v_num=full, train/loss_step=5.520]
Epoch 0:   0%|          | 395/267978 [04:26<50:03:37,  1.48it/s, v_num=full, train/loss_step=5.520]
Epoch 0:   0%|          | 395/267978 [04:26<50:03:37,  1.48it/s, v_num=full, train/loss_step=3.740]
Epoch 0:   0%|          | 396/267978 [04:26<50:02:28,  1.49it/s, v_num=full, train/loss_step=3.740]
Epoch 0:   0%|          | 396/267978 [04:26<50:02:29,  1.49it/s, v_num=full, train/loss_step=7.850]
Epoch 0:   0%|          | 397/267978 [04:27<50:02:12,  1.49it/s, v_num=full, train/loss_step=7.850]
Epoch 0:   0%|          | 397/267978 [04:27<50:02:13,  1.49it/s, v_num=full, train/loss_step=4.400]
Epoch 0:   0%|          | 398/267978 [04:27<50:01:43,  1.49it/s, v_num=full, train/loss_step=4.400]
Epoch 0:   0%|          | 398/267978 [04:27<50:01:44,  1.49it/s, v_num=full, train/loss_step=7.560]
Epoch 0:   0%|          | 399/267978 [04:28<50:01:14,  1.49it/s, v_num=full, train/loss_step=7.560]
Epoch 0:   0%|          | 399/267978 [04:28<50:01:14,  1.49it/s, v_num=full, train/loss_step=6.250]
Epoch 0:   0%|          | 400/267978 [04:35<51:07:41,  1.45it/s, v_num=full, train/loss_step=6.250]
Epoch 0:   0%|          | 400/267978 [04:35<51:07:42,  1.45it/s, v_num=full, train/loss_step=7.540]
============================================================
[Input Before LLM] - Global Step 400
============================================================
  Adaptor embeddings shape: torch.Size([4, 588, 896])
  Input embeddings shape: torch.Size([4, 588, 896])
  Attention mask shape: torch.Size([4, 588])
  Input dtype: torch.float16
  Adaptor embeddings range: [-22.7344, 23.0156]
  Input embeddings range: [-22.7344, 23.0156]
  Input embeddings mean: -0.0002, std: 0.7661
  Language inputs shape: torch.Size([4, 558, 896])

============================================================
Global Step 400
============================================================

[Losses]
  language_loss: 0.000648 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 1.926758 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 5.167969 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 401/267978 [04:35<51:07:37,  1.45it/s, v_num=full, train/loss_step=7.540]
Epoch 0:   0%|          | 401/267978 [04:35<51:07:38,  1.45it/s, v_num=full, train/loss_step=7.140]
Epoch 0:   0%|          | 402/267978 [04:36<51:06:52,  1.45it/s, v_num=full, train/loss_step=7.140]
Epoch 0:   0%|          | 402/267978 [04:36<51:06:52,  1.45it/s, v_num=full, train/loss_step=6.980]
Epoch 0:   0%|          | 403/267978 [04:37<51:06:14,  1.45it/s, v_num=full, train/loss_step=6.980]
Epoch 0:   0%|          | 403/267978 [04:37<51:06:15,  1.45it/s, v_num=full, train/loss_step=4.590]
Epoch 0:   0%|          | 404/267978 [04:37<51:05:33,  1.45it/s, v_num=full, train/loss_step=4.590]
Epoch 0:   0%|          | 404/267978 [04:37<51:05:33,  1.45it/s, v_num=full, train/loss_step=5.460]
Epoch 0:   0%|          | 405/267978 [04:38<51:04:51,  1.46it/s, v_num=full, train/loss_step=5.460]
Epoch 0:   0%|          | 405/267978 [04:38<51:04:52,  1.46it/s, v_num=full, train/loss_step=6.990]
Epoch 0:   0%|          | 406/267978 [04:38<51:04:11,  1.46it/s, v_num=full, train/loss_step=6.990]
Epoch 0:   0%|          | 406/267978 [04:38<51:04:12,  1.46it/s, v_num=full, train/loss_step=3.190]
Epoch 0:   0%|          | 407/267978 [04:39<51:03:32,  1.46it/s, v_num=full, train/loss_step=3.190]
Epoch 0:   0%|          | 407/267978 [04:39<51:03:33,  1.46it/s, v_num=full, train/loss_step=4.040]
Epoch 0:   0%|          | 408/267978 [04:40<51:02:59,  1.46it/s, v_num=full, train/loss_step=4.040]
Epoch 0:   0%|          | 408/267978 [04:40<51:03:00,  1.46it/s, v_num=full, train/loss_step=5.140]
Epoch 0:   0%|          | 409/267978 [04:40<51:02:22,  1.46it/s, v_num=full, train/loss_step=5.140]
Epoch 0:   0%|          | 409/267978 [04:40<51:02:22,  1.46it/s, v_num=full, train/loss_step=3.690]
Epoch 0:   0%|          | 410/267978 [04:41<51:01:45,  1.46it/s, v_num=full, train/loss_step=3.690]
Epoch 0:   0%|          | 410/267978 [04:41<51:01:45,  1.46it/s, v_num=full, train/loss_step=4.050]
============================================================
Global Step 410
============================================================

[Losses]
  language_loss: 0.000651 (shape: torch.Size([4, 560]), count: 28)
  route_loss: 1.847656 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 6.062500 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 411/267978 [04:42<51:01:10,  1.46it/s, v_num=full, train/loss_step=4.050]
Epoch 0:   0%|          | 411/267978 [04:42<51:01:11,  1.46it/s, v_num=full, train/loss_step=7.960]
Epoch 0:   0%|          | 412/267978 [04:42<51:00:34,  1.46it/s, v_num=full, train/loss_step=7.960]
Epoch 0:   0%|          | 412/267978 [04:42<51:00:34,  1.46it/s, v_num=full, train/loss_step=3.710]
Epoch 0:   0%|          | 413/267978 [04:43<50:59:46,  1.46it/s, v_num=full, train/loss_step=3.710]
Epoch 0:   0%|          | 413/267978 [04:43<50:59:47,  1.46it/s, v_num=full, train/loss_step=3.700]
Epoch 0:   0%|          | 414/267978 [04:43<50:58:30,  1.46it/s, v_num=full, train/loss_step=3.700]
Epoch 0:   0%|          | 414/267978 [04:43<50:58:31,  1.46it/s, v_num=full, train/loss_step=6.410]
Epoch 0:   0%|          | 415/267978 [04:44<50:57:25,  1.46it/s, v_num=full, train/loss_step=6.410]
Epoch 0:   0%|          | 415/267978 [04:44<50:57:25,  1.46it/s, v_num=full, train/loss_step=5.090]
Epoch 0:   0%|          | 416/267978 [04:45<50:56:14,  1.46it/s, v_num=full, train/loss_step=5.090]
Epoch 0:   0%|          | 416/267978 [04:45<50:56:14,  1.46it/s, v_num=full, train/loss_step=4.800]
Epoch 0:   0%|          | 417/267978 [04:45<50:55:19,  1.46it/s, v_num=full, train/loss_step=4.800]
Epoch 0:   0%|          | 417/267978 [04:45<50:55:19,  1.46it/s, v_num=full, train/loss_step=4.910]
Epoch 0:   0%|          | 418/267978 [04:46<50:54:26,  1.46it/s, v_num=full, train/loss_step=4.910]
Epoch 0:   0%|          | 418/267978 [04:46<50:54:26,  1.46it/s, v_num=full, train/loss_step=7.940]
Epoch 0:   0%|          | 419/267978 [04:46<50:53:36,  1.46it/s, v_num=full, train/loss_step=7.940]
Epoch 0:   0%|          | 419/267978 [04:46<50:53:36,  1.46it/s, v_num=full, train/loss_step=10.10]
Epoch 0:   0%|          | 420/267978 [04:47<50:52:42,  1.46it/s, v_num=full, train/loss_step=10.10]
Epoch 0:   0%|          | 420/267978 [04:47<50:52:43,  1.46it/s, v_num=full, train/loss_step=6.520]
============================================================
Global Step 420
============================================================

[Losses]
  language_loss: 0.000681 (shape: torch.Size([4, 558]), count: 28)
  route_loss: 2.574219 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.261719 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 421/267978 [04:48<50:51:49,  1.46it/s, v_num=full, train/loss_step=6.520]
Epoch 0:   0%|          | 421/267978 [04:48<50:51:50,  1.46it/s, v_num=full, train/loss_step=6.890]
Epoch 0:   0%|          | 422/267978 [04:48<50:50:56,  1.46it/s, v_num=full, train/loss_step=6.890]
Epoch 0:   0%|          | 422/267978 [04:48<50:50:56,  1.46it/s, v_num=full, train/loss_step=5.640]
Epoch 0:   0%|          | 423/267978 [04:49<50:50:03,  1.46it/s, v_num=full, train/loss_step=5.640]
Epoch 0:   0%|          | 423/267978 [04:49<50:50:04,  1.46it/s, v_num=full, train/loss_step=3.940]
Epoch 0:   0%|          | 424/267978 [04:49<50:49:08,  1.46it/s, v_num=full, train/loss_step=3.940]
Epoch 0:   0%|          | 424/267978 [04:49<50:49:09,  1.46it/s, v_num=full, train/loss_step=6.980]
Epoch 0:   0%|          | 425/267978 [04:50<50:48:09,  1.46it/s, v_num=full, train/loss_step=6.980]
Epoch 0:   0%|          | 425/267978 [04:50<50:48:10,  1.46it/s, v_num=full, train/loss_step=9.980]
Epoch 0:   0%|          | 426/267978 [04:51<50:47:22,  1.46it/s, v_num=full, train/loss_step=9.980]
Epoch 0:   0%|          | 426/267978 [04:51<50:47:23,  1.46it/s, v_num=full, train/loss_step=4.680]
Epoch 0:   0%|          | 427/267978 [04:51<50:46:34,  1.46it/s, v_num=full, train/loss_step=4.680]
Epoch 0:   0%|          | 427/267978 [04:51<50:46:35,  1.46it/s, v_num=full, train/loss_step=5.940]
Epoch 0:   0%|          | 428/267978 [04:52<50:45:39,  1.46it/s, v_num=full, train/loss_step=5.940]
Epoch 0:   0%|          | 428/267978 [04:52<50:45:40,  1.46it/s, v_num=full, train/loss_step=5.680]
Epoch 0:   0%|          | 429/267978 [04:52<50:44:45,  1.46it/s, v_num=full, train/loss_step=5.680]
Epoch 0:   0%|          | 429/267978 [04:52<50:44:45,  1.46it/s, v_num=full, train/loss_step=2.620]
Epoch 0:   0%|          | 430/267978 [04:53<50:43:53,  1.46it/s, v_num=full, train/loss_step=2.620]
Epoch 0:   0%|          | 430/267978 [04:53<50:43:53,  1.46it/s, v_num=full, train/loss_step=5.610]
============================================================
Global Step 430
============================================================

[Losses]
  language_loss: 0.000489 (shape: torch.Size([4, 561]), count: 28)
  route_loss: 2.097656 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 1.804688 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 431/267978 [04:54<50:42:58,  1.47it/s, v_num=full, train/loss_step=5.610]
Epoch 0:   0%|          | 431/267978 [04:54<50:42:59,  1.47it/s, v_num=full, train/loss_step=3.940]
Epoch 0:   0%|          | 432/267978 [04:54<50:42:05,  1.47it/s, v_num=full, train/loss_step=3.940]
Epoch 0:   0%|          | 432/267978 [04:54<50:42:05,  1.47it/s, v_num=full, train/loss_step=9.980]
Epoch 0:   0%|          | 433/267978 [04:55<50:41:12,  1.47it/s, v_num=full, train/loss_step=9.980]
Epoch 0:   0%|          | 433/267978 [04:55<50:41:13,  1.47it/s, v_num=full, train/loss_step=11.40]
Epoch 0:   0%|          | 434/267978 [04:55<50:40:21,  1.47it/s, v_num=full, train/loss_step=11.40]
Epoch 0:   0%|          | 434/267978 [04:55<50:40:22,  1.47it/s, v_num=full, train/loss_step=8.270]
Epoch 0:   0%|          | 435/267978 [04:56<50:39:34,  1.47it/s, v_num=full, train/loss_step=8.270]
Epoch 0:   0%|          | 435/267978 [04:56<50:39:35,  1.47it/s, v_num=full, train/loss_step=5.380]
Epoch 0:   0%|          | 436/267978 [04:57<50:38:45,  1.47it/s, v_num=full, train/loss_step=5.380]
Epoch 0:   0%|          | 436/267978 [04:57<50:38:46,  1.47it/s, v_num=full, train/loss_step=4.060]
Epoch 0:   0%|          | 437/267978 [04:57<50:37:55,  1.47it/s, v_num=full, train/loss_step=4.060]
Epoch 0:   0%|          | 437/267978 [04:57<50:37:56,  1.47it/s, v_num=full, train/loss_step=3.860]
Epoch 0:   0%|          | 438/267978 [04:58<50:37:04,  1.47it/s, v_num=full, train/loss_step=3.860]
Epoch 0:   0%|          | 438/267978 [04:58<50:37:05,  1.47it/s, v_num=full, train/loss_step=1.750]
Epoch 0:   0%|          | 439/267978 [04:58<50:36:20,  1.47it/s, v_num=full, train/loss_step=1.750]
Epoch 0:   0%|          | 439/267978 [04:58<50:36:21,  1.47it/s, v_num=full, train/loss_step=3.740]
Epoch 0:   0%|          | 440/267978 [04:59<50:35:28,  1.47it/s, v_num=full, train/loss_step=3.740]
Epoch 0:   0%|          | 440/267978 [04:59<50:35:28,  1.47it/s, v_num=full, train/loss_step=6.950]
============================================================
Global Step 440
============================================================

[Losses]
  language_loss: 0.000484 (shape: torch.Size([4, 558]), count: 28)
  route_loss: 0.560547 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.951172 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 441/267978 [05:00<50:34:41,  1.47it/s, v_num=full, train/loss_step=6.950]
Epoch 0:   0%|          | 441/267978 [05:00<50:34:42,  1.47it/s, v_num=full, train/loss_step=4.550]
Epoch 0:   0%|          | 442/267978 [05:00<50:34:01,  1.47it/s, v_num=full, train/loss_step=4.550]
Epoch 0:   0%|          | 442/267978 [05:00<50:34:02,  1.47it/s, v_num=full, train/loss_step=4.040]
Epoch 0:   0%|          | 443/267978 [05:01<50:33:19,  1.47it/s, v_num=full, train/loss_step=4.040]
Epoch 0:   0%|          | 443/267978 [05:01<50:33:19,  1.47it/s, v_num=full, train/loss_step=6.370]
Epoch 0:   0%|          | 444/267978 [05:01<50:32:34,  1.47it/s, v_num=full, train/loss_step=6.370]
Epoch 0:   0%|          | 444/267978 [05:01<50:32:34,  1.47it/s, v_num=full, train/loss_step=5.260]
Epoch 0:   0%|          | 445/267978 [05:02<50:31:53,  1.47it/s, v_num=full, train/loss_step=5.260]
Epoch 0:   0%|          | 445/267978 [05:02<50:31:53,  1.47it/s, v_num=full, train/loss_step=4.520]
Epoch 0:   0%|          | 446/267978 [05:03<50:31:19,  1.47it/s, v_num=full, train/loss_step=4.520]
Epoch 0:   0%|          | 446/267978 [05:03<50:31:19,  1.47it/s, v_num=full, train/loss_step=3.310]
Epoch 0:   0%|          | 447/267978 [05:03<50:30:34,  1.47it/s, v_num=full, train/loss_step=3.310]
Epoch 0:   0%|          | 447/267978 [05:03<50:30:35,  1.47it/s, v_num=full, train/loss_step=3.380]
Epoch 0:   0%|          | 448/267978 [05:04<50:29:56,  1.47it/s, v_num=full, train/loss_step=3.380]
Epoch 0:   0%|          | 448/267978 [05:04<50:29:57,  1.47it/s, v_num=full, train/loss_step=5.250]
Epoch 0:   0%|          | 449/267978 [05:05<50:29:19,  1.47it/s, v_num=full, train/loss_step=5.250]
Epoch 0:   0%|          | 449/267978 [05:05<50:29:19,  1.47it/s, v_num=full, train/loss_step=13.50]
Epoch 0:   0%|          | 450/267978 [05:05<50:28:34,  1.47it/s, v_num=full, train/loss_step=13.50]
Epoch 0:   0%|          | 450/267978 [05:05<50:28:35,  1.47it/s, v_num=full, train/loss_step=4.420]
============================================================
Global Step 450
============================================================

[Losses]
  language_loss: 0.000578 (shape: torch.Size([4, 561]), count: 28)
  route_loss: 1.791016 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 2.890625 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 451/267978 [05:06<50:27:56,  1.47it/s, v_num=full, train/loss_step=4.420]
Epoch 0:   0%|          | 451/267978 [05:06<50:27:57,  1.47it/s, v_num=full, train/loss_step=4.730]
Epoch 0:   0%|          | 452/267978 [05:06<50:27:18,  1.47it/s, v_num=full, train/loss_step=4.730]
Epoch 0:   0%|          | 452/267978 [05:06<50:27:19,  1.47it/s, v_num=full, train/loss_step=4.670]
Epoch 0:   0%|          | 453/267978 [05:07<50:26:35,  1.47it/s, v_num=full, train/loss_step=4.670]
Epoch 0:   0%|          | 453/267978 [05:07<50:26:35,  1.47it/s, v_num=full, train/loss_step=6.040]
Epoch 0:   0%|          | 454/267978 [05:08<50:25:51,  1.47it/s, v_num=full, train/loss_step=6.040]
Epoch 0:   0%|          | 454/267978 [05:08<50:25:51,  1.47it/s, v_num=full, train/loss_step=4.900]
Epoch 0:   0%|          | 455/267978 [05:08<50:25:12,  1.47it/s, v_num=full, train/loss_step=4.900]
Epoch 0:   0%|          | 455/267978 [05:08<50:25:13,  1.47it/s, v_num=full, train/loss_step=3.340]
Epoch 0:   0%|          | 456/267978 [05:09<50:24:28,  1.47it/s, v_num=full, train/loss_step=3.340]
Epoch 0:   0%|          | 456/267978 [05:09<50:24:28,  1.47it/s, v_num=full, train/loss_step=2.770]
Epoch 0:   0%|          | 457/267978 [05:09<50:23:45,  1.47it/s, v_num=full, train/loss_step=2.770]
Epoch 0:   0%|          | 457/267978 [05:09<50:23:45,  1.47it/s, v_num=full, train/loss_step=5.700]
Epoch 0:   0%|          | 458/267978 [05:10<50:23:03,  1.47it/s, v_num=full, train/loss_step=5.700]
Epoch 0:   0%|          | 458/267978 [05:10<50:23:03,  1.47it/s, v_num=full, train/loss_step=4.850]
Epoch 0:   0%|          | 459/267978 [05:11<50:22:22,  1.48it/s, v_num=full, train/loss_step=4.850]
Epoch 0:   0%|          | 459/267978 [05:11<50:22:23,  1.48it/s, v_num=full, train/loss_step=5.080]
Epoch 0:   0%|          | 460/267978 [05:11<50:21:38,  1.48it/s, v_num=full, train/loss_step=5.080]
Epoch 0:   0%|          | 460/267978 [05:11<50:21:39,  1.48it/s, v_num=full, train/loss_step=5.850]
============================================================
Global Step 460
============================================================

[Losses]
  language_loss: 0.000505 (shape: torch.Size([4, 556]), count: 28)
  route_loss: 3.251953 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 8.265625 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 461/267978 [05:12<50:20:59,  1.48it/s, v_num=full, train/loss_step=5.850]
Epoch 0:   0%|          | 461/267978 [05:12<50:21:00,  1.48it/s, v_num=full, train/loss_step=11.60]
Epoch 0:   0%|          | 462/267978 [05:12<50:20:17,  1.48it/s, v_num=full, train/loss_step=11.60]
Epoch 0:   0%|          | 462/267978 [05:12<50:20:17,  1.48it/s, v_num=full, train/loss_step=7.430]
Epoch 0:   0%|          | 463/267978 [05:13<50:19:38,  1.48it/s, v_num=full, train/loss_step=7.430]
Epoch 0:   0%|          | 463/267978 [05:13<50:19:39,  1.48it/s, v_num=full, train/loss_step=4.830]
Epoch 0:   0%|          | 464/267978 [05:14<50:18:51,  1.48it/s, v_num=full, train/loss_step=4.830]
Epoch 0:   0%|          | 464/267978 [05:14<50:18:51,  1.48it/s, v_num=full, train/loss_step=2.730]
Epoch 0:   0%|          | 465/267978 [05:14<50:18:14,  1.48it/s, v_num=full, train/loss_step=2.730]
Epoch 0:   0%|          | 465/267978 [05:14<50:18:15,  1.48it/s, v_num=full, train/loss_step=3.380]
Epoch 0:   0%|          | 466/267978 [05:15<50:17:35,  1.48it/s, v_num=full, train/loss_step=3.380]
Epoch 0:   0%|          | 466/267978 [05:15<50:17:36,  1.48it/s, v_num=full, train/loss_step=5.390]
Epoch 0:   0%|          | 467/267978 [05:16<50:17:01,  1.48it/s, v_num=full, train/loss_step=5.390]
Epoch 0:   0%|          | 467/267978 [05:16<50:17:01,  1.48it/s, v_num=full, train/loss_step=6.050]
Epoch 0:   0%|          | 468/267978 [05:16<50:16:21,  1.48it/s, v_num=full, train/loss_step=6.050]
Epoch 0:   0%|          | 468/267978 [05:16<50:16:21,  1.48it/s, v_num=full, train/loss_step=6.380]
Epoch 0:   0%|          | 469/267978 [05:17<50:15:39,  1.48it/s, v_num=full, train/loss_step=6.380]
Epoch 0:   0%|          | 469/267978 [05:17<50:15:40,  1.48it/s, v_num=full, train/loss_step=5.500]
Epoch 0:   0%|          | 470/267978 [05:17<50:14:57,  1.48it/s, v_num=full, train/loss_step=5.500]
Epoch 0:   0%|          | 470/267978 [05:17<50:14:57,  1.48it/s, v_num=full, train/loss_step=4.750]
============================================================
Global Step 470
============================================================

[Losses]
  language_loss: 0.000689 (shape: torch.Size([4, 551]), count: 28)
  route_loss: 1.660156 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 1.915039 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 471/267978 [05:18<50:14:18,  1.48it/s, v_num=full, train/loss_step=4.750]
Epoch 0:   0%|          | 471/267978 [05:18<50:14:19,  1.48it/s, v_num=full, train/loss_step=3.630]
Epoch 0:   0%|          | 472/267978 [05:19<50:13:41,  1.48it/s, v_num=full, train/loss_step=3.630]
Epoch 0:   0%|          | 472/267978 [05:19<50:13:41,  1.48it/s, v_num=full, train/loss_step=4.580]
Epoch 0:   0%|          | 473/267978 [05:19<50:13:02,  1.48it/s, v_num=full, train/loss_step=4.580]
Epoch 0:   0%|          | 473/267978 [05:19<50:13:02,  1.48it/s, v_num=full, train/loss_step=7.700]
Epoch 0:   0%|          | 474/267978 [05:20<50:12:25,  1.48it/s, v_num=full, train/loss_step=7.700]
Epoch 0:   0%|          | 474/267978 [05:20<50:12:25,  1.48it/s, v_num=full, train/loss_step=5.070]
Epoch 0:   0%|          | 475/267978 [05:20<50:11:52,  1.48it/s, v_num=full, train/loss_step=5.070]
Epoch 0:   0%|          | 475/267978 [05:20<50:11:53,  1.48it/s, v_num=full, train/loss_step=4.650]
Epoch 0:   0%|          | 476/267978 [05:21<50:11:18,  1.48it/s, v_num=full, train/loss_step=4.650]
Epoch 0:   0%|          | 476/267978 [05:21<50:11:19,  1.48it/s, v_num=full, train/loss_step=2.500]
Epoch 0:   0%|          | 477/267978 [05:22<50:10:39,  1.48it/s, v_num=full, train/loss_step=2.500]
Epoch 0:   0%|          | 477/267978 [05:22<50:10:39,  1.48it/s, v_num=full, train/loss_step=4.460]
Epoch 0:   0%|          | 478/267978 [05:22<50:09:59,  1.48it/s, v_num=full, train/loss_step=4.460]
Epoch 0:   0%|          | 478/267978 [05:22<50:10:00,  1.48it/s, v_num=full, train/loss_step=4.040]
Epoch 0:   0%|          | 479/267978 [05:23<50:09:21,  1.48it/s, v_num=full, train/loss_step=4.040]
Epoch 0:   0%|          | 479/267978 [05:23<50:09:21,  1.48it/s, v_num=full, train/loss_step=4.390]
Epoch 0:   0%|          | 480/267978 [05:23<50:08:47,  1.48it/s, v_num=full, train/loss_step=4.390]
Epoch 0:   0%|          | 480/267978 [05:23<50:08:47,  1.48it/s, v_num=full, train/loss_step=2.740]
============================================================
Global Step 480
============================================================

[Losses]
  language_loss: 0.000825 (shape: torch.Size([4, 553]), count: 28)
  route_loss: 0.177490 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 5.292969 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 481/267978 [05:24<50:08:14,  1.48it/s, v_num=full, train/loss_step=2.740]
Epoch 0:   0%|          | 481/267978 [05:24<50:08:15,  1.48it/s, v_num=full, train/loss_step=5.530]
Epoch 0:   0%|          | 482/267978 [05:25<50:07:40,  1.48it/s, v_num=full, train/loss_step=5.530]
Epoch 0:   0%|          | 482/267978 [05:25<50:07:41,  1.48it/s, v_num=full, train/loss_step=3.540]
Epoch 0:   0%|          | 483/267978 [05:25<50:06:59,  1.48it/s, v_num=full, train/loss_step=3.540]
Epoch 0:   0%|          | 483/267978 [05:25<50:07:00,  1.48it/s, v_num=full, train/loss_step=5.730]
Epoch 0:   0%|          | 484/267978 [05:26<50:06:21,  1.48it/s, v_num=full, train/loss_step=5.730]
Epoch 0:   0%|          | 484/267978 [05:26<50:06:22,  1.48it/s, v_num=full, train/loss_step=9.180]
Epoch 0:   0%|          | 485/267978 [05:26<50:05:47,  1.48it/s, v_num=full, train/loss_step=9.180]
Epoch 0:   0%|          | 485/267978 [05:26<50:05:47,  1.48it/s, v_num=full, train/loss_step=11.10]
Epoch 0:   0%|          | 486/267978 [05:27<50:05:05,  1.48it/s, v_num=full, train/loss_step=11.10]
Epoch 0:   0%|          | 486/267978 [05:27<50:05:05,  1.48it/s, v_num=full, train/loss_step=5.620]
Epoch 0:   0%|          | 487/267978 [05:28<50:04:20,  1.48it/s, v_num=full, train/loss_step=5.620]
Epoch 0:   0%|          | 487/267978 [05:28<50:04:20,  1.48it/s, v_num=full, train/loss_step=5.990]
Epoch 0:   0%|          | 488/267978 [05:28<50:03:44,  1.48it/s, v_num=full, train/loss_step=5.990]
Epoch 0:   0%|          | 488/267978 [05:28<50:03:45,  1.48it/s, v_num=full, train/loss_step=3.380]
Epoch 0:   0%|          | 489/267978 [05:29<50:03:07,  1.48it/s, v_num=full, train/loss_step=3.380]
Epoch 0:   0%|          | 489/267978 [05:29<50:03:08,  1.48it/s, v_num=full, train/loss_step=3.650]
Epoch 0:   0%|          | 490/267978 [05:30<50:02:32,  1.48it/s, v_num=full, train/loss_step=3.650]
Epoch 0:   0%|          | 490/267978 [05:30<50:02:33,  1.48it/s, v_num=full, train/loss_step=3.610]
============================================================
Global Step 490
============================================================

[Losses]
  language_loss: 0.000355 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 0.641602 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.859375 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 491/267978 [05:30<50:02:01,  1.49it/s, v_num=full, train/loss_step=3.610]
Epoch 0:   0%|          | 491/267978 [05:30<50:02:02,  1.49it/s, v_num=full, train/loss_step=5.530]
Epoch 0:   0%|          | 492/267978 [05:31<50:01:24,  1.49it/s, v_num=full, train/loss_step=5.530]
Epoch 0:   0%|          | 492/267978 [05:31<50:01:25,  1.49it/s, v_num=full, train/loss_step=10.80]
Epoch 0:   0%|          | 493/267978 [05:31<50:00:47,  1.49it/s, v_num=full, train/loss_step=10.80]
Epoch 0:   0%|          | 493/267978 [05:31<50:00:47,  1.49it/s, v_num=full, train/loss_step=8.590]
Epoch 0:   0%|          | 494/267978 [05:32<50:00:11,  1.49it/s, v_num=full, train/loss_step=8.590]
Epoch 0:   0%|          | 494/267978 [05:32<50:00:12,  1.49it/s, v_num=full, train/loss_step=8.560]
Epoch 0:   0%|          | 495/267978 [05:33<49:59:37,  1.49it/s, v_num=full, train/loss_step=8.560]
Epoch 0:   0%|          | 495/267978 [05:33<49:59:37,  1.49it/s, v_num=full, train/loss_step=7.820]
Epoch 0:   0%|          | 496/267978 [05:33<49:59:02,  1.49it/s, v_num=full, train/loss_step=7.820]
Epoch 0:   0%|          | 496/267978 [05:33<49:59:03,  1.49it/s, v_num=full, train/loss_step=3.960]
Epoch 0:   0%|          | 497/267978 [05:34<49:58:28,  1.49it/s, v_num=full, train/loss_step=3.960]
Epoch 0:   0%|          | 497/267978 [05:34<49:58:29,  1.49it/s, v_num=full, train/loss_step=4.250]
Epoch 0:   0%|          | 498/267978 [05:34<49:57:53,  1.49it/s, v_num=full, train/loss_step=4.250]
Epoch 0:   0%|          | 498/267978 [05:34<49:57:53,  1.49it/s, v_num=full, train/loss_step=10.90]
Epoch 0:   0%|          | 499/267978 [05:35<49:57:21,  1.49it/s, v_num=full, train/loss_step=10.90]
Epoch 0:   0%|          | 499/267978 [05:35<49:57:22,  1.49it/s, v_num=full, train/loss_step=5.970]
Epoch 0:   0%|          | 500/267978 [05:42<50:49:27,  1.46it/s, v_num=full, train/loss_step=5.970]
Epoch 0:   0%|          | 500/267978 [05:42<50:49:27,  1.46it/s, v_num=full, train/loss_step=5.850]
============================================================
[Input Before LLM] - Global Step 500
============================================================
  Adaptor embeddings shape: torch.Size([4, 588, 896])
  Input embeddings shape: torch.Size([4, 588, 896])
  Attention mask shape: torch.Size([4, 588])
  Input dtype: torch.float16
  Adaptor embeddings range: [-22.9375, 24.2500]
  Input embeddings range: [-22.9375, 24.2500]
  Input embeddings mean: 0.0000, std: 0.7778
  Language inputs shape: torch.Size([4, 558, 896])

============================================================
Global Step 500
============================================================

[Losses]
  language_loss: 0.000419 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 1.578125 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 9.164062 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 501/267978 [05:42<50:49:22,  1.46it/s, v_num=full, train/loss_step=5.850]
Epoch 0:   0%|          | 501/267978 [05:42<50:49:23,  1.46it/s, v_num=full, train/loss_step=10.80]
Epoch 0:   0%|          | 502/267978 [05:43<50:48:49,  1.46it/s, v_num=full, train/loss_step=10.80]
Epoch 0:   0%|          | 502/267978 [05:43<50:48:49,  1.46it/s, v_num=full, train/loss_step=7.810]
Epoch 0:   0%|          | 503/267978 [05:43<50:48:11,  1.46it/s, v_num=full, train/loss_step=7.810]
Epoch 0:   0%|          | 503/267978 [05:43<50:48:12,  1.46it/s, v_num=full, train/loss_step=6.700]
Epoch 0:   0%|          | 504/267978 [05:44<50:47:27,  1.46it/s, v_num=full, train/loss_step=6.700]
Epoch 0:   0%|          | 504/267978 [05:44<50:47:28,  1.46it/s, v_num=full, train/loss_step=8.040]
Epoch 0:   0%|          | 505/267978 [05:45<50:46:46,  1.46it/s, v_num=full, train/loss_step=8.040]
Epoch 0:   0%|          | 505/267978 [05:45<50:46:46,  1.46it/s, v_num=full, train/loss_step=10.10]
Epoch 0:   0%|          | 506/267978 [05:45<50:46:03,  1.46it/s, v_num=full, train/loss_step=10.10]
Epoch 0:   0%|          | 506/267978 [05:45<50:46:04,  1.46it/s, v_num=full, train/loss_step=3.780]
Epoch 0:   0%|          | 507/267978 [05:46<50:45:28,  1.46it/s, v_num=full, train/loss_step=3.780]
Epoch 0:   0%|          | 507/267978 [05:46<50:45:28,  1.46it/s, v_num=full, train/loss_step=7.180]
Epoch 0:   0%|          | 508/267978 [05:46<50:44:49,  1.46it/s, v_num=full, train/loss_step=7.180]
Epoch 0:   0%|          | 508/267978 [05:46<50:44:50,  1.46it/s, v_num=full, train/loss_step=9.790]
Epoch 0:   0%|          | 509/267978 [05:47<50:44:06,  1.46it/s, v_num=full, train/loss_step=9.790]
Epoch 0:   0%|          | 509/267978 [05:47<50:44:06,  1.46it/s, v_num=full, train/loss_step=7.210]
Epoch 0:   0%|          | 510/267978 [05:48<50:43:26,  1.46it/s, v_num=full, train/loss_step=7.210]
Epoch 0:   0%|          | 510/267978 [05:48<50:43:27,  1.46it/s, v_num=full, train/loss_step=6.010]
============================================================
Global Step 510
============================================================

[Losses]
  language_loss: 0.000419 (shape: torch.Size([4, 555]), count: 28)
  route_loss: 1.570312 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.160156 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 511/267978 [05:48<50:42:51,  1.46it/s, v_num=full, train/loss_step=6.010]
Epoch 0:   0%|          | 511/267978 [05:48<50:42:52,  1.46it/s, v_num=full, train/loss_step=4.770]
Epoch 0:   0%|          | 512/267978 [05:49<50:42:10,  1.47it/s, v_num=full, train/loss_step=4.770]
Epoch 0:   0%|          | 512/267978 [05:49<50:42:11,  1.47it/s, v_num=full, train/loss_step=7.290]
Epoch 0:   0%|          | 513/267978 [05:50<50:41:44,  1.47it/s, v_num=full, train/loss_step=7.290]
Epoch 0:   0%|          | 513/267978 [05:50<50:41:44,  1.47it/s, v_num=full, train/loss_step=8.380]
Epoch 0:   0%|          | 514/267978 [05:50<50:41:02,  1.47it/s, v_num=full, train/loss_step=8.380]
Epoch 0:   0%|          | 514/267978 [05:50<50:41:03,  1.47it/s, v_num=full, train/loss_step=3.470]
Epoch 0:   0%|          | 515/267978 [05:51<50:40:24,  1.47it/s, v_num=full, train/loss_step=3.470]
Epoch 0:   0%|          | 515/267978 [05:51<50:40:24,  1.47it/s, v_num=full, train/loss_step=12.80]
Epoch 0:   0%|          | 516/267978 [05:51<50:39:45,  1.47it/s, v_num=full, train/loss_step=12.80]
Epoch 0:   0%|          | 516/267978 [05:51<50:39:45,  1.47it/s, v_num=full, train/loss_step=4.570]
Epoch 0:   0%|          | 517/267978 [05:52<50:39:08,  1.47it/s, v_num=full, train/loss_step=4.570]
Epoch 0:   0%|          | 517/267978 [05:52<50:39:08,  1.47it/s, v_num=full, train/loss_step=9.590]
Epoch 0:   0%|          | 518/267978 [05:53<50:38:33,  1.47it/s, v_num=full, train/loss_step=9.590]
Epoch 0:   0%|          | 518/267978 [05:53<50:38:33,  1.47it/s, v_num=full, train/loss_step=5.920]
Epoch 0:   0%|          | 519/267978 [05:53<50:37:53,  1.47it/s, v_num=full, train/loss_step=5.920]
Epoch 0:   0%|          | 519/267978 [05:53<50:37:53,  1.47it/s, v_num=full, train/loss_step=7.110]
Epoch 0:   0%|          | 520/267978 [05:54<50:37:15,  1.47it/s, v_num=full, train/loss_step=7.110]
Epoch 0:   0%|          | 520/267978 [05:54<50:37:16,  1.47it/s, v_num=full, train/loss_step=5.420]
============================================================
Global Step 520
============================================================

[Losses]
  language_loss: 0.000596 (shape: torch.Size([4, 551]), count: 28)
  route_loss: 2.310547 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.673828 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 521/267978 [05:54<50:36:44,  1.47it/s, v_num=full, train/loss_step=5.420]
Epoch 0:   0%|          | 521/267978 [05:54<50:36:44,  1.47it/s, v_num=full, train/loss_step=6.030]
Epoch 0:   0%|          | 522/267978 [05:55<50:36:05,  1.47it/s, v_num=full, train/loss_step=6.030]
Epoch 0:   0%|          | 522/267978 [05:55<50:36:05,  1.47it/s, v_num=full, train/loss_step=4.430]
Epoch 0:   0%|          | 523/267978 [05:56<50:35:32,  1.47it/s, v_num=full, train/loss_step=4.430]
Epoch 0:   0%|          | 523/267978 [05:56<50:35:33,  1.47it/s, v_num=full, train/loss_step=6.360]
Epoch 0:   0%|          | 524/267978 [05:56<50:34:49,  1.47it/s, v_num=full, train/loss_step=6.360]
Epoch 0:   0%|          | 524/267978 [05:56<50:34:50,  1.47it/s, v_num=full, train/loss_step=5.610]
Epoch 0:   0%|          | 525/267978 [05:57<50:34:08,  1.47it/s, v_num=full, train/loss_step=5.610]
Epoch 0:   0%|          | 525/267978 [05:57<50:34:09,  1.47it/s, v_num=full, train/loss_step=8.340]
Epoch 0:   0%|          | 526/267978 [05:57<50:33:30,  1.47it/s, v_num=full, train/loss_step=8.340]
Epoch 0:   0%|          | 526/267978 [05:57<50:33:31,  1.47it/s, v_num=full, train/loss_step=9.210]
Epoch 0:   0%|          | 527/267978 [05:58<50:32:49,  1.47it/s, v_num=full, train/loss_step=9.210]
Epoch 0:   0%|          | 527/267978 [05:58<50:32:50,  1.47it/s, v_num=full, train/loss_step=3.530]
Epoch 0:   0%|          | 528/267978 [05:59<50:32:12,  1.47it/s, v_num=full, train/loss_step=3.530]
Epoch 0:   0%|          | 528/267978 [05:59<50:32:12,  1.47it/s, v_num=full, train/loss_step=5.340]
Epoch 0:   0%|          | 529/267978 [05:59<50:31:41,  1.47it/s, v_num=full, train/loss_step=5.340]
Epoch 0:   0%|          | 529/267978 [05:59<50:31:41,  1.47it/s, v_num=full, train/loss_step=3.830]
Epoch 0:   0%|          | 530/267978 [06:00<50:31:03,  1.47it/s, v_num=full, train/loss_step=3.830]
Epoch 0:   0%|          | 530/267978 [06:00<50:31:03,  1.47it/s, v_num=full, train/loss_step=6.520]
============================================================
Global Step 530
============================================================

[Losses]
  language_loss: 0.000543 (shape: torch.Size([4, 560]), count: 28)
  route_loss: 1.370117 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.744141 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 531/267978 [06:01<50:30:24,  1.47it/s, v_num=full, train/loss_step=6.520]
Epoch 0:   0%|          | 531/267978 [06:01<50:30:24,  1.47it/s, v_num=full, train/loss_step=5.160]
Epoch 0:   0%|          | 532/267978 [06:01<50:29:50,  1.47it/s, v_num=full, train/loss_step=5.160]
Epoch 0:   0%|          | 532/267978 [06:01<50:29:51,  1.47it/s, v_num=full, train/loss_step=4.200]
Epoch 0:   0%|          | 533/267978 [06:02<50:29:14,  1.47it/s, v_num=full, train/loss_step=4.200]
Epoch 0:   0%|          | 533/267978 [06:02<50:29:15,  1.47it/s, v_num=full, train/loss_step=9.050]
Epoch 0:   0%|          | 534/267978 [06:02<50:28:37,  1.47it/s, v_num=full, train/loss_step=9.050]
Epoch 0:   0%|          | 534/267978 [06:02<50:28:37,  1.47it/s, v_num=full, train/loss_step=7.780]
Epoch 0:   0%|          | 535/267978 [06:03<50:28:04,  1.47it/s, v_num=full, train/loss_step=7.780]
Epoch 0:   0%|          | 535/267978 [06:03<50:28:05,  1.47it/s, v_num=full, train/loss_step=3.900]
Epoch 0:   0%|          | 536/267978 [06:04<50:27:26,  1.47it/s, v_num=full, train/loss_step=3.900]
Epoch 0:   0%|          | 536/267978 [06:04<50:27:27,  1.47it/s, v_num=full, train/loss_step=5.510]
Epoch 0:   0%|          | 537/267978 [06:04<50:26:48,  1.47it/s, v_num=full, train/loss_step=5.510]
Epoch 0:   0%|          | 537/267978 [06:04<50:26:49,  1.47it/s, v_num=full, train/loss_step=4.550]
Epoch 0:   0%|          | 538/267978 [06:05<50:26:09,  1.47it/s, v_num=full, train/loss_step=4.550]
Epoch 0:   0%|          | 538/267978 [06:05<50:26:09,  1.47it/s, v_num=full, train/loss_step=1.840]
Epoch 0:   0%|          | 539/267978 [06:05<50:25:30,  1.47it/s, v_num=full, train/loss_step=1.840]
Epoch 0:   0%|          | 539/267978 [06:05<50:25:30,  1.47it/s, v_num=full, train/loss_step=8.550]
Epoch 0:   0%|          | 540/267978 [06:06<50:24:49,  1.47it/s, v_num=full, train/loss_step=8.550]
Epoch 0:   0%|          | 540/267978 [06:06<50:24:50,  1.47it/s, v_num=full, train/loss_step=4.410]
============================================================
Global Step 540
============================================================

[Losses]
  language_loss: 0.000384 (shape: torch.Size([4, 553]), count: 28)
  route_loss: 3.330078 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 8.601562 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 541/267978 [06:07<50:24:16,  1.47it/s, v_num=full, train/loss_step=4.410]
Epoch 0:   0%|          | 541/267978 [06:07<50:24:16,  1.47it/s, v_num=full, train/loss_step=12.00]
Epoch 0:   0%|          | 542/267978 [06:07<50:23:36,  1.47it/s, v_num=full, train/loss_step=12.00]
Epoch 0:   0%|          | 542/267978 [06:07<50:23:37,  1.47it/s, v_num=full, train/loss_step=5.730]
Epoch 0:   0%|          | 543/267978 [06:08<50:23:00,  1.47it/s, v_num=full, train/loss_step=5.730]
Epoch 0:   0%|          | 543/267978 [06:08<50:23:01,  1.47it/s, v_num=full, train/loss_step=4.890]
Epoch 0:   0%|          | 544/267978 [06:08<50:22:22,  1.47it/s, v_num=full, train/loss_step=4.890]
Epoch 0:   0%|          | 544/267978 [06:08<50:22:23,  1.47it/s, v_num=full, train/loss_step=5.690]
Epoch 0:   0%|          | 545/267978 [06:09<50:21:48,  1.48it/s, v_num=full, train/loss_step=5.690]
Epoch 0:   0%|          | 545/267978 [06:09<50:21:48,  1.48it/s, v_num=full, train/loss_step=6.690]
Epoch 0:   0%|          | 546/267978 [06:10<50:21:14,  1.48it/s, v_num=full, train/loss_step=6.690]
Epoch 0:   0%|          | 546/267978 [06:10<50:21:15,  1.48it/s, v_num=full, train/loss_step=3.380]
Epoch 0:   0%|          | 547/267978 [06:10<50:20:41,  1.48it/s, v_num=full, train/loss_step=3.380]
Epoch 0:   0%|          | 547/267978 [06:10<50:20:42,  1.48it/s, v_num=full, train/loss_step=4.470]
Epoch 0:   0%|          | 548/267978 [06:11<50:20:06,  1.48it/s, v_num=full, train/loss_step=4.470]
Epoch 0:   0%|          | 548/267978 [06:11<50:20:07,  1.48it/s, v_num=full, train/loss_step=3.890]
Epoch 0:   0%|          | 549/267978 [06:11<50:19:20,  1.48it/s, v_num=full, train/loss_step=3.890]
Epoch 0:   0%|          | 549/267978 [06:11<50:19:20,  1.48it/s, v_num=full, train/loss_step=2.540]
Epoch 0:   0%|          | 550/267978 [06:12<50:18:49,  1.48it/s, v_num=full, train/loss_step=2.540]
Epoch 0:   0%|          | 550/267978 [06:12<50:18:49,  1.48it/s, v_num=full, train/loss_step=7.330]
============================================================
Global Step 550
============================================================

[Losses]
  language_loss: 0.000727 (shape: torch.Size([4, 550]), count: 28)
  route_loss: 0.823730 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 6.457031 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 551/267978 [06:13<50:18:11,  1.48it/s, v_num=full, train/loss_step=7.330]
Epoch 0:   0%|          | 551/267978 [06:13<50:18:12,  1.48it/s, v_num=full, train/loss_step=7.340]
Epoch 0:   0%|          | 552/267978 [06:13<50:17:37,  1.48it/s, v_num=full, train/loss_step=7.340]
Epoch 0:   0%|          | 552/267978 [06:13<50:17:37,  1.48it/s, v_num=full, train/loss_step=1.960]
Epoch 0:   0%|          | 553/267978 [06:14<50:17:04,  1.48it/s, v_num=full, train/loss_step=1.960]
Epoch 0:   0%|          | 553/267978 [06:14<50:17:04,  1.48it/s, v_num=full, train/loss_step=4.840]
Epoch 0:   0%|          | 554/267978 [06:14<50:16:34,  1.48it/s, v_num=full, train/loss_step=4.840]
Epoch 0:   0%|          | 554/267978 [06:14<50:16:34,  1.48it/s, v_num=full, train/loss_step=7.340]
Epoch 0:   0%|          | 555/267978 [06:15<50:15:59,  1.48it/s, v_num=full, train/loss_step=7.340]
Epoch 0:   0%|          | 555/267978 [06:15<50:15:59,  1.48it/s, v_num=full, train/loss_step=3.200]
Epoch 0:   0%|          | 556/267978 [06:16<50:15:25,  1.48it/s, v_num=full, train/loss_step=3.200]
Epoch 0:   0%|          | 556/267978 [06:16<50:15:26,  1.48it/s, v_num=full, train/loss_step=5.560]
Epoch 0:   0%|          | 557/267978 [06:16<50:14:48,  1.48it/s, v_num=full, train/loss_step=5.560]
Epoch 0:   0%|          | 557/267978 [06:16<50:14:49,  1.48it/s, v_num=full, train/loss_step=14.60]
Epoch 0:   0%|          | 558/267978 [06:17<50:14:15,  1.48it/s, v_num=full, train/loss_step=14.60]
Epoch 0:   0%|          | 558/267978 [06:17<50:14:16,  1.48it/s, v_num=full, train/loss_step=4.430]
Epoch 0:   0%|          | 559/267978 [06:17<50:13:45,  1.48it/s, v_num=full, train/loss_step=4.430]
Epoch 0:   0%|          | 559/267978 [06:17<50:13:46,  1.48it/s, v_num=full, train/loss_step=1.460]
Epoch 0:   0%|          | 560/267978 [06:18<50:13:14,  1.48it/s, v_num=full, train/loss_step=1.460]
Epoch 0:   0%|          | 560/267978 [06:18<50:13:14,  1.48it/s, v_num=full, train/loss_step=4.030]
============================================================
Global Step 560
============================================================

[Losses]
  language_loss: 0.000351 (shape: torch.Size([4, 552]), count: 28)
  route_loss: 0.597656 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.681641 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 561/267978 [06:19<50:12:41,  1.48it/s, v_num=full, train/loss_step=4.030]
Epoch 0:   0%|          | 561/267978 [06:19<50:12:42,  1.48it/s, v_num=full, train/loss_step=4.310]
Epoch 0:   0%|          | 562/267978 [06:19<50:12:11,  1.48it/s, v_num=full, train/loss_step=4.310]
Epoch 0:   0%|          | 562/267978 [06:19<50:12:12,  1.48it/s, v_num=full, train/loss_step=12.20]
Epoch 0:   0%|          | 563/267978 [06:20<50:11:37,  1.48it/s, v_num=full, train/loss_step=12.20]
Epoch 0:   0%|          | 563/267978 [06:20<50:11:38,  1.48it/s, v_num=full, train/loss_step=3.540]
Epoch 0:   0%|          | 564/267978 [06:21<50:11:02,  1.48it/s, v_num=full, train/loss_step=3.540]
Epoch 0:   0%|          | 564/267978 [06:21<50:11:03,  1.48it/s, v_num=full, train/loss_step=3.800]
Epoch 0:   0%|          | 565/267978 [06:21<50:10:29,  1.48it/s, v_num=full, train/loss_step=3.800]
Epoch 0:   0%|          | 565/267978 [06:21<50:10:29,  1.48it/s, v_num=full, train/loss_step=5.400]
Epoch 0:   0%|          | 566/267978 [06:22<50:09:55,  1.48it/s, v_num=full, train/loss_step=5.400]
Epoch 0:   0%|          | 566/267978 [06:22<50:09:55,  1.48it/s, v_num=full, train/loss_step=5.700]
Epoch 0:   0%|          | 567/267978 [06:22<50:09:22,  1.48it/s, v_num=full, train/loss_step=5.700]
Epoch 0:   0%|          | 567/267978 [06:22<50:09:23,  1.48it/s, v_num=full, train/loss_step=4.240]
Epoch 0:   0%|          | 568/267978 [06:23<50:08:54,  1.48it/s, v_num=full, train/loss_step=4.240]
Epoch 0:   0%|          | 568/267978 [06:23<50:08:54,  1.48it/s, v_num=full, train/loss_step=5.390]
Epoch 0:   0%|          | 569/267978 [06:24<50:08:20,  1.48it/s, v_num=full, train/loss_step=5.390]
Epoch 0:   0%|          | 569/267978 [06:24<50:08:20,  1.48it/s, v_num=full, train/loss_step=2.790]
Epoch 0:   0%|          | 570/267978 [06:24<50:07:48,  1.48it/s, v_num=full, train/loss_step=2.790]
Epoch 0:   0%|          | 570/267978 [06:24<50:07:49,  1.48it/s, v_num=full, train/loss_step=2.560]
============================================================
Global Step 570
============================================================

[Losses]
  language_loss: 0.000522 (shape: torch.Size([4, 551]), count: 28)
  route_loss: 0.625977 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 5.187500 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 571/267978 [06:25<50:07:22,  1.48it/s, v_num=full, train/loss_step=2.560]
Epoch 0:   0%|          | 571/267978 [06:25<50:07:22,  1.48it/s, v_num=full, train/loss_step=5.860]
Epoch 0:   0%|          | 572/267978 [06:25<50:06:50,  1.48it/s, v_num=full, train/loss_step=5.860]
Epoch 0:   0%|          | 572/267978 [06:25<50:06:51,  1.48it/s, v_num=full, train/loss_step=8.160]
Epoch 0:   0%|          | 573/267978 [06:26<50:06:24,  1.48it/s, v_num=full, train/loss_step=8.160]
Epoch 0:   0%|          | 573/267978 [06:26<50:06:24,  1.48it/s, v_num=full, train/loss_step=2.780]
Epoch 0:   0%|          | 574/267978 [06:27<50:05:54,  1.48it/s, v_num=full, train/loss_step=2.780]
Epoch 0:   0%|          | 574/267978 [06:27<50:05:54,  1.48it/s, v_num=full, train/loss_step=4.300]
Epoch 0:   0%|          | 575/267978 [06:27<50:05:24,  1.48it/s, v_num=full, train/loss_step=4.300]
Epoch 0:   0%|          | 575/267978 [06:27<50:05:24,  1.48it/s, v_num=full, train/loss_step=6.430]
Epoch 0:   0%|          | 576/267978 [06:28<50:04:54,  1.48it/s, v_num=full, train/loss_step=6.430]
Epoch 0:   0%|          | 576/267978 [06:28<50:04:54,  1.48it/s, v_num=full, train/loss_step=4.160]
Epoch 0:   0%|          | 577/267978 [06:28<50:04:26,  1.48it/s, v_num=full, train/loss_step=4.160]
Epoch 0:   0%|          | 577/267978 [06:28<50:04:26,  1.48it/s, v_num=full, train/loss_step=6.390]
Epoch 0:   0%|          | 578/267978 [06:29<50:03:55,  1.48it/s, v_num=full, train/loss_step=6.390]
Epoch 0:   0%|          | 578/267978 [06:29<50:03:56,  1.48it/s, v_num=full, train/loss_step=4.870]
Epoch 0:   0%|          | 579/267978 [06:30<50:03:26,  1.48it/s, v_num=full, train/loss_step=4.870]
Epoch 0:   0%|          | 579/267978 [06:30<50:03:26,  1.48it/s, v_num=full, train/loss_step=4.600]
Epoch 0:   0%|          | 580/267978 [06:30<50:02:53,  1.48it/s, v_num=full, train/loss_step=4.600]
Epoch 0:   0%|          | 580/267978 [06:30<50:02:53,  1.48it/s, v_num=full, train/loss_step=2.250]
============================================================
Global Step 580
============================================================

[Losses]
  language_loss: 0.000355 (shape: torch.Size([4, 560]), count: 28)
  route_loss: 0.190674 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 1.494141 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 581/267978 [06:31<50:02:25,  1.48it/s, v_num=full, train/loss_step=2.250]
Epoch 0:   0%|          | 581/267978 [06:31<50:02:25,  1.48it/s, v_num=full, train/loss_step=1.710]
Epoch 0:   0%|          | 582/267978 [06:32<50:02:01,  1.48it/s, v_num=full, train/loss_step=1.710]
Epoch 0:   0%|          | 582/267978 [06:32<50:02:01,  1.48it/s, v_num=full, train/loss_step=7.270]
Epoch 0:   0%|          | 583/267978 [06:32<50:01:25,  1.48it/s, v_num=full, train/loss_step=7.270]
Epoch 0:   0%|          | 583/267978 [06:32<50:01:26,  1.48it/s, v_num=full, train/loss_step=4.050]
Epoch 0:   0%|          | 584/267978 [06:33<50:00:55,  1.49it/s, v_num=full, train/loss_step=4.050]
Epoch 0:   0%|          | 584/267978 [06:33<50:00:55,  1.49it/s, v_num=full, train/loss_step=9.570]
Epoch 0:   0%|          | 585/267978 [06:33<50:00:24,  1.49it/s, v_num=full, train/loss_step=9.570]
Epoch 0:   0%|          | 585/267978 [06:33<50:00:24,  1.49it/s, v_num=full, train/loss_step=5.350]
Epoch 0:   0%|          | 586/267978 [06:34<49:59:52,  1.49it/s, v_num=full, train/loss_step=5.350]
Epoch 0:   0%|          | 586/267978 [06:34<49:59:53,  1.49it/s, v_num=full, train/loss_step=4.790]
Epoch 0:   0%|          | 587/267978 [06:35<49:59:22,  1.49it/s, v_num=full, train/loss_step=4.790]
Epoch 0:   0%|          | 587/267978 [06:35<49:59:23,  1.49it/s, v_num=full, train/loss_step=9.450]
Epoch 0:   0%|          | 588/267978 [06:35<49:58:50,  1.49it/s, v_num=full, train/loss_step=9.450]
Epoch 0:   0%|          | 588/267978 [06:35<49:58:50,  1.49it/s, v_num=full, train/loss_step=4.270]
Epoch 0:   0%|          | 589/267978 [06:36<49:58:20,  1.49it/s, v_num=full, train/loss_step=4.270]
Epoch 0:   0%|          | 589/267978 [06:36<49:58:21,  1.49it/s, v_num=full, train/loss_step=5.230]
Epoch 0:   0%|          | 590/267978 [06:36<49:57:48,  1.49it/s, v_num=full, train/loss_step=5.230]
Epoch 0:   0%|          | 590/267978 [06:36<49:57:49,  1.49it/s, v_num=full, train/loss_step=7.210]
============================================================
Global Step 590
============================================================

[Losses]
  language_loss: 0.000334 (shape: torch.Size([4, 546]), count: 28)
  route_loss: 0.763184 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.179688 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 591/267978 [06:37<49:57:15,  1.49it/s, v_num=full, train/loss_step=7.210]
Epoch 0:   0%|          | 591/267978 [06:37<49:57:15,  1.49it/s, v_num=full, train/loss_step=4.970]
Epoch 0:   0%|          | 592/267978 [06:38<49:56:42,  1.49it/s, v_num=full, train/loss_step=4.970]
Epoch 0:   0%|          | 592/267978 [06:38<49:56:42,  1.49it/s, v_num=full, train/loss_step=7.400]
Epoch 0:   0%|          | 593/267978 [06:38<49:56:12,  1.49it/s, v_num=full, train/loss_step=7.400]
Epoch 0:   0%|          | 593/267978 [06:38<49:56:13,  1.49it/s, v_num=full, train/loss_step=5.930]
Epoch 0:   0%|          | 594/267978 [06:39<49:55:42,  1.49it/s, v_num=full, train/loss_step=5.930]
Epoch 0:   0%|          | 594/267978 [06:39<49:55:42,  1.49it/s, v_num=full, train/loss_step=5.040]
Epoch 0:   0%|          | 595/267978 [06:39<49:55:15,  1.49it/s, v_num=full, train/loss_step=5.040]
Epoch 0:   0%|          | 595/267978 [06:39<49:55:15,  1.49it/s, v_num=full, train/loss_step=5.150]
Epoch 0:   0%|          | 596/267978 [06:40<49:54:44,  1.49it/s, v_num=full, train/loss_step=5.150]
Epoch 0:   0%|          | 596/267978 [06:40<49:54:45,  1.49it/s, v_num=full, train/loss_step=10.50]
Epoch 0:   0%|          | 597/267978 [06:41<49:54:12,  1.49it/s, v_num=full, train/loss_step=10.50]
Epoch 0:   0%|          | 597/267978 [06:41<49:54:13,  1.49it/s, v_num=full, train/loss_step=6.000]
Epoch 0:   0%|          | 598/267978 [06:41<49:53:41,  1.49it/s, v_num=full, train/loss_step=6.000]
Epoch 0:   0%|          | 598/267978 [06:41<49:53:41,  1.49it/s, v_num=full, train/loss_step=1.620]
Epoch 0:   0%|          | 599/267978 [06:42<49:53:10,  1.49it/s, v_num=full, train/loss_step=1.620]
Epoch 0:   0%|          | 599/267978 [06:42<49:53:10,  1.49it/s, v_num=full, train/loss_step=2.270]
Epoch 0:   0%|          | 600/267978 [06:48<50:35:28,  1.47it/s, v_num=full, train/loss_step=2.270]
Epoch 0:   0%|          | 600/267978 [06:48<50:35:28,  1.47it/s, v_num=full, train/loss_step=6.420]
============================================================
[Input Before LLM] - Global Step 600
============================================================
  Adaptor embeddings shape: torch.Size([4, 590, 896])
  Input embeddings shape: torch.Size([4, 590, 896])
  Attention mask shape: torch.Size([4, 590])
  Input dtype: torch.float16
  Adaptor embeddings range: [-6.7578, 8.4219]
  Input embeddings range: [-6.7578, 8.4219]
  Input embeddings mean: -0.0017, std: 0.7524
  Language inputs shape: torch.Size([4, 560, 896])

============================================================
Global Step 600
============================================================

[Losses]
  language_loss: 0.000266 (shape: torch.Size([4, 559]), count: 28)
  route_loss: 1.562500 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 7.464844 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 601/267978 [06:49<50:35:14,  1.47it/s, v_num=full, train/loss_step=6.420]
Epoch 0:   0%|          | 601/267978 [06:49<50:35:15,  1.47it/s, v_num=full, train/loss_step=9.050]
Epoch 0:   0%|          | 602/267978 [06:49<50:34:37,  1.47it/s, v_num=full, train/loss_step=9.050]
Epoch 0:   0%|          | 602/267978 [06:49<50:34:37,  1.47it/s, v_num=full, train/loss_step=12.00]
Epoch 0:   0%|          | 603/267978 [06:50<50:34:01,  1.47it/s, v_num=full, train/loss_step=12.00]
Epoch 0:   0%|          | 603/267978 [06:50<50:34:01,  1.47it/s, v_num=full, train/loss_step=4.590]
Epoch 0:   0%|          | 604/267978 [06:51<50:33:31,  1.47it/s, v_num=full, train/loss_step=4.590]
Epoch 0:   0%|          | 604/267978 [06:51<50:33:32,  1.47it/s, v_num=full, train/loss_step=3.630]
Epoch 0:   0%|          | 605/267978 [06:51<50:33:02,  1.47it/s, v_num=full, train/loss_step=3.630]
Epoch 0:   0%|          | 605/267978 [06:51<50:33:02,  1.47it/s, v_num=full, train/loss_step=6.930]
Epoch 0:   0%|          | 606/267978 [06:52<50:32:30,  1.47it/s, v_num=full, train/loss_step=6.930]
Epoch 0:   0%|          | 606/267978 [06:52<50:32:30,  1.47it/s, v_num=full, train/loss_step=4.810]
Epoch 0:   0%|          | 607/267978 [06:52<50:31:56,  1.47it/s, v_num=full, train/loss_step=4.810]
Epoch 0:   0%|          | 607/267978 [06:52<50:31:57,  1.47it/s, v_num=full, train/loss_step=6.450]
Epoch 0:   0%|          | 608/267978 [06:53<50:31:23,  1.47it/s, v_num=full, train/loss_step=6.450]
Epoch 0:   0%|          | 608/267978 [06:53<50:31:24,  1.47it/s, v_num=full, train/loss_step=4.470]
Epoch 0:   0%|          | 609/267978 [06:54<50:30:49,  1.47it/s, v_num=full, train/loss_step=4.470]
Epoch 0:   0%|          | 609/267978 [06:54<50:30:50,  1.47it/s, v_num=full, train/loss_step=2.810]
Epoch 0:   0%|          | 610/267978 [06:54<50:30:19,  1.47it/s, v_num=full, train/loss_step=2.810]
Epoch 0:   0%|          | 610/267978 [06:54<50:30:20,  1.47it/s, v_num=full, train/loss_step=3.560]
============================================================
Global Step 610
============================================================

[Losses]
  language_loss: 0.000198 (shape: torch.Size([4, 565]), count: 28)
  route_loss: 1.083984 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 6.691406 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 611/267978 [06:55<50:29:47,  1.47it/s, v_num=full, train/loss_step=3.560]
Epoch 0:   0%|          | 611/267978 [06:55<50:29:47,  1.47it/s, v_num=full, train/loss_step=7.790]
Epoch 0:   0%|          | 612/267978 [06:56<50:29:15,  1.47it/s, v_num=full, train/loss_step=7.790]
Epoch 0:   0%|          | 612/267978 [06:56<50:29:16,  1.47it/s, v_num=full, train/loss_step=11.90]
Epoch 0:   0%|          | 613/267978 [06:56<50:28:46,  1.47it/s, v_num=full, train/loss_step=11.90]
Epoch 0:   0%|          | 613/267978 [06:56<50:28:46,  1.47it/s, v_num=full, train/loss_step=7.710]
Epoch 0:   0%|          | 614/267978 [06:57<50:28:14,  1.47it/s, v_num=full, train/loss_step=7.710]
Epoch 0:   0%|          | 614/267978 [06:57<50:28:14,  1.47it/s, v_num=full, train/loss_step=7.930]
Epoch 0:   0%|          | 615/267978 [06:57<50:27:41,  1.47it/s, v_num=full, train/loss_step=7.930]
Epoch 0:   0%|          | 615/267978 [06:57<50:27:42,  1.47it/s, v_num=full, train/loss_step=3.500]
Epoch 0:   0%|          | 616/267978 [06:58<50:27:07,  1.47it/s, v_num=full, train/loss_step=3.500]
Epoch 0:   0%|          | 616/267978 [06:58<50:27:07,  1.47it/s, v_num=full, train/loss_step=4.660]
Epoch 0:   0%|          | 617/267978 [06:59<50:26:33,  1.47it/s, v_num=full, train/loss_step=4.660]
Epoch 0:   0%|          | 617/267978 [06:59<50:26:34,  1.47it/s, v_num=full, train/loss_step=4.000]
Epoch 0:   0%|          | 618/267978 [06:59<50:25:58,  1.47it/s, v_num=full, train/loss_step=4.000]
Epoch 0:   0%|          | 618/267978 [06:59<50:25:58,  1.47it/s, v_num=full, train/loss_step=4.730]
Epoch 0:   0%|          | 619/267978 [07:00<50:25:27,  1.47it/s, v_num=full, train/loss_step=4.730]
Epoch 0:   0%|          | 619/267978 [07:00<50:25:27,  1.47it/s, v_num=full, train/loss_step=7.370]
Epoch 0:   0%|          | 620/267978 [07:00<50:24:55,  1.47it/s, v_num=full, train/loss_step=7.370]
Epoch 0:   0%|          | 620/267978 [07:00<50:24:55,  1.47it/s, v_num=full, train/loss_step=5.240]
============================================================
Global Step 620
============================================================

[Losses]
  language_loss: 0.000215 (shape: torch.Size([4, 565]), count: 28)
  route_loss: 1.413086 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 2.904297 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 621/267978 [07:01<50:24:23,  1.47it/s, v_num=full, train/loss_step=5.240]
Epoch 0:   0%|          | 621/267978 [07:01<50:24:23,  1.47it/s, v_num=full, train/loss_step=4.340]
Epoch 0:   0%|          | 622/267978 [07:02<50:23:52,  1.47it/s, v_num=full, train/loss_step=4.340]
Epoch 0:   0%|          | 622/267978 [07:02<50:23:53,  1.47it/s, v_num=full, train/loss_step=5.050]
Epoch 0:   0%|          | 623/267978 [07:02<50:23:23,  1.47it/s, v_num=full, train/loss_step=5.050]
Epoch 0:   0%|          | 623/267978 [07:02<50:23:24,  1.47it/s, v_num=full, train/loss_step=8.160]
Epoch 0:   0%|          | 624/267978 [07:03<50:22:52,  1.47it/s, v_num=full, train/loss_step=8.160]
Epoch 0:   0%|          | 624/267978 [07:03<50:22:53,  1.47it/s, v_num=full, train/loss_step=4.800]
Epoch 0:   0%|          | 625/267978 [07:03<50:22:20,  1.47it/s, v_num=full, train/loss_step=4.800]
Epoch 0:   0%|          | 625/267978 [07:03<50:22:20,  1.47it/s, v_num=full, train/loss_step=4.180]
Epoch 0:   0%|          | 626/267978 [07:04<50:21:49,  1.47it/s, v_num=full, train/loss_step=4.180]
Epoch 0:   0%|          | 626/267978 [07:04<50:21:50,  1.47it/s, v_num=full, train/loss_step=6.310]
Epoch 0:   0%|          | 627/267978 [07:05<50:21:14,  1.47it/s, v_num=full, train/loss_step=6.310]
Epoch 0:   0%|          | 627/267978 [07:05<50:21:15,  1.47it/s, v_num=full, train/loss_step=2.650]
Epoch 0:   0%|          | 628/267978 [07:05<50:20:41,  1.48it/s, v_num=full, train/loss_step=2.650]
Epoch 0:   0%|          | 628/267978 [07:05<50:20:42,  1.48it/s, v_num=full, train/loss_step=5.480]
Epoch 0:   0%|          | 629/267978 [07:06<50:20:05,  1.48it/s, v_num=full, train/loss_step=5.480]
Epoch 0:   0%|          | 629/267978 [07:06<50:20:05,  1.48it/s, v_num=full, train/loss_step=4.530]
Epoch 0:   0%|          | 630/267978 [07:06<50:19:31,  1.48it/s, v_num=full, train/loss_step=4.530]
Epoch 0:   0%|          | 630/267978 [07:06<50:19:31,  1.48it/s, v_num=full, train/loss_step=5.160]
============================================================
Global Step 630
============================================================

[Losses]
  language_loss: 0.000418 (shape: torch.Size([4, 559]), count: 28)
  route_loss: 1.851562 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 5.039062 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 631/267978 [07:07<50:19:02,  1.48it/s, v_num=full, train/loss_step=5.160]
Epoch 0:   0%|          | 631/267978 [07:07<50:19:03,  1.48it/s, v_num=full, train/loss_step=6.930]
Epoch 0:   0%|          | 632/267978 [07:08<50:18:36,  1.48it/s, v_num=full, train/loss_step=6.930]
Epoch 0:   0%|          | 632/267978 [07:08<50:18:36,  1.48it/s, v_num=full, train/loss_step=4.040]
Epoch 0:   0%|          | 633/267978 [07:08<50:18:02,  1.48it/s, v_num=full, train/loss_step=4.040]
Epoch 0:   0%|          | 633/267978 [07:08<50:18:02,  1.48it/s, v_num=full, train/loss_step=5.840]
Epoch 0:   0%|          | 634/267978 [07:09<50:17:31,  1.48it/s, v_num=full, train/loss_step=5.840]
Epoch 0:   0%|          | 634/267978 [07:09<50:17:31,  1.48it/s, v_num=full, train/loss_step=3.070]
Epoch 0:   0%|          | 635/267978 [07:09<50:16:56,  1.48it/s, v_num=full, train/loss_step=3.070]
Epoch 0:   0%|          | 635/267978 [07:09<50:16:56,  1.48it/s, v_num=full, train/loss_step=7.410]
Epoch 0:   0%|          | 636/267978 [07:10<50:16:27,  1.48it/s, v_num=full, train/loss_step=7.410]
Epoch 0:   0%|          | 636/267978 [07:10<50:16:27,  1.48it/s, v_num=full, train/loss_step=3.670]
Epoch 0:   0%|          | 637/267978 [07:11<50:16:09,  1.48it/s, v_num=full, train/loss_step=3.670]
Epoch 0:   0%|          | 637/267978 [07:11<50:16:10,  1.48it/s, v_num=full, train/loss_step=6.390]
Epoch 0:   0%|          | 638/267978 [07:11<50:15:41,  1.48it/s, v_num=full, train/loss_step=6.390]
Epoch 0:   0%|          | 638/267978 [07:11<50:15:41,  1.48it/s, v_num=full, train/loss_step=5.600]
Epoch 0:   0%|          | 639/267978 [07:12<50:15:07,  1.48it/s, v_num=full, train/loss_step=5.600]
Epoch 0:   0%|          | 639/267978 [07:12<50:15:08,  1.48it/s, v_num=full, train/loss_step=3.970]
Epoch 0:   0%|          | 640/267978 [07:13<50:14:37,  1.48it/s, v_num=full, train/loss_step=3.970]
Epoch 0:   0%|          | 640/267978 [07:13<50:14:38,  1.48it/s, v_num=full, train/loss_step=4.560]
============================================================
Global Step 640
============================================================

[Losses]
  language_loss: 0.000278 (shape: torch.Size([4, 551]), count: 28)
  route_loss: 1.549805 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 2.916016 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 641/267978 [07:13<50:14:08,  1.48it/s, v_num=full, train/loss_step=4.560]
Epoch 0:   0%|          | 641/267978 [07:13<50:14:08,  1.48it/s, v_num=full, train/loss_step=4.490]
Epoch 0:   0%|          | 642/267978 [07:14<50:13:34,  1.48it/s, v_num=full, train/loss_step=4.490]
Epoch 0:   0%|          | 642/267978 [07:14<50:13:34,  1.48it/s, v_num=full, train/loss_step=5.100]
Epoch 0:   0%|          | 643/267978 [07:14<50:13:03,  1.48it/s, v_num=full, train/loss_step=5.100]
Epoch 0:   0%|          | 643/267978 [07:14<50:13:04,  1.48it/s, v_num=full, train/loss_step=5.230]
Epoch 0:   0%|          | 644/267978 [07:15<50:12:35,  1.48it/s, v_num=full, train/loss_step=5.230]
Epoch 0:   0%|          | 644/267978 [07:15<50:12:35,  1.48it/s, v_num=full, train/loss_step=4.800]
Epoch 0:   0%|          | 645/267978 [07:16<50:12:06,  1.48it/s, v_num=full, train/loss_step=4.800]
Epoch 0:   0%|          | 645/267978 [07:16<50:12:06,  1.48it/s, v_num=full, train/loss_step=8.320]
Epoch 0:   0%|          | 646/267978 [07:16<50:11:40,  1.48it/s, v_num=full, train/loss_step=8.320]
Epoch 0:   0%|          | 646/267978 [07:16<50:11:40,  1.48it/s, v_num=full, train/loss_step=4.890]
Epoch 0:   0%|          | 647/267978 [07:17<50:11:13,  1.48it/s, v_num=full, train/loss_step=4.890]
Epoch 0:   0%|          | 647/267978 [07:17<50:11:14,  1.48it/s, v_num=full, train/loss_step=6.420]
Epoch 0:   0%|          | 648/267978 [07:17<50:10:46,  1.48it/s, v_num=full, train/loss_step=6.420]
Epoch 0:   0%|          | 648/267978 [07:17<50:10:46,  1.48it/s, v_num=full, train/loss_step=7.700]
Epoch 0:   0%|          | 649/267978 [07:18<50:10:16,  1.48it/s, v_num=full, train/loss_step=7.700]
Epoch 0:   0%|          | 649/267978 [07:18<50:10:16,  1.48it/s, v_num=full, train/loss_step=5.980]
Epoch 0:   0%|          | 650/267978 [07:19<50:09:49,  1.48it/s, v_num=full, train/loss_step=5.980]
Epoch 0:   0%|          | 650/267978 [07:19<50:09:49,  1.48it/s, v_num=full, train/loss_step=9.120]
============================================================
Global Step 650
============================================================

[Losses]
  language_loss: 0.000370 (shape: torch.Size([4, 550]), count: 28)
  route_loss: 0.986328 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 2.189453 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 651/267978 [07:19<50:09:31,  1.48it/s, v_num=full, train/loss_step=9.120]
Epoch 0:   0%|          | 651/267978 [07:19<50:09:32,  1.48it/s, v_num=full, train/loss_step=3.210]
Epoch 0:   0%|          | 652/267978 [07:20<50:09:06,  1.48it/s, v_num=full, train/loss_step=3.210]
Epoch 0:   0%|          | 652/267978 [07:20<50:09:07,  1.48it/s, v_num=full, train/loss_step=6.400]
Epoch 0:   0%|          | 653/267978 [07:20<50:08:38,  1.48it/s, v_num=full, train/loss_step=6.400]
Epoch 0:   0%|          | 653/267978 [07:20<50:08:38,  1.48it/s, v_num=full, train/loss_step=4.490]
Epoch 0:   0%|          | 654/267978 [07:21<50:08:19,  1.48it/s, v_num=full, train/loss_step=4.490]
Epoch 0:   0%|          | 654/267978 [07:21<50:08:19,  1.48it/s, v_num=full, train/loss_step=5.620]
Epoch 0:   0%|          | 655/267978 [07:22<50:07:54,  1.48it/s, v_num=full, train/loss_step=5.620]
Epoch 0:   0%|          | 655/267978 [07:22<50:07:54,  1.48it/s, v_num=full, train/loss_step=3.820]
Epoch 0:   0%|          | 656/267978 [07:22<50:07:33,  1.48it/s, v_num=full, train/loss_step=3.820]
Epoch 0:   0%|          | 656/267978 [07:22<50:07:33,  1.48it/s, v_num=full, train/loss_step=7.520]
Epoch 0:   0%|          | 657/267978 [07:23<50:07:03,  1.48it/s, v_num=full, train/loss_step=7.520]
Epoch 0:   0%|          | 657/267978 [07:23<50:07:04,  1.48it/s, v_num=full, train/loss_step=6.440]
Epoch 0:   0%|          | 658/267978 [07:24<50:06:35,  1.48it/s, v_num=full, train/loss_step=6.440]
Epoch 0:   0%|          | 658/267978 [07:24<50:06:35,  1.48it/s, v_num=full, train/loss_step=2.300]
Epoch 0:   0%|          | 659/267978 [07:24<50:06:10,  1.48it/s, v_num=full, train/loss_step=2.300]
Epoch 0:   0%|          | 659/267978 [07:24<50:06:10,  1.48it/s, v_num=full, train/loss_step=5.820]
Epoch 0:   0%|          | 660/267978 [07:25<50:05:42,  1.48it/s, v_num=full, train/loss_step=5.820]
Epoch 0:   0%|          | 660/267978 [07:25<50:05:43,  1.48it/s, v_num=full, train/loss_step=1.750]
============================================================
Global Step 660
============================================================

[Losses]
  language_loss: 0.000328 (shape: torch.Size([4, 546]), count: 28)
  route_loss: 1.727539 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.238281 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 661/267978 [07:25<50:05:21,  1.48it/s, v_num=full, train/loss_step=1.750]
Epoch 0:   0%|          | 661/267978 [07:25<50:05:22,  1.48it/s, v_num=full, train/loss_step=4.990]
Epoch 0:   0%|          | 662/267978 [07:26<50:04:54,  1.48it/s, v_num=full, train/loss_step=4.990]
Epoch 0:   0%|          | 662/267978 [07:26<50:04:54,  1.48it/s, v_num=full, train/loss_step=6.480]
Epoch 0:   0%|          | 663/267978 [07:27<50:04:28,  1.48it/s, v_num=full, train/loss_step=6.480]
Epoch 0:   0%|          | 663/267978 [07:27<50:04:29,  1.48it/s, v_num=full, train/loss_step=4.900]
Epoch 0:   0%|          | 664/267978 [07:27<50:04:02,  1.48it/s, v_num=full, train/loss_step=4.900]
Epoch 0:   0%|          | 664/267978 [07:27<50:04:03,  1.48it/s, v_num=full, train/loss_step=7.220]
Epoch 0:   0%|          | 665/267978 [07:28<50:03:36,  1.48it/s, v_num=full, train/loss_step=7.220]
Epoch 0:   0%|          | 665/267978 [07:28<50:03:36,  1.48it/s, v_num=full, train/loss_step=3.380]
Epoch 0:   0%|          | 666/267978 [07:28<50:03:08,  1.48it/s, v_num=full, train/loss_step=3.380]
Epoch 0:   0%|          | 666/267978 [07:28<50:03:09,  1.48it/s, v_num=full, train/loss_step=4.640]
Epoch 0:   0%|          | 667/267978 [07:29<50:02:44,  1.48it/s, v_num=full, train/loss_step=4.640]
Epoch 0:   0%|          | 667/267978 [07:29<50:02:44,  1.48it/s, v_num=full, train/loss_step=7.180]
Epoch 0:   0%|          | 668/267978 [07:30<50:02:19,  1.48it/s, v_num=full, train/loss_step=7.180]
Epoch 0:   0%|          | 668/267978 [07:30<50:02:19,  1.48it/s, v_num=full, train/loss_step=2.140]
Epoch 0:   0%|          | 669/267978 [07:30<50:01:42,  1.48it/s, v_num=full, train/loss_step=2.140]
Epoch 0:   0%|          | 669/267978 [07:30<50:01:42,  1.48it/s, v_num=full, train/loss_step=6.950]
Epoch 0:   0%|          | 670/267978 [07:31<50:01:16,  1.48it/s, v_num=full, train/loss_step=6.950]
Epoch 0:   0%|          | 670/267978 [07:31<50:01:17,  1.48it/s, v_num=full, train/loss_step=7.180]
============================================================
Global Step 670
============================================================

[Losses]
  language_loss: 0.000203 (shape: torch.Size([4, 552]), count: 28)
  route_loss: 1.383789 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.359375 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 671/267978 [07:31<50:00:55,  1.48it/s, v_num=full, train/loss_step=7.180]
Epoch 0:   0%|          | 671/267978 [07:31<50:00:55,  1.48it/s, v_num=full, train/loss_step=5.760]
Epoch 0:   0%|          | 672/267978 [07:32<50:00:30,  1.48it/s, v_num=full, train/loss_step=5.760]
Epoch 0:   0%|          | 672/267978 [07:32<50:00:30,  1.48it/s, v_num=full, train/loss_step=4.960]
Epoch 0:   0%|          | 673/267978 [07:33<50:00:04,  1.48it/s, v_num=full, train/loss_step=4.960]
Epoch 0:   0%|          | 673/267978 [07:33<50:00:05,  1.48it/s, v_num=full, train/loss_step=5.480]
Epoch 0:   0%|          | 674/267978 [07:33<49:59:39,  1.49it/s, v_num=full, train/loss_step=5.480]
Epoch 0:   0%|          | 674/267978 [07:33<49:59:39,  1.49it/s, v_num=full, train/loss_step=3.440]
Epoch 0:   0%|          | 675/267978 [07:34<49:59:21,  1.49it/s, v_num=full, train/loss_step=3.440]
Epoch 0:   0%|          | 675/267978 [07:34<49:59:21,  1.49it/s, v_num=full, train/loss_step=4.750]
Epoch 0:   0%|          | 676/267978 [07:35<49:58:56,  1.49it/s, v_num=full, train/loss_step=4.750]
Epoch 0:   0%|          | 676/267978 [07:35<49:58:57,  1.49it/s, v_num=full, train/loss_step=5.420]
Epoch 0:   0%|          | 677/267978 [07:35<49:58:34,  1.49it/s, v_num=full, train/loss_step=5.420]
Epoch 0:   0%|          | 677/267978 [07:35<49:58:34,  1.49it/s, v_num=full, train/loss_step=4.810]
Epoch 0:   0%|          | 678/267978 [07:36<49:58:11,  1.49it/s, v_num=full, train/loss_step=4.810]
Epoch 0:   0%|          | 678/267978 [07:36<49:58:11,  1.49it/s, v_num=full, train/loss_step=5.110]
Epoch 0:   0%|          | 679/267978 [07:36<49:57:51,  1.49it/s, v_num=full, train/loss_step=5.110]
Epoch 0:   0%|          | 679/267978 [07:36<49:57:52,  1.49it/s, v_num=full, train/loss_step=7.970]
Epoch 0:   0%|          | 680/267978 [07:37<49:57:25,  1.49it/s, v_num=full, train/loss_step=7.970]
Epoch 0:   0%|          | 680/267978 [07:37<49:57:25,  1.49it/s, v_num=full, train/loss_step=2.790]
============================================================
Global Step 680
============================================================

[Losses]
  language_loss: 0.000321 (shape: torch.Size([4, 552]), count: 28)
  route_loss: 2.058594 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 2.099609 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 681/267978 [07:38<49:57:00,  1.49it/s, v_num=full, train/loss_step=2.790]
Epoch 0:   0%|          | 681/267978 [07:38<49:57:00,  1.49it/s, v_num=full, train/loss_step=4.180]
Epoch 0:   0%|          | 682/267978 [07:38<49:56:35,  1.49it/s, v_num=full, train/loss_step=4.180]
Epoch 0:   0%|          | 682/267978 [07:38<49:56:36,  1.49it/s, v_num=full, train/loss_step=2.390]
Epoch 0:   0%|          | 683/267978 [07:39<49:56:10,  1.49it/s, v_num=full, train/loss_step=2.390]
Epoch 0:   0%|          | 683/267978 [07:39<49:56:10,  1.49it/s, v_num=full, train/loss_step=5.880]
Epoch 0:   0%|          | 684/267978 [07:39<49:55:48,  1.49it/s, v_num=full, train/loss_step=5.880]
Epoch 0:   0%|          | 684/267978 [07:39<49:55:48,  1.49it/s, v_num=full, train/loss_step=3.590]
Epoch 0:   0%|          | 685/267978 [07:40<49:55:21,  1.49it/s, v_num=full, train/loss_step=3.590]
Epoch 0:   0%|          | 685/267978 [07:40<49:55:22,  1.49it/s, v_num=full, train/loss_step=5.000]
Epoch 0:   0%|          | 686/267978 [07:41<49:55:00,  1.49it/s, v_num=full, train/loss_step=5.000]
Epoch 0:   0%|          | 686/267978 [07:41<49:55:00,  1.49it/s, v_num=full, train/loss_step=6.460]
Epoch 0:   0%|          | 687/267978 [07:41<49:54:33,  1.49it/s, v_num=full, train/loss_step=6.460]
Epoch 0:   0%|          | 687/267978 [07:41<49:54:34,  1.49it/s, v_num=full, train/loss_step=3.460]
Epoch 0:   0%|          | 688/267978 [07:42<49:54:10,  1.49it/s, v_num=full, train/loss_step=3.460]
Epoch 0:   0%|          | 688/267978 [07:42<49:54:10,  1.49it/s, v_num=full, train/loss_step=2.470]
Epoch 0:   0%|          | 689/267978 [07:43<49:53:48,  1.49it/s, v_num=full, train/loss_step=2.470]
Epoch 0:   0%|          | 689/267978 [07:43<49:53:48,  1.49it/s, v_num=full, train/loss_step=4.980]
Epoch 0:   0%|          | 690/267978 [07:43<49:53:25,  1.49it/s, v_num=full, train/loss_step=4.980]
Epoch 0:   0%|          | 690/267978 [07:43<49:53:25,  1.49it/s, v_num=full, train/loss_step=6.020]
============================================================
Global Step 690
============================================================

[Losses]
  language_loss: 0.000172 (shape: torch.Size([4, 563]), count: 28)
  route_loss: 1.859375 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 2.097656 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 691/267978 [07:44<49:53:01,  1.49it/s, v_num=full, train/loss_step=6.020]
Epoch 0:   0%|          | 691/267978 [07:44<49:53:01,  1.49it/s, v_num=full, train/loss_step=3.970]
Epoch 0:   0%|          | 692/267978 [07:44<49:52:36,  1.49it/s, v_num=full, train/loss_step=3.970]
Epoch 0:   0%|          | 692/267978 [07:44<49:52:36,  1.49it/s, v_num=full, train/loss_step=1.240]
Epoch 0:   0%|          | 693/267978 [07:45<49:52:13,  1.49it/s, v_num=full, train/loss_step=1.240]
Epoch 0:   0%|          | 693/267978 [07:45<49:52:14,  1.49it/s, v_num=full, train/loss_step=4.260]
Epoch 0:   0%|          | 694/267978 [07:46<49:51:46,  1.49it/s, v_num=full, train/loss_step=4.260]
Epoch 0:   0%|          | 694/267978 [07:46<49:51:47,  1.49it/s, v_num=full, train/loss_step=3.690]
Epoch 0:   0%|          | 695/267978 [07:46<49:51:25,  1.49it/s, v_num=full, train/loss_step=3.690]
Epoch 0:   0%|          | 695/267978 [07:46<49:51:25,  1.49it/s, v_num=full, train/loss_step=10.00]
Epoch 0:   0%|          | 696/267978 [07:47<49:50:58,  1.49it/s, v_num=full, train/loss_step=10.00]
Epoch 0:   0%|          | 696/267978 [07:47<49:50:59,  1.49it/s, v_num=full, train/loss_step=6.060]
Epoch 0:   0%|          | 697/267978 [07:47<49:50:35,  1.49it/s, v_num=full, train/loss_step=6.060]
Epoch 0:   0%|          | 697/267978 [07:47<49:50:35,  1.49it/s, v_num=full, train/loss_step=7.520]
Epoch 0:   0%|          | 698/267978 [07:48<49:50:09,  1.49it/s, v_num=full, train/loss_step=7.520]
Epoch 0:   0%|          | 698/267978 [07:48<49:50:09,  1.49it/s, v_num=full, train/loss_step=4.290]
Epoch 0:   0%|          | 699/267978 [07:49<49:49:42,  1.49it/s, v_num=full, train/loss_step=4.290]
Epoch 0:   0%|          | 699/267978 [07:49<49:49:43,  1.49it/s, v_num=full, train/loss_step=6.200]
Epoch 0:   0%|          | 700/267978 [07:55<50:26:58,  1.47it/s, v_num=full, train/loss_step=6.200]
Epoch 0:   0%|          | 700/267978 [07:57<50:36:46,  1.47it/s, v_num=full, train/loss_step=9.820]
============================================================
[Input Before LLM] - Global Step 700
============================================================
  Adaptor embeddings shape: torch.Size([4, 593, 896])
  Input embeddings shape: torch.Size([4, 593, 896])
  Attention mask shape: torch.Size([4, 593])
  Input dtype: torch.float16
  Adaptor embeddings range: [-6.1367, 8.0312]
  Input embeddings range: [-6.1367, 8.0312]
  Input embeddings mean: -0.0036, std: 0.7397
  Language inputs shape: torch.Size([4, 563, 896])

============================================================
Global Step 700
============================================================

[Losses]
  language_loss: 0.000135 (shape: torch.Size([4, 562]), count: 28)
  route_loss: 1.239258 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.585938 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 701/267978 [07:57<50:36:29,  1.47it/s, v_num=full, train/loss_step=9.820]
Epoch 0:   0%|          | 701/267978 [07:57<50:36:29,  1.47it/s, v_num=full, train/loss_step=5.840]
Epoch 0:   0%|          | 702/267978 [07:58<50:35:53,  1.47it/s, v_num=full, train/loss_step=5.840]
Epoch 0:   0%|          | 702/267978 [07:58<50:35:53,  1.47it/s, v_num=full, train/loss_step=4.410]
Epoch 0:   0%|          | 703/267978 [07:59<50:35:22,  1.47it/s, v_num=full, train/loss_step=4.410]
Epoch 0:   0%|          | 703/267978 [07:59<50:35:22,  1.47it/s, v_num=full, train/loss_step=4.780]
Epoch 0:   0%|          | 704/267978 [07:59<50:34:51,  1.47it/s, v_num=full, train/loss_step=4.780]
Epoch 0:   0%|          | 704/267978 [07:59<50:34:51,  1.47it/s, v_num=full, train/loss_step=3.730]
Epoch 0:   0%|          | 705/267978 [08:00<50:34:20,  1.47it/s, v_num=full, train/loss_step=3.730]
Epoch 0:   0%|          | 705/267978 [08:00<50:34:20,  1.47it/s, v_num=full, train/loss_step=7.080]
Epoch 0:   0%|          | 706/267978 [08:00<50:33:49,  1.47it/s, v_num=full, train/loss_step=7.080]
Epoch 0:   0%|          | 706/267978 [08:00<50:33:49,  1.47it/s, v_num=full, train/loss_step=3.140]
Epoch 0:   0%|          | 707/267978 [08:01<50:33:12,  1.47it/s, v_num=full, train/loss_step=3.140]
Epoch 0:   0%|          | 707/267978 [08:01<50:33:13,  1.47it/s, v_num=full, train/loss_step=4.820]
Epoch 0:   0%|          | 708/267978 [08:02<50:32:41,  1.47it/s, v_num=full, train/loss_step=4.820]
Epoch 0:   0%|          | 708/267978 [08:02<50:32:41,  1.47it/s, v_num=full, train/loss_step=3.890]
Epoch 0:   0%|          | 709/267978 [08:02<50:32:10,  1.47it/s, v_num=full, train/loss_step=3.890]
Epoch 0:   0%|          | 709/267978 [08:02<50:32:10,  1.47it/s, v_num=full, train/loss_step=5.350]
Epoch 0:   0%|          | 710/267978 [08:03<50:31:43,  1.47it/s, v_num=full, train/loss_step=5.350]
Epoch 0:   0%|          | 710/267978 [08:03<50:31:43,  1.47it/s, v_num=full, train/loss_step=10.10]
============================================================
Global Step 710
============================================================

[Losses]
  language_loss: 0.000185 (shape: torch.Size([4, 560]), count: 28)
  route_loss: 1.339844 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 6.640625 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 711/267978 [08:03<50:31:11,  1.47it/s, v_num=full, train/loss_step=10.10]
Epoch 0:   0%|          | 711/267978 [08:03<50:31:11,  1.47it/s, v_num=full, train/loss_step=8.000]
Epoch 0:   0%|          | 712/267978 [08:04<50:30:40,  1.47it/s, v_num=full, train/loss_step=8.000]
Epoch 0:   0%|          | 712/267978 [08:04<50:30:40,  1.47it/s, v_num=full, train/loss_step=3.670]
Epoch 0:   0%|          | 713/267978 [08:05<50:30:10,  1.47it/s, v_num=full, train/loss_step=3.670]
Epoch 0:   0%|          | 713/267978 [08:05<50:30:10,  1.47it/s, v_num=full, train/loss_step=5.500]
Epoch 0:   0%|          | 714/267978 [08:05<50:29:39,  1.47it/s, v_num=full, train/loss_step=5.500]
Epoch 0:   0%|          | 714/267978 [08:05<50:29:39,  1.47it/s, v_num=full, train/loss_step=4.360]
Epoch 0:   0%|          | 715/267978 [08:06<50:29:08,  1.47it/s, v_num=full, train/loss_step=4.360]
Epoch 0:   0%|          | 715/267978 [08:06<50:29:08,  1.47it/s, v_num=full, train/loss_step=2.880]
Epoch 0:   0%|          | 716/267978 [08:06<50:28:39,  1.47it/s, v_num=full, train/loss_step=2.880]
Epoch 0:   0%|          | 716/267978 [08:06<50:28:40,  1.47it/s, v_num=full, train/loss_step=6.000]
Epoch 0:   0%|          | 717/267978 [08:07<50:28:14,  1.47it/s, v_num=full, train/loss_step=6.000]
Epoch 0:   0%|          | 717/267978 [08:07<50:28:15,  1.47it/s, v_num=full, train/loss_step=7.430]
Epoch 0:   0%|          | 718/267978 [08:08<50:27:45,  1.47it/s, v_num=full, train/loss_step=7.430]
Epoch 0:   0%|          | 718/267978 [08:08<50:27:46,  1.47it/s, v_num=full, train/loss_step=2.470]
Epoch 0:   0%|          | 719/267978 [08:08<50:27:14,  1.47it/s, v_num=full, train/loss_step=2.470]
Epoch 0:   0%|          | 719/267978 [08:08<50:27:14,  1.47it/s, v_num=full, train/loss_step=5.490]
Epoch 0:   0%|          | 720/267978 [08:09<50:26:42,  1.47it/s, v_num=full, train/loss_step=5.490]
Epoch 0:   0%|          | 720/267978 [08:09<50:26:42,  1.47it/s, v_num=full, train/loss_step=13.70]
============================================================
Global Step 720
============================================================

[Losses]
  language_loss: 0.000201 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 1.095703 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 1.757812 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 721/267978 [08:09<50:26:15,  1.47it/s, v_num=full, train/loss_step=13.70]
Epoch 0:   0%|          | 721/267978 [08:09<50:26:15,  1.47it/s, v_num=full, train/loss_step=2.870]
Epoch 0:   0%|          | 722/267978 [08:10<50:25:47,  1.47it/s, v_num=full, train/loss_step=2.870]
Epoch 0:   0%|          | 722/267978 [08:10<50:25:47,  1.47it/s, v_num=full, train/loss_step=3.040]
Epoch 0:   0%|          | 723/267978 [08:11<50:25:17,  1.47it/s, v_num=full, train/loss_step=3.040]
Epoch 0:   0%|          | 723/267978 [08:11<50:25:18,  1.47it/s, v_num=full, train/loss_step=5.890]
Epoch 0:   0%|          | 724/267978 [08:11<50:24:48,  1.47it/s, v_num=full, train/loss_step=5.890]
Epoch 0:   0%|          | 724/267978 [08:11<50:24:48,  1.47it/s, v_num=full, train/loss_step=5.410]
Epoch 0:   0%|          | 725/267978 [08:12<50:24:18,  1.47it/s, v_num=full, train/loss_step=5.410]
Epoch 0:   0%|          | 725/267978 [08:12<50:24:19,  1.47it/s, v_num=full, train/loss_step=1.640]
Epoch 0:   0%|          | 726/267978 [08:12<50:23:49,  1.47it/s, v_num=full, train/loss_step=1.640]
Epoch 0:   0%|          | 726/267978 [08:12<50:23:49,  1.47it/s, v_num=full, train/loss_step=4.110]
Epoch 0:   0%|          | 727/267978 [08:13<50:23:21,  1.47it/s, v_num=full, train/loss_step=4.110]
Epoch 0:   0%|          | 727/267978 [08:13<50:23:21,  1.47it/s, v_num=full, train/loss_step=4.120]
Epoch 0:   0%|          | 728/267978 [08:14<50:25:14,  1.47it/s, v_num=full, train/loss_step=4.120]
Epoch 0:   0%|          | 728/267978 [08:14<50:25:14,  1.47it/s, v_num=full, train/loss_step=4.090]
Epoch 0:   0%|          | 729/267978 [08:15<50:24:46,  1.47it/s, v_num=full, train/loss_step=4.090]
Epoch 0:   0%|          | 729/267978 [08:15<50:24:47,  1.47it/s, v_num=full, train/loss_step=3.980]
Epoch 0:   0%|          | 730/267978 [08:15<50:24:15,  1.47it/s, v_num=full, train/loss_step=3.980]
Epoch 0:   0%|          | 730/267978 [08:15<50:24:15,  1.47it/s, v_num=full, train/loss_step=7.340]
============================================================
Global Step 730
============================================================

[Losses]
  language_loss: 0.000314 (shape: torch.Size([4, 558]), count: 28)
  route_loss: 2.771484 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 7.816406 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 731/267978 [08:16<50:23:51,  1.47it/s, v_num=full, train/loss_step=7.340]
Epoch 0:   0%|          | 731/267978 [08:16<50:23:51,  1.47it/s, v_num=full, train/loss_step=10.60]
Epoch 0:   0%|          | 732/267978 [08:16<50:23:20,  1.47it/s, v_num=full, train/loss_step=10.60]
Epoch 0:   0%|          | 732/267978 [08:16<50:23:21,  1.47it/s, v_num=full, train/loss_step=5.160]
Epoch 0:   0%|          | 733/267978 [08:17<50:22:51,  1.47it/s, v_num=full, train/loss_step=5.160]
Epoch 0:   0%|          | 733/267978 [08:17<50:22:51,  1.47it/s, v_num=full, train/loss_step=6.230]
Epoch 0:   0%|          | 734/267978 [08:18<50:22:22,  1.47it/s, v_num=full, train/loss_step=6.230]
Epoch 0:   0%|          | 734/267978 [08:18<50:22:22,  1.47it/s, v_num=full, train/loss_step=8.230]
Epoch 0:   0%|          | 735/267978 [08:18<50:21:54,  1.47it/s, v_num=full, train/loss_step=8.230]
Epoch 0:   0%|          | 735/267978 [08:18<50:21:55,  1.47it/s, v_num=full, train/loss_step=2.960]
Epoch 0:   0%|          | 736/267978 [08:19<50:21:25,  1.47it/s, v_num=full, train/loss_step=2.960]
Epoch 0:   0%|          | 736/267978 [08:19<50:21:26,  1.47it/s, v_num=full, train/loss_step=5.750]
Epoch 0:   0%|          | 737/267978 [08:19<50:20:59,  1.47it/s, v_num=full, train/loss_step=5.750]
Epoch 0:   0%|          | 737/267978 [08:19<50:20:59,  1.47it/s, v_num=full, train/loss_step=7.320]
Epoch 0:   0%|          | 738/267978 [08:20<50:20:29,  1.47it/s, v_num=full, train/loss_step=7.320]
Epoch 0:   0%|          | 738/267978 [08:20<50:20:29,  1.47it/s, v_num=full, train/loss_step=4.350]
Epoch 0:   0%|          | 739/267978 [08:21<50:20:02,  1.47it/s, v_num=full, train/loss_step=4.350]
Epoch 0:   0%|          | 739/267978 [08:21<50:20:03,  1.47it/s, v_num=full, train/loss_step=7.520]
Epoch 0:   0%|          | 740/267978 [08:21<50:19:36,  1.48it/s, v_num=full, train/loss_step=7.520]
Epoch 0:   0%|          | 740/267978 [08:21<50:19:36,  1.48it/s, v_num=full, train/loss_step=3.550]
============================================================
Global Step 740
============================================================

[Losses]
  language_loss: 0.000216 (shape: torch.Size([4, 550]), count: 28)
  route_loss: 1.734375 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.123047 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 741/267978 [08:22<50:19:10,  1.48it/s, v_num=full, train/loss_step=3.550]
Epoch 0:   0%|          | 741/267978 [08:22<50:19:10,  1.48it/s, v_num=full, train/loss_step=4.880]
Epoch 0:   0%|          | 742/267978 [08:22<50:18:45,  1.48it/s, v_num=full, train/loss_step=4.880]
Epoch 0:   0%|          | 742/267978 [08:22<50:18:45,  1.48it/s, v_num=full, train/loss_step=4.830]
Epoch 0:   0%|          | 743/267978 [08:23<50:18:20,  1.48it/s, v_num=full, train/loss_step=4.830]
Epoch 0:   0%|          | 743/267978 [08:23<50:18:20,  1.48it/s, v_num=full, train/loss_step=3.730]
Epoch 0:   0%|          | 744/267978 [08:24<50:17:55,  1.48it/s, v_num=full, train/loss_step=3.730]
Epoch 0:   0%|          | 744/267978 [08:24<50:17:56,  1.48it/s, v_num=full, train/loss_step=2.090]
Epoch 0:   0%|          | 745/267978 [08:24<50:17:27,  1.48it/s, v_num=full, train/loss_step=2.090]
Epoch 0:   0%|          | 745/267978 [08:24<50:17:27,  1.48it/s, v_num=full, train/loss_step=2.180]
Epoch 0:   0%|          | 746/267978 [08:25<50:17:02,  1.48it/s, v_num=full, train/loss_step=2.180]
Epoch 0:   0%|          | 746/267978 [08:25<50:17:02,  1.48it/s, v_num=full, train/loss_step=4.060]
Epoch 0:   0%|          | 747/267978 [08:25<50:16:34,  1.48it/s, v_num=full, train/loss_step=4.060]
Epoch 0:   0%|          | 747/267978 [08:25<50:16:34,  1.48it/s, v_num=full, train/loss_step=6.690]
Epoch 0:   0%|          | 748/267978 [08:26<50:16:09,  1.48it/s, v_num=full, train/loss_step=6.690]
Epoch 0:   0%|          | 748/267978 [08:26<50:16:09,  1.48it/s, v_num=full, train/loss_step=4.240]
Epoch 0:   0%|          | 749/267978 [08:27<50:15:42,  1.48it/s, v_num=full, train/loss_step=4.240]
Epoch 0:   0%|          | 749/267978 [08:27<50:15:43,  1.48it/s, v_num=full, train/loss_step=5.390]
Epoch 0:   0%|          | 750/267978 [08:27<50:15:20,  1.48it/s, v_num=full, train/loss_step=5.390]
Epoch 0:   0%|          | 750/267978 [08:27<50:15:20,  1.48it/s, v_num=full, train/loss_step=6.610]
============================================================
Global Step 750
============================================================

[Losses]
  language_loss: 0.000306 (shape: torch.Size([4, 554]), count: 28)
  route_loss: 1.434570 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 5.992188 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 751/267978 [08:28<50:14:52,  1.48it/s, v_num=full, train/loss_step=6.610]
Epoch 0:   0%|          | 751/267978 [08:28<50:14:52,  1.48it/s, v_num=full, train/loss_step=7.450]
Epoch 0:   0%|          | 752/267978 [08:28<50:14:24,  1.48it/s, v_num=full, train/loss_step=7.450]
Epoch 0:   0%|          | 752/267978 [08:28<50:14:25,  1.48it/s, v_num=full, train/loss_step=4.360]
Epoch 0:   0%|          | 753/267978 [08:29<50:13:59,  1.48it/s, v_num=full, train/loss_step=4.360]
Epoch 0:   0%|          | 753/267978 [08:29<50:13:59,  1.48it/s, v_num=full, train/loss_step=2.160]
Epoch 0:   0%|          | 754/267978 [08:30<50:13:31,  1.48it/s, v_num=full, train/loss_step=2.160]
Epoch 0:   0%|          | 754/267978 [08:30<50:13:31,  1.48it/s, v_num=full, train/loss_step=9.720]
Epoch 0:   0%|          | 755/267978 [08:30<50:13:03,  1.48it/s, v_num=full, train/loss_step=9.720]
Epoch 0:   0%|          | 755/267978 [08:30<50:13:04,  1.48it/s, v_num=full, train/loss_step=5.440]
Epoch 0:   0%|          | 756/267978 [08:31<50:12:35,  1.48it/s, v_num=full, train/loss_step=5.440]
Epoch 0:   0%|          | 756/267978 [08:31<50:12:35,  1.48it/s, v_num=full, train/loss_step=6.970]
Epoch 0:   0%|          | 757/267978 [08:31<50:12:09,  1.48it/s, v_num=full, train/loss_step=6.970]
Epoch 0:   0%|          | 757/267978 [08:31<50:12:09,  1.48it/s, v_num=full, train/loss_step=7.080]
Epoch 0:   0%|          | 758/267978 [08:32<50:11:52,  1.48it/s, v_num=full, train/loss_step=7.080]
Epoch 0:   0%|          | 758/267978 [08:32<50:11:52,  1.48it/s, v_num=full, train/loss_step=3.890]
Epoch 0:   0%|          | 759/267978 [08:33<50:11:26,  1.48it/s, v_num=full, train/loss_step=3.890]
Epoch 0:   0%|          | 759/267978 [08:33<50:11:26,  1.48it/s, v_num=full, train/loss_step=6.960]
Epoch 0:   0%|          | 760/267978 [08:33<50:10:52,  1.48it/s, v_num=full, train/loss_step=6.960]
Epoch 0:   0%|          | 760/267978 [08:33<50:10:52,  1.48it/s, v_num=full, train/loss_step=5.860]
============================================================
Global Step 760
============================================================

[Losses]
  language_loss: 0.000237 (shape: torch.Size([4, 565]), count: 28)
  route_loss: 1.268555 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.238281 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 761/267978 [08:34<50:10:26,  1.48it/s, v_num=full, train/loss_step=5.860]
Epoch 0:   0%|          | 761/267978 [08:34<50:10:27,  1.48it/s, v_num=full, train/loss_step=4.530]
Epoch 0:   0%|          | 762/267978 [08:35<50:09:59,  1.48it/s, v_num=full, train/loss_step=4.530]
Epoch 0:   0%|          | 762/267978 [08:35<50:09:59,  1.48it/s, v_num=full, train/loss_step=2.730]
Epoch 0:   0%|          | 763/267978 [08:35<50:09:34,  1.48it/s, v_num=full, train/loss_step=2.730]
Epoch 0:   0%|          | 763/267978 [08:35<50:09:35,  1.48it/s, v_num=full, train/loss_step=6.940]
Epoch 0:   0%|          | 764/267978 [08:36<50:09:12,  1.48it/s, v_num=full, train/loss_step=6.940]
Epoch 0:   0%|          | 764/267978 [08:36<50:09:12,  1.48it/s, v_num=full, train/loss_step=3.540]
Epoch 0:   0%|          | 765/267978 [08:36<50:08:47,  1.48it/s, v_num=full, train/loss_step=3.540]
Epoch 0:   0%|          | 765/267978 [08:36<50:08:47,  1.48it/s, v_num=full, train/loss_step=4.520]
Epoch 0:   0%|          | 766/267978 [08:37<50:08:19,  1.48it/s, v_num=full, train/loss_step=4.520]
Epoch 0:   0%|          | 766/267978 [08:37<50:08:19,  1.48it/s, v_num=full, train/loss_step=4.580]
Epoch 0:   0%|          | 767/267978 [08:38<50:07:52,  1.48it/s, v_num=full, train/loss_step=4.580]
Epoch 0:   0%|          | 767/267978 [08:38<50:07:52,  1.48it/s, v_num=full, train/loss_step=3.970]
Epoch 0:   0%|          | 768/267978 [08:38<50:07:25,  1.48it/s, v_num=full, train/loss_step=3.970]
Epoch 0:   0%|          | 768/267978 [08:38<50:07:25,  1.48it/s, v_num=full, train/loss_step=3.790]
Epoch 0:   0%|          | 769/267978 [08:39<50:06:59,  1.48it/s, v_num=full, train/loss_step=3.790]
Epoch 0:   0%|          | 769/267978 [08:39<50:06:59,  1.48it/s, v_num=full, train/loss_step=3.550]
Epoch 0:   0%|          | 770/267978 [08:39<50:06:33,  1.48it/s, v_num=full, train/loss_step=3.550]
Epoch 0:   0%|          | 770/267978 [08:39<50:06:33,  1.48it/s, v_num=full, train/loss_step=9.770]
============================================================
Global Step 770
============================================================

[Losses]
  language_loss: 0.000313 (shape: torch.Size([4, 550]), count: 28)
  route_loss: 0.993164 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.800781 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 771/267978 [08:40<50:06:10,  1.48it/s, v_num=full, train/loss_step=9.770]
Epoch 0:   0%|          | 771/267978 [08:40<50:06:10,  1.48it/s, v_num=full, train/loss_step=5.820]
Epoch 0:   0%|          | 772/267978 [08:41<50:05:49,  1.48it/s, v_num=full, train/loss_step=5.820]
Epoch 0:   0%|          | 772/267978 [08:41<50:05:50,  1.48it/s, v_num=full, train/loss_step=9.760]
Epoch 0:   0%|          | 773/267978 [08:41<50:05:25,  1.48it/s, v_num=full, train/loss_step=9.760]
Epoch 0:   0%|          | 773/267978 [08:41<50:05:25,  1.48it/s, v_num=full, train/loss_step=5.410]
Epoch 0:   0%|          | 774/267978 [08:42<50:05:03,  1.48it/s, v_num=full, train/loss_step=5.410]
Epoch 0:   0%|          | 774/267978 [08:42<50:05:03,  1.48it/s, v_num=full, train/loss_step=7.430]
Epoch 0:   0%|          | 775/267978 [08:42<50:04:39,  1.48it/s, v_num=full, train/loss_step=7.430]
Epoch 0:   0%|          | 775/267978 [08:42<50:04:39,  1.48it/s, v_num=full, train/loss_step=5.420]
Epoch 0:   0%|          | 776/267978 [08:43<50:04:17,  1.48it/s, v_num=full, train/loss_step=5.420]
Epoch 0:   0%|          | 776/267978 [08:43<50:04:17,  1.48it/s, v_num=full, train/loss_step=3.770]
Epoch 0:   0%|          | 777/267978 [08:44<50:03:57,  1.48it/s, v_num=full, train/loss_step=3.770]
Epoch 0:   0%|          | 777/267978 [08:44<50:03:57,  1.48it/s, v_num=full, train/loss_step=5.900]
Epoch 0:   0%|          | 778/267978 [08:44<50:03:36,  1.48it/s, v_num=full, train/loss_step=5.900]
Epoch 0:   0%|          | 778/267978 [08:44<50:03:36,  1.48it/s, v_num=full, train/loss_step=6.830]
Epoch 0:   0%|          | 779/267978 [08:45<50:03:16,  1.48it/s, v_num=full, train/loss_step=6.830]
Epoch 0:   0%|          | 779/267978 [08:45<50:03:16,  1.48it/s, v_num=full, train/loss_step=5.620]
Epoch 0:   0%|          | 780/267978 [08:45<50:02:55,  1.48it/s, v_num=full, train/loss_step=5.620]
Epoch 0:   0%|          | 780/267978 [08:45<50:02:55,  1.48it/s, v_num=full, train/loss_step=4.350]
============================================================
Global Step 780
============================================================

[Losses]
  language_loss: 0.000142 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 0.868652 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 1.952148 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 781/267978 [08:46<50:02:39,  1.48it/s, v_num=full, train/loss_step=4.350]
Epoch 0:   0%|          | 781/267978 [08:46<50:02:39,  1.48it/s, v_num=full, train/loss_step=2.830]
Epoch 0:   0%|          | 782/267978 [08:47<50:02:20,  1.48it/s, v_num=full, train/loss_step=2.830]
Epoch 0:   0%|          | 782/267978 [08:47<50:02:21,  1.48it/s, v_num=full, train/loss_step=5.390]
Epoch 0:   0%|          | 783/267978 [08:47<50:01:57,  1.48it/s, v_num=full, train/loss_step=5.390]
Epoch 0:   0%|          | 783/267978 [08:47<50:01:58,  1.48it/s, v_num=full, train/loss_step=9.660]
Epoch 0:   0%|          | 784/267978 [08:48<50:01:36,  1.48it/s, v_num=full, train/loss_step=9.660]
Epoch 0:   0%|          | 784/267978 [08:48<50:01:36,  1.48it/s, v_num=full, train/loss_step=3.790]
Epoch 0:   0%|          | 785/267978 [08:49<50:01:14,  1.48it/s, v_num=full, train/loss_step=3.790]
Epoch 0:   0%|          | 785/267978 [08:49<50:01:14,  1.48it/s, v_num=full, train/loss_step=5.360]
Epoch 0:   0%|          | 786/267978 [08:49<50:00:56,  1.48it/s, v_num=full, train/loss_step=5.360]
Epoch 0:   0%|          | 786/267978 [08:49<50:00:56,  1.48it/s, v_num=full, train/loss_step=7.890]
Epoch 0:   0%|          | 787/267978 [08:50<50:00:31,  1.48it/s, v_num=full, train/loss_step=7.890]
Epoch 0:   0%|          | 787/267978 [08:50<50:00:31,  1.48it/s, v_num=full, train/loss_step=3.030]
Epoch 0:   0%|          | 788/267978 [08:50<50:00:09,  1.48it/s, v_num=full, train/loss_step=3.030]
Epoch 0:   0%|          | 788/267978 [08:50<50:00:10,  1.48it/s, v_num=full, train/loss_step=6.120]
Epoch 0:   0%|          | 789/267978 [08:51<49:59:47,  1.48it/s, v_num=full, train/loss_step=6.120]
Epoch 0:   0%|          | 789/267978 [08:51<49:59:48,  1.48it/s, v_num=full, train/loss_step=11.00]
Epoch 0:   0%|          | 790/267978 [08:52<49:59:19,  1.48it/s, v_num=full, train/loss_step=11.00]
Epoch 0:   0%|          | 790/267978 [08:52<49:59:20,  1.48it/s, v_num=full, train/loss_step=5.870]
============================================================
Global Step 790
============================================================

[Losses]
  language_loss: 0.000185 (shape: torch.Size([4, 559]), count: 28)
  route_loss: 2.326172 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.845703 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 791/267978 [08:52<49:59:01,  1.48it/s, v_num=full, train/loss_step=5.870]
Epoch 0:   0%|          | 791/267978 [08:55<50:12:54,  1.48it/s, v_num=full, train/loss_step=6.190]
Epoch 0:   0%|          | 792/267978 [08:58<50:27:17,  1.47it/s, v_num=full, train/loss_step=6.190]
Epoch 0:   0%|          | 792/267978 [09:00<50:38:24,  1.47it/s, v_num=full, train/loss_step=7.680]
Epoch 0:   0%|          | 793/267978 [09:03<50:52:42,  1.46it/s, v_num=full, train/loss_step=7.680]
Epoch 0:   0%|          | 793/267978 [09:05<51:04:04,  1.45it/s, v_num=full, train/loss_step=6.130]
Epoch 0:   0%|          | 794/267978 [09:08<51:18:31,  1.45it/s, v_num=full, train/loss_step=6.130]
Epoch 0:   0%|          | 794/267978 [09:08<51:18:32,  1.45it/s, v_num=full, train/loss_step=5.520]
Epoch 0:   0%|          | 795/267978 [09:09<51:18:03,  1.45it/s, v_num=full, train/loss_step=5.520]
Epoch 0:   0%|          | 795/267978 [09:09<51:18:04,  1.45it/s, v_num=full, train/loss_step=4.600]
Epoch 0:   0%|          | 796/267978 [09:10<51:17:41,  1.45it/s, v_num=full, train/loss_step=4.600]
Epoch 0:   0%|          | 796/267978 [09:10<51:17:42,  1.45it/s, v_num=full, train/loss_step=5.710]
Epoch 0:   0%|          | 797/267978 [09:10<51:17:19,  1.45it/s, v_num=full, train/loss_step=5.710]
Epoch 0:   0%|          | 797/267978 [09:10<51:17:20,  1.45it/s, v_num=full, train/loss_step=4.210]
Epoch 0:   0%|          | 798/267978 [09:11<51:16:57,  1.45it/s, v_num=full, train/loss_step=4.210]
Epoch 0:   0%|          | 798/267978 [09:11<51:16:57,  1.45it/s, v_num=full, train/loss_step=4.100]
Epoch 0:   0%|          | 799/267978 [09:12<51:16:34,  1.45it/s, v_num=full, train/loss_step=4.100]
Epoch 0:   0%|          | 799/267978 [09:12<51:16:34,  1.45it/s, v_num=full, train/loss_step=4.200]
Epoch 0:   0%|          | 800/267978 [09:18<51:50:12,  1.43it/s, v_num=full, train/loss_step=4.200]
Epoch 0:   0%|          | 800/267978 [09:18<51:50:13,  1.43it/s, v_num=full, train/loss_step=3.640]
============================================================
[Input Before LLM] - Global Step 800
============================================================
  Adaptor embeddings shape: torch.Size([4, 588, 896])
  Input embeddings shape: torch.Size([4, 588, 896])
  Attention mask shape: torch.Size([4, 588])
  Input dtype: torch.float16
  Adaptor embeddings range: [-7.1367, 9.0078]
  Input embeddings range: [-7.1367, 9.0078]
  Input embeddings mean: -0.0028, std: 0.7568
  Language inputs shape: torch.Size([4, 558, 896])

============================================================
Global Step 800
============================================================

[Losses]
  language_loss: 0.000133 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 0.554199 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 5.128906 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 801/267978 [09:19<51:49:53,  1.43it/s, v_num=full, train/loss_step=3.640]
Epoch 0:   0%|          | 801/267978 [09:19<51:49:54,  1.43it/s, v_num=full, train/loss_step=5.690]
Epoch 0:   0%|          | 802/267978 [09:20<51:49:21,  1.43it/s, v_num=full, train/loss_step=5.690]
Epoch 0:   0%|          | 802/267978 [09:20<51:49:21,  1.43it/s, v_num=full, train/loss_step=2.700]
Epoch 0:   0%|          | 803/267978 [09:20<51:48:48,  1.43it/s, v_num=full, train/loss_step=2.700]
Epoch 0:   0%|          | 803/267978 [09:20<51:48:49,  1.43it/s, v_num=full, train/loss_step=3.320]
Epoch 0:   0%|          | 804/267978 [09:21<51:48:16,  1.43it/s, v_num=full, train/loss_step=3.320]
Epoch 0:   0%|          | 804/267978 [09:21<51:48:17,  1.43it/s, v_num=full, train/loss_step=5.320]
Epoch 0:   0%|          | 805/267978 [09:21<51:47:40,  1.43it/s, v_num=full, train/loss_step=5.320]
Epoch 0:   0%|          | 805/267978 [09:21<51:47:40,  1.43it/s, v_num=full, train/loss_step=3.090]
Epoch 0:   0%|          | 806/267978 [09:22<51:47:10,  1.43it/s, v_num=full, train/loss_step=3.090]
Epoch 0:   0%|          | 806/267978 [09:22<51:47:10,  1.43it/s, v_num=full, train/loss_step=9.210]
Epoch 0:   0%|          | 807/267978 [09:23<51:46:40,  1.43it/s, v_num=full, train/loss_step=9.210]
Epoch 0:   0%|          | 807/267978 [09:23<51:46:40,  1.43it/s, v_num=full, train/loss_step=5.350]
Epoch 0:   0%|          | 808/267978 [09:23<51:46:09,  1.43it/s, v_num=full, train/loss_step=5.350]
Epoch 0:   0%|          | 808/267978 [09:23<51:46:09,  1.43it/s, v_num=full, train/loss_step=5.800]
Epoch 0:   0%|          | 809/267978 [09:24<51:45:40,  1.43it/s, v_num=full, train/loss_step=5.800]
Epoch 0:   0%|          | 809/267978 [09:24<51:45:40,  1.43it/s, v_num=full, train/loss_step=3.830]
Epoch 0:   0%|          | 810/267978 [09:24<51:45:08,  1.43it/s, v_num=full, train/loss_step=3.830]
Epoch 0:   0%|          | 810/267978 [09:24<51:45:08,  1.43it/s, v_num=full, train/loss_step=4.810]
============================================================
Global Step 810
============================================================

[Losses]
  language_loss: 0.000114 (shape: torch.Size([4, 562]), count: 28)
  route_loss: 2.599609 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 10.812500 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 811/267978 [09:25<51:44:37,  1.43it/s, v_num=full, train/loss_step=4.810]
Epoch 0:   0%|          | 811/267978 [09:25<51:44:38,  1.43it/s, v_num=full, train/loss_step=13.40]
Epoch 0:   0%|          | 812/267978 [09:26<51:44:10,  1.43it/s, v_num=full, train/loss_step=13.40]
Epoch 0:   0%|          | 812/267978 [09:26<51:44:11,  1.43it/s, v_num=full, train/loss_step=5.420]
Epoch 0:   0%|          | 813/267978 [09:26<51:43:38,  1.43it/s, v_num=full, train/loss_step=5.420]
Epoch 0:   0%|          | 813/267978 [09:26<51:43:38,  1.43it/s, v_num=full, train/loss_step=6.860]
Epoch 0:   0%|          | 814/267978 [09:27<51:43:08,  1.43it/s, v_num=full, train/loss_step=6.860]
Epoch 0:   0%|          | 814/267978 [09:27<51:43:09,  1.43it/s, v_num=full, train/loss_step=3.630]
Epoch 0:   0%|          | 815/267978 [09:27<51:42:37,  1.44it/s, v_num=full, train/loss_step=3.630]
Epoch 0:   0%|          | 815/267978 [09:27<51:42:38,  1.44it/s, v_num=full, train/loss_step=6.460]
Epoch 0:   0%|          | 816/267978 [09:28<51:42:10,  1.44it/s, v_num=full, train/loss_step=6.460]
Epoch 0:   0%|          | 816/267978 [09:28<51:42:10,  1.44it/s, v_num=full, train/loss_step=7.590]
Epoch 0:   0%|          | 817/267978 [09:29<51:41:41,  1.44it/s, v_num=full, train/loss_step=7.590]
Epoch 0:   0%|          | 817/267978 [09:29<51:41:41,  1.44it/s, v_num=full, train/loss_step=5.650]
Epoch 0:   0%|          | 818/267978 [09:29<51:41:14,  1.44it/s, v_num=full, train/loss_step=5.650]
Epoch 0:   0%|          | 818/267978 [09:29<51:41:14,  1.44it/s, v_num=full, train/loss_step=5.180]
Epoch 0:   0%|          | 819/267978 [09:30<51:40:46,  1.44it/s, v_num=full, train/loss_step=5.180]
Epoch 0:   0%|          | 819/267978 [09:30<51:40:47,  1.44it/s, v_num=full, train/loss_step=6.890]
Epoch 0:   0%|          | 820/267978 [09:30<51:40:18,  1.44it/s, v_num=full, train/loss_step=6.890]
Epoch 0:   0%|          | 820/267978 [09:30<51:40:18,  1.44it/s, v_num=full, train/loss_step=3.130]
============================================================
Global Step 820
============================================================

[Losses]
  language_loss: 0.000162 (shape: torch.Size([4, 555]), count: 28)
  route_loss: 1.514648 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.132812 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 821/267978 [09:31<51:39:48,  1.44it/s, v_num=full, train/loss_step=3.130]
Epoch 0:   0%|          | 821/267978 [09:31<51:39:48,  1.44it/s, v_num=full, train/loss_step=5.660]
Epoch 0:   0%|          | 822/267978 [09:32<51:39:19,  1.44it/s, v_num=full, train/loss_step=5.660]
Epoch 0:   0%|          | 822/267978 [09:32<51:39:20,  1.44it/s, v_num=full, train/loss_step=5.430]
Epoch 0:   0%|          | 823/267978 [09:32<51:38:47,  1.44it/s, v_num=full, train/loss_step=5.430]
Epoch 0:   0%|          | 823/267978 [09:32<51:38:47,  1.44it/s, v_num=full, train/loss_step=6.770]
Epoch 0:   0%|          | 824/267978 [09:33<51:38:22,  1.44it/s, v_num=full, train/loss_step=6.770]
Epoch 0:   0%|          | 824/267978 [09:33<51:38:22,  1.44it/s, v_num=full, train/loss_step=8.040]
Epoch 0:   0%|          | 825/267978 [09:33<51:37:51,  1.44it/s, v_num=full, train/loss_step=8.040]
Epoch 0:   0%|          | 825/267978 [09:33<51:37:51,  1.44it/s, v_num=full, train/loss_step=8.070]
Epoch 0:   0%|          | 826/267978 [09:34<51:37:30,  1.44it/s, v_num=full, train/loss_step=8.070]
Epoch 0:   0%|          | 826/267978 [09:34<51:37:31,  1.44it/s, v_num=full, train/loss_step=2.990]
Epoch 0:   0%|          | 827/267978 [09:35<51:37:01,  1.44it/s, v_num=full, train/loss_step=2.990]
Epoch 0:   0%|          | 827/267978 [09:35<51:37:01,  1.44it/s, v_num=full, train/loss_step=3.740]
Epoch 0:   0%|          | 828/267978 [09:35<51:36:32,  1.44it/s, v_num=full, train/loss_step=3.740]
Epoch 0:   0%|          | 828/267978 [09:35<51:36:32,  1.44it/s, v_num=full, train/loss_step=6.090]
Epoch 0:   0%|          | 829/267978 [09:36<51:36:03,  1.44it/s, v_num=full, train/loss_step=6.090]
Epoch 0:   0%|          | 829/267978 [09:36<51:36:04,  1.44it/s, v_num=full, train/loss_step=5.300]
Epoch 0:   0%|          | 830/267978 [09:37<51:35:33,  1.44it/s, v_num=full, train/loss_step=5.300]
Epoch 0:   0%|          | 830/267978 [09:37<51:35:33,  1.44it/s, v_num=full, train/loss_step=7.690]
============================================================
Global Step 830
============================================================

[Losses]
  language_loss: 0.000246 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 1.854492 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 7.265625 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 831/267978 [09:37<51:35:10,  1.44it/s, v_num=full, train/loss_step=7.690]
Epoch 0:   0%|          | 831/267978 [09:37<51:35:11,  1.44it/s, v_num=full, train/loss_step=9.140]
Epoch 0:   0%|          | 832/267978 [09:38<51:34:43,  1.44it/s, v_num=full, train/loss_step=9.140]
Epoch 0:   0%|          | 832/267978 [09:38<51:34:43,  1.44it/s, v_num=full, train/loss_step=4.970]
Epoch 0:   0%|          | 833/267978 [09:38<51:34:15,  1.44it/s, v_num=full, train/loss_step=4.970]
Epoch 0:   0%|          | 833/267978 [09:38<51:34:15,  1.44it/s, v_num=full, train/loss_step=7.860]
Epoch 0:   0%|          | 834/267978 [09:39<51:33:50,  1.44it/s, v_num=full, train/loss_step=7.860]
Epoch 0:   0%|          | 834/267978 [09:39<51:33:50,  1.44it/s, v_num=full, train/loss_step=7.860]
Epoch 0:   0%|          | 835/267978 [09:40<51:33:25,  1.44it/s, v_num=full, train/loss_step=7.860]
Epoch 0:   0%|          | 835/267978 [09:40<51:33:26,  1.44it/s, v_num=full, train/loss_step=6.110]
Epoch 0:   0%|          | 836/267978 [09:40<51:32:59,  1.44it/s, v_num=full, train/loss_step=6.110]
Epoch 0:   0%|          | 836/267978 [09:40<51:32:59,  1.44it/s, v_num=full, train/loss_step=3.900]
Epoch 0:   0%|          | 837/267978 [09:41<51:32:31,  1.44it/s, v_num=full, train/loss_step=3.900]
Epoch 0:   0%|          | 837/267978 [09:41<51:32:31,  1.44it/s, v_num=full, train/loss_step=5.060]
Epoch 0:   0%|          | 838/267978 [09:41<51:32:05,  1.44it/s, v_num=full, train/loss_step=5.060]
Epoch 0:   0%|          | 838/267978 [09:41<51:32:05,  1.44it/s, v_num=full, train/loss_step=3.210]
Epoch 0:   0%|          | 839/267978 [09:42<51:31:39,  1.44it/s, v_num=full, train/loss_step=3.210]
Epoch 0:   0%|          | 839/267978 [09:42<51:31:39,  1.44it/s, v_num=full, train/loss_step=3.470]
Epoch 0:   0%|          | 840/267978 [09:43<51:31:16,  1.44it/s, v_num=full, train/loss_step=3.470]
Epoch 0:   0%|          | 840/267978 [09:43<51:31:17,  1.44it/s, v_num=full, train/loss_step=4.950]
============================================================
Global Step 840
============================================================

[Losses]
  language_loss: 0.000186 (shape: torch.Size([4, 546]), count: 28)
  route_loss: 1.141602 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.121094 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 841/267978 [09:43<51:30:54,  1.44it/s, v_num=full, train/loss_step=4.950]
Epoch 0:   0%|          | 841/267978 [09:43<51:30:54,  1.44it/s, v_num=full, train/loss_step=4.280]
Epoch 0:   0%|          | 842/267978 [09:44<51:30:32,  1.44it/s, v_num=full, train/loss_step=4.280]
Epoch 0:   0%|          | 842/267978 [09:44<51:30:32,  1.44it/s, v_num=full, train/loss_step=6.880]
Epoch 0:   0%|          | 843/267978 [09:45<51:30:09,  1.44it/s, v_num=full, train/loss_step=6.880]
Epoch 0:   0%|          | 843/267978 [09:45<51:30:09,  1.44it/s, v_num=full, train/loss_step=3.360]
Epoch 0:   0%|          | 844/267978 [09:45<51:29:47,  1.44it/s, v_num=full, train/loss_step=3.360]
Epoch 0:   0%|          | 844/267978 [09:45<51:29:47,  1.44it/s, v_num=full, train/loss_step=8.570]
Epoch 0:   0%|          | 845/267978 [09:46<51:29:25,  1.44it/s, v_num=full, train/loss_step=8.570]
Epoch 0:   0%|          | 845/267978 [09:46<51:29:25,  1.44it/s, v_num=full, train/loss_step=7.260]
Epoch 0:   0%|          | 846/267978 [09:46<51:28:58,  1.44it/s, v_num=full, train/loss_step=7.260]
Epoch 0:   0%|          | 846/267978 [09:46<51:28:58,  1.44it/s, v_num=full, train/loss_step=7.070]
Epoch 0:   0%|          | 847/267978 [09:47<51:28:31,  1.44it/s, v_num=full, train/loss_step=7.070]
Epoch 0:   0%|          | 847/267978 [09:47<51:28:32,  1.44it/s, v_num=full, train/loss_step=4.730]
Epoch 0:   0%|          | 848/267978 [09:48<51:28:04,  1.44it/s, v_num=full, train/loss_step=4.730]
Epoch 0:   0%|          | 848/267978 [09:48<51:28:04,  1.44it/s, v_num=full, train/loss_step=5.770]
Epoch 0:   0%|          | 849/267978 [09:48<51:27:38,  1.44it/s, v_num=full, train/loss_step=5.770]
Epoch 0:   0%|          | 849/267978 [09:53<51:50:48,  1.43it/s, v_num=full, train/loss_step=2.680]
Epoch 0:   0%|          | 850/267978 [09:53<51:50:34,  1.43it/s, v_num=full, train/loss_step=2.680]
Epoch 0:   0%|          | 850/267978 [09:53<51:50:34,  1.43it/s, v_num=full, train/loss_step=3.480]
============================================================
Global Step 850
============================================================

[Losses]
  language_loss: 0.000244 (shape: torch.Size([4, 561]), count: 28)
  route_loss: 0.909180 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 6.027344 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 851/267978 [09:54<51:50:06,  1.43it/s, v_num=full, train/loss_step=3.480]
Epoch 0:   0%|          | 851/267978 [09:54<51:50:06,  1.43it/s, v_num=full, train/loss_step=6.960]
Epoch 0:   0%|          | 852/267978 [09:55<51:49:39,  1.43it/s, v_num=full, train/loss_step=6.960]
Epoch 0:   0%|          | 852/267978 [09:55<51:49:39,  1.43it/s, v_num=full, train/loss_step=3.080]
Epoch 0:   0%|          | 853/267978 [09:55<51:49:08,  1.43it/s, v_num=full, train/loss_step=3.080]
Epoch 0:   0%|          | 853/267978 [09:55<51:49:08,  1.43it/s, v_num=full, train/loss_step=3.580]
Epoch 0:   0%|          | 854/267978 [09:56<51:48:38,  1.43it/s, v_num=full, train/loss_step=3.580]
Epoch 0:   0%|          | 854/267978 [09:56<51:48:38,  1.43it/s, v_num=full, train/loss_step=3.660]
Epoch 0:   0%|          | 855/267978 [09:56<51:48:10,  1.43it/s, v_num=full, train/loss_step=3.660]
Epoch 0:   0%|          | 855/267978 [09:56<51:48:10,  1.43it/s, v_num=full, train/loss_step=3.870]
Epoch 0:   0%|          | 856/267978 [09:57<51:47:44,  1.43it/s, v_num=full, train/loss_step=3.870]
Epoch 0:   0%|          | 856/267978 [09:57<51:47:44,  1.43it/s, v_num=full, train/loss_step=2.000]
Epoch 0:   0%|          | 857/267978 [09:58<51:47:18,  1.43it/s, v_num=full, train/loss_step=2.000]
Epoch 0:   0%|          | 857/267978 [09:58<51:47:18,  1.43it/s, v_num=full, train/loss_step=3.010]
Epoch 0:   0%|          | 858/267978 [09:58<51:46:51,  1.43it/s, v_num=full, train/loss_step=3.010]
Epoch 0:   0%|          | 858/267978 [09:58<51:46:51,  1.43it/s, v_num=full, train/loss_step=3.080]
Epoch 0:   0%|          | 859/267978 [09:59<51:46:23,  1.43it/s, v_num=full, train/loss_step=3.080]
Epoch 0:   0%|          | 859/267978 [09:59<51:46:23,  1.43it/s, v_num=full, train/loss_step=6.950]
Epoch 0:   0%|          | 860/267978 [09:59<51:45:55,  1.43it/s, v_num=full, train/loss_step=6.950]
Epoch 0:   0%|          | 860/267978 [09:59<51:45:55,  1.43it/s, v_num=full, train/loss_step=4.140]
============================================================
Global Step 860
============================================================

[Losses]
  language_loss: 0.000239 (shape: torch.Size([4, 563]), count: 28)
  route_loss: 1.520508 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.699219 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 861/267978 [10:00<51:45:29,  1.43it/s, v_num=full, train/loss_step=4.140]
Epoch 0:   0%|          | 861/267978 [10:00<51:45:30,  1.43it/s, v_num=full, train/loss_step=5.240]
Epoch 0:   0%|          | 862/267978 [10:01<51:45:01,  1.43it/s, v_num=full, train/loss_step=5.240]
Epoch 0:   0%|          | 862/267978 [10:01<51:45:02,  1.43it/s, v_num=full, train/loss_step=4.830]
Epoch 0:   0%|          | 863/267978 [10:01<51:44:38,  1.43it/s, v_num=full, train/loss_step=4.830]
Epoch 0:   0%|          | 863/267978 [10:01<51:44:38,  1.43it/s, v_num=full, train/loss_step=3.260]
Epoch 0:   0%|          | 864/267978 [10:02<51:44:11,  1.43it/s, v_num=full, train/loss_step=3.260]
Epoch 0:   0%|          | 864/267978 [10:02<51:44:12,  1.43it/s, v_num=full, train/loss_step=3.930]
Epoch 0:   0%|          | 865/267978 [10:03<51:43:44,  1.43it/s, v_num=full, train/loss_step=3.930]
Epoch 0:   0%|          | 865/267978 [10:03<51:43:44,  1.43it/s, v_num=full, train/loss_step=6.280]
Epoch 0:   0%|          | 866/267978 [10:03<51:43:18,  1.43it/s, v_num=full, train/loss_step=6.280]
Epoch 0:   0%|          | 866/267978 [10:03<51:43:18,  1.43it/s, v_num=full, train/loss_step=5.510]
Epoch 0:   0%|          | 867/267978 [10:04<51:42:51,  1.43it/s, v_num=full, train/loss_step=5.510]
Epoch 0:   0%|          | 867/267978 [10:04<51:42:51,  1.43it/s, v_num=full, train/loss_step=3.230]
Epoch 0:   0%|          | 868/267978 [10:04<51:42:23,  1.43it/s, v_num=full, train/loss_step=3.230]
Epoch 0:   0%|          | 868/267978 [10:04<51:42:24,  1.43it/s, v_num=full, train/loss_step=2.500]
Epoch 0:   0%|          | 869/267978 [10:05<51:41:57,  1.44it/s, v_num=full, train/loss_step=2.500]
Epoch 0:   0%|          | 869/267978 [10:05<51:41:57,  1.44it/s, v_num=full, train/loss_step=5.280]
Epoch 0:   0%|          | 870/267978 [10:06<51:41:28,  1.44it/s, v_num=full, train/loss_step=5.280]
Epoch 0:   0%|          | 870/267978 [10:06<51:41:28,  1.44it/s, v_num=full, train/loss_step=5.550]
============================================================
Global Step 870
============================================================

[Losses]
  language_loss: 0.000137 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 1.004883 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.205078 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 871/267978 [10:06<51:40:59,  1.44it/s, v_num=full, train/loss_step=5.550]
Epoch 0:   0%|          | 871/267978 [10:06<51:40:59,  1.44it/s, v_num=full, train/loss_step=4.220]
Epoch 0:   0%|          | 872/267978 [10:07<51:40:31,  1.44it/s, v_num=full, train/loss_step=4.220]
Epoch 0:   0%|          | 872/267978 [10:07<51:40:31,  1.44it/s, v_num=full, train/loss_step=3.760]
Epoch 0:   0%|          | 873/267978 [10:07<51:40:05,  1.44it/s, v_num=full, train/loss_step=3.760]
Epoch 0:   0%|          | 873/267978 [10:07<51:40:05,  1.44it/s, v_num=full, train/loss_step=9.430]
Epoch 0:   0%|          | 874/267978 [10:08<51:39:40,  1.44it/s, v_num=full, train/loss_step=9.430]
Epoch 0:   0%|          | 874/267978 [10:08<51:39:41,  1.44it/s, v_num=full, train/loss_step=4.990]
Epoch 0:   0%|          | 875/267978 [10:09<51:39:14,  1.44it/s, v_num=full, train/loss_step=4.990]
Epoch 0:   0%|          | 875/267978 [10:09<51:39:14,  1.44it/s, v_num=full, train/loss_step=2.310]
Epoch 0:   0%|          | 876/267978 [10:09<51:38:56,  1.44it/s, v_num=full, train/loss_step=2.310]
Epoch 0:   0%|          | 876/267978 [10:09<51:38:56,  1.44it/s, v_num=full, train/loss_step=1.900]
Epoch 0:   0%|          | 877/267978 [10:10<51:38:26,  1.44it/s, v_num=full, train/loss_step=1.900]
Epoch 0:   0%|          | 877/267978 [10:10<51:38:27,  1.44it/s, v_num=full, train/loss_step=2.650]
Epoch 0:   0%|          | 878/267978 [10:11<51:37:59,  1.44it/s, v_num=full, train/loss_step=2.650]
Epoch 0:   0%|          | 878/267978 [10:11<51:38:00,  1.44it/s, v_num=full, train/loss_step=2.090]
Epoch 0:   0%|          | 879/267978 [10:11<51:37:33,  1.44it/s, v_num=full, train/loss_step=2.090]
Epoch 0:   0%|          | 879/267978 [10:11<51:37:34,  1.44it/s, v_num=full, train/loss_step=5.970]
Epoch 0:   0%|          | 880/267978 [10:12<51:37:03,  1.44it/s, v_num=full, train/loss_step=5.970]
Epoch 0:   0%|          | 880/267978 [10:12<51:37:03,  1.44it/s, v_num=full, train/loss_step=3.920]
============================================================
Global Step 880
============================================================

[Losses]
  language_loss: 0.000054 (shape: torch.Size([4, 555]), count: 28)
  route_loss: 0.645996 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.222656 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 881/267978 [10:12<51:36:36,  1.44it/s, v_num=full, train/loss_step=3.920]
Epoch 0:   0%|          | 881/267978 [10:12<51:36:36,  1.44it/s, v_num=full, train/loss_step=3.870]
Epoch 0:   0%|          | 882/267978 [10:13<51:36:07,  1.44it/s, v_num=full, train/loss_step=3.870]
Epoch 0:   0%|          | 882/267978 [10:13<51:36:12,  1.44it/s, v_num=full, train/loss_step=3.370]
Epoch 0:   0%|          | 883/267978 [10:14<51:35:49,  1.44it/s, v_num=full, train/loss_step=3.370]
Epoch 0:   0%|          | 883/267978 [10:14<51:35:49,  1.44it/s, v_num=full, train/loss_step=6.650]
Epoch 0:   0%|          | 884/267978 [10:14<51:35:23,  1.44it/s, v_num=full, train/loss_step=6.650]
Epoch 0:   0%|          | 884/267978 [10:14<51:35:24,  1.44it/s, v_num=full, train/loss_step=6.060]
Epoch 0:   0%|          | 885/267978 [10:15<51:34:57,  1.44it/s, v_num=full, train/loss_step=6.060]
Epoch 0:   0%|          | 885/267978 [10:15<51:34:57,  1.44it/s, v_num=full, train/loss_step=5.950]
Epoch 0:   0%|          | 886/267978 [10:15<51:34:31,  1.44it/s, v_num=full, train/loss_step=5.950]
Epoch 0:   0%|          | 886/267978 [10:15<51:34:32,  1.44it/s, v_num=full, train/loss_step=5.080]
Epoch 0:   0%|          | 887/267978 [10:16<51:34:03,  1.44it/s, v_num=full, train/loss_step=5.080]
Epoch 0:   0%|          | 887/267978 [10:16<51:34:03,  1.44it/s, v_num=full, train/loss_step=4.850]
Epoch 0:   0%|          | 888/267978 [10:17<51:33:38,  1.44it/s, v_num=full, train/loss_step=4.850]
Epoch 0:   0%|          | 888/267978 [10:17<51:33:39,  1.44it/s, v_num=full, train/loss_step=5.390]
Epoch 0:   0%|          | 889/267978 [10:17<51:33:12,  1.44it/s, v_num=full, train/loss_step=5.390]
Epoch 0:   0%|          | 889/267978 [10:17<51:33:13,  1.44it/s, v_num=full, train/loss_step=2.880]
Epoch 0:   0%|          | 890/267978 [10:18<51:32:49,  1.44it/s, v_num=full, train/loss_step=2.880]
Epoch 0:   0%|          | 890/267978 [10:18<51:32:49,  1.44it/s, v_num=full, train/loss_step=3.960]
============================================================
Global Step 890
============================================================

[Losses]
  language_loss: 0.000120 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 0.801758 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.546875 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 891/267978 [10:18<51:32:23,  1.44it/s, v_num=full, train/loss_step=3.960]
Epoch 0:   0%|          | 891/267978 [10:18<51:32:23,  1.44it/s, v_num=full, train/loss_step=5.360]
Epoch 0:   0%|          | 892/267978 [10:19<51:31:57,  1.44it/s, v_num=full, train/loss_step=5.360]
Epoch 0:   0%|          | 892/267978 [10:19<51:31:57,  1.44it/s, v_num=full, train/loss_step=7.980]
Epoch 0:   0%|          | 893/267978 [10:20<51:31:34,  1.44it/s, v_num=full, train/loss_step=7.980]
Epoch 0:   0%|          | 893/267978 [10:20<51:31:34,  1.44it/s, v_num=full, train/loss_step=6.140]
Epoch 0:   0%|          | 894/267978 [10:20<51:31:08,  1.44it/s, v_num=full, train/loss_step=6.140]
Epoch 0:   0%|          | 894/267978 [10:20<51:31:08,  1.44it/s, v_num=full, train/loss_step=5.960]
Epoch 0:   0%|          | 895/267978 [10:21<51:30:39,  1.44it/s, v_num=full, train/loss_step=5.960]
Epoch 0:   0%|          | 895/267978 [10:21<51:30:40,  1.44it/s, v_num=full, train/loss_step=8.950]
Epoch 0:   0%|          | 896/267978 [10:21<51:30:05,  1.44it/s, v_num=full, train/loss_step=8.950]
Epoch 0:   0%|          | 896/267978 [10:21<51:30:05,  1.44it/s, v_num=full, train/loss_step=1.820]
Epoch 0:   0%|          | 897/267978 [10:22<51:29:37,  1.44it/s, v_num=full, train/loss_step=1.820]
Epoch 0:   0%|          | 897/267978 [10:22<51:29:38,  1.44it/s, v_num=full, train/loss_step=6.910]
Epoch 0:   0%|          | 898/267978 [10:23<51:29:11,  1.44it/s, v_num=full, train/loss_step=6.910]
Epoch 0:   0%|          | 898/267978 [10:23<51:29:12,  1.44it/s, v_num=full, train/loss_step=3.800]
Epoch 0:   0%|          | 899/267978 [10:23<51:28:48,  1.44it/s, v_num=full, train/loss_step=3.800]
Epoch 0:   0%|          | 899/267978 [10:23<51:28:48,  1.44it/s, v_num=full, train/loss_step=4.130]
Epoch 0:   0%|          | 900/267978 [10:30<51:57:51,  1.43it/s, v_num=full, train/loss_step=4.130]
Epoch 0:   0%|          | 900/267978 [10:30<51:57:51,  1.43it/s, v_num=full, train/loss_step=4.890]
============================================================
[Input Before LLM] - Global Step 900
============================================================
  Adaptor embeddings shape: torch.Size([4, 584, 896])
  Input embeddings shape: torch.Size([4, 584, 896])
  Attention mask shape: torch.Size([4, 584])
  Input dtype: torch.float16
  Adaptor embeddings range: [-36.2500, 35.5312]
  Input embeddings range: [-36.2500, 35.5312]
  Input embeddings mean: -0.0024, std: 0.7896
  Language inputs shape: torch.Size([4, 554, 896])

============================================================
Global Step 900
============================================================

[Losses]
  language_loss: 0.000219 (shape: torch.Size([4, 553]), count: 28)
  route_loss: 2.853516 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 5.054688 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 901/267978 [10:31<51:57:42,  1.43it/s, v_num=full, train/loss_step=4.890]
Epoch 0:   0%|          | 901/267978 [10:31<51:57:43,  1.43it/s, v_num=full, train/loss_step=7.930]
Epoch 0:   0%|          | 902/267978 [10:31<51:57:16,  1.43it/s, v_num=full, train/loss_step=7.930]
Epoch 0:   0%|          | 902/267978 [10:31<51:57:16,  1.43it/s, v_num=full, train/loss_step=4.990]
Epoch 0:   0%|          | 903/267978 [10:32<51:56:47,  1.43it/s, v_num=full, train/loss_step=4.990]
Epoch 0:   0%|          | 903/267978 [10:32<51:56:47,  1.43it/s, v_num=full, train/loss_step=4.210]
Epoch 0:   0%|          | 904/267978 [10:32<51:56:19,  1.43it/s, v_num=full, train/loss_step=4.210]
Epoch 0:   0%|          | 904/267978 [10:32<51:56:19,  1.43it/s, v_num=full, train/loss_step=8.330]
Epoch 0:   0%|          | 905/267978 [10:33<51:55:54,  1.43it/s, v_num=full, train/loss_step=8.330]
Epoch 0:   0%|          | 905/267978 [10:33<51:55:55,  1.43it/s, v_num=full, train/loss_step=5.960]
Epoch 0:   0%|          | 906/267978 [10:34<51:55:26,  1.43it/s, v_num=full, train/loss_step=5.960]
Epoch 0:   0%|          | 906/267978 [10:34<51:55:26,  1.43it/s, v_num=full, train/loss_step=8.390]
Epoch 0:   0%|          | 907/267978 [10:34<51:54:59,  1.43it/s, v_num=full, train/loss_step=8.390]
Epoch 0:   0%|          | 907/267978 [10:34<51:55:00,  1.43it/s, v_num=full, train/loss_step=3.860]
Epoch 0:   0%|          | 908/267978 [10:35<51:54:34,  1.43it/s, v_num=full, train/loss_step=3.860]
Epoch 0:   0%|          | 908/267978 [10:35<51:54:34,  1.43it/s, v_num=full, train/loss_step=4.420]
Epoch 0:   0%|          | 909/267978 [10:35<51:54:05,  1.43it/s, v_num=full, train/loss_step=4.420]
Epoch 0:   0%|          | 909/267978 [10:35<51:54:05,  1.43it/s, v_num=full, train/loss_step=4.370]
Epoch 0:   0%|          | 910/267978 [10:36<51:53:39,  1.43it/s, v_num=full, train/loss_step=4.370]
Epoch 0:   0%|          | 910/267978 [10:36<51:53:39,  1.43it/s, v_num=full, train/loss_step=8.150]
============================================================
Global Step 910
============================================================

[Losses]
  language_loss: 0.000114 (shape: torch.Size([4, 558]), count: 28)
  route_loss: 1.426758 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 7.621094 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 911/267978 [10:37<51:53:09,  1.43it/s, v_num=full, train/loss_step=8.150]
Epoch 0:   0%|          | 911/267978 [10:37<51:53:09,  1.43it/s, v_num=full, train/loss_step=9.060]
Epoch 0:   0%|          | 912/267978 [10:37<51:52:38,  1.43it/s, v_num=full, train/loss_step=9.060]
Epoch 0:   0%|          | 912/267978 [10:37<51:52:38,  1.43it/s, v_num=full, train/loss_step=5.640]
Epoch 0:   0%|          | 913/267978 [10:38<51:52:12,  1.43it/s, v_num=full, train/loss_step=5.640]
Epoch 0:   0%|          | 913/267978 [10:38<51:52:12,  1.43it/s, v_num=full, train/loss_step=4.000]
Epoch 0:   0%|          | 914/267978 [10:38<51:51:44,  1.43it/s, v_num=full, train/loss_step=4.000]
Epoch 0:   0%|          | 914/267978 [10:38<51:51:44,  1.43it/s, v_num=full, train/loss_step=1.810]
Epoch 0:   0%|          | 915/267978 [10:39<51:51:15,  1.43it/s, v_num=full, train/loss_step=1.810]
Epoch 0:   0%|          | 915/267978 [10:39<51:51:15,  1.43it/s, v_num=full, train/loss_step=3.400]
Epoch 0:   0%|          | 916/267978 [10:40<51:50:50,  1.43it/s, v_num=full, train/loss_step=3.400]
Epoch 0:   0%|          | 916/267978 [10:40<51:50:50,  1.43it/s, v_num=full, train/loss_step=4.030]
Epoch 0:   0%|          | 917/267978 [10:40<51:50:20,  1.43it/s, v_num=full, train/loss_step=4.030]
Epoch 0:   0%|          | 917/267978 [10:40<51:50:21,  1.43it/s, v_num=full, train/loss_step=4.930]
Epoch 0:   0%|          | 918/267978 [10:41<51:49:52,  1.43it/s, v_num=full, train/loss_step=4.930]
Epoch 0:   0%|          | 918/267978 [10:41<51:49:52,  1.43it/s, v_num=full, train/loss_step=3.000]
Epoch 0:   0%|          | 919/267978 [10:42<51:49:25,  1.43it/s, v_num=full, train/loss_step=3.000]
Epoch 0:   0%|          | 919/267978 [10:42<51:49:25,  1.43it/s, v_num=full, train/loss_step=2.760]
Epoch 0:   0%|          | 920/267978 [10:42<51:49:01,  1.43it/s, v_num=full, train/loss_step=2.760]
Epoch 0:   0%|          | 920/267978 [10:42<51:49:01,  1.43it/s, v_num=full, train/loss_step=2.860]
============================================================
Global Step 920
============================================================

[Losses]
  language_loss: 0.000128 (shape: torch.Size([4, 553]), count: 28)
  route_loss: 0.594238 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 1.576172 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 921/267978 [10:43<51:48:33,  1.43it/s, v_num=full, train/loss_step=2.860]
Epoch 0:   0%|          | 921/267978 [10:43<51:48:34,  1.43it/s, v_num=full, train/loss_step=2.180]
Epoch 0:   0%|          | 922/267978 [10:43<51:48:10,  1.43it/s, v_num=full, train/loss_step=2.180]
Epoch 0:   0%|          | 922/267978 [10:43<51:48:10,  1.43it/s, v_num=full, train/loss_step=4.140]
Epoch 0:   0%|          | 923/267978 [10:44<51:47:42,  1.43it/s, v_num=full, train/loss_step=4.140]
Epoch 0:   0%|          | 923/267978 [10:44<51:47:42,  1.43it/s, v_num=full, train/loss_step=3.320]
Epoch 0:   0%|          | 924/267978 [10:45<51:47:17,  1.43it/s, v_num=full, train/loss_step=3.320]
Epoch 0:   0%|          | 924/267978 [10:45<51:47:17,  1.43it/s, v_num=full, train/loss_step=5.940]
Epoch 0:   0%|          | 925/267978 [10:45<51:46:50,  1.43it/s, v_num=full, train/loss_step=5.940]
Epoch 0:   0%|          | 925/267978 [10:45<51:46:50,  1.43it/s, v_num=full, train/loss_step=5.780]
Epoch 0:   0%|          | 926/267978 [10:46<51:46:22,  1.43it/s, v_num=full, train/loss_step=5.780]
Epoch 0:   0%|          | 926/267978 [10:46<51:46:23,  1.43it/s, v_num=full, train/loss_step=5.050]
Epoch 0:   0%|          | 927/267978 [10:46<51:45:58,  1.43it/s, v_num=full, train/loss_step=5.050]
Epoch 0:   0%|          | 927/267978 [10:46<51:45:58,  1.43it/s, v_num=full, train/loss_step=3.140]
Epoch 0:   0%|          | 928/267978 [10:47<51:45:29,  1.43it/s, v_num=full, train/loss_step=3.140]
Epoch 0:   0%|          | 928/267978 [10:47<51:45:29,  1.43it/s, v_num=full, train/loss_step=4.450]
Epoch 0:   0%|          | 929/267978 [10:48<51:45:01,  1.43it/s, v_num=full, train/loss_step=4.450]
Epoch 0:   0%|          | 929/267978 [10:48<51:45:02,  1.43it/s, v_num=full, train/loss_step=10.20]
Epoch 0:   0%|          | 930/267978 [10:48<51:44:35,  1.43it/s, v_num=full, train/loss_step=10.20]
Epoch 0:   0%|          | 930/267978 [10:48<51:44:36,  1.43it/s, v_num=full, train/loss_step=2.890]
============================================================
Global Step 930
============================================================

[Losses]
  language_loss: 0.000095 (shape: torch.Size([4, 554]), count: 28)
  route_loss: 0.791016 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.179688 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 931/267978 [10:49<51:44:09,  1.43it/s, v_num=full, train/loss_step=2.890]
Epoch 0:   0%|          | 931/267978 [10:49<51:44:09,  1.43it/s, v_num=full, train/loss_step=4.980]
Epoch 0:   0%|          | 932/267978 [10:49<51:43:42,  1.43it/s, v_num=full, train/loss_step=4.980]
Epoch 0:   0%|          | 932/267978 [10:49<51:43:43,  1.43it/s, v_num=full, train/loss_step=6.350]
Epoch 0:   0%|          | 933/267978 [10:50<51:43:18,  1.43it/s, v_num=full, train/loss_step=6.350]
Epoch 0:   0%|          | 933/267978 [10:50<51:43:19,  1.43it/s, v_num=full, train/loss_step=2.970]
Epoch 0:   0%|          | 934/267978 [10:51<51:42:50,  1.43it/s, v_num=full, train/loss_step=2.970]
Epoch 0:   0%|          | 934/267978 [10:51<51:42:50,  1.43it/s, v_num=full, train/loss_step=6.020]
Epoch 0:   0%|          | 935/267978 [10:51<51:42:26,  1.43it/s, v_num=full, train/loss_step=6.020]
Epoch 0:   0%|          | 935/267978 [10:51<51:42:26,  1.43it/s, v_num=full, train/loss_step=6.430]
Epoch 0:   0%|          | 936/267978 [10:52<51:42:02,  1.43it/s, v_num=full, train/loss_step=6.430]
Epoch 0:   0%|          | 936/267978 [10:52<51:42:02,  1.43it/s, v_num=full, train/loss_step=7.370]
Epoch 0:   0%|          | 937/267978 [10:52<51:41:31,  1.43it/s, v_num=full, train/loss_step=7.370]
Epoch 0:   0%|          | 937/267978 [10:52<51:41:31,  1.43it/s, v_num=full, train/loss_step=4.750]
Epoch 0:   0%|          | 938/267978 [10:53<51:41:04,  1.44it/s, v_num=full, train/loss_step=4.750]
Epoch 0:   0%|          | 938/267978 [10:53<51:41:05,  1.44it/s, v_num=full, train/loss_step=3.520]
Epoch 0:   0%|          | 939/267978 [10:54<51:40:37,  1.44it/s, v_num=full, train/loss_step=3.520]
Epoch 0:   0%|          | 939/267978 [10:54<51:40:37,  1.44it/s, v_num=full, train/loss_step=4.890]
Epoch 0:   0%|          | 940/267978 [10:54<51:40:10,  1.44it/s, v_num=full, train/loss_step=4.890]
Epoch 0:   0%|          | 940/267978 [10:54<51:40:10,  1.44it/s, v_num=full, train/loss_step=2.820]
============================================================
Global Step 940
============================================================

[Losses]
  language_loss: 0.000129 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 0.696289 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.279297 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 941/267978 [10:55<51:39:46,  1.44it/s, v_num=full, train/loss_step=2.820]
Epoch 0:   0%|          | 941/267978 [10:55<51:39:46,  1.44it/s, v_num=full, train/loss_step=3.980]
Epoch 0:   0%|          | 942/267978 [10:55<51:39:20,  1.44it/s, v_num=full, train/loss_step=3.980]
Epoch 0:   0%|          | 942/267978 [10:55<51:39:21,  1.44it/s, v_num=full, train/loss_step=6.880]
Epoch 0:   0%|          | 943/267978 [10:56<51:38:54,  1.44it/s, v_num=full, train/loss_step=6.880]
Epoch 0:   0%|          | 943/267978 [10:56<51:38:54,  1.44it/s, v_num=full, train/loss_step=4.180]
Epoch 0:   0%|          | 944/267978 [10:57<51:38:27,  1.44it/s, v_num=full, train/loss_step=4.180]
Epoch 0:   0%|          | 944/267978 [10:57<51:38:28,  1.44it/s, v_num=full, train/loss_step=4.100]
Epoch 0:   0%|          | 945/267978 [10:57<51:38:02,  1.44it/s, v_num=full, train/loss_step=4.100]
Epoch 0:   0%|          | 945/267978 [10:57<51:38:02,  1.44it/s, v_num=full, train/loss_step=6.500]
Epoch 0:   0%|          | 946/267978 [10:58<51:37:35,  1.44it/s, v_num=full, train/loss_step=6.500]
Epoch 0:   0%|          | 946/267978 [10:58<51:37:36,  1.44it/s, v_num=full, train/loss_step=2.100]
Epoch 0:   0%|          | 947/267978 [10:59<51:37:11,  1.44it/s, v_num=full, train/loss_step=2.100]
Epoch 0:   0%|          | 947/267978 [10:59<51:37:12,  1.44it/s, v_num=full, train/loss_step=2.040]
Epoch 0:   0%|          | 948/267978 [10:59<51:36:46,  1.44it/s, v_num=full, train/loss_step=2.040]
Epoch 0:   0%|          | 948/267978 [10:59<51:36:46,  1.44it/s, v_num=full, train/loss_step=8.680]
Epoch 0:   0%|          | 949/267978 [11:00<51:36:23,  1.44it/s, v_num=full, train/loss_step=8.680]
Epoch 0:   0%|          | 949/267978 [11:00<51:36:23,  1.44it/s, v_num=full, train/loss_step=8.250]
Epoch 0:   0%|          | 950/267978 [11:00<51:35:59,  1.44it/s, v_num=full, train/loss_step=8.250]
Epoch 0:   0%|          | 950/267978 [11:00<51:36:00,  1.44it/s, v_num=full, train/loss_step=6.170]
============================================================
Global Step 950
============================================================

[Losses]
  language_loss: 0.000103 (shape: torch.Size([4, 557]), count: 28)
  route_loss: 0.963379 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 3.095703 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 951/267978 [11:01<51:35:37,  1.44it/s, v_num=full, train/loss_step=6.170]
Epoch 0:   0%|          | 951/267978 [11:01<51:35:37,  1.44it/s, v_num=full, train/loss_step=4.070]
Epoch 0:   0%|          | 952/267978 [11:02<51:35:12,  1.44it/s, v_num=full, train/loss_step=4.070]
Epoch 0:   0%|          | 952/267978 [11:02<51:35:12,  1.44it/s, v_num=full, train/loss_step=3.960]
Epoch 0:   0%|          | 953/267978 [11:02<51:34:48,  1.44it/s, v_num=full, train/loss_step=3.960]
Epoch 0:   0%|          | 953/267978 [11:02<51:34:49,  1.44it/s, v_num=full, train/loss_step=6.040]
Epoch 0:   0%|          | 954/267978 [11:03<51:34:25,  1.44it/s, v_num=full, train/loss_step=6.040]
Epoch 0:   0%|          | 954/267978 [11:03<51:34:25,  1.44it/s, v_num=full, train/loss_step=6.460]
Epoch 0:   0%|          | 955/267978 [11:03<51:34:01,  1.44it/s, v_num=full, train/loss_step=6.460]
Epoch 0:   0%|          | 955/267978 [11:03<51:34:01,  1.44it/s, v_num=full, train/loss_step=8.120]
Epoch 0:   0%|          | 956/267978 [11:04<51:33:34,  1.44it/s, v_num=full, train/loss_step=8.120]
Epoch 0:   0%|          | 956/267978 [11:04<51:33:34,  1.44it/s, v_num=full, train/loss_step=2.150]
Epoch 0:   0%|          | 957/267978 [11:05<51:33:11,  1.44it/s, v_num=full, train/loss_step=2.150]
Epoch 0:   0%|          | 957/267978 [11:05<51:33:11,  1.44it/s, v_num=full, train/loss_step=6.490]
Epoch 0:   0%|          | 958/267978 [11:05<51:32:45,  1.44it/s, v_num=full, train/loss_step=6.490]
Epoch 0:   0%|          | 958/267978 [11:05<51:32:46,  1.44it/s, v_num=full, train/loss_step=5.940]
Epoch 0:   0%|          | 959/267978 [11:06<51:32:20,  1.44it/s, v_num=full, train/loss_step=5.940]
Epoch 0:   0%|          | 959/267978 [11:06<51:32:21,  1.44it/s, v_num=full, train/loss_step=3.300]
Epoch 0:   0%|          | 960/267978 [11:06<51:31:55,  1.44it/s, v_num=full, train/loss_step=3.300]
Epoch 0:   0%|          | 960/267978 [11:06<51:31:56,  1.44it/s, v_num=full, train/loss_step=3.650]
============================================================
Global Step 960
============================================================

[Losses]
  language_loss: 0.000083 (shape: torch.Size([4, 555]), count: 28)
  route_loss: 0.296875 (shape: torch.Size([4, 20]), count: 80)
  speed_wps_loss: 4.593750 (shape: torch.Size([4, 10]), count: 40)

Epoch 0:   0%|          | 961/267978 [11:07<51:31:29,  1.44it/s, v_num=full, train/loss_step=3.650]
Epoch 0:   0%|          | 961/267978 [11:07<51:31:29,  1.44it/s, v_num=full, train/loss_step=4.900]
Epoch 0:   0%|          | 962/267978 [11:08<51:31:03,  1.44it/s, v_num=full, train/loss_step=4.900]
Epoch 0:   0%|          | 962/267978 [11:08<51:31:03,  1.44it/s, v_num=full, train/loss_step=2.570]
Epoch 0:   0%|          | 963/267978 [11:08<51:30:35,  1.44it/s, v_num=full, train/loss_step=2.570]
Epoch 0:   0%|          | 963/267978 [11:08<51:30:36,  1.44it/s, v_num=full, train/loss_step=2.770]
Epoch 0:   0%|          | 964/267978 [11:09<51:30:09,  1.44it/s, v_num=full, train/loss_step=2.770]
Epoch 0:   0%|          | 964/267978 [11:09<51:30:09,  1.44it/s, v_num=full, train/loss_step=3.030]
Epoch 0:   0%|          | 965/267978 [11:09<51:29:42,  1.44it/s, v_num=full, train/loss_step=3.030]
Epoch 0:   0%|          | 965/267978 [11:09<51:29:43,  1.44it/s, v_num=full, train/loss_step=3.120]
Epoch 0:   0%|          | 966/267978 [11:10<51:29:10,  1.44it/s, v_num=full, train/loss_step=3.120]
Epoch 0:   0%|          | 966/267978 [11:10<51:29:10,  1.44it/s, v_num=full, train/loss_step=4.040]
Epoch 0:   0%|          | 967/267978 [11:11<51:28:45,  1.44it/s, v_num=full, train/loss_step=4.040]
Epoch 0:   0%|          | 967/267978 [11:11<51:28:45,  1.44it/s, v_num=full, train/loss_step=5.300]
Epoch 0:   0%|          | 968/267978 [11:11<51:28:20,  1.44it/s, v_num=full, train/loss_step=5.300]
Epoch 0:   0%|          | 968/267978 [11:11<51:28:21,  1.44it/s, v_num=full, train/loss_step=9.710]